VCG/VIBE 2026 AI統合運用マスタードキュメント（最新版 / 2026-01-09）
目的：個人が50+フォルダ級の大規模開発を、迷いなく・事故なく・トップクラス精度で完走するための「運用SSOT（Single Source of Truth）」を1本化する。
狙いは「自分が書く」ではなく AIリソース（調査・設計・実装・検証・修理・証跡化）を運用設計で統率すること。
________________


0. 前提（課金AI・必須ツール・禁止事項）
0.1 いま課金しているAI（固定）
* Claude Code Plus（Anthropic）
* ChatGPT Plus（OpenAI）
* Google One Pro（= Google AI Pro相当の特典を含む想定）
* Z.ai Lite（GLM Coding Plan）
0.2 使用ツール（必ず記載：本運用の“身体”）
* IDEハブ：Google Antigravity（あなたの主IDE・中心）
※Google AI Proには「Google Antigravity（agentic development platform）の高いレート制限」等が含まれる旨が明記されています。 (Google One)
* 実装：Claude Code（CLI/Agent）（主戦力）
※Claude Codeは「低レベルで柔軟・スクリプト可能なエージェント型CLI」としてベストプラクティスが公開されています。 (Anthropic)
* 監査/合否判定：ChatGPT Plus（GPT）（Spec凍結・監査・最終判定）
* 調査・外部根拠：Gemini（Google One Pro）（Deep Search/NotebookLM等を含む想定） (Google One)
* 安い手足：Z.ai（GLM）（整形・要約・ログ処理・前処理・Context Pack生成）
* OpenAI衛星：Codex（Codex CLI / Codex Web等）
※Codex CLIは端末上でリポジトリを読み・編集し・コマンド実行でき、ChatGPT Plusに含まれると明記。 (OpenAI Developers)
* Google衛星：Jules / Gemini Code Assist / Gemini CLI（必要時）
※Google AI Proの含有として「Jules（タスク/並列上限増）」「Gemini Code Assist & Gemini CLI（リクエスト上限増）」が明記。 (Google One)
* MCP（Model Context Protocol）：AIの“外部ツール接続”標準
※MCPはLLMアプリと外部データ/ツールを繋ぐオープンプロトコルとして仕様が公開。 (Model Context Protocol)
* 自動化/CI：GitHub Actions（Verifyの機械判定）
* 実行環境：Git / Docker（可能なら）
* 検索：ripgrep（rg）
* （任意）ローカルLLM：Ollama / LM Studio / vLLM（秘匿・高速・コスト削減）
* （任意）静的解析：Semgrep / Bandit 等
0.3 禁止事項（事故ゼロのための非交渉ルール）
   * Cursorは使わない（方針固定）
   * 全域リライト／破壊操作／勝手な自動実行は禁止（例外は後述の「承認つき例外ルート」のみ）
   * 「気合い」禁止：権限・環境で物理的に不可能化する（Allowlist/ReadOnly/サンドボックス）
________________


1. コア思想（“精度はモデルではなく運用で作る”）
1.1 精度の定義
ここでいう精度は「それっぽいコード」ではなく、次を同時達成すること：
   * 仕様の解釈が正しい
   * Verifyで機械的に合否が出る
   * 修理が最小差分で収束する
   * 証跡（なぜ/どう検証したか）が残り、再利用できる
1.2 運用の中心は「SSOT→Verify→Evidence→Immutable Release」
   * SSOT（唯一の真実）に集約し、Verifyを通った根拠をEvidenceとして残し、Releaseを不変化する、という流れを毎チケットで再現する。
________________


2. Core4（役割固定）と“出力契約”（迷いを消す）
2.1 Core4の固定役割（原則）
   * Claude（実装・修理）
   * GPT（設計凍結・監査・文章化・最終判定）
   * Gemini（調査・周辺知識・Google連携・エージェント群）
   * GLM/Z.ai（安い手足：整形・要約・抽出・前処理）
2.2 “出力契約”＝AI同士が噛み合う最小フォーマット
この運用が強い理由は、AIに「自由作文」させず、必ずファイルで引き継ぐ点にある。以降はすべて「ファイル納品」。
引き継ぎファイル（標準セット）
   * TRIAGE.md（調査結果＋根拠リンク＋論点）
   * RISK_REGISTER.md（最大5件：脅威/リスク/対策/残余）
   * SPEC.md（PRD/DESIGN/ACCEPTANCE統合の凍結仕様）
   * CONTEXT_PACK.md（最小で強い入力束：FILELIST/DIFF/制約/過去証跡）
   * PATCHSET.diff（最小差分）
   * VERIFY_REPORT.md（CI結果＋合否＋再発防止）
   * EVIDENCE.md（何を/なぜ/どう検証/学び）
   * RELEASE_NOTE.md（不変リリース説明）
________________


3. VIBEKANBAN（チケット駆動の唯一の運用台帳）
3.1 ライフサイクル（固定）
INBOX→TRIAGE→SPEC→BUILD→VERIFY→REPAIR→EVIDENCE→RELEASE
3.2 各ステージの「必須アウトプット」（これだけ見れば迷いゼロ）
INBOX（受け皿）
   * 目的：アイデア/要求/バグ/改善を未加工で入れる
   * 出力：TICKET.md（一行要約・背景・期待）
TRIAGE（調査と論点の確定：Gemini主担当）
   * 目的：仕様にする前に、根拠を揃えて“決める”
   * 必須：
   * 参照URL（公式/一次情報優先）
   * 既存コード影響範囲
   * 代替案（最低2案）
   * Risk Register（最大5件）
SPEC（凍結仕様：GPT主担当）
   * 目的：曖昧語を排除し、Verifyで合否判定できる形に落とす
   * SPEC.mdに必須（あなたの既存テンプレを強化して固定）：
目的/非目的/制約/受入基準/Verify手順/リスク/ロールバック
   * ルール：SPECは「意図を凍結」。実装方法は最小差分優先。
BUILD（実装：Claude Code主担当）
      * 入力：SPEC.md + 最小関連ファイル + 制約
      * 出力：最小パッチ差分 / 影響範囲 / 追加・更新テスト / ロールバック
      * 禁止：全域リライト、破壊操作、無承認の自動実行
VERIFY（機械判定：CI + GPT）
      * 目的：“良さそう”を排除し、機械で合否
      * あなたの強化案（採用）：
      * Fast Verify（1〜3分）：lint/test/sast
      * Full Verify：CI全部＋SBOM＋再現実行
      * GPTの仕事：ログを読み、SPEC受入基準に照らして合否＋最短修理方針＋再発防止
REPAIR（収束：Claude Code）
      * 入力：SPEC + 失敗ログ要約 + 現在の差分
      * 目的：最小修正でGreenへ→再Verifyで証明
EVIDENCE（証跡化：GPT + Z.ai）
      * 目的：次回から“考えずに再利用”できる状態にする
      * 必須4点：何を変えたか／なぜ変えたか／どう検証したか／学び・再発防止
RELEASE（不変化）
      * 目的：後で壊れない“完成物”として封印（immutable）
________________


4. ガードレール（事故を仕組みで潰す：気合い禁止）
4.1 物理的強制（必須3点）
      1. Permission Allowlistを機械化
Claude Codeには危険な運用（YOLO等）が存在するため、運用側で許可設計を固定する。
      2. 作業領域をコピー/worktreeに限定し、VAULT/ と RELEASE/ をOS/FS権限でReadOnly化
      3. Antigravity前提の追加ガード：エディタ/ターミナル/ブラウザ横断で計画・実行・検証ができる設計＝権限とサンドボックスが必須 (Google One)
4.2 例外ルート（“どうしても破壊操作が必要”なとき）
         * 例外は「ルール破り」ではなく「別ルート」
         * 必須条件：
         * SPEC.mdにロールバック手順が明記されている
         * サンドボックス（Docker/複製worktree）でのみ実行
         * 実行は承認つき（人間がon-the-loop）
________________


5. コンテキスト工学（入力で勝つ：個人のボトルネックを消す）
5.1 “最小で強い”を自動化する（人力は破綻する）
         * 現状思想（最小主義・参照固定・ログ要約→修理）は正しいが、「最小」が人力だと個人ボトルネック化する
         * 採用ルール：毎チケット、必ず CONTEXT_PACK.md を生成してからBUILDに入る
         * 生成担当は GLM/Z.ai固定（安く速く）
         * Claudeは Packだけ読んで実装へ
5.2 CONTEXT_PACKの標準中身（固定）
         * SPEC.md（凍結仕様）
         * FILELIST.md（変更対象と読むべきファイルの最小集合）
         * DIFF.md（現状差分/予定差分）
         * FAIL_SUMMARY.md（失敗ログ要約：VerifyがRedのとき）
         * EVIDENCE_LINKS.md（過去の類似チケット/ADR/VERIFY_REPORT）
________________


6. RAG/ナレッジ基盤（“重いRAG”でなく、運用に溶けるRAG）
6.1 原則：RAGは「SSOT/VAULTだけ」を見せる
         * 実用案：SSOT-Only MCP RAG Server（SSOT/VAULTのみ索引、_TRASH無視）
         * 理由：運用思想（真実の固定・事故ゼロ）と完全一致
6.2 “コンテキスト事前生成”が個人運用に最適
         * リアルタイムRAGは運用コストが重い。代わりに、チケット開始時に Z.aiでContext Packを自動生成し、そこだけ読ませる。
6.3 “失敗RAG”（Repairの収束速度を上げる）
         * VAULT/VERIFY/ や VAULT/TRACE/ を別索引にして、Verify失敗時に「過去に同じエラーがあったか？」を引く
6.4 “スナップショットRAG”（リリース単位で更新）
         * 索引更新は RELEASE時のみ（中途半端なSSOTを見て事故るのを防ぐ）
6.5 “rg検索×AI要約”のハイブリッド（軽くて強い）
         * rg -t md -t jsonl "keyword" SSOT/ VAULT/ の結果をそのままContextとして渡す（ベクタのドリフト無し、決定的）
________________


7. VERIFY（品質を“機能”から“運用＋供給網＋安全”へ拡張）
7.1 VERIFYは「二層」＋「仕様準拠判定」
         * Fast Verify / Full Verifyの二層化（あなたの強化案を正式採用）
         * GPTはテストログをSPEC受入基準に照合して合否判定する
7.2 VERIFYに統合すべき追加観点（2026標準）
         * SAST/依存脆弱性/シークレット漏洩（Semgrep/Bandit等）
         * SBOM（Full Verify側）
         * 再現実行（同じ手順で再現する：証跡の核）
________________


8. コスト管理（“感覚”を排除して指標で回す）
8.1 Cost Ledger（チケット単位で残す）
         * 時間/トークン/失敗回数を残す（改善は指標で回す）
         * 目標は「重い推論は本当に必要な局面だけ」
8.2 “安い手足”の固定運用
         * Z.ai/ローカルLLM：整形・要約・抽出・Context Pack生成（高頻度）
         * GPT/Claude：合否判定・設計矛盾検出・最重要の実装判断だけ（低頻度）
________________


9. 並列（コンカレンシー）前提の運用（直感的＝同時進行が勝手に噛み合う）
あなたの現行は「線形パイプライン」が強い一方、2026の実務では 同時並行の監査と調査 が精度を押し上げる、という指摘が入っています。
9.1 並列の基本形（“同時に回すが、書き込みは一箇所”）
         * Claude：実装（Patchを作る）
         * GPT：同時に監査（仕様矛盾・危険変更・抜けテスト）
         * Gemini：同時に根拠確認（公式仕様・API・バージョン差）
         * Z.ai：同時にPack整形（FILELIST/DIFF/FAIL_SUMMARY）
重要：書き込み先は常に「チケットの作業領域」だけ。SSOT/VAULT/RELEASEはReadOnly。
________________


10. OpenAI/Anthropic/Googleの“標準化ファイル”を運用に取り込む
10.1 Codexの AGENTS.md（OpenAI）
         * Codexは ~/.codex/AGENTS.md（全体規約）と、リポジトリ直下 AGENTS.md（プロジェクト規約）を読み込ませて作業合意を永続化できる。 (OpenAI Developers)
→ VCG/VIBEではこれを「運用ルールの二重化（グローバル＋リポジトリ）」として採用。
10.2 Claude Code側の “プロジェクト規約ファイル”運用
            * Claude Codeは低レベルで柔軟＝プロジェクト規約がないと暴れる
→ リポジトリ直下に CLAUDE.md（または同等） を置き、禁止事項・実行許可・出力契約（PATCHSET/VERIFY/EVIDENCE）を固定する（ベストプラクティス思想に一致）。 (Anthropic)
※あなたの改善案でも「Allowlist固定」が最重要として挙げられている
10.3 MCP（共通の神経系）
               * MCPは「LLMアプリと外部ツール/データを繋ぐ標準」 (Model Context Protocol)
→ VCG/VIBEでは「SSOT/VAULTだけ読めるMCPサーバ」を中核にする（事故ゼロと相性が良い）
________________


11. テンプレ（これだけで毎回同じ精度が出る：コピペ運用）
方針：テンプレは“長くていい”。個人運用は「考える部分」を減らした方が強い。
11.1 SPEC.md（凍結仕様）
# SPEC: <チケット名>


## 目的
## 非目的（やらないこと）
## 制約（技術/互換/性能/セキュリティ）
## 受入基準（Verifyで合否が出る形）
- [ ] ...
- [ ] ...


## Verify手順（コマンド/CI/期待結果）
## リスク（最大5件）と対策
## ロールバック手順


（必須要件として明記済み）
11.2 BUILD.md（Claudeへの入力プロトコル）
入力:
- SPEC.md
- CONTEXT_PACK.md


出力:
- 最小パッチ差分（理由つき）
- 影響範囲
- 追加/更新テスト
- ロールバック手順（更新が必要なら追記）


禁止:
- 全域リライト
- 破壊操作
- 無承認の自動実行


11.3 VERIFY_PROMPT.md（GPT判定）
このテスト結果とログを読み、SPEC.mdの受入基準に照らして合否判定して。
失敗がある場合は：
- 最短の修理方針
- 再発防止の観点
を箇条書きで出して。


11.4 EVIDENCE.md（証跡）
# EVIDENCE: <チケット名>


## 何を変えたか
## なぜ変えたか
## どう検証したか（Verify結果へのリンク）
## 学び・再発防止


11.5 CONTEXT_PACK.md（Z.ai生成：固定フォーマット）
# CONTEXT_PACK: <チケット名>


## SPEC要約（1画面）
## FILELIST（読む/変える最小集合）
## DIFF（現状差分 or 予定差分）
## 制約（絶対に破るな）
## 既知の落とし穴（過去VERIFY/障害）
## FAIL_SUMMARY（Verify Redのときだけ）


（自動生成の必須化：採用）
________________


12. “最高峰”にするための追加強化（ただし運用思想は維持）
ここからは「あなたの文書群で追加候補として挙がっているが、今の運用に自然に溶ける形」に再設計して組み込む。
12.1 Conductor（オーケストレーション：概念は採用、名前は自由）
                  * 目的：チケットの状態から「次に誰が何をするか」を自動提案し、並列を破綻させない
                  * 追加候補として Conductor / Plan-and-Execute / 自己修復 / 観測が列挙されている
                  * ただし本書では「ランク」ではなく、常に同じ規約（出力契約）で動く運用部品として扱う
12.2 自己修復ループ（REPAIRの自動化率を上げる）
                  * “VerifyがRed→人間待ち”を減らす
                  * 追加候補として自己修復ループが明記
                  * 実装方針（運用としての要点）：
                  * Redのたびに FAIL_SUMMARY を生成（Z.ai）
                  * 修理案を2案出す（Claude）
                  * GPTが「最短でGreen」案を選ぶ（監査）
                  * ただし実行はサンドボックス＋承認つき
12.3 観測可能性（Observability）
                  * “ログがある”だけでは弱い → チケット単位で追える必要がある
                  * 追加候補としてダッシュボード/アラート/週次レポートが列挙
                  * 最小セット：
                  * RUNLOG.jsonl（操作・コマンド・結果）
                  * VERIFY_REPORT.md
                  * COST_LEDGER.md（時間/トークン/失敗回数）
________________


13. 最終チェックリスト（毎回これだけ守れば“トップクラス精度”に寄る）
13.1 チケット開始前
                  * SSOT/VAULT/RELEASEはReadOnlyになっている
                  * 作業はコピー/worktreeで行う
                  * Allowlistが有効（危険コマンドは通らない）
13.2 SPEC凍結時
                  * 受入基準がVerifyで判定できる（曖昧語なし）
                  * ロールバック手順がある
                  * Risk Register（最大5件）
13.3 BUILD時
                  * CONTEXT_PACKのみで実装できる状態になっている
                  * 最小差分（全域リライトしない）
13.4 VERIFY時
                  * Fast Verify → Full Verifyの順で、合否は機械判定
                  * GPTがSPEC受入基準で合否判定
13.5 RELEASE時
                  * EVIDENCEが4点セットで残っている
                  * RELEASEは不変（後から直さない）
________________


14. 実装できていない（または未導入になりやすい）項目 ※最後に明記
以下は、あなたの追加資料で「追加候補」として明示されているか、強化案として挙がっている一方で、現状の運用から見て“未導入/未自動化”になりやすい項目です（導入済みならスキップ）：
                  * Conductor Agent（自動オーケストレーション）
                  * 自己修復ループの自動化（REPAIRの自走率アップ）
                  * 段階検証の完全組込み（Fast/Fullはあるが、より細かなゲート分割）
                  * 類似バグRAG（Failure RAG）の実装・運用定着
                  * 観測可能性（ダッシュボード/アラート/週次レポート自動生成）
                  * Cost Ledgerの自動集計（チケット単位の指標運用）
                  * MCPで“SSOT/VAULT限定”アクセスを強制するローカルサーバ（方針は固いが実装は別途） (Model Context Protocol)
                  * CodexのAGENTS.md（グローバル＋repo規約）を運用規約として統合 (OpenAI Developers)
________________


必要なら、この最新版ドキュメントを「あなたの実フォルダ構成（SSOT/VAULT/RELEASE/WORKの実パス、現在のCI、既存スクリプト）」に合わせて**“コピペして即運用できる”形に正規化（ファイル名・テンプレ一式の統一、禁止コマンドAllowlist案、AGENTS.md/CLAUDE.md雛形まで）**して出します。