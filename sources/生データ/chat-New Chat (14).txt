### USER
５０フォルダ以上の大規模な開発をバイブコーディングでやりたい時、精度を最大に上げるワークフローを教えてほしい。

### ASSISTANT
<details type="reasoning" done="true" duration="5" view="" last_tool_call_name="">
> ユーザーは50以上のフォルダを持つ大規模開発において、バイブコーディングの精度を最大化するためのワークフローを求めている。これには、大規模なコードベースを管理し、コード生成を正確に行うための体系的なアプローチが必要だ。プロジェクトの構造を理解し、依存関係を管理し、コード生成のためにコンテキストを適切に提供することが重要となる。明確なステップ、コンテキスト管理、ツールの活用が、ワークフローの鍵となるだろう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"A Comprehensive Guide to Vibe Coding Tools","url":"https://medium.com/madhukarkumar/a-comprehensive-guide-to-vibe-coding-tools-2bd35e2d7b4f","text":"In this article we saw the different categories of AI tools that can be used for “vibe coding” and each has its pros and cons.","index":1,"favicon":"","host_name":"medium.com"},{"title":"Increase Vibe Coding Accuracy with the Plan-Implement-Run","url":"https://raffertyuy.com/raztype/vibe-coding-plan-implement-run","text":"Discover how the Plan-Implement-Run Pattern can transform chaotic vibe coding into a structured, predictable, and highly effective workflow.","index":2,"favicon":"","host_name":"raffertyuy.com"},{"title":"I vibe coded a 200000-line product. I'd like to share some","url":"https://www.reddit.com/r/vibecoding/comments/1ojv43w/i_vibe_coded_a_200000line_product_id_like_to","text":"I made a Japanese learning product with 200,000 lines of code, over 99.5% of which written by AI. I have a script to roughly calculate so I ...","index":3,"favicon":"","host_name":"www.reddit.com"},{"title":"A Structured Workflow for \"Vibe Coding\" Full-Stack Apps","url":"https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l","text":"Below, you'll find my honest review and the workflow that I found that really worked while using Cursor with Google's Gemini 2.5 Pro, and a solid UI template.","index":4,"favicon":"","host_name":"dev.to"},{"title":"5 Vibe Coding Best Practices to Implement in Your Workflow","url":"https://zencoder.ai/blog/vibe-coding-best-practices","text":"This article explores five key vibe coding best practices that every software engineer should incorporate into their workflow.","index":5,"favicon":"","host_name":"zencoder.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"In this article, I'll share how I plan, code, and collaborate with AI going into 2026, distilling tips and best practices from my experience and ...","index":6,"favicon":"","host_name":"addyosmani.com"},{"title":"What are tips for vibe-coding workflow?","url":"https://www.facebook.com/groups/vibecodinglife/posts/1817494222172440","text":"Most people think coding with AI is confusing But this guy dropped 12 vibe coding rules that changed everything Here's how you can replicate too ...","index":7,"favicon":"","host_name":"www.facebook.com"},{"title":"Vibe Planning: Get the Most Out of Claude Code : r/ClaudeAI","url":"https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code","text":"Clean context – Separating planning from coding keeps Claude Code focused on executing the task with only the relevant files in context.","index":8,"favicon":"","host_name":"www.reddit.com"},{"title":"Vibe Coding: Complete Guide to AI-Assisted Software","url":"https://almcorp.com/blog/vibe-coding-complete-guide","text":"Its Composer feature enables multi-file editing, where you can describe changes and watch Cursor modify code across your entire project ...","index":9,"favicon":"","host_name":"almcorp.com"},{"title":"What's your actual AI coding workflow? : r/vibecoding","url":"https://www.reddit.com/r/vibecoding/comments/1nyzb5e/whats_your_actual_ai_coding_workflow","text":"I create a detailed and step-by-step plan in markdown formatting. I do this outside of my IDE. Lots of talk, suggestions, edge cases, possible ...","index":10,"favicon":"","host_name":"www.reddit.com"},{"title":"AI開発の効率を爆発的に高める方法","url":"https://zenn.dev/querypie/articles/aa04b4bcf8dd21","text":"既存の「感情に依存したコーディング（Vibe Coding）」から脱却し、体系的で検証可能な開発ワークフローを提供します。 核心特徴：. 4段階ゲートシステム: ...","index":11,"favicon":"","host_name":"zenn.dev"},{"title":"最近目にする「Vibe Coding」解説~ AIを活用した新しい","url":"https://note.com/ogawa_ramo/n/n6d6e65742c14","text":"Vibe Coding（バイブコーディング）とは、AI（主に大規模言語モデル）を活用して開発者が自然言語で指示を出すだけでコードを生成し、アプリケーションを構築 ...","index":12,"favicon":"","host_name":"note.com"},{"title":"9,573個ものRFCドキュメントをDifyで全部取り込んでみた話","url":"https://eng-blog.iij.ad.jp/archives/31802","text":"Vibe Coding での挑戦、APIゲートウェイの制作で紹介した経路を通じて ... 大規模ナレッジベース構築に挑戦する皆さんの参考になれば幸いです ...","index":13,"favicon":"","host_name":"eng-blog.iij.ad.jp"},{"title":"AIワークフロー・Difyで業務効率化を実現する完全ガイド","url":"https://www.ai-native.jp/blog/ai-workflow-complete-guide","text":"AIワークフロー・Difyを活用した業務効率化の意思決定ポイントから、導入ロードマップまで、経営判断に必要な情報を網羅的に解説します。","index":14,"favicon":"","host_name":"www.ai-native.jp"},{"title":"AI活用 100本ノック","url":"https://fullswing.dena.com/pdf/AI_100tips_slide.pdf","text":"いわゆる「バイブコーディング」（Vibes-based coding：感覚や雰囲気でコーディングすること）で、. 専門的な知識がなくても開発作業を進められました。 成果. これまで ...","index":15,"favicon":"","host_name":"fullswing.dena.com"},{"title":"AI時代の新常識：「Vibe Codingの限界」と「SDD - 仕様駆動","url":"https://qiita.com/nogataka/items/b2c2cb475fa28333b56a","text":"本記事では、GitHubが2024年に提唱した**Spec-Driven Development (SDD - 仕様駆動開発 / スペック駆動開発)**の実践方法を、実際のツールと事例を交えて ...","index":16,"favicon":"","host_name":"qiita.com"},{"title":"【AI×モバイルアプリ開発のリアル】BLOCKSMITH&Co.が","url":"https://ai-market.jp/contributed-article/ai-mobile-dev-real","text":"生成AIを活用して1名・2か月で30画面以上のモバイルアプリを開発したBLOCKSMITH&Co.の事例から、「AIが得意な領域」と「AIに決して任せてはいけない ...","index":17,"favicon":"","host_name":"ai-market.jp"},{"title":"Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底","url":"https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704","text":"Sourcegraph Codyは、コードを深く理解するAIコーディングアシスタント。開発生産性を劇的に向上させ、複雑なコードベースを効率的にナビゲートし ...","index":18,"favicon":"","host_name":"skywork.ai"},{"title":"Claude Code月額20ドルで開発効率40%向上！プロが教える","url":"https://axconstdx.com/2025/06/23/claude-code%E6%9C%88%E9%A1%8D20%E3%83%89%E3%83%AB%E3%81%A7%E9%96%8B%E7%99%BA%E5%8A%B9%E7%8E%8740%E5%90%91%E4%B8%8A%EF%BC%81%E3%83%97%E3%83%AD%E3%81%8C%E6%95%99%E3%81%88%E3%82%8B2025%E5%B9%B4%E6%9C%80","text":"複数ファイルにまたがるリファクタリングや、大規模なテストコード生成なども自動でこなし、開発者が「一人でコーディングしていない」感覚で作業できる ...","index":19,"favicon":"","host_name":"axconstdx.com"},{"title":"バイブコーディング（Vibe Coding）とは？始め方やおすすめ","url":"https://www.ai-souken.com/article/what-is-vibe-coding","text":"バイブコーディングとは、AIとの対話でコードを“ノリ”よく生成する新時代の開発手法です。CopilotやCursorなどのツール、メリット・課題、実践方法 ...","index":20,"favicon":"","host_name":"www.ai-souken.com"}]},"metadata":{"arguments":"{\"query\":\"vibe coding 大規模開発 50フォルダ以上 精度向上 ワークフロー\"}","display_result":"","duration":"4s","id":"call_wkfaJSIkhF","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【10†AI開発の効率を爆発的に高める方法†https://zenn.dev/querypie/articles/aa04b4bcf8dd21】\n既存の「感情に依存したコーディング（Vibe Coding）」から脱却し、体系的で検証可能な開発ワークフローを提供します。 核心特徴：. 4段階ゲートシステム: ...\n\n【11†最近目にする「Vibe Coding」解説~ AIを活用した新しい†https://note.com/ogawa_ramo/n/n6d6e65742c14】\nVibe Coding（バイブコーディング）とは、AI（主に大規模言語モデル）を活用して開発者が自然言語で指示を出すだけでコードを生成し、アプリケーションを構築 ...\n\n【12†9,573個ものRFCドキュメントをDifyで全部取り込んでみた話†https://eng-blog.iij.ad.jp/archives/31802】\nVibe Coding での挑戦、APIゲートウェイの制作で紹介した経路を通じて ... 大規模ナレッジベース構築に挑戦する皆さんの参考になれば幸いです ...\n\n【13†AIワークフロー・Difyで業務効率化を実現する完全ガイド†https://www.ai-native.jp/blog/ai-workflow-complete-guide】\nAIワークフロー・Difyを活用した業務効率化の意思決定ポイントから、導入ロードマップまで、経営判断に必要な情報を網羅的に解説します。\n\n【14†AI活用 100本ノック†https://fullswing.dena.com/pdf/AI_100tips_slide.pdf】\nいわゆる「バイブコーディング」（Vibes-based coding：感覚や雰囲気でコーディングすること）で、. 専門的な知識がなくても開発作業を進められました。 成果. これまで ...\n\n【15†AI時代の新常識：「Vibe Codingの限界」と「SDD - 仕様駆動†https://qiita.com/nogataka/items/b2c2cb475fa28333b56a】\n本記事では、GitHubが2024年に提唱した**Spec-Driven Development (SDD - 仕様駆動開発 / スペック駆動開発)**の実践方法を、実際のツールと事例を交えて ...\n\n【16†【AI×モバイルアプリ開発のリアル】BLOCKSMITH&Co.が†https://ai-market.jp/contributed-article/ai-mobile-dev-real】\n生成AIを活用して1名・2か月で30画面以上のモバイルアプリを開発したBLOCKSMITH&Co.の事例から、「AIが得意な領域」と「AIに決して任せてはいけない ...\n\n【17†Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底†https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704】\nSourcegraph Codyは、コードを深く理解するAIコーディングアシスタント。開発生産性を劇的に向上させ、複雑なコードベースを効率的にナビゲートし ...\n\n【18†Claude Code月額20ドルで開発効率40%向上！プロが教える†https://axconstdx.com/2025/06/23/claude-code%E6%9C%88%E9%A1%8D20%E3%83%89%E3%83%AB%E3%81%A7%E9%96%8B%E7%99%BA%E5%8A%B9%E7%8E%8740%E5%90%91%E4%B8%8A%EF%BC%81%E3%83%97%E3%83%AD%E3%81%8C%E6%95%99%E3%81%88%E3%82%8B2025%E5%B9%B4%E6%9C%80】\n複数ファイルにまたがるリファクタリングや、大規模なテストコード生成なども自動でこなし、開発者が「一人でコーディングしていない」感覚で作業できる ...\n\n【19†バイブコーディング（Vibe Coding）とは？始め方やおすすめ†https://www.ai-souken.com/article/what-is-vibe-coding】\nバイブコーディングとは、AIとの対話でコードを“ノリ”よく生成する新時代の開発手法です。CopilotやCursorなどのツール、メリット・課題、実践方法 ...\n","status":"completed"}},"type":"mcp"}</glm_block>
<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"A Comprehensive Guide to Vibe Coding Tools","url":"https://medium.com/madhukarkumar/a-comprehensive-guide-to-vibe-coding-tools-2bd35e2d7b4f","text":"In this article we saw the different categories of AI tools that can be used for “vibe coding” and each has its pros and cons.","index":1,"favicon":"","host_name":"medium.com"},{"title":"Increase Vibe Coding Accuracy with the Plan-Implement-Run","url":"https://raffertyuy.com/raztype/vibe-coding-plan-implement-run","text":"Discover how the Plan-Implement-Run Pattern can transform chaotic vibe coding into a structured, predictable, and highly effective workflow.","index":2,"favicon":"","host_name":"raffertyuy.com"},{"title":"I vibe coded a 200000-line product. I'd like to share some","url":"https://www.reddit.com/r/vibecoding/comments/1ojv43w/i_vibe_coded_a_200000line_product_id_like_to","text":"I made a Japanese learning product with 200,000 lines of code, over 99.5% of which written by AI. I have a script to roughly calculate so I ...","index":3,"favicon":"","host_name":"www.reddit.com"},{"title":"A Structured Workflow for \"Vibe Coding\" Full-Stack Apps","url":"https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l","text":"Below, you'll find my honest review and the workflow that I found that really worked while using Cursor with Google's Gemini 2.5 Pro, and a solid UI template.","index":4,"favicon":"","host_name":"dev.to"},{"title":"5 Vibe Coding Best Practices to Implement in Your Workflow","url":"https://zencoder.ai/blog/vibe-coding-best-practices","text":"This article explores five key vibe coding best practices that every software engineer should incorporate into their workflow.","index":5,"favicon":"","host_name":"zencoder.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"In this article, I'll share how I plan, code, and collaborate with AI going into 2026, distilling tips and best practices from my experience and ...","index":6,"favicon":"","host_name":"addyosmani.com"},{"title":"What are tips for vibe-coding workflow?","url":"https://www.facebook.com/groups/vibecodinglife/posts/1817494222172440","text":"Most people think coding with AI is confusing But this guy dropped 12 vibe coding rules that changed everything Here's how you can replicate too ...","index":7,"favicon":"","host_name":"www.facebook.com"},{"title":"Vibe Planning: Get the Most Out of Claude Code : r/ClaudeAI","url":"https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code","text":"Clean context – Separating planning from coding keeps Claude Code focused on executing the task with only the relevant files in context.","index":8,"favicon":"","host_name":"www.reddit.com"},{"title":"Vibe Coding: Complete Guide to AI-Assisted Software","url":"https://almcorp.com/blog/vibe-coding-complete-guide","text":"Its Composer feature enables multi-file editing, where you can describe changes and watch Cursor modify code across your entire project ...","index":9,"favicon":"","host_name":"almcorp.com"},{"title":"What's your actual AI coding workflow? : r/vibecoding","url":"https://www.reddit.com/r/vibecoding/comments/1nyzb5e/whats_your_actual_ai_coding_workflow","text":"I create a detailed and step-by-step plan in markdown formatting. I do this outside of my IDE. Lots of talk, suggestions, edge cases, possible ...","index":10,"favicon":"","host_name":"www.reddit.com"}]},"metadata":{"arguments":"{\"query\":\"vibe coding accuracy improvement large codebase multiple folders workflow\"}","display_result":"","duration":"4s","id":"call_vJDLfAuoul","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【0†A Comprehensive Guide to Vibe Coding Tools†https://medium.com/madhukarkumar/a-comprehensive-guide-to-vibe-coding-tools-2bd35e2d7b4f】\nIn this article we saw the different categories of AI tools that can be used for “vibe coding” and each has its pros and cons.\n\n【1†Increase Vibe Coding Accuracy with the Plan-Implement-Run†https://raffertyuy.com/raztype/vibe-coding-plan-implement-run】\nDiscover how the Plan-Implement-Run Pattern can transform chaotic vibe coding into a structured, predictable, and highly effective workflow.\n\n【2†I vibe coded a 200000-line product. I'd like to share some†https://www.reddit.com/r/vibecoding/comments/1ojv43w/i_vibe_coded_a_200000line_product_id_like_to】\nI made a Japanese learning product with 200,000 lines of code, over 99.5% of which written by AI. I have a script to roughly calculate so I ...\n\n【3†A Structured Workflow for \"Vibe Coding\" Full-Stack Apps†https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l】\nBelow, you'll find my honest review and the workflow that I found that really worked while using Cursor with Google's Gemini 2.5 Pro, and a solid UI template.\n\n【4†5 Vibe Coding Best Practices to Implement in Your Workflow†https://zencoder.ai/blog/vibe-coding-best-practices】\nThis article explores five key vibe coding best practices that every software engineer should incorporate into their workflow.\n\n【5†My LLM coding workflow going into 2026†https://addyosmani.com/blog/ai-coding-workflow】\nIn this article, I'll share how I plan, code, and collaborate with AI going into 2026, distilling tips and best practices from my experience and ...\n\n【6†What are tips for vibe-coding workflow?†https://www.facebook.com/groups/vibecodinglife/posts/1817494222172440】\nMost people think coding with AI is confusing But this guy dropped 12 vibe coding rules that changed everything Here's how you can replicate too ...\n\n【7†Vibe Planning: Get the Most Out of Claude Code : r/ClaudeAI†https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code】\nClean context – Separating planning from coding keeps Claude Code focused on executing the task with only the relevant files in context.\n\n【8†Vibe Coding: Complete Guide to AI-Assisted Software†https://almcorp.com/blog/vibe-coding-complete-guide】\nIts Composer feature enables multi-file editing, where you can describe changes and watch Cursor modify code across your entire project ...\n\n【9†What's your actual AI coding workflow? : r/vibecoding†https://www.reddit.com/r/vibecoding/comments/1nyzb5e/whats_your_actual_ai_coding_workflow】\nI create a detailed and step-by-step plan in markdown formatting. I do this outside of my IDE. Lots of talk, suggestions, edge cases, possible ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="5" view="" last_tool_call_name="search">
> ユーザーは、50以上のフォルダを持つ大規模プロジェクトにおいて、バイブコーディングの精度を最大化するためのワークフローを求めている。重要な要素としては、プロジェクト構造の理解、依存関係のマッピング、AIコンテキストの管理、ファイルの分割、検証、自動化などが考えられる。これらの要素を組み合わせて、効率的かつ正確なバイブコーディングのワークフローを提案する必要がある。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://raffertyuy.com/raztype/vibe-coding-plan-implement-run","title":"Increase Vibe Coding Accuracy with the Plan-Implement-Run","content":"【1†Increase Vibe Coding Accuracy with the Plan-Implement-Run†https://raffertyuy.com/raztype/vibe-coding-plan-implement-run】\nTitle: Increase Vibe Coding Accuracy with the Plan-Implement-Run Pattern\n\nURL Source: https://raffertyuy.com/raztype/vibe-coding-plan-implement-run\n\nPublished Time: 2025-08-19T20:00:00+08:00\n\nMarkdown Content:\nIn the world of AI-assisted coding, getting agents to generate structured and predictable results can often feel like a challenge. Many developers rely on single-shot prompts, hoping their AI coding agents will deliver the perfect solution on the first try. While this can be a fun way to practice prompt engineering, it is often impractical for daily use.\n\nIn this post, I’m sharing a better approach: the **Plan-Implement-Run Pattern**. This simple 3-step methodology transforms chaotic “vibe coding” into a streamlined, effective workflow.\n\n**This is not a new concept** but rather my attempt to articulate an observation from various implementations, including my own experiences.\n\n*   Since the early days of Semantic Kernel and LangChain, the idea of forcing AI to think step-by-step by first generating a plan before executing a task has been a common practice. This is something developers can learn from and apply effectively.\n*   GitHub Copilot Workspace generated a plan and asked for developer confirmation before proceeding with implementation. The more recent GitHub Copilot Coding Agent follows the same approach, except now the plan is included in the Pull Request.\n*   Cursor’s planning mode and Windsurf’s cascade adopt similar methodologies.\n*   Other blogs share comparable ideas but articulate them differently. A quick web search led me to Can AI Learn to Plan Before It Codes? and Why Planning Features with AI Before Coding Will Revolutionize Your Development Process.\n\nInstead of relying on the AI coding agent to intuitively create a plan or waiting for specific AI coding products to improve their planning features, I’m sharing how you can take control and guide the agent to follow this approach effectively.\n\n> For the examples in this post, I am using GitHub Copilot with VSCode. If you are using a different coding agent or IDE, the concepts will still apply.\n\nPre-requisite: Markdown Documentation in Your Codebase\n------------------------------------------------------\n\nThink of the coding agent as a new hire that you’ll need to guide with very clear instructions. As with any new hire, you need to provide it with a wealth of information about your project, such as:\n\n*   The application overview\n*   The technology stack\n*   The specification documents\n*   The database schema\n*   The files and folder structure of the codebase\n*   The coding standards\n*   And more\n\nThe challenge here is figuring out how to give the coding agent access to all of this. I have found that having all this information in markdown documents saved in the `docs/` folder of your codebase is the cleanest and most efficient way.\n\n> **Note:** If your documents are currently stored in other locations (e.g., SharePoint, Confluence, etc.), this transition might not be straightforward. Here are some suggestions to ease the process:\n> \n> \n> *   Convert only the relevant documents to markdown; you likely won’t need everything. Tools like markitdown can help with this conversion.\n> *   Use the `#fetch` tool (or its equivalent) to extract information from public websites. This is particularly useful for public documentation.\n> *   Use or create your own MCP Server. For instance, Context7 is a recommended tool for retrieving the latest documents about your tech stack.\n\nHere’s an example of a codebase file structure with markdown documentation:\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n# File Structure\n\nThis document outlines the complete file and folder structure of the Uy Kape project codebase.\n\nIt includes:\n- A description of all the files in the `/` root directory  \n- A description of every root folder  \n- A description of all the files and subdirectories in the `docs/` folder  \n\nmy-application/\n├── .git/                           # Git repository metadata\n├── .github/                        # GitHub configuration and workflows\n│   ├── chatmodes/                  # GitHub Copilot custom agent chat modes\n│   ├── instructions/               # AI agent prompt instructions based on file extension\n│   ├── prompt-snippets/            # Reusable prompt snippets\n│   │   └── coding-standards.md     # General coding standards\n│   ├── prompts/                    # AI agent reusable prompts\n│   │   ├── 1-plan.prompt.md        # AI agent prompt for creating a coding implementation plan\n│   │   ├── 2-implement.prompt.md   # AI agent prompt for implementing a plan\n│   │   └── 3-run.prompt.md         # AI agent prompt for running and fixing an implementation\n│   ├── workflows/                  # GitHub Actions workflows\n│   └── copilot-instructions.md     # AI agent system prompt\n├── .gitignore                      # Git ignore rules\n├── .vscode/                        # VS Code workspace configuration\n│   └── mcp.json                    # Model Context Protocol configuration\n├── docs/                           # Documentation\n│   ├── plans/                      # Implementation plans generated by the coding assistant\n│   ├── screens/                    # Screenshots and UI mockups\n│   │   └── wireframe1.png          # Interface mockup\n│   ├── specs/                      # Specifications and requirements\n│   │   ├── architecture.md         # Application architecture\n│   │   ├── db_schema.md            # Database schema\n│   │   ├── initial_idea.md         # Initial project idea documentation\n│   │   └── specifications.md       # Technical specifications\n│   └── file_structure.md           # This file. Files and folder structure of this codebase\n├── README.md                       # Project overview and setup instructions\n└── src/                            # Source code directory\n```\n\ndocs/file_structure.md\n\n> The above is an actual file structure for a personal project that I’m working on. See this changeset for the initial version of this project, before I started coding anything. _(Note: Many folders are missing because Git doesn’t commit empty folders.)_\n\nAs you can see from this structure, the idea is to document everything you want the coding agent to know in the `docs/` folder. Then, **inform the agent about the documents in this folder**. To achieve this, include this instruction in the system prompt.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nGeneral Development Guidelines\n\n## **CORE RULES**\n### Reference Specific File Type Instructions\nCheck the files in `/.github/instructions/*.instructions.md` for any additional instructions based on the file you are working on. This **INCLUDES _NEW_** files that you are creating.\n- Check each file in this folder and check `applyTo: '**/*.<extension>` to see which files the instructions apply to.\n- For example, follow the instructions in `/.github/instructions/reactjs.instructions.md` for `**/*.jsx, **/*.tsx, **/*.js, **/*.ts, **/*.css, **/*.scss` files.\n\n**REMINDER**: If you are creating a new file, follow the above instructions as you create this file. If you didn't, review the file and modify it to follow the instructions in the relevant `.instructions.md` file.\n\n### File and Folder Structure\nTo know what each file and folder does, or to look for any project documentation information, refer to [file_structure](/docs/file_structure.md)\n\n...\n## Quality Standards\nFollow [coding-standards](/.github/prompt-snippets/coding-standards.md)\n```\n\n.github/copilot-instructions.md\n\nThe Plan-Implement-Run Pattern\n------------------------------\n\nOnce the codebase is set up so that the coding agent knows where to find information about your application, we can now vibe code in 3 easy steps!\n\n1.   `/1-plan implementation of the <feature/module>. Refer to the #file:initial_idea.md and #file:db.schema.md for this implementation.`\n2.   `/2-implement #file:<feature/module>.plan.md`\n3.   `/3-run the <feature/module>`\n\nOf course, each reusable prompt needs to be written. Here are the details.\n\n### 1. Plan\n\nThe first step is to use your AI coding agent to **think deeply** and generate an implementation plan.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n---\ndescription: \"Plan for a coding implementation for an AI coding assistant to follow.\"\n---\nYour goal is to generate an coding implementation plan for an AI coding assistant to follow.\nCreate this plan in a new markdown .md file in `/docs/plans/<requirement_name>.plan.md`, for the requirement provided to you. You can decide on the appropriate requirement name.\nFor example, if the requirement name is \"Implement User Authentication\", the file should be created as `/docs/plans/user_authentication.plan.md`.\n\n## RULES:\n- Keep implementations simple, do not over architect\n- Do not generate real code for your plan, pseudocode is OK\n- For each step in your plan, include the objective of the step, the steps to achieve that objective, and any necessary pseudocode.\n- Call out any necessary user intervention required for each step\n- Consider accessibility part of each step and not a separate step\n\n## Steps to Follow\n### 1. FIRST\n- Review the attached specification document to understand the requirements and objectives.\n- If needed, use context7 to get the latest documentation of the technology stack (e.g., Supabase, React.js, Vite).\n\n### 2. THEN\n- Create a detailed implementation plan that outlines the steps needed to achieve the objectives of the specification document.\n- The plan should be structured, clear, and easy to follow.\n- Add a frontmatter to the implementation plan\n\n```markdown\n---\ndescription: \"Implementation plan for <requirement>\"\ncreated-date: YYYY-MM-DD\n---\n\nPLAN HERE\n```\n\n- Always add validation steps in your plan to ensure the implementation meets the requirements.\n- Structure your plan as follows, and output as Markdown code block\n\n```markdown\n# Implementation Plan for [Spec Name]\n- [ ] Step 1: [Brief title]\n  - **Task**: [Detailed explanation of what needs to be implemented]\n  - **Files**: [Maximum of 20 files, ideally less]\n    - `path/to/file1.ts`: [Description of changes], [Pseudocode for implementation]\n  - **Dependencies**: [Dependencies for step]\n\n[Additional steps...]\n```\n\n### 3. NEXT:\n- Validate and self-review your plan to ensure it meets the requirements and is ready for implementation.\n- Iterate with me until I am satisifed with the plan\n\n### 4. FINALLY:\n- DO NOT start implementation without my permission.\n```\n\nThen, run the reusable prompt with GitHub Copilot Chat. For example:\n\n`/1-plan implementation of the Barista Admin Module - Menu Management. Refer to the #file:initial_idea.md and #file:db.schema.md for this implementation.`\n\nThis will generate a new `docs/plans/<feature>.plan.md` document, like this:\n\n_Output: Barista Admin Module - Menu Management - Implementation Plan_\n\nIt’s always prudent to review the plan before implementation. However, in my experience, if the AI agent correctly references the technical documentation in the `docs/` folder, these generated plans rarely require significant edits. Before coding assistants, we spent a lot of time thinking and planning before writing code. Now, we’re simply ensuring the AI coding agent follows the same disciplined approach.\n\n### 2. Implement\n\nThe next step is straightforward: simply run `/2-implement #file:OUTPUT_PLAN_HERE.md` and watch the magic happen. Here’s my reusable prompt.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n---\ndescription: \"Implement a plan step by step\"\n---\n\nYour task is to implement each step of the provided plan, one at a time.\n\n- The plan is just a suggestion to guide you in the right direction.\n- You do not have to strictly follow it if it does not make sense.\n- ALWAYS mark each step done in the provided plan Markdown file when you have completed a step before moving on to the next step.\n\nRefer to [file_structure.md](/docs/file_structure.md) and check other implementations in the workspace to see how they are done. **DO NOT** make changes to the other files that you are only using for reference.\n\nImplement and run the unit tests as described in the plan.\nValidate and self-review your implementation to ensure that it meets the requirements.\n\nIterate with me until I am satisfied with the implementation.\n```\n\n### 3. Run\n\nFinally, get your AI coding agent to run the application and address any issues that arise.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n---\nmode: \"agent\"\ndescription: \"Run the application locally and fix any errors encountered.\"\n---\n\nYour task is to run this application locally for functional testing.\n\n- Before attempting to run the app, check if it is already running.\n\n\n"},"metadata":{"arguments":"{\"link_id\":1}","display_result":"","duration":"4s","id":"call_9YsTnQslIu","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【1†Increase Vibe Coding Accuracy with the Plan-Implement-Run†https://raffertyuy.com/raztype/vibe-coding-plan-implement-run】\nTitle: Increase Vibe Coding Accuracy with the Plan-Implement-Run Pattern\n\nURL Source: https://raffertyuy.com/raztype/vibe-coding-plan-implement-run\n\nPublished Time: 2025-08-19T20:00:00+08:00\n\nMarkdown Content:\nIn the world of AI-assisted coding, getting agents to generate structured and predictable results can often feel like a challenge. Many developers rely on single-shot prompts, hoping their AI coding agents will deliver the perfect solution on the first try. While this can be a fun way to practice prompt engineering, it is often impractical for daily use.\n\nIn this post, I’m sharing a better approach: the **Plan-Implement-Run Pattern**. This simple 3-step methodology transforms chaotic “vibe coding” into a streamlined, effective workflow.\n\n**This is not a new concept** but rather my attempt to articulate an observation from various implementations, including my own experiences.\n\n*   Since the early days of Semantic Kernel and LangChain, the idea of forcing AI to think step-by-step by first generating a plan before executing a task has been a common practice. This is something developers can learn from and apply effectively.\n*   GitHub Copilot Workspace generated a plan and asked for developer confirmation before proceeding with implementation. The more recent GitHub Copilot Coding Agent follows the same approach, except now the plan is included in the Pull Request.\n*   Cursor’s planning mode and Windsurf’s cascade adopt similar methodologies.\n*   Other blogs share comparable ideas but articulate them differently. A quick web search led me to Can AI Learn to Plan Before It Codes? and Why Planning Features with AI Before Coding Will Revolutionize Your Development Process.\n\nInstead of relying on the AI coding agent to intuitively create a plan or waiting for specific AI coding products to improve their planning features, I’m sharing how you can take control and guide the agent to follow this approach effectively.\n\n> For the examples in this post, I am using GitHub Copilot with VSCode. If you are using a different coding agent or IDE, the concepts will still apply.\n\nPre-requisite: Markdown Documentation in Your Codebase\n------------------------------------------------------\n\nThink of the coding agent as a new hire that you’ll need to guide with very clear instructions. As with any new hire, you need to provide it with a wealth of information about your project, such as:\n\n*   The application overview\n*   The technology stack\n*   The specification documents\n*   The database schema\n*   The files and folder structure of the codebase\n*   The coding standards\n*   And more\n\nThe challenge here is figuring out how to give the coding agent access to all of this. I have found that having all this information in markdown documents saved in the `docs/` folder of your codebase is the cleanest and most efficient way.\n\n> **Note:** If your documents are currently stored in other locations (e.g., SharePoint, Confluence, etc.), this transition might not be straightforward. Here are some suggestions to ease the process:\n> \n> \n> *   Convert only the relevant documents to markdown; you likely won’t need everything. Tools like markitdown can help with this conversion.\n> *   Use the `#fetch` tool (or its equivalent) to extract information from public websites. This is particularly useful for public documentation.\n> *   Use or create your own MCP Server. For instance, Context7 is a recommended tool for retrieving the latest documents about your tech stack.\n\nHere’s an example of a codebase file structure with markdown documentation:\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n# File Structure\n\nThis document outlines the complete file and folder structure of the Uy Kape project codebase.\n\nIt includes:\n- A description of all the files in the `/` root directory  \n- A description of every root folder  \n- A description of all the files and subdirectories in the `docs/` folder  \n\nmy-application/\n├── .git/                           # Git repository metadata\n├── .github/                        # GitHub configuration and workflows\n│   ├── chatmodes/                  # GitHub Copilot custom agent chat modes\n│   ├── instructions/               # AI agent prompt instructions based on file extension\n│   ├── prompt-snippets/            # Reusable prompt snippets\n│   │   └── coding-standards.md     # General coding standards\n│   ├── prompts/                    # AI agent reusable prompts\n│   │   ├── 1-plan.prompt.md        # AI agent prompt for creating a coding implementation plan\n│   │   ├── 2-implement.prompt.md   # AI agent prompt for implementing a plan\n│   │   └── 3-run.prompt.md         # AI agent prompt for running and fixing an implementation\n│   ├── workflows/                  # GitHub Actions workflows\n│   └── copilot-instructions.md     # AI agent system prompt\n├── .gitignore                      # Git ignore rules\n├── .vscode/                        # VS Code workspace configuration\n│   └── mcp.json                    # Model Context Protocol configuration\n├── docs/                           # Documentation\n│   ├── plans/                      # Implementation plans generated by the coding assistant\n│   ├── screens/                    # Screenshots and UI mockups\n│   │   └── wireframe1.png          # Interface mockup\n│   ├── specs/                      # Specifications and requirements\n│   │   ├── architecture.md         # Application architecture\n│   │   ├── db_schema.md            # Database schema\n│   │   ├── initial_idea.md         # Initial project idea documentation\n│   │   └── specifications.md       # Technical specifications\n│   └── file_structure.md           # This file. Files and folder structure of this codebase\n├── README.md                       # Project overview and setup instructions\n└── src/                            # Source code directory\n```\n\ndocs/file_structure.md\n\n> The above is an actual file structure for a personal project that I’m working on. See this changeset for the initial version of this project, before I started coding anything. _(Note: Many folders are missing because Git doesn’t commit empty folders.)_\n\nAs you can see from this structure, the idea is to document everything you want the coding agent to know in the `docs/` folder. Then, **inform the agent about the documents in this folder**. To achieve this, include this instruction in the system prompt.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\nGeneral Development Guidelines\n\n## **CORE RULES**\n### Reference Specific File Type Instructions\nCheck the files in `/.github/instructions/*.instructions.md` for any additional instructions based on the file you are working on. This **INCLUDES _NEW_** files that you are creating.\n- Check each file in this folder and check `applyTo: '**/*.<extension>` to see which files the instructions apply to.\n- For example, follow the instructions in `/.github/instructions/reactjs.instructions.md` for `**/*.jsx, **/*.tsx, **/*.js, **/*.ts, **/*.css, **/*.scss` files.\n\n**REMINDER**: If you are creating a new file, follow the above instructions as you create this file. If you didn't, review the file and modify it to follow the instructions in the relevant `.instructions.md` file.\n\n### File and Folder Structure\nTo know what each file and folder does, or to look for any project documentation information, refer to [file_structure](/docs/file_structure.md)\n\n...\n## Quality Standards\nFollow [coding-standards](/.github/prompt-snippets/coding-standards.md)\n```\n\n.github/copilot-instructions.md\n\nThe Plan-Implement-Run Pattern\n------------------------------\n\nOnce the codebase is set up so that the coding agent knows where to find information about your application, we can now vibe code in 3 easy steps!\n\n1.   `/1-plan implementation of the <feature/module>. Refer to the #file:initial_idea.md and #file:db.schema.md for this implementation.`\n2.   `/2-implement #file:<feature/module>.plan.md`\n3.   `/3-run the <feature/module>`\n\nOf course, each reusable prompt needs to be written. Here are the details.\n\n### 1. Plan\n\nThe first step is to use your AI coding agent to **think deeply** and generate an implementation plan.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n22\n23\n24\n25\n26\n27\n28\n29\n30\n31\n32\n33\n34\n35\n36\n37\n38\n39\n40\n41\n42\n43\n44\n45\n46\n47\n48\n49\n50\n51\n52\n53\n---\ndescription: \"Plan for a coding implementation for an AI coding assistant to follow.\"\n---\nYour goal is to generate an coding implementation plan for an AI coding assistant to follow.\nCreate this plan in a new markdown .md file in `/docs/plans/<requirement_name>.plan.md`, for the requirement provided to you. You can decide on the appropriate requirement name.\nFor example, if the requirement name is \"Implement User Authentication\", the file should be created as `/docs/plans/user_authentication.plan.md`.\n\n## RULES:\n- Keep implementations simple, do not over architect\n- Do not generate real code for your plan, pseudocode is OK\n- For each step in your plan, include the objective of the step, the steps to achieve that objective, and any necessary pseudocode.\n- Call out any necessary user intervention required for each step\n- Consider accessibility part of each step and not a separate step\n\n## Steps to Follow\n### 1. FIRST\n- Review the attached specification document to understand the requirements and objectives.\n- If needed, use context7 to get the latest documentation of the technology stack (e.g., Supabase, React.js, Vite).\n\n### 2. THEN\n- Create a detailed implementation plan that outlines the steps needed to achieve the objectives of the specification document.\n- The plan should be structured, clear, and easy to follow.\n- Add a frontmatter to the implementation plan\n\n```markdown\n---\ndescription: \"Implementation plan for <requirement>\"\ncreated-date: YYYY-MM-DD\n---\n\nPLAN HERE\n```\n\n- Always add validation steps in your plan to ensure the implementation meets the requirements.\n- Structure your plan as follows, and output as Markdown code block\n\n```markdown\n# Implementation Plan for [Spec Name]\n- [ ] Step 1: [Brief title]\n  - **Task**: [Detailed explanation of what needs to be implemented]\n  - **Files**: [Maximum of 20 files, ideally less]\n    - `path/to/file1.ts`: [Description of changes], [Pseudocode for implementation]\n  - **Dependencies**: [Dependencies for step]\n\n[Additional steps...]\n```\n\n### 3. NEXT:\n- Validate and self-review your plan to ensure it meets the requirements and is ready for implementation.\n- Iterate with me until I am satisifed with the plan\n\n### 4. FINALLY:\n- DO NOT start implementation without my permission.\n```\n\nThen, run the reusable prompt with GitHub Copilot Chat. For example:\n\n`/1-plan implementation of the Barista Admin Module - Menu Management. Refer to the #file:initial_idea.md and #file:db.schema.md for this implementation.`\n\nThis will generate a new `docs/plans/<feature>.plan.md` document, like this:\n\n_Output: Barista Admin Module - Menu Management - Implementation Plan_\n\nIt’s always prudent to review the plan before implementation. However, in my experience, if the AI agent correctly references the technical documentation in the `docs/` folder, these generated plans rarely require significant edits. Before coding assistants, we spent a lot of time thinking and planning before writing code. Now, we’re simply ensuring the AI coding agent follows the same disciplined approach.\n\n### 2. Implement\n\nThe next step is straightforward: simply run `/2-implement #file:OUTPUT_PLAN_HERE.md` and watch the magic happen. Here’s my reusable prompt.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n---\ndescription: \"Implement a plan step by step\"\n---\n\nYour task is to implement each step of the provided plan, one at a time.\n\n- The plan is just a suggestion to guide you in the right direction.\n- You do not have to strictly follow it if it does not make sense.\n- ALWAYS mark each step done in the provided plan Markdown file when you have completed a step before moving on to the next step.\n\nRefer to [file_structure.md](/docs/file_structure.md) and check other implementations in the workspace to see how they are done. **DO NOT** make changes to the other files that you are only using for reference.\n\nImplement and run the unit tests as described in the plan.\nValidate and self-review your implementation to ensure that it meets the requirements.\n\nIterate with me until I am satisfied with the implementation.\n```\n\n### 3. Run\n\nFinally, get your AI coding agent to run the application and address any issues that arise.\n\n```\n1\n2\n3\n4\n5\n6\n7\n8\n9\n10\n11\n12\n13\n14\n15\n16\n17\n18\n19\n20\n21\n---\nmode: \"agent\"\ndescription: \"Run the application locally and fix any errors encountered.\"\n---\n\nYour task is to run this application locally for functional testing.\n\n- Before attempting to run the app, check if it is already running.\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://addyosmani.com/blog/ai-coding-workflow","title":"My LLM coding workflow going into 2026","content":"【5†My LLM coding workflow going into 2026†https://addyosmani.com/blog/ai-coding-workflow】\nTitle: My LLM coding workflow going into 2026\n\nURL Source: https://addyosmani.com/blog/ai-coding-workflow\n\nMarkdown Content:\n**AI coding assistants became game-changers in 2025, but harnessing them effectively takes skill and structure.** These tools dramatically increased what LLMs can do for real-world coding, and many developers (myself included) embraced them.\n\nAt Anthropic, for example, engineers adopted Claude Code so heavily that **today****~90% of the code for Claude Code is written by Claude Code itself**. Yet, using LLMs for programming is _not_ a push-button magic experience - it’s “difficult and unintuitive” and getting great results requires learning new patterns. Critical thinking remains key. Over a year of projects, I’ve converged on a workflow similar to what many experienced devs are discovering: treat the LLM as a powerful pair programmer that **requires clear direction, context and oversight** rather than autonomous judgment.\n\nIn this article, I’ll share how I plan, code, and collaborate with AI going into 2026, distilling tips and best practices from my experience and the community’s collective learning. It’s a more disciplined **“AI-assisted engineering”** approach - leveraging AI aggressively while **staying proudly accountable for the software produced**.\n\nIf you’re interested in more on my workflow, see “The AI-Native Software Engineer”, otherwise let’s dive straight into some of the lessons I learned.\n\n**Start with a clear plan (specs before code)**\n-----------------------------------------------\n\n**Don’t just throw wishes at the LLM - begin by defining the problem and planning a solution.**\n\nOne common mistake is diving straight into code generation with a vague prompt. In my workflow, and in many others’, the first step is **brainstorming a detailed specification**_with_ the AI, then outlining a step-by-step plan, _before_ writing any actual code. For a new project, I’ll describe the idea and ask the LLM to **iteratively ask me questions** until we’ve fleshed out requirements and edge cases. By the end, we compile this into a comprehensive **spec.md** - containing requirements, architecture decisions, data models, and even a testing strategy. This spec forms the foundation for development.\n\nNext, I feed the spec into a reasoning-capable model and prompt it to **generate a project plan**: break the implementation into logical, bite-sized tasks or milestones. The AI essentially helps me do a mini “design doc” or project plan. I often iterate on this plan - editing and asking the AI to critique or refine it - until it’s coherent and complete. _Only then_ do I proceed to coding. This upfront investment might feel slow, but it pays off enormously. As Les Orchard put it, it’s like doing a **“waterfall in 15 minutes”** - a rapid structured planning phase that makes the subsequent coding much smoother.\n\nHaving a clear spec and plan means when we unleash the codegen, both the human and the LLM know exactly what we’re building and why. In short, **planning first** forces you and the AI onto the same page and prevents wasted cycles. It’s a step many people are tempted to skip, but experienced LLM developers now treat a robust spec/plan as the cornerstone of the workflow.\n\n**Break work into small, iterative chunks**\n-------------------------------------------\n\n**Scope management is everything - feed the LLM manageable tasks, not the whole codebase at once.**\n\nA crucial lesson I’ve learned is to avoid asking the AI for large, monolithic outputs. Instead, we **break the project into iterative steps or tickets** and tackle them one by one. This mirrors good software engineering practice, but it’s even more important with AI in the loop. LLMs do best when given focused prompts: implement one function, fix one bug, add one feature at a time. For example, after planning, I will prompt the codegen model: _“Okay, let’s implement Step 1 from the plan”_. We code that, test it, then move to Step 2, and so on. Each chunk is small enough that the AI can handle it within context and you can understand the code it produces.\n\nThis approach guards against the model going off the rails. If you ask for too much in one go, it’s likely to get confused or produce a **“jumbled mess”** that’s hard to untangle. Developers report that when they tried to have an LLM generate huge swaths of an app, they ended up with inconsistency and duplication - “like 10 devs worked on it without talking to each other,” one said. I’ve felt that pain; the fix is to **stop, back up, and split the problem into smaller pieces**. Each iteration, we carry forward the context of what’s been built and incrementally add to it. This also fits nicely with a **test-driven development (TDD)** approach - we can write or generate tests for each piece as we go (more on testing soon).\n\nSeveral coding-agent tools now explicitly support this chunked workflow. For instance, I often generate a structured **“prompt plan”** file that contains a sequence of prompts for each task, so that tools like Cursor can execute them one by one. The key point is to **avoid huge leaps**. By iterating in small loops, we greatly reduce the chance of catastrophic errors and we can course-correct quickly. LLMs excel at quick, contained tasks - use that to your advantage.\n\n**Provide extensive context and guidance**\n------------------------------------------\n\n**LLMs are only as good as the context you provide - _show them_ the relevant code, docs, and constraints.**\n\nWhen working on a codebase, I make sure to **feed the AI all the information it needs** to perform well. That includes the code it should modify or refer to, the project’s technical constraints, and any known pitfalls or preferred approaches. Modern tools help with this: for example, Anthropic’s Claude can import an entire GitHub repo into its context in “Projects” mode, and IDE assistants like Cursor or Copilot auto-include open files in the prompt. But I often go further - I will either use an MCP like Context7 or manually copy important pieces of the codebase or API docs into the conversation if I suspect the model doesn’t have them.\n\nExpert LLM users emphasize this “context packing” step. For example, doing a **“brain dump”** of everything the model should know before coding, including: high-level goals and invariants, examples of good solutions, and warnings about approaches to avoid. If I’m asking an AI to implement a tricky solution, I might tell it which naive solutions are too slow, or provide a reference implementation from elsewhere. If I’m using a niche library or a brand-new API, I’ll paste in the official docs or README so the AI isn’t flying blind. All of this upfront context dramatically improves the quality of its output, because the model isn’t guessing - it has the facts and constraints in front of it.\n\nThere are now utilities to automate context packaging. I’ve experimented with tools like **gitingest** or **repo2txt**, which essentially **“dump” the relevant parts of your codebase into a text file for the LLM to read**. These can be a lifesaver when dealing with a large project - you generate an output.txt bundle of key source files and let the model ingest that. The principle is: **don’t make the AI operate on partial information**. If a bug fix requires understanding four different modules, show it those four modules. Yes, we must watch token limits, but current frontier models have pretty huge context windows (tens of thousands of tokens). Use them wisely. I often selectively include just the portions of code relevant to the task at hand, and explicitly tell the AI what _not_ to focus on if something is out of scope (to save tokens).\n\nI think **Claude Skills** have potential because they turn what used to be fragile repeated prompting into something **durable and reusable** by packaging instructions, scripts, and domain specific expertise into modular capabilities that tools can automatically apply when a request matches the Skill. This means you get more reliable and context aware results than a generic prompt ever could and you move away from one off interactions toward workflows that encode repeatable procedures and team knowledge for tasks in a consistent way. A number of community-curated Skills collections exist, but one of my favorite examples is the frontend-design skill which can “end” the purple design aesthetic prevalent in LLM generated UIs. Until more tools support Skills officially, workarounds exist.\n\nFinally, **guide the AI with comments and rules inside the prompt**. I might precede a code snippet with: “Here is the current implementation of X. We need to extend it to do Y, but be careful not to break Z.” These little hints go a long way. LLMs are **literalists** - they’ll follow instructions, so give them detailed, contextual instructions. By proactively providing context and guidance, we minimize hallucinations and off-base suggestions and get code that fits our project’s needs.\n\n**Choose the right model (and use multiple when needed)**\n---------------------------------------------------------\n\n**Not all coding LLMs are equal - pick your tool with intention, and don’t be afraid to swap models mid-stream.**\n\nIn 2025 we’ve been spoiled with a variety of capable code-focused LLMs. Part of my workflow is **choosing the model or service best suited to each task**. Sometimes it can be valuable to even try two or more LLMs in parallel to cross-check how they might approach the same problem differently.\n\nEach model has its own “personality”. The key is: **if one model gets stuck or gives mediocre outputs, try another.** I’ve literally copied the same prompt from one chat into another service to see if it can handle it better. This “model musical chairs” can rescue you when you hit a model’s blind spot.\n\nAlso, make sure you’re using _the best version_ available. If you can, use the newest “pro” tier models - because quality matters. And yes, it often means paying for access, but the productivity gains can justify it. Ultimately, pick the AI pair programmer whose **“vibe” meshes with you**. I know folks who prefer one model simply because they like how its responses _feel_. That’s valid - when you’re essentially in a constant dialogue with an AI, the UX and tone make a difference.\n\nPersonally I gravitate towards Gemini for a lot of coding work these days because the interaction feels more natural and it often understands my requests on the first try. But I will not hesitate to switch to another model if needed; sometimes a second opinion helps the solution emerge. In summary: **use the best tool for the job, and remember you have an arsenal of AIs at your disposal.**\n\n**Leverage AI coding across the lifecycle**\n-------------------------------------------\n\n**Supercharge your workflow with coding-specific AI help across the SDLC.**\n\nOn the command-line, new AI agents emerged. **Claude Code, OpenAI’s Codex CLI** and **Google’s Gemini CLI** are CLI tools where you can chat with them directly in your project directory - they can read files, run tests, and even multi-step fix issues. I’ve used Google’s **Jules** and GitHub’s **Copilot Agent** as well - these are **asynchronous coding agents** that actually clone your repo into a cloud VM and work on tasks in the background (writing tests, fixing bugs, then opening a PR for you). It’s a bit eerie to witness: you issue a command like “refactor the payment module for X” and a little while later you get a pull request with code changes and passing tests. We are truly living in the future. You can read more about this in conductors to orchestrators.\n\nThat said, **these tools are not infallible, and you must understand their limits**. They accelerate the mechanical parts of coding - generating boilerplate, applying repetitive changes, running tests automatically - but they still benefit greatly from your guidance. For instance, when I use an agent like Claude or Copilot to implement something, I often supply it with the plan or to-do list from earlier steps so it knows the exact sequence of tasks. If the agent supports it, I’ll load up my spec.md or plan.md in the context before telling it to execute. This keeps it on track.\n\n\n"},"metadata":{"arguments":"{\"link_id\":5}","display_result":"","duration":"3s","id":"call_YBUZnVkygx","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【5†My LLM coding workflow going into 2026†https://addyosmani.com/blog/ai-coding-workflow】\nTitle: My LLM coding workflow going into 2026\n\nURL Source: https://addyosmani.com/blog/ai-coding-workflow\n\nMarkdown Content:\n**AI coding assistants became game-changers in 2025, but harnessing them effectively takes skill and structure.** These tools dramatically increased what LLMs can do for real-world coding, and many developers (myself included) embraced them.\n\nAt Anthropic, for example, engineers adopted Claude Code so heavily that **today****~90% of the code for Claude Code is written by Claude Code itself**. Yet, using LLMs for programming is _not_ a push-button magic experience - it’s “difficult and unintuitive” and getting great results requires learning new patterns. Critical thinking remains key. Over a year of projects, I’ve converged on a workflow similar to what many experienced devs are discovering: treat the LLM as a powerful pair programmer that **requires clear direction, context and oversight** rather than autonomous judgment.\n\nIn this article, I’ll share how I plan, code, and collaborate with AI going into 2026, distilling tips and best practices from my experience and the community’s collective learning. It’s a more disciplined **“AI-assisted engineering”** approach - leveraging AI aggressively while **staying proudly accountable for the software produced**.\n\nIf you’re interested in more on my workflow, see “The AI-Native Software Engineer”, otherwise let’s dive straight into some of the lessons I learned.\n\n**Start with a clear plan (specs before code)**\n-----------------------------------------------\n\n**Don’t just throw wishes at the LLM - begin by defining the problem and planning a solution.**\n\nOne common mistake is diving straight into code generation with a vague prompt. In my workflow, and in many others’, the first step is **brainstorming a detailed specification**_with_ the AI, then outlining a step-by-step plan, _before_ writing any actual code. For a new project, I’ll describe the idea and ask the LLM to **iteratively ask me questions** until we’ve fleshed out requirements and edge cases. By the end, we compile this into a comprehensive **spec.md** - containing requirements, architecture decisions, data models, and even a testing strategy. This spec forms the foundation for development.\n\nNext, I feed the spec into a reasoning-capable model and prompt it to **generate a project plan**: break the implementation into logical, bite-sized tasks or milestones. The AI essentially helps me do a mini “design doc” or project plan. I often iterate on this plan - editing and asking the AI to critique or refine it - until it’s coherent and complete. _Only then_ do I proceed to coding. This upfront investment might feel slow, but it pays off enormously. As Les Orchard put it, it’s like doing a **“waterfall in 15 minutes”** - a rapid structured planning phase that makes the subsequent coding much smoother.\n\nHaving a clear spec and plan means when we unleash the codegen, both the human and the LLM know exactly what we’re building and why. In short, **planning first** forces you and the AI onto the same page and prevents wasted cycles. It’s a step many people are tempted to skip, but experienced LLM developers now treat a robust spec/plan as the cornerstone of the workflow.\n\n**Break work into small, iterative chunks**\n-------------------------------------------\n\n**Scope management is everything - feed the LLM manageable tasks, not the whole codebase at once.**\n\nA crucial lesson I’ve learned is to avoid asking the AI for large, monolithic outputs. Instead, we **break the project into iterative steps or tickets** and tackle them one by one. This mirrors good software engineering practice, but it’s even more important with AI in the loop. LLMs do best when given focused prompts: implement one function, fix one bug, add one feature at a time. For example, after planning, I will prompt the codegen model: _“Okay, let’s implement Step 1 from the plan”_. We code that, test it, then move to Step 2, and so on. Each chunk is small enough that the AI can handle it within context and you can understand the code it produces.\n\nThis approach guards against the model going off the rails. If you ask for too much in one go, it’s likely to get confused or produce a **“jumbled mess”** that’s hard to untangle. Developers report that when they tried to have an LLM generate huge swaths of an app, they ended up with inconsistency and duplication - “like 10 devs worked on it without talking to each other,” one said. I’ve felt that pain; the fix is to **stop, back up, and split the problem into smaller pieces**. Each iteration, we carry forward the context of what’s been built and incrementally add to it. This also fits nicely with a **test-driven development (TDD)** approach - we can write or generate tests for each piece as we go (more on testing soon).\n\nSeveral coding-agent tools now explicitly support this chunked workflow. For instance, I often generate a structured **“prompt plan”** file that contains a sequence of prompts for each task, so that tools like Cursor can execute them one by one. The key point is to **avoid huge leaps**. By iterating in small loops, we greatly reduce the chance of catastrophic errors and we can course-correct quickly. LLMs excel at quick, contained tasks - use that to your advantage.\n\n**Provide extensive context and guidance**\n------------------------------------------\n\n**LLMs are only as good as the context you provide - _show them_ the relevant code, docs, and constraints.**\n\nWhen working on a codebase, I make sure to **feed the AI all the information it needs** to perform well. That includes the code it should modify or refer to, the project’s technical constraints, and any known pitfalls or preferred approaches. Modern tools help with this: for example, Anthropic’s Claude can import an entire GitHub repo into its context in “Projects” mode, and IDE assistants like Cursor or Copilot auto-include open files in the prompt. But I often go further - I will either use an MCP like Context7 or manually copy important pieces of the codebase or API docs into the conversation if I suspect the model doesn’t have them.\n\nExpert LLM users emphasize this “context packing” step. For example, doing a **“brain dump”** of everything the model should know before coding, including: high-level goals and invariants, examples of good solutions, and warnings about approaches to avoid. If I’m asking an AI to implement a tricky solution, I might tell it which naive solutions are too slow, or provide a reference implementation from elsewhere. If I’m using a niche library or a brand-new API, I’ll paste in the official docs or README so the AI isn’t flying blind. All of this upfront context dramatically improves the quality of its output, because the model isn’t guessing - it has the facts and constraints in front of it.\n\nThere are now utilities to automate context packaging. I’ve experimented with tools like **gitingest** or **repo2txt**, which essentially **“dump” the relevant parts of your codebase into a text file for the LLM to read**. These can be a lifesaver when dealing with a large project - you generate an output.txt bundle of key source files and let the model ingest that. The principle is: **don’t make the AI operate on partial information**. If a bug fix requires understanding four different modules, show it those four modules. Yes, we must watch token limits, but current frontier models have pretty huge context windows (tens of thousands of tokens). Use them wisely. I often selectively include just the portions of code relevant to the task at hand, and explicitly tell the AI what _not_ to focus on if something is out of scope (to save tokens).\n\nI think **Claude Skills** have potential because they turn what used to be fragile repeated prompting into something **durable and reusable** by packaging instructions, scripts, and domain specific expertise into modular capabilities that tools can automatically apply when a request matches the Skill. This means you get more reliable and context aware results than a generic prompt ever could and you move away from one off interactions toward workflows that encode repeatable procedures and team knowledge for tasks in a consistent way. A number of community-curated Skills collections exist, but one of my favorite examples is the frontend-design skill which can “end” the purple design aesthetic prevalent in LLM generated UIs. Until more tools support Skills officially, workarounds exist.\n\nFinally, **guide the AI with comments and rules inside the prompt**. I might precede a code snippet with: “Here is the current implementation of X. We need to extend it to do Y, but be careful not to break Z.” These little hints go a long way. LLMs are **literalists** - they’ll follow instructions, so give them detailed, contextual instructions. By proactively providing context and guidance, we minimize hallucinations and off-base suggestions and get code that fits our project’s needs.\n\n**Choose the right model (and use multiple when needed)**\n---------------------------------------------------------\n\n**Not all coding LLMs are equal - pick your tool with intention, and don’t be afraid to swap models mid-stream.**\n\nIn 2025 we’ve been spoiled with a variety of capable code-focused LLMs. Part of my workflow is **choosing the model or service best suited to each task**. Sometimes it can be valuable to even try two or more LLMs in parallel to cross-check how they might approach the same problem differently.\n\nEach model has its own “personality”. The key is: **if one model gets stuck or gives mediocre outputs, try another.** I’ve literally copied the same prompt from one chat into another service to see if it can handle it better. This “model musical chairs” can rescue you when you hit a model’s blind spot.\n\nAlso, make sure you’re using _the best version_ available. If you can, use the newest “pro” tier models - because quality matters. And yes, it often means paying for access, but the productivity gains can justify it. Ultimately, pick the AI pair programmer whose **“vibe” meshes with you**. I know folks who prefer one model simply because they like how its responses _feel_. That’s valid - when you’re essentially in a constant dialogue with an AI, the UX and tone make a difference.\n\nPersonally I gravitate towards Gemini for a lot of coding work these days because the interaction feels more natural and it often understands my requests on the first try. But I will not hesitate to switch to another model if needed; sometimes a second opinion helps the solution emerge. In summary: **use the best tool for the job, and remember you have an arsenal of AIs at your disposal.**\n\n**Leverage AI coding across the lifecycle**\n-------------------------------------------\n\n**Supercharge your workflow with coding-specific AI help across the SDLC.**\n\nOn the command-line, new AI agents emerged. **Claude Code, OpenAI’s Codex CLI** and **Google’s Gemini CLI** are CLI tools where you can chat with them directly in your project directory - they can read files, run tests, and even multi-step fix issues. I’ve used Google’s **Jules** and GitHub’s **Copilot Agent** as well - these are **asynchronous coding agents** that actually clone your repo into a cloud VM and work on tasks in the background (writing tests, fixing bugs, then opening a PR for you). It’s a bit eerie to witness: you issue a command like “refactor the payment module for X” and a little while later you get a pull request with code changes and passing tests. We are truly living in the future. You can read more about this in conductors to orchestrators.\n\nThat said, **these tools are not infallible, and you must understand their limits**. They accelerate the mechanical parts of coding - generating boilerplate, applying repetitive changes, running tests automatically - but they still benefit greatly from your guidance. For instance, when I use an agent like Claude or Copilot to implement something, I often supply it with the plan or to-do list from earlier steps so it knows the exact sequence of tasks. If the agent supports it, I’ll load up my spec.md or plan.md in the context before telling it to execute. This keeps it on track.\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://zencoder.ai/blog/vibe-coding-best-practices","title":"5 Vibe Coding Best Practices to Implement in Your Workflow","content":"【4†5 Vibe Coding Best Practices to Implement in Your Workflow†https://zencoder.ai/blog/vibe-coding-best-practices】\nTitle: 5 Vibe Coding Best Practices to Implement in Your Workflow\n\nURL Source: https://zencoder.ai/blog/vibe-coding-best-practices\n\nPublished Time: 2025-04-02T16:10:41.000Z\n\nMarkdown Content:\nIn the world of software development, new methodologies and tools are constantly emerging to improve efficiency, accessibility, and innovation. One such approach that has gained significant traction is vibe coding, an AI-assisted paradigm that leverages natural language processing to transform human instructions into functional code. As developers increasingly adopt this cutting-edge methodology, understanding and implementing best practices becomes essential to ensure code quality, maintain productivity, and maximize the benefits of this transformative approach.\n\nThis article explores five key vibe coding best practices that every software engineer should incorporate into their workflow. From crafting clear prompts to embedding security measures, these strategies will help you harness the full potential of vibe coding while avoiding common pitfalls.\n\nLet’s dive in!\n\n### What is Vibe Coding?\n\nBefore diving into the best practices, it’s important to understand what vibe coding is and why it’s reshaping the software development landscape.\n\nVibe coding represents a shift from traditional coding methodologies by integrating AI tools that interpret natural language instructions and generate code accordingly. This approach not only accelerates development but also makes coding more accessible to individuals with limited programming experience.\n\n#### Definition and Core Concept\n\nAt its core, vibe coding relies on AI-powered tools to bridge the gap between human intent and machine execution. Developers provide detailed prompts or specifications in natural language, and the AI translates these into executable code. Unlike traditional coding, which requires a deep understanding of syntax and programming languages, vibe coding allows developers to focus on the \"what\" rather than the \"how.\"\n\nThis methodology has its roots in advancements in AI and machine learning, particularly in natural language processing (NLP). Tools like GitHub Copilot,Zencoder, and other AI-driven platforms have made it possible to generate code snippets, debug errors, and even create entire applications based on user input.\n\n#### Impact on Modern Software Development\n\nVibe coding is revolutionizing software development in several ways:\n\n*   **Accelerated Development:** By automating repetitive tasks and generating code quickly, vibe coding significantly reduces development time. Developers can focus on refining and optimizing the code rather than starting from scratch.\n*   **Enhanced Accessibility:** Non-technical stakeholders can contribute to the development process by providing natural language instructions, fostering greater collaboration between technical and non-technical teams.\n*   **Rapid Prototyping:** Developers can quickly create prototypes and iterate on ideas, enabling faster innovation and experimentation. This is particularly useful in startups and agile environments where speed is critical.\n\nFor example, tools like Zencoder allow developers to write comments describing desired functionality, and the AI generates corresponding code. This capability is particularly useful for tasks like creating boilerplate code, automating tests, or implementing standard algorithms.\n\n### Best Practice #1: Define Clear and Detailed Prompts\n\nThe foundation of effective vibe coding lies in the quality of the prompts you provide. Since AI tools rely on natural language input to generate code, ambiguous or incomplete instructions can lead to errors, misinterpretations, and wasted time.\n\n#### Writing Effective Prompts\n\nTo ensure accurate code generation, follow these guidelines when crafting prompts:\n\n1.   **Be Specific:** Clearly define the desired functionality, including input parameters, expected outputs, and any constraints. For example, instead of saying, \"Create a function to process data,\" specify, \"Write a Python function that takes a CSV file as input, filters rows where the 'status' column equals 'active,' and returns the filtered data as a list of dictionaries.\"\n2.   **Use Context:** Provide relevant context, such as the programming language, framework, or libraries to be used. This helps the AI tailor its output to your requirements.\n3.   **Break Down Complex Tasks:** Divide large tasks into smaller, manageable components. For instance, instead of asking for a complete web application, start with individual features like user authentication or database integration.\n\nHere’s how easy it is to do so with Zencoder directly into your favouride IDE:\n\n#### Benefits of Clarity\n\nClear prompts not only improve the accuracy of AI-generated code but also reduce the time spent on debugging and revisions. By minimizing misinterpretations, you can achieve higher-quality results on the first attempt, ultimately enhancing productivity and efficiency.\n\nAdditionally, clear prompts help the AI understand the nuances of your requirements. For example, specifying the desired output format (e.g., JSON, XML, or plain text) ensures that the generated code aligns with your expectations.\n\n### Best Practice #2: Adopt an incremental and Interative Approach\n\nVibe coding is most effective when used in an incremental and iterative manner. Rather than attempting to generate an entire project in one go, break it down into smaller components and refine each step through continuous testing and feedback.\n\n#### Breaking Down Tasks\n\nDecomposing complex projects into discrete tasks allows you to focus on one aspect of the code at a time. For example, if you’re building an e-commerce platform, you might start with user registration, then move on to product listing, shopping cart functionality, and payment integration. This approach not only simplifies the development process but also makes it easier to identify and address issues as they arise.\n\nBreaking down tasks also allows you to test individual components in isolation, ensuring that each part functions correctly before integrating it into the larger system.\n\n#### Interative Refinement and Testing\n\nOnce the AI generates code, test it immediately to ensure it meets your requirements. Use feedback loops to refine the code, either by adjusting the prompt or manually editing the output. For instance, if the AI-generated code for a login feature lacks proper error handling, you can update the prompt to include this requirement and regenerate the code.\n\nIterative refinement is particularly important when working with AI-generated code, as it allows you to catch errors early and ensure the final product meets your standards. This approach also helps you build confidence in the AI’s capabilities while maintaining control over the development process.\n\n### Best Practice #3: Utilize Robust Version Control\n\nMaintaining an organized and well-documented codebase is essential when working with AI-generated code. Version control systems like Git provide a structured way to manage changes, collaborate with team members, and track the evolution of your project.\n\n#### Branching Strategies and Regular Commits\n\nAdopt best practices for version control, such as:\n\n*   **Creating Branches:** Use separate branches for different features or tasks to avoid conflicts and maintain a clean main branch.\n*   **Making Regular Commits:** Commit changes frequently with descriptive messages to document progress and make it easier to identify issues.\n*   **Merging Carefully:** Review and test code thoroughly before merging branches to ensure stability.\n\n#### Code Reviews and Documentation\n\nPeer reviews are invaluable for maintaining code quality and catching errors that may have been overlooked. Additionally, thorough documentation helps team members understand the purpose and functionality of the code, facilitating collaboration and long-term maintainability.\n\nFor AI-generated code, documentation is especially important, as it provides context for why certain decisions were made and how the code is intended to function.\n\n### Best Practice #4: Automate Testing and Debugging Processes\n\nAutomated testing is a cornerstone of modern software development, and it’s especially important when working with AI-generated code. By implementing automated testing frameworks, you can ensure code reliability and detect errors early in the development cycle.\n\n#### Implementing Continuous Integration/Testing\n\nContinuous integration (CI) tools like Jenkins, Travis CI, or GitHub Actions can automate the testing process, running unit tests, integration tests, and other checks whenever new code is added. This ensures that your codebase remains stable and functional as it evolves.\n\n#### Strategies for Debugging AI-Generated Code\n\nDebugging AI-generated code can be challenging, as the logic may not always align with human expectations. To address this, consider the following techniques:\n\n*   **Use Logging:** Add logging statements to track the flow of execution and identify potential issues.\n*   **Verify Step-by-Step:** Break down the code into smaller sections and test each part individually.\n*   **Leverage AI for Debugging:** Some AI tools can assist in identifying and fixing errors, saving time and effort.\n\nBest Practice #5: Embed Security and Quality Assurance into Your Workflow\n\nSecurity and quality assurance should be integral to your vibe coding workflow. By incorporating these practices from the outset, you can minimize vulnerabilities and ensure the long-term maintainability of your code.\n\n#### Incorporating Security Best Practices\n\nWhen using AI tools, explicitly include security requirements in your prompts. For example, if you’re generating code for a web application, specify that it should include input validation, authentication, and protection against common vulnerabilities like SQL injection and cross-site scripting (XSS).\n\nAdditionally, use automated security scanning tools to identify potential issues in your codebase. Tools like Snyk, SonarQube, and Dependabot can help detect vulnerabilities and suggest fixes.\n\n#### Regular Audits and Peer Reviews\n\nConduct regular code audits to identify areas for improvement and ensure compliance with security standards. Foster a culture of peer review, where team members collaborate to maintain code quality and reduce technical debt.\n\n### Conclusion\n\nVibe coding is a powerful tool that has the potential to transform software development by making it faster, more accessible, and more efficient. However, to fully realize its benefits, developers must adopt best practices that address the unique challenges of this approach.\n\nAs AI technology continues to advance, vibe coding is likely to become even more sophisticated, enabling developers to tackle increasingly complex projects with ease. Future improvements in AI capabilities, such as better contextual understanding and enhanced debugging tools, will further enhance the potential of vibe coding.\n\nBy staying informed about emerging trends and continuously refining your workflow, you can stay ahead of the curve and make the most of this exciting new paradigm in software development.\n\n**How Zencoder Can Help**\n\nZencoder, an advanced AI agent, offers powerful abilities to help developers in their daily work, superpowering your vibe coding habits. By leveraging machine learning algorithms, Zencoder analyzes existing code to identify patterns and suggest optimizations, reducing the risk of errors during the transition.\n\nThe tool also provides automated refactoring and dependency management, ensuring that the code is compatible with new frameworks.\n\nTry out Zencoder and share your experience by leaving a comment below. Don’t forget to subscribe to Zencoder to stay informed about the latest AI-driven strategies for improving your code governance. Your insights, questions, and feedback can help shape the future of coding practices.\n\n"},"metadata":{"arguments":"{\"link_id\":4}","display_result":"","duration":"5s","id":"call_6ZQx5dv38X","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【4†5 Vibe Coding Best Practices to Implement in Your Workflow†https://zencoder.ai/blog/vibe-coding-best-practices】\nTitle: 5 Vibe Coding Best Practices to Implement in Your Workflow\n\nURL Source: https://zencoder.ai/blog/vibe-coding-best-practices\n\nPublished Time: 2025-04-02T16:10:41.000Z\n\nMarkdown Content:\nIn the world of software development, new methodologies and tools are constantly emerging to improve efficiency, accessibility, and innovation. One such approach that has gained significant traction is vibe coding, an AI-assisted paradigm that leverages natural language processing to transform human instructions into functional code. As developers increasingly adopt this cutting-edge methodology, understanding and implementing best practices becomes essential to ensure code quality, maintain productivity, and maximize the benefits of this transformative approach.\n\nThis article explores five key vibe coding best practices that every software engineer should incorporate into their workflow. From crafting clear prompts to embedding security measures, these strategies will help you harness the full potential of vibe coding while avoiding common pitfalls.\n\nLet’s dive in!\n\n### What is Vibe Coding?\n\nBefore diving into the best practices, it’s important to understand what vibe coding is and why it’s reshaping the software development landscape.\n\nVibe coding represents a shift from traditional coding methodologies by integrating AI tools that interpret natural language instructions and generate code accordingly. This approach not only accelerates development but also makes coding more accessible to individuals with limited programming experience.\n\n#### Definition and Core Concept\n\nAt its core, vibe coding relies on AI-powered tools to bridge the gap between human intent and machine execution. Developers provide detailed prompts or specifications in natural language, and the AI translates these into executable code. Unlike traditional coding, which requires a deep understanding of syntax and programming languages, vibe coding allows developers to focus on the \"what\" rather than the \"how.\"\n\nThis methodology has its roots in advancements in AI and machine learning, particularly in natural language processing (NLP). Tools like GitHub Copilot,Zencoder, and other AI-driven platforms have made it possible to generate code snippets, debug errors, and even create entire applications based on user input.\n\n#### Impact on Modern Software Development\n\nVibe coding is revolutionizing software development in several ways:\n\n*   **Accelerated Development:** By automating repetitive tasks and generating code quickly, vibe coding significantly reduces development time. Developers can focus on refining and optimizing the code rather than starting from scratch.\n*   **Enhanced Accessibility:** Non-technical stakeholders can contribute to the development process by providing natural language instructions, fostering greater collaboration between technical and non-technical teams.\n*   **Rapid Prototyping:** Developers can quickly create prototypes and iterate on ideas, enabling faster innovation and experimentation. This is particularly useful in startups and agile environments where speed is critical.\n\nFor example, tools like Zencoder allow developers to write comments describing desired functionality, and the AI generates corresponding code. This capability is particularly useful for tasks like creating boilerplate code, automating tests, or implementing standard algorithms.\n\n### Best Practice #1: Define Clear and Detailed Prompts\n\nThe foundation of effective vibe coding lies in the quality of the prompts you provide. Since AI tools rely on natural language input to generate code, ambiguous or incomplete instructions can lead to errors, misinterpretations, and wasted time.\n\n#### Writing Effective Prompts\n\nTo ensure accurate code generation, follow these guidelines when crafting prompts:\n\n1.   **Be Specific:** Clearly define the desired functionality, including input parameters, expected outputs, and any constraints. For example, instead of saying, \"Create a function to process data,\" specify, \"Write a Python function that takes a CSV file as input, filters rows where the 'status' column equals 'active,' and returns the filtered data as a list of dictionaries.\"\n2.   **Use Context:** Provide relevant context, such as the programming language, framework, or libraries to be used. This helps the AI tailor its output to your requirements.\n3.   **Break Down Complex Tasks:** Divide large tasks into smaller, manageable components. For instance, instead of asking for a complete web application, start with individual features like user authentication or database integration.\n\nHere’s how easy it is to do so with Zencoder directly into your favouride IDE:\n\n#### Benefits of Clarity\n\nClear prompts not only improve the accuracy of AI-generated code but also reduce the time spent on debugging and revisions. By minimizing misinterpretations, you can achieve higher-quality results on the first attempt, ultimately enhancing productivity and efficiency.\n\nAdditionally, clear prompts help the AI understand the nuances of your requirements. For example, specifying the desired output format (e.g., JSON, XML, or plain text) ensures that the generated code aligns with your expectations.\n\n### Best Practice #2: Adopt an incremental and Interative Approach\n\nVibe coding is most effective when used in an incremental and iterative manner. Rather than attempting to generate an entire project in one go, break it down into smaller components and refine each step through continuous testing and feedback.\n\n#### Breaking Down Tasks\n\nDecomposing complex projects into discrete tasks allows you to focus on one aspect of the code at a time. For example, if you’re building an e-commerce platform, you might start with user registration, then move on to product listing, shopping cart functionality, and payment integration. This approach not only simplifies the development process but also makes it easier to identify and address issues as they arise.\n\nBreaking down tasks also allows you to test individual components in isolation, ensuring that each part functions correctly before integrating it into the larger system.\n\n#### Interative Refinement and Testing\n\nOnce the AI generates code, test it immediately to ensure it meets your requirements. Use feedback loops to refine the code, either by adjusting the prompt or manually editing the output. For instance, if the AI-generated code for a login feature lacks proper error handling, you can update the prompt to include this requirement and regenerate the code.\n\nIterative refinement is particularly important when working with AI-generated code, as it allows you to catch errors early and ensure the final product meets your standards. This approach also helps you build confidence in the AI’s capabilities while maintaining control over the development process.\n\n### Best Practice #3: Utilize Robust Version Control\n\nMaintaining an organized and well-documented codebase is essential when working with AI-generated code. Version control systems like Git provide a structured way to manage changes, collaborate with team members, and track the evolution of your project.\n\n#### Branching Strategies and Regular Commits\n\nAdopt best practices for version control, such as:\n\n*   **Creating Branches:** Use separate branches for different features or tasks to avoid conflicts and maintain a clean main branch.\n*   **Making Regular Commits:** Commit changes frequently with descriptive messages to document progress and make it easier to identify issues.\n*   **Merging Carefully:** Review and test code thoroughly before merging branches to ensure stability.\n\n#### Code Reviews and Documentation\n\nPeer reviews are invaluable for maintaining code quality and catching errors that may have been overlooked. Additionally, thorough documentation helps team members understand the purpose and functionality of the code, facilitating collaboration and long-term maintainability.\n\nFor AI-generated code, documentation is especially important, as it provides context for why certain decisions were made and how the code is intended to function.\n\n### Best Practice #4: Automate Testing and Debugging Processes\n\nAutomated testing is a cornerstone of modern software development, and it’s especially important when working with AI-generated code. By implementing automated testing frameworks, you can ensure code reliability and detect errors early in the development cycle.\n\n#### Implementing Continuous Integration/Testing\n\nContinuous integration (CI) tools like Jenkins, Travis CI, or GitHub Actions can automate the testing process, running unit tests, integration tests, and other checks whenever new code is added. This ensures that your codebase remains stable and functional as it evolves.\n\n#### Strategies for Debugging AI-Generated Code\n\nDebugging AI-generated code can be challenging, as the logic may not always align with human expectations. To address this, consider the following techniques:\n\n*   **Use Logging:** Add logging statements to track the flow of execution and identify potential issues.\n*   **Verify Step-by-Step:** Break down the code into smaller sections and test each part individually.\n*   **Leverage AI for Debugging:** Some AI tools can assist in identifying and fixing errors, saving time and effort.\n\nBest Practice #5: Embed Security and Quality Assurance into Your Workflow\n\nSecurity and quality assurance should be integral to your vibe coding workflow. By incorporating these practices from the outset, you can minimize vulnerabilities and ensure the long-term maintainability of your code.\n\n#### Incorporating Security Best Practices\n\nWhen using AI tools, explicitly include security requirements in your prompts. For example, if you’re generating code for a web application, specify that it should include input validation, authentication, and protection against common vulnerabilities like SQL injection and cross-site scripting (XSS).\n\nAdditionally, use automated security scanning tools to identify potential issues in your codebase. Tools like Snyk, SonarQube, and Dependabot can help detect vulnerabilities and suggest fixes.\n\n#### Regular Audits and Peer Reviews\n\nConduct regular code audits to identify areas for improvement and ensure compliance with security standards. Foster a culture of peer review, where team members collaborate to maintain code quality and reduce technical debt.\n\n### Conclusion\n\nVibe coding is a powerful tool that has the potential to transform software development by making it faster, more accessible, and more efficient. However, to fully realize its benefits, developers must adopt best practices that address the unique challenges of this approach.\n\nAs AI technology continues to advance, vibe coding is likely to become even more sophisticated, enabling developers to tackle increasingly complex projects with ease. Future improvements in AI capabilities, such as better contextual understanding and enhanced debugging tools, will further enhance the potential of vibe coding.\n\nBy staying informed about emerging trends and continuously refining your workflow, you can stay ahead of the curve and make the most of this exciting new paradigm in software development.\n\n**How Zencoder Can Help**\n\nZencoder, an advanced AI agent, offers powerful abilities to help developers in their daily work, superpowering your vibe coding habits. By leveraging machine learning algorithms, Zencoder analyzes existing code to identify patterns and suggest optimizations, reducing the risk of errors during the transition.\n\nThe tool also provides automated refactoring and dependency management, ensuring that the code is compatible with new frameworks.\n\nTry out Zencoder and share your experience by leaving a comment below. Don’t forget to subscribe to Zencoder to stay informed about the latest AI-driven strategies for improving your code governance. Your insights, questions, and feedback can help shape the future of coding practices.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://almcorp.com/blog/vibe-coding-complete-guide","title":"Vibe Coding: Complete Guide to AI-Assisted Software","content":"【8†Vibe Coding: Complete Guide to AI-Assisted Software†https://almcorp.com/blog/vibe-coding-complete-guide】\nTitle: Vibe Coding: The Complete Guide to AI-Assisted Software Development\n\nURL Source: https://almcorp.com/blog/vibe-coding-complete-guide\n\nPublished Time: 2025-12-20T04:34:28+00:00\n\nMarkdown Content:\nThe software development landscape is experiencing a seismic shift. For decades, creating functional applications required mastering programming languages, understanding complex frameworks, and spending countless hours writing, debugging, and refining code. But what if you could build sophisticated software simply by describing what you want in plain English? Welcome to the era of vibe coding—a revolutionary approach that’s democratizing software development and transforming how we think about creating digital products.\n\n**What Is Vibe Coding? Understanding the Revolutionary Development Method**\n---------------------------------------------------------------------------\n\nVibe coding represents a fundamental paradigm shift in how software gets built. At its core, it’s an AI-assisted software development technique where developers—or even non-developers—communicate their intentions using natural language, and artificial intelligence translates those instructions into functional, executable code.\n\nThe term “vibe coding” was coined by**Andrej Karpathy**, the renowned computer scientist and former Director of AI at Tesla, in February 2025. In his influential social media post, Karpathy described it as “a new kind of coding where you fully give in to the vibes, embrace exponentials, and forget that the code even exists.” This seemingly casual description captures something profound: the ability to focus entirely on**what**you want to build rather than**how**to build it.\n\nUnlike traditional programming, where developers must manually write every line of code with precise syntax, vibe coding allows you to work at a higher level of abstraction. You’re essentially having a conversation with an AI assistant, describing your vision, iterating on ideas, and refining functionality—all without diving deep into technical implementation details.\n\nThe rise of vibe coding isn’t accidental. It’s been made possible by dramatic advances in large language models (LLMs) like GPT-4, Claude, and Gemini. These AI systems have been trained on billions of lines of code across dozens of programming languages, enabling them to understand context, generate syntactically correct code, and even debug errors. The result? A development experience that feels less like programming and more like collaborative problem-solving.\n\n**The Origin Story: How Vibe Coding Emerged from AI Innovation**\n----------------------------------------------------------------\n\nTo truly understand vibe coding, we need to trace its evolutionary path. The journey began with simple code autocompletion tools that could suggest the next line based on context. GitHub Copilot, launched in 2021, represented an early milestone—it could generate entire functions based on comments or partial code.\n\nBut these were still assistive tools for developers who understood programming. The real breakthrough came when LLMs became sophisticated enough to understand high-level instructions and translate them into complete, working applications. This wasn’t just autocomplete on steroids; it was a fundamentally different way of creating software.\n\nAndrej Karpathy’s February 2025 tweet crystallized something that developers were already experiencing: the ability to build without traditional coding constraints. His term “vibe coding” resonated because it captured the intuitive, almost improvisational nature of this new approach. You’re working with the “vibes” or essence of what you want to create, trusting AI to handle the technical minutiae.\n\nWithin weeks, “vibe coding” became more than industry jargon. It was added to Merriam-Webster’s “slang & trending” terms and ultimately named Collins Dictionary’s Word of the Year for 2025—a testament to its cultural impact beyond the tech community.\n\n**How Vibe Coding Works: The Technical Foundation Explained**\n-------------------------------------------------------------\n\nWhile the user experience of vibe coding feels magical, understanding the mechanics helps you use it more effectively. Here’s what happens beneath the surface:\n\n### **The AI Processing Pipeline**\n\nWhen you provide a natural language instruction like “Create a task management app with user authentication and a dashboard showing incomplete tasks,” the AI goes through several sophisticated steps:\n\n1.   **Intent Understanding**: The LLM analyzes your prompt to identify key requirements—a task management system, authentication functionality, and a filtered dashboard view.\n\n2.   **Architecture Planning**: Based on its training, the AI determines an appropriate technical architecture. Should this be a React frontend with a Node.js backend? What database makes sense? What authentication library is best suited?\n\n3.   **Code Generation**: The AI writes the necessary code across multiple files—component structures, API endpoints, database schemas, and styling—ensuring they work together cohesively.\n\n4.   **Dependency Management**: It identifies and includes required libraries, configures build tools, and sets up the development environment.\n\n5.   **Testing and Refinement**: Advanced vibe coding platforms can even run the code, identify errors, and self-correct before presenting the result.\n\n### **The Iterative Conversation Model**\n\nEffective vibe coding rarely happens with a single prompt. Instead, it’s a conversation:\n\n*   **Initial Prompt**: “Build a recipe sharing website”\n*   **AI Response**: Generates basic structure with recipe listings\n*   **Refinement 1**: “Add user profiles and the ability to favorite recipes”\n*   **AI Response**: Implements user authentication and favorite functionality\n*   **Refinement 2**: “Include search and filtering by cuisine type”\n*   **AI Response**: Adds search functionality with filter options\n\nEach iteration builds upon the previous state, with the AI maintaining context about what’s already been created. This conversational approach mirrors how you might work with a human developer, except the AI responds in seconds rather than hours.\n\n**Vibe Coding vs. Traditional Coding: A Comprehensive Comparison**\n------------------------------------------------------------------\n\nUnderstanding where vibe coding fits in the development ecosystem requires comparing it to conventional approaches:\n\n### **Development Speed and Efficiency**\n\n**Traditional Coding**: A skilled developer might spend days or weeks building a functional prototype. They need to set up the development environment, choose and configure frameworks, write boilerplate code, implement business logic, handle edge cases, and debug issues.\n\n**Vibe Coding**: The same prototype can materialize in hours—sometimes minutes. The AI handles setup, configuration, and standard implementations instantly. According to recent studies, developers using vibe coding tools report productivity increases of 3-5x for common development tasks.\n\n### **Skill Requirements and Accessibility**\n\n**Traditional Coding**: Requires months to years of learning programming languages, frameworks, design patterns, and best practices. The barrier to entry is high, limiting who can create software.\n\n**Vibe Coding**: Dramatically lowers the skill floor. While technical knowledge still helps (especially for refinement and debugging), non-programmers can now build functional applications. Product managers, designers, entrepreneurs, and domain experts can translate their ideas directly into code.\n\n### **Control and Precision**\n\n**Traditional Coding**: Developers have complete control over every aspect of their code—architecture decisions, performance optimizations, security implementations, and edge case handling.\n\n**Vibe Coding**: Offers less granular control. You’re trusting the AI to make reasonable technical decisions. While you can provide increasingly specific prompts, there’s an inherent trade-off between ease-of-use and precision.\n\n### **Code Quality and Maintainability**\n\n**Traditional Coding**: Experienced developers write clean, documented, maintainable code following established patterns. Code quality depends entirely on the developer’s skill and discipline.\n\n**Vibe Coding**: Code quality varies significantly. AI-generated code might be verbose, use outdated patterns, or lack proper documentation. Research from Veracode indicates that approximately 45% of AI-generated code contains security vulnerabilities that require human review and correction.\n\n### **Ideal Use Cases**\n\n**Traditional Coding Excels For**:\n\n*   Mission-critical systems requiring absolute reliability\n*   Complex, custom solutions with unique requirements\n*   Applications demanding optimal performance\n*   Projects where long-term maintainability is paramount\n*   Systems requiring deep domain-specific knowledge\n\n**Vibe Coding Excels For**:\n\n*   Rapid prototyping and MVP development\n*   Internal tools with straightforward requirements\n*   Learning and educational projects\n*   Automating repetitive coding tasks\n*   Validating ideas before full development investment\n\n**The Vibe Coding Tool Ecosystem: Platforms and Technologies**\n--------------------------------------------------------------\n\nThe vibe coding landscape features diverse platforms, each with distinct strengths. Understanding these tools helps you choose the right solution for your needs.\n\n### **Replit: The Complete Vibe Coding Experience**\n\n**Replit**has positioned itself as the premier vibe coding platform by offering an integrated, browser-based environment that eliminates setup friction. Their**Replit Agent**feature allows you to describe an application in natural language, and the AI handles everything—from setting up the development environment to writing code across multiple files to deploying the final product.\n\nWhat distinguishes Replit is its holistic approach. Unlike tools that just generate code, Replit provides built-in databases, object storage, authentication systems, and one-click deployment. This end-to-end integration means you can go from idea to live, publicly accessible application without ever leaving the platform. According to Replit CEO Amjad Masad, 75% of their customers don’t write any code manually—they’re pure vibe coders.\n\n**Best For**: Non-technical founders, rapid prototyping, educational projects, anyone wanting the simplest path from idea to deployed application.\n\n### **Cursor: The Developer’s Vibe Coding Tool**\n\n**Cursor**takes a different approach, positioning itself as an AI-enhanced replacement for traditional code editors like VS Code. Rather than generating entire applications from scratch, Cursor excels at augmenting the development workflow with intelligent code suggestions, contextual completions, and conversational debugging.\n\nCursor integrates multiple AI models (including GPT-4, Claude, and others), allowing developers to choose the best model for their specific task. Its**Composer**feature enables multi-file editing, where you can describe changes and watch Cursor modify code across your entire project intelligently.\n\n**Best For**: Experienced developers seeking productivity enhancement, teams working with existing codebases, projects requiring precise control alongside AI assistance.\n\n### **Windsurf: The Agentic Coding Platform**\n\n**Windsurf**, developed by Codeium, represents the next evolution in AI-assisted development with its agentic coding approach. Unlike tools that wait for instructions, Windsurf’s**Cascade**AI agent can understand project context, anticipate needs, and proactively suggest improvements.\n\nThe platform excels at understanding complex codebases and maintaining consistency across large projects. Windsurf’s AI doesn’t just respond to prompts—it actively participates in the development process, identifying opportunities for refactoring, spotting potential bugs, and suggesting architectural improvements.\n\n**Best For**: Medium to large projects, teams needing intelligent code analysis, developers who want an AI “pair programmer” that proactively contributes.\n\n### **GitHub Copilot: AI-Powered Code Completion**\n\n**GitHub Copilot**, backed by OpenAI technology, pioneered mainstream AI-assisted coding. While not a pure vibe coding platform (it doesn’t generate entire applications from descriptions), Copilot excels at context-aware code suggestions within your existing development environment.\n\nRecent versions include**Copilot Chat**, which brings conversational coding to the tool. You can ask questions, request code explanations, and get debugging help directly in your editor.\n\n**Best For**: Developers who prefer their existing development environment, teams already using GitHub, incremental productivity enhancement rather than full vibe coding.\n\n### **Claude Code: Conversational Development**\n\n**Claude Code**leverages Anthropic’s Claude AI model for development tasks. Its strength lies in understanding complex, nuanced instructions and generating thoughtful, well-structured code. Claude particularly excels at explaining its reasoning, making it valuable for learning and understanding the code it generates.\n\n**Best For**: Complex problem-solving, situations requiring detailed explanations, developers who want to understand and learn from AI-generated code.\n\n### **Platform Comparison Matrix**\n\n| Platform | Best For | Learning Curve | Deployment | Pricing Model |\n| --- | --- | --- | --- | --- |\n| **Replit** | Complete beginners, rapid deployment | Easiest | Integrated | Freemium |\n| **Cursor** | Experienced developers | Moderate | External | Subscription |\n| **Windsurf** | Agentic development, large projects | Moderate | External | Freemium |\n| **GitHub Copilot** | Existing developer workflows | Low | External | Subscription |\n| **Claude Code** | Complex reasoning, learning | Low | External | Pay-per-use |\n\n**Vibe Coding in Practice: Real-World Applications and Success Stories**\n------------------------------------------------------------------------\n\nThe theoretical promise of vibe coding becomes compelling when we examine real-world implementations across industries.\n\n### **Startup Velocity: From Concept to Market in Days**\n\n**Menlo Park Lab**, a generative AI startup founded by Misbah Syed, exemplifies vibe coding’s potential. Using AI-assisted development, Syed built**Brainy Docs**—a tool that transforms PDF documents into explainer videos with slides—with minimal manual coding. What might have taken a team of developers months was accomplished in weeks, allowing rapid iteration based on user feedback.\n\nThis acceleration isn’t unique. According to Y Combinator, approximately 25% of their portfolio companies now use vibe coding techniques for initial development, enabling founders to validate product-market fit before investing in traditional engineering teams.\n\n### **Enterprise Efficiency: Accenture and IBM’s AI Integration**\n\nLarge consultancies like**Accenture**and**IBM**have quietly leveraged proto-vibe coding techniques for years. These organizations often have teams where only a fraction possess deep programming expertise, while others work with predefined APIs and frameworks—essentially “vibing” their way through projects by following patterns rather than writing from scratch.\n\n\n"},"metadata":{"arguments":"{\"link_id\":8}","display_result":"","duration":"5s","id":"call_6vyhowUXM5","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【8†Vibe Coding: Complete Guide to AI-Assisted Software†https://almcorp.com/blog/vibe-coding-complete-guide】\nTitle: Vibe Coding: The Complete Guide to AI-Assisted Software Development\n\nURL Source: https://almcorp.com/blog/vibe-coding-complete-guide\n\nPublished Time: 2025-12-20T04:34:28+00:00\n\nMarkdown Content:\nThe software development landscape is experiencing a seismic shift. For decades, creating functional applications required mastering programming languages, understanding complex frameworks, and spending countless hours writing, debugging, and refining code. But what if you could build sophisticated software simply by describing what you want in plain English? Welcome to the era of vibe coding—a revolutionary approach that’s democratizing software development and transforming how we think about creating digital products.\n\n**What Is Vibe Coding? Understanding the Revolutionary Development Method**\n---------------------------------------------------------------------------\n\nVibe coding represents a fundamental paradigm shift in how software gets built. At its core, it’s an AI-assisted software development technique where developers—or even non-developers—communicate their intentions using natural language, and artificial intelligence translates those instructions into functional, executable code.\n\nThe term “vibe coding” was coined by**Andrej Karpathy**, the renowned computer scientist and former Director of AI at Tesla, in February 2025. In his influential social media post, Karpathy described it as “a new kind of coding where you fully give in to the vibes, embrace exponentials, and forget that the code even exists.” This seemingly casual description captures something profound: the ability to focus entirely on**what**you want to build rather than**how**to build it.\n\nUnlike traditional programming, where developers must manually write every line of code with precise syntax, vibe coding allows you to work at a higher level of abstraction. You’re essentially having a conversation with an AI assistant, describing your vision, iterating on ideas, and refining functionality—all without diving deep into technical implementation details.\n\nThe rise of vibe coding isn’t accidental. It’s been made possible by dramatic advances in large language models (LLMs) like GPT-4, Claude, and Gemini. These AI systems have been trained on billions of lines of code across dozens of programming languages, enabling them to understand context, generate syntactically correct code, and even debug errors. The result? A development experience that feels less like programming and more like collaborative problem-solving.\n\n**The Origin Story: How Vibe Coding Emerged from AI Innovation**\n----------------------------------------------------------------\n\nTo truly understand vibe coding, we need to trace its evolutionary path. The journey began with simple code autocompletion tools that could suggest the next line based on context. GitHub Copilot, launched in 2021, represented an early milestone—it could generate entire functions based on comments or partial code.\n\nBut these were still assistive tools for developers who understood programming. The real breakthrough came when LLMs became sophisticated enough to understand high-level instructions and translate them into complete, working applications. This wasn’t just autocomplete on steroids; it was a fundamentally different way of creating software.\n\nAndrej Karpathy’s February 2025 tweet crystallized something that developers were already experiencing: the ability to build without traditional coding constraints. His term “vibe coding” resonated because it captured the intuitive, almost improvisational nature of this new approach. You’re working with the “vibes” or essence of what you want to create, trusting AI to handle the technical minutiae.\n\nWithin weeks, “vibe coding” became more than industry jargon. It was added to Merriam-Webster’s “slang & trending” terms and ultimately named Collins Dictionary’s Word of the Year for 2025—a testament to its cultural impact beyond the tech community.\n\n**How Vibe Coding Works: The Technical Foundation Explained**\n-------------------------------------------------------------\n\nWhile the user experience of vibe coding feels magical, understanding the mechanics helps you use it more effectively. Here’s what happens beneath the surface:\n\n### **The AI Processing Pipeline**\n\nWhen you provide a natural language instruction like “Create a task management app with user authentication and a dashboard showing incomplete tasks,” the AI goes through several sophisticated steps:\n\n1.   **Intent Understanding**: The LLM analyzes your prompt to identify key requirements—a task management system, authentication functionality, and a filtered dashboard view.\n\n2.   **Architecture Planning**: Based on its training, the AI determines an appropriate technical architecture. Should this be a React frontend with a Node.js backend? What database makes sense? What authentication library is best suited?\n\n3.   **Code Generation**: The AI writes the necessary code across multiple files—component structures, API endpoints, database schemas, and styling—ensuring they work together cohesively.\n\n4.   **Dependency Management**: It identifies and includes required libraries, configures build tools, and sets up the development environment.\n\n5.   **Testing and Refinement**: Advanced vibe coding platforms can even run the code, identify errors, and self-correct before presenting the result.\n\n### **The Iterative Conversation Model**\n\nEffective vibe coding rarely happens with a single prompt. Instead, it’s a conversation:\n\n*   **Initial Prompt**: “Build a recipe sharing website”\n*   **AI Response**: Generates basic structure with recipe listings\n*   **Refinement 1**: “Add user profiles and the ability to favorite recipes”\n*   **AI Response**: Implements user authentication and favorite functionality\n*   **Refinement 2**: “Include search and filtering by cuisine type”\n*   **AI Response**: Adds search functionality with filter options\n\nEach iteration builds upon the previous state, with the AI maintaining context about what’s already been created. This conversational approach mirrors how you might work with a human developer, except the AI responds in seconds rather than hours.\n\n**Vibe Coding vs. Traditional Coding: A Comprehensive Comparison**\n------------------------------------------------------------------\n\nUnderstanding where vibe coding fits in the development ecosystem requires comparing it to conventional approaches:\n\n### **Development Speed and Efficiency**\n\n**Traditional Coding**: A skilled developer might spend days or weeks building a functional prototype. They need to set up the development environment, choose and configure frameworks, write boilerplate code, implement business logic, handle edge cases, and debug issues.\n\n**Vibe Coding**: The same prototype can materialize in hours—sometimes minutes. The AI handles setup, configuration, and standard implementations instantly. According to recent studies, developers using vibe coding tools report productivity increases of 3-5x for common development tasks.\n\n### **Skill Requirements and Accessibility**\n\n**Traditional Coding**: Requires months to years of learning programming languages, frameworks, design patterns, and best practices. The barrier to entry is high, limiting who can create software.\n\n**Vibe Coding**: Dramatically lowers the skill floor. While technical knowledge still helps (especially for refinement and debugging), non-programmers can now build functional applications. Product managers, designers, entrepreneurs, and domain experts can translate their ideas directly into code.\n\n### **Control and Precision**\n\n**Traditional Coding**: Developers have complete control over every aspect of their code—architecture decisions, performance optimizations, security implementations, and edge case handling.\n\n**Vibe Coding**: Offers less granular control. You’re trusting the AI to make reasonable technical decisions. While you can provide increasingly specific prompts, there’s an inherent trade-off between ease-of-use and precision.\n\n### **Code Quality and Maintainability**\n\n**Traditional Coding**: Experienced developers write clean, documented, maintainable code following established patterns. Code quality depends entirely on the developer’s skill and discipline.\n\n**Vibe Coding**: Code quality varies significantly. AI-generated code might be verbose, use outdated patterns, or lack proper documentation. Research from Veracode indicates that approximately 45% of AI-generated code contains security vulnerabilities that require human review and correction.\n\n### **Ideal Use Cases**\n\n**Traditional Coding Excels For**:\n\n*   Mission-critical systems requiring absolute reliability\n*   Complex, custom solutions with unique requirements\n*   Applications demanding optimal performance\n*   Projects where long-term maintainability is paramount\n*   Systems requiring deep domain-specific knowledge\n\n**Vibe Coding Excels For**:\n\n*   Rapid prototyping and MVP development\n*   Internal tools with straightforward requirements\n*   Learning and educational projects\n*   Automating repetitive coding tasks\n*   Validating ideas before full development investment\n\n**The Vibe Coding Tool Ecosystem: Platforms and Technologies**\n--------------------------------------------------------------\n\nThe vibe coding landscape features diverse platforms, each with distinct strengths. Understanding these tools helps you choose the right solution for your needs.\n\n### **Replit: The Complete Vibe Coding Experience**\n\n**Replit**has positioned itself as the premier vibe coding platform by offering an integrated, browser-based environment that eliminates setup friction. Their**Replit Agent**feature allows you to describe an application in natural language, and the AI handles everything—from setting up the development environment to writing code across multiple files to deploying the final product.\n\nWhat distinguishes Replit is its holistic approach. Unlike tools that just generate code, Replit provides built-in databases, object storage, authentication systems, and one-click deployment. This end-to-end integration means you can go from idea to live, publicly accessible application without ever leaving the platform. According to Replit CEO Amjad Masad, 75% of their customers don’t write any code manually—they’re pure vibe coders.\n\n**Best For**: Non-technical founders, rapid prototyping, educational projects, anyone wanting the simplest path from idea to deployed application.\n\n### **Cursor: The Developer’s Vibe Coding Tool**\n\n**Cursor**takes a different approach, positioning itself as an AI-enhanced replacement for traditional code editors like VS Code. Rather than generating entire applications from scratch, Cursor excels at augmenting the development workflow with intelligent code suggestions, contextual completions, and conversational debugging.\n\nCursor integrates multiple AI models (including GPT-4, Claude, and others), allowing developers to choose the best model for their specific task. Its**Composer**feature enables multi-file editing, where you can describe changes and watch Cursor modify code across your entire project intelligently.\n\n**Best For**: Experienced developers seeking productivity enhancement, teams working with existing codebases, projects requiring precise control alongside AI assistance.\n\n### **Windsurf: The Agentic Coding Platform**\n\n**Windsurf**, developed by Codeium, represents the next evolution in AI-assisted development with its agentic coding approach. Unlike tools that wait for instructions, Windsurf’s**Cascade**AI agent can understand project context, anticipate needs, and proactively suggest improvements.\n\nThe platform excels at understanding complex codebases and maintaining consistency across large projects. Windsurf’s AI doesn’t just respond to prompts—it actively participates in the development process, identifying opportunities for refactoring, spotting potential bugs, and suggesting architectural improvements.\n\n**Best For**: Medium to large projects, teams needing intelligent code analysis, developers who want an AI “pair programmer” that proactively contributes.\n\n### **GitHub Copilot: AI-Powered Code Completion**\n\n**GitHub Copilot**, backed by OpenAI technology, pioneered mainstream AI-assisted coding. While not a pure vibe coding platform (it doesn’t generate entire applications from descriptions), Copilot excels at context-aware code suggestions within your existing development environment.\n\nRecent versions include**Copilot Chat**, which brings conversational coding to the tool. You can ask questions, request code explanations, and get debugging help directly in your editor.\n\n**Best For**: Developers who prefer their existing development environment, teams already using GitHub, incremental productivity enhancement rather than full vibe coding.\n\n### **Claude Code: Conversational Development**\n\n**Claude Code**leverages Anthropic’s Claude AI model for development tasks. Its strength lies in understanding complex, nuanced instructions and generating thoughtful, well-structured code. Claude particularly excels at explaining its reasoning, making it valuable for learning and understanding the code it generates.\n\n**Best For**: Complex problem-solving, situations requiring detailed explanations, developers who want to understand and learn from AI-generated code.\n\n### **Platform Comparison Matrix**\n\n| Platform | Best For | Learning Curve | Deployment | Pricing Model |\n| --- | --- | --- | --- | --- |\n| **Replit** | Complete beginners, rapid deployment | Easiest | Integrated | Freemium |\n| **Cursor** | Experienced developers | Moderate | External | Subscription |\n| **Windsurf** | Agentic development, large projects | Moderate | External | Freemium |\n| **GitHub Copilot** | Existing developer workflows | Low | External | Subscription |\n| **Claude Code** | Complex reasoning, learning | Low | External | Pay-per-use |\n\n**Vibe Coding in Practice: Real-World Applications and Success Stories**\n------------------------------------------------------------------------\n\nThe theoretical promise of vibe coding becomes compelling when we examine real-world implementations across industries.\n\n### **Startup Velocity: From Concept to Market in Days**\n\n**Menlo Park Lab**, a generative AI startup founded by Misbah Syed, exemplifies vibe coding’s potential. Using AI-assisted development, Syed built**Brainy Docs**—a tool that transforms PDF documents into explainer videos with slides—with minimal manual coding. What might have taken a team of developers months was accomplished in weeks, allowing rapid iteration based on user feedback.\n\nThis acceleration isn’t unique. According to Y Combinator, approximately 25% of their portfolio companies now use vibe coding techniques for initial development, enabling founders to validate product-market fit before investing in traditional engineering teams.\n\n### **Enterprise Efficiency: Accenture and IBM’s AI Integration**\n\nLarge consultancies like**Accenture**and**IBM**have quietly leveraged proto-vibe coding techniques for years. These organizations often have teams where only a fraction possess deep programming expertise, while others work with predefined APIs and frameworks—essentially “vibing” their way through projects by following patterns rather than writing from scratch.\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l","title":"A Structured Workflow for \"Vibe Coding\" Full-Stack Apps","content":"【3†A Structured Workflow for \"Vibe Coding\" Full-Stack Apps†https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l】\nTitle: A Structured Workflow for \"Vibe Coding\" Full-Stack Apps\n\nURL Source: https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l\n\nPublished Time: 2025-04-16T08:46:36Z\n\nMarkdown Content:\nThere's a lot of hype surrounding \"vibe coding\". You've probably seen the AI influencers making claims like how you can build SaaS apps in 15 minutes with just a few tools and prompts.\n\nBut, as you might have guessed, these example workflows are pretty flimsy.\n\nYes, you can copy a landing page, or build a decent CRUD app, but you're not gonna be able to build a complex SaaS or internal tool with them.\n\nBut that doesn't mean there aren't workflows out there that can positively augment your development workflow. Anyone who's tinkered around with different AI-assisted techniques can tell you that there is some real magic in these tools.\n\nThat's why I spent a couple weeks researching the best techniques and workflow tips and put them to the test by building a full-featured, full-stack app with them.\n\nBelow, you'll find my honest review and the workflow that I found that really worked while using Cursor with Google's Gemini 2.5 Pro, and a solid UI template.\n\nBy the way, I came up with this workflow by testing and building a full-stack personal finance app in my spare time, tweaking and improving the process the entire time. Then, after landing on a good template and workflow, I rebuilt the app again and recorded it entirely, from start to deployments, in a ~3 hour long youtube video (above).\n\nThis article is a summary of the key approaches to implementing this workflow.\n\nStep 1: Laying the Foundation\n-----------------------------\n\nThere are a lot of moving parts in modern full-stack web apps. Trying to get your LLM to glue it all together for you cohesively just doesn't work.\n\nThat's why you should give your AI helper a helping hand by starting with a solid foundation and leveraging the tools we have at our disposal.\n\nIn practical terms this means using stuff like:\n\n1.   UI Component Libraries\n2.   Boilerplate templates\n3.   Full-stack frameworks with batteries-included\n\nComponent libraries and templates are great ways to give the LLM a known foundation to build upon. It also takes the guess work out of styling and helps those styles be consistent as the app grows.\n\nUsing a full-stack framework with batteries-included, such as Wasp for JavaScript (React, Node.js, Prisma) or Laravel for PHP, takes the complexity out of piecing the different parts of the stack together. Since these frameworks are opinionated, they've chosen a set of tools that work well together, and the have the added benefit of doing a lot of work under-the-hood. In the end, the AI can focus on just the business logic of the app.\n\nTake Wasp's main config file, for example (see below). All you or the LLM has to do is define your backend operations, and the framework takes care of managing the server setup and configuration for you. On top of that, this config file acts as a central \"source of truth\" the LLM can always reference to see how the app is defined as it builds new features.\n\n```\napp vibeCodeWasp {\n  wasp: { version: \"^0.16.3\" },\n  title: \"Vibe Code Workflow\",\n  auth: {\n    userEntity: User,\n    methods: {\n      email: {},\n      google: {},\n      github: {},\n    },\n  },\n  client: {\n    rootComponent: import Main from \"@src/main\",\n    setupFn: import QuerySetup from \"@src/config/querySetup\",\n  },\n}\n\nroute LoginRoute { path: \"/login\", to: Login }\npage Login {\n  component: import { Login } from \"@src/features/auth/login\"\n}\n\nroute EnvelopesRoute { path: \"/envelopes\", to: EnvelopesPage }\npage EnvelopesPage {\n  authRequired: true,\n  component: import { EnvelopesPage } from \"@src/features/envelopes/EnvelopesPage.tsx\"\n}\n\nquery getEnvelopes {\n  fn: import { getEnvelopes } from \"@src/features/envelopes/operations.ts\",\n  entities: [Envelope, BudgetProfile, UserBudgetProfile] // Need BudgetProfile to check ownership\n}\n\naction createEnvelope {\n  fn: import { createEnvelope } from \"@src/features/envelopes/operations.ts\",\n  entities: [Envelope, BudgetProfile, UserBudgetProfile] // Need BudgetProfile to link\n}\n\n//...\n```\n\nStep 2: Getting the Most Out of Your AI Assistant\n-------------------------------------------------\n\nOnce you've got a solid foundation to work with, you need create a comprehensive set of rules for your editor and LLM to follow.\n\nTo arrive at a solid set of rules you need to:\n\n1.   Start building something\n2.   Look out for times when the LLM (repeatedly) _doesn't meet your expectations_ and define rules for them\n3.   Constantly ask the LLM to help you improve your workflow\n\nDefining Rules\n--------------\n\nDifferent IDE's and coding tools have different naming conventions for the rules you define, but they all function more or less the same way (I used Cursor for this project so I'll be referring to Cursor's conventions here).\n\nCursor deprecated their `.cursorrules` config file in favor of a `.cursor/rules/` directory with multiple files. In this set of rules, you can pack in general rules that align with your coding style, and project-specific rules (e.g. conventions, operations, auth).\n\nThe key here is to provide structured context for the LLM so that it doesn't have to rely on broader knowledge.\n\nWhat does that mean exactly? It means telling the LLM about the current project and template you'll be building on, what conventions it should use, and how it should deal with common issues (e.g. the examples picture above, which are taken from the tutorial video's accompanying repo.\n\nYou can also add general strategies to rules files that you can manually reference in chat windows. For example, I often like telling the LLM to \"think about 3 different strategies/approaches, pick the best one, and give your rationale for why you chose it.\" So I created a rule for it, `7-possible-solutions-thinking.mdc`, and I pass it in whenever I want to use it, saving myself from typing the same thing over and over.\n\nUsing AI to Critique and Improve Your Workflow\n----------------------------------------------\n\nAside from this, I view the set of rules as a fluid object. As I worked on my apps, I started with a set of rules and iterated on them to get the kind of output I was looking for. This meant adding new rules to deal with common errors the LLM would introduce, or to overcome project-specific issues that didn't meet the general expectations of the LLM.\n\nAs I amended these rules, I would also take time to use the LLM as a source of feedback, asking it to critique my current workflow and find ways I could improve it.\n\nThis meant passing in my rules files into context, along with other documents like Plans and READMEs, and ask it to look for areas where we could improve them, using the past chat sessions as context as well.\n\nA lot of time this just means asking the LLM something like:\n\n> Can you review for breadth and clarity and think of a few ways it could be improved, if necessary. Remember, these documents are to be used as context for AI-assisted coding workflows.\n\nStep 3: Defining the \"What\" and the \"How\" (PRD & Plan)\n------------------------------------------------------\n\nAn extremely important step in all this is the initial prompts you use to guide the generation of the Product Requirement Doc (PRD) and the step-by-step actionable plan you create from it.\n\nThe PRD is basically just a detailed guideline for how the app should look and behave, and some guidelines for how it should be implemented.\n\nAfter generating the PRD, we ask the LLM to generate a step-by-step actionable plan that will implement the app in phases using a modified **vertical slice method** suitable for LLM-assisted development.\n\nThe vertical slice implementation is important because it instructs the LLM to develop the app in full-stack \"slices\" -- from DB to UI -- in increasingly complexity. That might look like developing a super simple version of a full-stack feature in an early phase, and then adding more complexity to that feature in the later phases.\n\n**This approach highlights a common recurring theme in this workflow: build a simple, solid foundation and increasing add on complexity in focused chunks**\n\nAfter the initial generation of each of these docs, I will often ask the LLM to review it's own work and look for possible ways to improve the documents based on the project structure and the fact that it will be used for assisted coding. Sometimes it finds seem interesting improvements, or at the very least it finds redundant information it can remove.\n\nHere is an example prompt for generating the step-by-step plan (all example prompts used in the walkthrough video can be found in the accompanying repo):\n\n> From this PRD, create an actionable, step-by-step plan using a modified vertical slice implmentation approach that's suitable for LLM-assisted coding. Before you create the plan, think about a few different plan styles that would be suitable for this project and the implmentation style before selecting the best one. Give your reasoning for why you think we should use this plan style. Remember that we will constantly refer to this plan to guide our coding implementation so it should be well structured, concise, and actionable, while still providing enough information to guide the LLM.\n\n### Finding this tutorial interesting?\n\nWasp team is working hard to create content like this, not to mention building a modern, open-source React/NodeJS framework.\n\nThe easiest way to show your support is just to star Wasp repo! 🐝 But it would be greatly appreciated if you could take a look at the repository (for contributions, or to simply test the product). Click on the button below to give Wasp a star and show your support!\n\n⭐️ Thank You For Your Support 💪\n\nStep 4: Building End-to-End - Vertical Slices in Action\n-------------------------------------------------------\n\nAs mentioned above, the vertical slice approach lends itself well to building with full-stack frameworks because of the heavy-lifting they can do for you and the LLM.\n\nRather than trying to define all your database models from the start, for example, this approach tackles the simplest form of a full-stack feature individually, and then builds upon them in later phases. This means, in an early phase, we might only define the database models needed for Authentication, then its related server-side functions, and the UI for it like Login forms and pages.\n\nIn my Wasp project, that flow for implementing a phase/feature looked a lot like: \n\n -> Define necessary DB entities in `schema.prisma` for that feature only\n\n -> Define operations in the `main.wasp` file\n\n -> Write the server operations logic \n\n -> Define pages/routes in the `main.wasp` file\n\n -> src/features or src/components UI \n\n -> Connect things via Wasp hooks and other library hooks and modules (react-router-dom, recharts, tanstack-table).\n\nThis gave me and the LLM a huge advantage in being able to build the app incrementally without getting too bogged down by the amount of complexity.\n\nOnce the basis for these features was working smoothly, we could improve the complexity of them, and add on other sub-features, with little to no issues!\n\nThe other advantage this had was that, if I realised there was a feature set I wanted to add on later that didn't already exist in the plan, I could ask the LLM to review the plan and find the best time/phase within it to implement it. Sometimes that time was then at the moment, and other times it gave great recommendations for deferring the new feature idea until later. If so, we'd update the plan accordingly.\n\nStep 5: Closing the Loop - AI-Assisted Documentation\n----------------------------------------------------\n\nDocumentation often gets pushed to the back burner. But in an AI-assisted workflow, keeping track of why things were built a certain way and how the current implementation works becomes even more crucial.\n\nThe AI doesn't inherently \"remember\" the context from three phases ago unless you provide it. So we get the LLM to provide it for itself :)\n\nAfter completing a significant phase or feature slice defined in our Plan, I made it a habit to task the AI with documenting what we just built. I even created a rule file for this task to make it easier.\n\nThe process looked something like this:\n\n\n"},"metadata":{"arguments":"{\"link_id\":3}","display_result":"","duration":"40s","id":"call_QH6Re4YMvD","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【3†A Structured Workflow for \"Vibe Coding\" Full-Stack Apps†https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l】\nTitle: A Structured Workflow for \"Vibe Coding\" Full-Stack Apps\n\nURL Source: https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l\n\nPublished Time: 2025-04-16T08:46:36Z\n\nMarkdown Content:\nThere's a lot of hype surrounding \"vibe coding\". You've probably seen the AI influencers making claims like how you can build SaaS apps in 15 minutes with just a few tools and prompts.\n\nBut, as you might have guessed, these example workflows are pretty flimsy.\n\nYes, you can copy a landing page, or build a decent CRUD app, but you're not gonna be able to build a complex SaaS or internal tool with them.\n\nBut that doesn't mean there aren't workflows out there that can positively augment your development workflow. Anyone who's tinkered around with different AI-assisted techniques can tell you that there is some real magic in these tools.\n\nThat's why I spent a couple weeks researching the best techniques and workflow tips and put them to the test by building a full-featured, full-stack app with them.\n\nBelow, you'll find my honest review and the workflow that I found that really worked while using Cursor with Google's Gemini 2.5 Pro, and a solid UI template.\n\nBy the way, I came up with this workflow by testing and building a full-stack personal finance app in my spare time, tweaking and improving the process the entire time. Then, after landing on a good template and workflow, I rebuilt the app again and recorded it entirely, from start to deployments, in a ~3 hour long youtube video (above).\n\nThis article is a summary of the key approaches to implementing this workflow.\n\nStep 1: Laying the Foundation\n-----------------------------\n\nThere are a lot of moving parts in modern full-stack web apps. Trying to get your LLM to glue it all together for you cohesively just doesn't work.\n\nThat's why you should give your AI helper a helping hand by starting with a solid foundation and leveraging the tools we have at our disposal.\n\nIn practical terms this means using stuff like:\n\n1.   UI Component Libraries\n2.   Boilerplate templates\n3.   Full-stack frameworks with batteries-included\n\nComponent libraries and templates are great ways to give the LLM a known foundation to build upon. It also takes the guess work out of styling and helps those styles be consistent as the app grows.\n\nUsing a full-stack framework with batteries-included, such as Wasp for JavaScript (React, Node.js, Prisma) or Laravel for PHP, takes the complexity out of piecing the different parts of the stack together. Since these frameworks are opinionated, they've chosen a set of tools that work well together, and the have the added benefit of doing a lot of work under-the-hood. In the end, the AI can focus on just the business logic of the app.\n\nTake Wasp's main config file, for example (see below). All you or the LLM has to do is define your backend operations, and the framework takes care of managing the server setup and configuration for you. On top of that, this config file acts as a central \"source of truth\" the LLM can always reference to see how the app is defined as it builds new features.\n\n```\napp vibeCodeWasp {\n  wasp: { version: \"^0.16.3\" },\n  title: \"Vibe Code Workflow\",\n  auth: {\n    userEntity: User,\n    methods: {\n      email: {},\n      google: {},\n      github: {},\n    },\n  },\n  client: {\n    rootComponent: import Main from \"@src/main\",\n    setupFn: import QuerySetup from \"@src/config/querySetup\",\n  },\n}\n\nroute LoginRoute { path: \"/login\", to: Login }\npage Login {\n  component: import { Login } from \"@src/features/auth/login\"\n}\n\nroute EnvelopesRoute { path: \"/envelopes\", to: EnvelopesPage }\npage EnvelopesPage {\n  authRequired: true,\n  component: import { EnvelopesPage } from \"@src/features/envelopes/EnvelopesPage.tsx\"\n}\n\nquery getEnvelopes {\n  fn: import { getEnvelopes } from \"@src/features/envelopes/operations.ts\",\n  entities: [Envelope, BudgetProfile, UserBudgetProfile] // Need BudgetProfile to check ownership\n}\n\naction createEnvelope {\n  fn: import { createEnvelope } from \"@src/features/envelopes/operations.ts\",\n  entities: [Envelope, BudgetProfile, UserBudgetProfile] // Need BudgetProfile to link\n}\n\n//...\n```\n\nStep 2: Getting the Most Out of Your AI Assistant\n-------------------------------------------------\n\nOnce you've got a solid foundation to work with, you need create a comprehensive set of rules for your editor and LLM to follow.\n\nTo arrive at a solid set of rules you need to:\n\n1.   Start building something\n2.   Look out for times when the LLM (repeatedly) _doesn't meet your expectations_ and define rules for them\n3.   Constantly ask the LLM to help you improve your workflow\n\nDefining Rules\n--------------\n\nDifferent IDE's and coding tools have different naming conventions for the rules you define, but they all function more or less the same way (I used Cursor for this project so I'll be referring to Cursor's conventions here).\n\nCursor deprecated their `.cursorrules` config file in favor of a `.cursor/rules/` directory with multiple files. In this set of rules, you can pack in general rules that align with your coding style, and project-specific rules (e.g. conventions, operations, auth).\n\nThe key here is to provide structured context for the LLM so that it doesn't have to rely on broader knowledge.\n\nWhat does that mean exactly? It means telling the LLM about the current project and template you'll be building on, what conventions it should use, and how it should deal with common issues (e.g. the examples picture above, which are taken from the tutorial video's accompanying repo.\n\nYou can also add general strategies to rules files that you can manually reference in chat windows. For example, I often like telling the LLM to \"think about 3 different strategies/approaches, pick the best one, and give your rationale for why you chose it.\" So I created a rule for it, `7-possible-solutions-thinking.mdc`, and I pass it in whenever I want to use it, saving myself from typing the same thing over and over.\n\nUsing AI to Critique and Improve Your Workflow\n----------------------------------------------\n\nAside from this, I view the set of rules as a fluid object. As I worked on my apps, I started with a set of rules and iterated on them to get the kind of output I was looking for. This meant adding new rules to deal with common errors the LLM would introduce, or to overcome project-specific issues that didn't meet the general expectations of the LLM.\n\nAs I amended these rules, I would also take time to use the LLM as a source of feedback, asking it to critique my current workflow and find ways I could improve it.\n\nThis meant passing in my rules files into context, along with other documents like Plans and READMEs, and ask it to look for areas where we could improve them, using the past chat sessions as context as well.\n\nA lot of time this just means asking the LLM something like:\n\n> Can you review for breadth and clarity and think of a few ways it could be improved, if necessary. Remember, these documents are to be used as context for AI-assisted coding workflows.\n\nStep 3: Defining the \"What\" and the \"How\" (PRD & Plan)\n------------------------------------------------------\n\nAn extremely important step in all this is the initial prompts you use to guide the generation of the Product Requirement Doc (PRD) and the step-by-step actionable plan you create from it.\n\nThe PRD is basically just a detailed guideline for how the app should look and behave, and some guidelines for how it should be implemented.\n\nAfter generating the PRD, we ask the LLM to generate a step-by-step actionable plan that will implement the app in phases using a modified **vertical slice method** suitable for LLM-assisted development.\n\nThe vertical slice implementation is important because it instructs the LLM to develop the app in full-stack \"slices\" -- from DB to UI -- in increasingly complexity. That might look like developing a super simple version of a full-stack feature in an early phase, and then adding more complexity to that feature in the later phases.\n\n**This approach highlights a common recurring theme in this workflow: build a simple, solid foundation and increasing add on complexity in focused chunks**\n\nAfter the initial generation of each of these docs, I will often ask the LLM to review it's own work and look for possible ways to improve the documents based on the project structure and the fact that it will be used for assisted coding. Sometimes it finds seem interesting improvements, or at the very least it finds redundant information it can remove.\n\nHere is an example prompt for generating the step-by-step plan (all example prompts used in the walkthrough video can be found in the accompanying repo):\n\n> From this PRD, create an actionable, step-by-step plan using a modified vertical slice implmentation approach that's suitable for LLM-assisted coding. Before you create the plan, think about a few different plan styles that would be suitable for this project and the implmentation style before selecting the best one. Give your reasoning for why you think we should use this plan style. Remember that we will constantly refer to this plan to guide our coding implementation so it should be well structured, concise, and actionable, while still providing enough information to guide the LLM.\n\n### Finding this tutorial interesting?\n\nWasp team is working hard to create content like this, not to mention building a modern, open-source React/NodeJS framework.\n\nThe easiest way to show your support is just to star Wasp repo! 🐝 But it would be greatly appreciated if you could take a look at the repository (for contributions, or to simply test the product). Click on the button below to give Wasp a star and show your support!\n\n⭐️ Thank You For Your Support 💪\n\nStep 4: Building End-to-End - Vertical Slices in Action\n-------------------------------------------------------\n\nAs mentioned above, the vertical slice approach lends itself well to building with full-stack frameworks because of the heavy-lifting they can do for you and the LLM.\n\nRather than trying to define all your database models from the start, for example, this approach tackles the simplest form of a full-stack feature individually, and then builds upon them in later phases. This means, in an early phase, we might only define the database models needed for Authentication, then its related server-side functions, and the UI for it like Login forms and pages.\n\nIn my Wasp project, that flow for implementing a phase/feature looked a lot like: \n\n -> Define necessary DB entities in `schema.prisma` for that feature only\n\n -> Define operations in the `main.wasp` file\n\n -> Write the server operations logic \n\n -> Define pages/routes in the `main.wasp` file\n\n -> src/features or src/components UI \n\n -> Connect things via Wasp hooks and other library hooks and modules (react-router-dom, recharts, tanstack-table).\n\nThis gave me and the LLM a huge advantage in being able to build the app incrementally without getting too bogged down by the amount of complexity.\n\nOnce the basis for these features was working smoothly, we could improve the complexity of them, and add on other sub-features, with little to no issues!\n\nThe other advantage this had was that, if I realised there was a feature set I wanted to add on later that didn't already exist in the plan, I could ask the LLM to review the plan and find the best time/phase within it to implement it. Sometimes that time was then at the moment, and other times it gave great recommendations for deferring the new feature idea until later. If so, we'd update the plan accordingly.\n\nStep 5: Closing the Loop - AI-Assisted Documentation\n----------------------------------------------------\n\nDocumentation often gets pushed to the back burner. But in an AI-assisted workflow, keeping track of why things were built a certain way and how the current implementation works becomes even more crucial.\n\nThe AI doesn't inherently \"remember\" the context from three phases ago unless you provide it. So we get the LLM to provide it for itself :)\n\nAfter completing a significant phase or feature slice defined in our Plan, I made it a habit to task the AI with documenting what we just built. I even created a rule file for this task to make it easier.\n\nThe process looked something like this:\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code","title":"Vibe Planning: Get the Most Out of Claude Code : r/ClaudeAI","content":"【7†Vibe Planning: Get the Most Out of Claude Code : r/ClaudeAI†https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code】\nTitle: \n\nURL Source: https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code\n\nWarning: Target URL returned error 403: Forbidden\n\nMarkdown Content:\nYou've been blocked by network security.\n\nTo continue, log in to your Reddit account or use your developer token\n\nIf you think you've been blocked by mistake, file a ticket below and we'll look into it.\n\nLog in File a ticket\n\n"},"metadata":{"arguments":"{\"link_id\":7}","display_result":"","duration":"4s","id":"call_67BGcMs6HZ","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【7†Vibe Planning: Get the Most Out of Claude Code : r/ClaudeAI†https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code】\nTitle: \n\nURL Source: https://www.reddit.com/r/ClaudeAI/comments/1ljesg7/vibe_planning_get_the_most_out_of_claude_code\n\nWarning: Target URL returned error 403: Forbidden\n\nMarkdown Content:\nYou've been blocked by network security.\n\nTo continue, log in to your Reddit account or use your developer token\n\nIf you think you've been blocked by mistake, file a ticket below and we'll look into it.\n\nLog in File a ticket\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="10" view="" last_tool_call_name="click">
> 大規模なコードベース（50以上のフォルダ）でバイブコーディングの精度を最大化するには、計画、コンテキスト管理、反復的開発、検証が重要だ。プロジェクトのドキュメント化、ファイル構造の定義、依存関係のマッピング、AIへの指示の明確化がポイント。ステップとしては、プロジェクトの理解、ドキュメントの準備、AIツールの選定、計画の策定、コード生成、テストとデバッグ、文書化、バージョン管理のプロセスを推奨。具体的なツールや手法を提案し、ユーザーが実際に適用できるようにサポートする。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704","title":"Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底","content":"【17†Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底†https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704】\nTitle: Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底解説と実践\n\nURL Source: https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704\n\nMarkdown Content:\nSourcegraph Codyとは？- コードを「知る」AIアシスタントの全貌\n----------------------------------------\n\n### 核心的な特性「コード認識（Code-Awareness）」\n\n### 主要機能の紹介\n\n### ターゲットユーザー\n\n競合製品との徹底比較：Codyはなぜ選ばれるのか？\n-------------------------\n\n### 総合比較表\n\n### vs. GitHub Copilot\n\n### vs. Amazon CodeWhisperer (現 Amazon Q Developer)\n\n### vs. Tabnine\n\n### vs. Cursor\n\nSourcegraph Cody実践活用ガイド：明日から使えるTips＆テクニック\n-----------------------------------------\n\n### Step 1: インストールと初期設定\n\n### Step 2: 基本機能を使ってみる\n\n### Step 3: 実践的なユースケース\n\n### Step 4: パワーユーザー向けTips\n\nSourcegraphの戦略とAIの未来：Codyの進化と業界の動向\n----------------------------------\n\n### Sourcegraphの歩みと戦略的転換\n\n### 業界全体のトレンドとCodyの位置づけ\n\n### 課題と論点\n\nCodyが開発者と組織にもたらす変革\n------------------\n\n### 技術リーダー/マネージャーへの示唆\n\n### 開発者への示唆\n\nよくある質問（FAQ）\n-----------\n\nまとめと今後の展望\n---------\n\n目次 導入：なぜ今、AIコーディングアシスタント「Cody」に注目すべきなのか？ Sourcegraph Codyとは？- コードを「知る」AIアシスタントの全貌 核心的な特性「コード認識（Code-Awareness）」 主要機能の紹介 ターゲットユーザー 競合製品との徹底比較：Codyはなぜ選ばれるのか？ 総合比較表 vs. GitHub Copilot vs. Amazon CodeWhisperer (現 Amazon Q Developer) vs. Tabnine vs. Cursor Sourcegraph Cody実践活用ガイド：明日から使えるTips＆テクニック Step 1: インストールと初期設定 Step 2: 基本機能を使ってみる Step 3: 実践的なユースケース Step 4: パワーユーザー向けTips Sourcegraphの戦略とAIの未来：Codyの進化と業界の動向 Sourcegraphの歩みと戦略的転換 業界全体のトレンドとCodyの位置づけ 課題と論点 Codyが開発者と組織にもたらす変革 技術リーダー/マネージャーへの示唆 開発者への示唆 よくある質問（FAQ） まとめと今後の展望 導入：なぜ今、AIコーディングアシスタント「Cody」に注目すべきなのか？ 現代のソフトウェア開発は、かつてないほどの複雑さに直面しています。コードベースは巨大化し、マイクロサービスアーキテクチャは依存関係を複雑に絡ませ、市場は絶えず迅速な機能リリースを要求します。私たち開発者は、コードを書く時間よりも、既存のコードを理解し、デバッグし、技術的負債と格闘する時間の方が長い、と感じることも少なくないでしょう。 IDEに統合され、開発者を支援するSourcegraph Cody このような課題に対する強力な解決策として、AIコーディングアシスタントが登場しました。当初は単純なコード補完ツールでしたが、今やその能力は飛躍的に進化しています。そして、その進化の最前線にいるのが、本記事で深掘りする「Sourcegraph Cody」です。 Codyは、単なるコードスニペットの提案者ではありません。それは、あなたの組織が持つコードベース全体を理解し、文脈に基づいた対話ができる真の「相棒」です。この記事では、Codyがなぜ「コードを理解する」とまで言われるのか、その核心技術から、GitHub Copilotなどの競合製品との違い、明日から使える実践的な活用法、そしてSourcegraph社の戦略とAI開発の未来まで、徹底的に解説していきます。 図表1：現代の開発者が直面する時間の使い方 この記事を読み終える頃には、Codyがあなたの開発ワークフローをどのように変革し、チームの生産性をいかにして新たなレベルへと引き上げる可能性があるのか、明確なビジョンを描けるようになっているはずです。 図表2：AIコーディングアシスタントの進化段階 Sourcegraph Codyとは？- コードを「知る」AIアシスタントの全貌 Sourcegraph Codyは、一言で言えば「コードを深く理解するAIコーディングアシスタント」です。これは、2013年に創業されたSourcegraph社 が長年培ってきた「コードインテリジェンスプラットフォーム」の技術を基盤としています。Codyは単体で存在するのではなく、Sourcegraphの強力なコード検索・分析能力の上に成り立っているのです。 CodyのチャットUI。複数のファイル（例：Read 16 files）を文脈として読み込み、的確な回答を生成する。 核心的な特性「コード認識（Code-Awareness）」 Codyが他の多くのAIツールと一線を画す最大の理由は、その「コード認識（Code-Awareness）」能力にあります。これは、Sourcegraph独自の「コードグラフ（Code Graph）」技術によって実現されています。 多くのAIアシスタントは、現在開いているファイルや、限定的なプロジェクト内の情報しか文脈として利用できません。しかしCodyは、コードグラフを用いて、組織内に存在するすべてのリポジトリ、ライブラリ間の依存関係、関数の定義元と呼び出し先といった関係性を網羅的に把握します。いわば、コードベース全体の地図を持っているようなものです。 そして、この広大な地図から最適な情報を引き出すために、CodyはRAG（Retrieval-Augmented Generation）という技術を駆使します。ユーザーからの質問（プロンプト）を受け取ると、Codyはまずコードグラフを検索し、関連性の高いコードスニペットやドキュメントを「文脈」として収集します。そして、その豊富な文脈情報と共にプロンプトを大規模言語モデル（LLM）に渡すことで、驚くほど正確で、文脈に即した回答を生成するのです 。 図表2：CodyのRAG（Retrieval-Augmented Generation）アーキテクチャ概念図 主要機能の紹介 Codyの強力な基盤技術は、開発者の日常業務を支援する多彩な機能として結実しています。 コンテキストを考慮したチャット： 「このプロジェクトの認証ロジックはどこで実装されていますか？」といった抽象的な質問に対し、Codyは複数のリポジトリを横断して関連ファイルを探し出し、具体的なコードを引用しながら回答します。これは、新しいチームメンバーが巨大なコードベースを理解する上で絶大な効果を発揮します。 高精度な自動補完： コードグラフから得られる文脈のおかげで、Codyのコード補完は、存在しない関数名を提案したり、型エラーを含むコードを生成したりする「ハルシネーション（幻覚）」が大幅に抑制されています。Sourcegraphは、このアプローチにより30%以上の補完受け入れ率（Completion Acceptance Rate）を達成したと報告しています 。 コマンドとPrompt Library： /explain（コード説明）や/test（単体テスト生成）といった便利な組み込みコマンドが用意されています。さらに強力なのが「Prompt Library」機能で、チーム独自のコーディング規約やレビュー観点をカスタムプロンプトとして保存・共有できます。これにより、AIアシスタントをチームの「標準」に合わせて教育することが可能になります 。 コードの理解とデバッグ支援： 複雑な正規表現の解説、バグ報告からの原因特定、レガシーコードのリファクタリング提案など、開発ライフサイクルのあらゆる場面で開発者の認知負荷を軽減します。 図表1：Sourcegraph Codyの主要機能一覧 動画：Sourcegraph Codyの初心者向けチュートリアル ターゲットユーザー これらの特性から、Codyの主なターゲットユーザーは明確です。それは、大規模で複雑、かつ分散したコードベースを扱うエンタープライズ（大企業）です。特に、以下のようなニーズを持つ組織にとって、Codyは強力な選択肢となります 。 複数のコードホスト（GitHub, GitLabなど）にリポジトリが分散している。 マイクロサービスアーキテクチャを採用しており、サービス間の依存関係を理解するのが難しい。 AIが生成するコードの精度と信頼性を重視する。 セキュリティ要件が厳しく、セルフホストや使用するLLMを自社でコントロールしたい。 競合製品との徹底比較：Codyはなぜ選ばれるのか？ AIコーディングアシスタント市場は活況を呈しており、多くの優れたツールが存在します。ここでは、技術選定を行う読者のために、Codyを主要な競合製品であるGitHub Copilot、Amazon CodeWhisperer（現Amazon Q Developer）、Tabnine、Cursorと比較し、その独自性を明らかにします。 AIコーディングアシスタント市場の主要プレイヤー 総合比較表 まず、各ツールの特徴を一覧で比較してみましょう。これにより、全体像を素早く把握できます。 機能/特性 Sourcegraph Cody GitHub Copilot Amazon Q (CodeWhisperer) Tabnine Cursor コンテキスト理解 コードベース全体（複数リポジトリ）、コードグラフ 主に単一リポジトリ、開いているファイル 主に開いているファイル、AWS SDKに最適化 プロジェクト全体、自己学習 手動でのファイル/フォルダ指定 核心技術 コードグラフ + RAG OpenAI Codex/GPT Amazon独自LLM Tabnine独自LLM OpenAI/Anthropic LLM ターゲット層 エンタープライズ、大規模チーム 個人〜エンタープライズ（GitHub中心） 個人（AWSユーザー）〜エンタープライズ 個人〜エンタープライズ 個人開発者、小規模チーム LLM柔軟性 非常に高い（OpenAI, Anthropic, OSS, Azure, Bedrock対応） 限定的（OpenAIモデル） 限定的（Amazonモデル） 高い（自社モデル + 3rd party） 高い（OpenAI, Anthropic） セキュリティ 高い（セルフホスト、Air-Gap対応可） Enterprise版で強化 AWSセキュリティ基準 高い（セルフホスト可） SOC 2 Type II、SaaS中心 IDEサポート VS Code, JetBrains, Neovim, Web VS Code, JetBrains, Visual Studio VS Code, JetBrains, AWS Cloud9等 多数のIDEに対応 IDEそのもの（VS Codeフォーク） 図表1：主要AIコーディングアシスタント機能比較表 図表2：各ツールの特性レーダーチャート vs. GitHub Copilot GitHub Copilotは市場で最も知名度が高く、特にGitHubエコシステム内で作業する開発者にとっては非常に強力です。コード生成の速さと手軽さでは右に出るものはいません。 しかし、両者の決定的な違いは「コンテキストの深さ」にあります。Copilotのコンテキストは主に開いているファイルや単一のリポジトリに限定されがちです。一方、Codyは前述の通り、コードグラフを用いて組織全体のコードを理解します。 Sourcegraphが公開した比較記事では、新しいコードベースのセットアップ方法を質問した際、Copilotは一般的なnpm startコマンドを提案しましたが、そのプロジェクトには存在しないコマンドでした。対してCodyは、12個の関連ファイルを読み込み、.envファイルの設定やデータベースのマイグレーションを含む正確な手順を提示しました 。これは、Codyが単に「推測」するのではなく、「事実に基づいて」回答する能力の証左です。 Codyの強み： 複数リポジトリにまたがる複雑なエンタープライズ環境での深いコード理解と、回答の根拠を提示する透明性。 vs. Amazon CodeWhisperer (現 Amazon Q Developer) Amazon CodeWhisperer（現在はAmazon Q Developerに統合）のユニークな点は、AWSのAPIやベストプラクティスに最適化されていることです 。AWS上で開発を行う開発者にとっては、非常に的確なコード提案が期待できます。 Codyの優位性は、その汎用性とインフラの柔軟性にあります。Codyは特定のクラウドプラットフォームに依存せず、あらゆる種類のコードベースに対応できます。また、企業が自社のセキュリティポリシーに合わせてLLMをAzure OpenAIやAmazon Bedrock上でホストしたり、完全にセルフホストしたりできる選択肢の広さは、多くのエンタープライズにとって重要な要素です。 Codyの強み： 特定のベンダーにロックインされない汎用性と、エンタープライズの要求に応えるデプロイメントの柔軟性。 vs. Tabnine TabnineはAIコード補完の草分け的存在であり、特にプライバシーを重視する企業から支持されています。AIモデルをローカルマシンや自社サーバーで完全に実行できるオプションは大きな特徴です 。 Codyとの違いは、ツールの主眼にあります。Tabnineが主に「コード補完」というタスクに特化しているのに対し、Codyはコード補完に加えて、チャットを通じてコードベース全体と対話し、理解を深める「アシスタント」としての役割をより重視しています。Codyは「書く」だけでなく、「読む」「理解する」「修正する」という開発サイクル全体をサポートするツールと言えるでしょう。 Codyの強み： コード補完に留まらない、チャットを通じた対話的なコードベース全体の理解と分析能力。 vs. Cursor Cursorは「AI-first」を掲げるエディタそのものであり、VS Codeのフォークとして開発されています。UIにAI機能が深く統合されており、特に個人開発者や小規模チームから熱狂的な支持を得ています。手動で@メンションを使ってコンテキストを指定する操作感は直感的です。 Codyは既存のワークフローを尊重するアプローチを取ります。開発者が使い慣れたVS CodeやJetBrains IDEにプラグインとして追加するため、IDEの乗り換えを強制しません。これは、多様な開発環境が混在するエンタープライズ組織にとって、導入の障壁を大きく下げる要因となります 。 Codyの強み： 既存の開発環境やワークフローを妨げないシームレスな統合と、エンタープライズ規模での導入のしやすさ。 図表3：あなたのニーズに合ったAIアシスタント選択フローチャート Sourcegraph Cody実践活用ガイド：明日から使えるTips＆テクニック Codyの真価は、実際に使ってみて初めて実感できます。ここでは、Codyをあなたの「最強の相棒」にするための、具体的なステップとパワーユーザー向けのテクニックを紹介します。 Step 1: インストールと初期設定 Codyを始めるのは非常に簡単です。ここではVS Codeを例に説明します。 VS Code拡張機能のインストール： VS CodeのMarketplaceで「Cody AI Code Assistant」を検索し、インストールします。 アカウントへのサインイン： インストール後、Codyのサイドバーが表示されます。Sourcegraph.comのアカウント（GitHub, GitLab, Googleアカウントでサインイン可能）でログインします。エンタープライズ版を利用する場合は、自社のSourcegraphインスタンスのURLとアクセストークンを入力します。 準備完了： これだけで、Codyのチャットや自動補完機能が使えるようになります。 VS Code Marketplaceで公開されているCody AIアシスタント 【ポイント】JetBrains系のIDE（IntelliJ, PyCharmなど）やNeovimにも対応しています。お使いの環境に合わせて公式ドキュメントを参照してください 。 Step 2: 基本機能を使ってみる まずは基本的な機能に慣れましょう。 AIチャット： サイドバーのチャットウィンドウに、人間と話すように質問を投げかけてみましょう。例えば、開いているファイルについて「この関数の役割を教えてください」と尋ねるだけで、Codyが詳細な説明を返してくれます。 自動補完： コードを書き始めると、Codyが灰色の文字で補完候補を提案します。Tabキーを押すだけで、その提案を受け入れることができます。単一行だけでなく、関数全体を補完してくれることもあります。 インラインチャット： エディタから離れたくない場合は、コード上でCommand + Shift + C（Mac）またはCtrl + Shift + C（Windows/Linux）を押すと、その場にチャットウィンドウが現れます。特定のコードブロックを選択して実行すれば、そのコードだけを文脈にした対話が可能です。 エディタ内で直接対話できるインラインチャット機能 Step 3: 実践的なユースケース Codyの真価は、リアルな開発シナリオで発揮されます。Sourcegraphのブログで紹介されていたシナリオを参考に、Codyの実力を試してみましょう。 シナリオ1：新しいコードベースの理解 新しいプロジェクトに参加したとします。まずはCodyに「このアプリケーションは何をするものですか？」と聞いてみましょう。CodyはREADMEファイルだけでなく、ソースコード全体をスキャンし、使用されている技術スタック、主要な機能、外部APIの利用状況などをまとめた、非常に詳細な概要を生成してくれます。 シナリオ2：開発環境のセットアップ 次に、「開発モードでこのアプリを起動する方法を教えてください」と質問します。Codyはpackage.jsonや設定ファイルを解析し、依存関係のインストール、環境変数ファイル（.env）の作成、データベースのマイグレーション、そして正しい起動コマンド（例：npm run dev）まで、具体的な手順をステップバイステップで教えてくれます。 シナリオ3：新機能の追加 「ミリ秒をSMPTEタイムコード形式（HH:MM:SS:FF）に変換するJavaScript関数を書いてください」と依頼します。Codyは、単にコードを生成するだけでなく、既存のコードスタイルや規約に合わせて、適切な場所に配置できる品質のコードを提案してくれます。 具体的な要求に対し、Reactコンポーネントのコードを生成するCody Step 4: パワーユーザー向けTips Codyをさらに使いこなすための秘訣をいくつか紹介します。 効果的なプロンプトの書き方： Codyを「何も知らない新人のチームメンバー」だと思って接するのがコツです。「この関数を修正して」ではなく、「このcalculatePrice関数に、顧客がプレミアム会員の場合は10%割引を適用するロジックを追加してください。価格は小数点以下2桁に丸める必要があります」のように、役割、文脈、具体例、制約条件を明確に伝えましょう 。 Prompt Libraryの活用： チームで頻繁に行うタスク（例：「このコンポーネントに我々の標準的なStorybookファイルを作成して」）をカスタムコマンドとして「Prompt Library」に登録しましょう。これにより、チーム全体の生産性が向上し、コーディング標準も自然と守られるようになります。 IDEのカスタマイズ： 私は、CodyのパネルをVS Codeの左側のメインサイドバーから右側のセカンダリサイドバーにドラッグ＆ドロップして使っています。これにより、左側でファイルエクスプローラーを開きながら、右側でCodyと常に対話できるため、作業が非常にスムーズになります 。 図表1：効果的なCodyプロンプトの構成要素 動画：Cody、Copilot、Cursorの比較デモ 図表2：Codyを活用した開発ワークフローの変化 Sourcegraphの戦略とAIの未来：Codyの進化と業界の動向 Codyを理解するためには、開発元であるSourcegraph社の戦略と、AI開発業界全体の大きな潮流を把握することが不可欠です。 Sourcegraphの歩みと戦略的転換 2013年に創業したSourcegraphは、もともと「ユニバーサルコード検索」をミッションに掲げ、開発者が巨大なコードベースを人間がナビゲートするためのツールを提供してきました 。このコード検索技術と、コードの構造を理解する「コードグラフ」が、後のCodyの強力な基盤となります。 しかし、AIの波が押し寄せる中で、Sourcegraphは大きな戦略転換を決断します。それが、エンタープライズ市場への集中です。 2024年6月、SourcegraphはCodyのFreeプランおよびProプランの新規受付を停止し、2025年7月23日をもってサービスを終了することを発表しました 。これは、Codyを大規模で複雑なコードベースを持つエンタープライズ向けの高度なソリューションとして磨き上げることにリソースを集中させるための決断です。 そして、個人開発者や最先端のAI機能を求めるユーザー向けには、新たな後継製品として「Amp」を発表しました。Codyが「コードを理解するアシスタント」であるのに対し、Ampはより自律的にタスクを計画・実行する「AIエージェント」と位置づけられています。この二本柱の戦略は、Sourcegraphが市場の異なるセグメントに最適化された製品を提供しようとしていることを示しています。 Codyの後継として個人開発者やエージェント機能を求めるユーザー向けに投入された「Amp」 図表1：Sourcegraph社の製品ポートフォリオ（2025年時点） 業界全体のトレンドとCodyの位置づけ 現在のAI開発ツール業界には、二つの大きなトレンドがあります。 「アシスタント」から「エージェント」へ： 単にコードを提案する「アシスタント」から、より複雑なタスク（例：「このバグを修正して、テストを書いて、プルリクエストを作成して」）を自律的に実行する「エージェント」への進化です。Sourcegraphは、Cody（特にDeep Cody構想）でアシスタント能力を深めつつ、Ampでエージェントの領域に踏み込むことで、このトレンドに対応しています。 コンテキストの重要性の認識： AIの性能は、基盤となるLLMの賢さだけでなく、「いかに質の高い、的確なコンテキストを与えられるか」で決まるという認識が業界の共通理解となっています。この点で、Sourcegraphが長年培ってきたコード検索とコードグラフ技術は、CodyのRAG（検索拡張生成）における圧倒的な優位性の源泉となっており、同社の最大の競争力と言えるでしょう 。 図表2：AIコーディングツールの進化段階と各製品の位置づけ 課題と論点 一方で、Sourcegraphの歩みは順風満帆なだけではありません。信頼性（Trustworthiness）を評価する上で、いくつかの課題にも触れておく必要があります。 オープンソース戦略の変更： かつて「100%オープンに開発する」文化を誇っていたSourcegraphですが、2023年頃から主要なリポジトリを非公開に転換しました。これには、ビジネス上の理由（競合による模倣の防止など）がありましたが、一部のコミュニティからは失望の声も上がりました 。これは、オープンソースとビジネスの両立の難しさを示す一例です。 セキュリティインシデント： 2023年8月、開発者が誤って公開リポジトリにコミットした管理者アクセストークンが不正利用されるインシデントが発生しました 。Sourcegraphは迅速にインシデントを検知・公表し、影響範囲を限定しましたが、この出来事は、いかに厳重なセキュリティ体制が求められるかを浮き彫りにしました。 これらの課題に透明性をもって対応し、エンタープライズ顧客からの信頼をいかに維持・向上させていくかが、同社の今後の成長の鍵を握っています。 図表3：SourcegraphおよびCodyに関連する主要な出来事のタイムライン Codyが開発者と組織にもたらす変革 Codyは単なるツールではなく、開発の文化そのものを変革するポテンシャルを秘めています。ここでは、Codyがもたらす具体的な価値を、技術リーダーと開発者、それぞれの視点から探ります。 CodyはLeidos、Qualtrics、Coinbaseなど多くの先進的企業で採用されている 技術リーダー/マネージャーへの示唆 経営層やチームリーダーにとって、Codyは投資対効果（ROI）の高い戦略的ツールとなり得ます。 測定可能な生産性向上： 導入企業からは、具体的な成果が報告されています。例えば、Qualtrics社では、Codyを利用するエンジニアはコード理解速度が25%向上し、Web検索の頻度が28%減少、1日あたり10〜30分の時間を節約していると報告しています 。防衛・IT大手のLeidos社では、シニア開発者がジュニア開発者を指導する時間が週8時間から2時間に短縮されたといいます 。 コード品質と標準化の推進： 「Prompt Library」機能は、単なる効率化ツールではありません。チームのコーディング規約やセキュリティのベストプラクティスをカスタムコマンドとして組み込むことで、Codyを「品質ゲートキーパー」として機能させることができます。これにより、コードレビューの負担を軽減し、組織全体のコード品質を底上げすることが可能です。 鉄壁のセキュリティとコンプライアンス： エンタープライズにとってセキュリティは最優先事項です。Codyは、セルフホストやAir-Gap（閉鎖網）環境へのデプロイメントオプションを提供し、企業の機密コードが外部に出ることを完全に防ぎます。また、RBAC（ロールベースのアクセス制御）により、開発者がアクセス権のないリポジトリの情報をCody経由で閲覧することも防げるため、厳格なコンプライアンス要件にも対応できます。 図表1：Qualtrics社のケーススタディに見るCody導入による生産性向上効果 開発者への示唆 開発者個人にとっては、Codyは日々の業務の質を劇的に向上させるパートナーとなります。 認知負荷の劇的な軽減： 巨大で複雑なレガシーコードや、初めて触るマイクロサービスのコードを理解するのは、多大な精神的エネルギーを消耗します。Codyがあれば、コードの海を泳ぎ回る代わりに、「このAPIのエンドポイントは何？」「このエラーの原因は？」と尋ねるだけで済みます。Leidos社で生まれた「まだCodyに聞いてないなら、私に聞くな（If you haven&#39;t yet asked Cody, don&#39;t ask me.）」というルールは、Codyが開発者の認知負荷をいかに軽減するかを象徴しています。 超高速なスキルアップツール： 新しいプログラミング言語、フレームワーク、あるいは社内ライブラリを学ぶ際、Codyは最高の家庭教師になります。ドキュメントを探し回る代わりに、実際のコード例を生成させたり、既存の実装を解説させたりすることで、実践的にスキルを習得できます。 「面白い仕事」への集中： 定型的なコードの記述、単体テストの生成、ドキュメント作成といった退屈な作業をCodyに任せることで、開発者はより創造的で、本質的な問題解決、つまり「面白い仕事」に集中できるようになります。これは、開発者の満足度とエンゲージメントを高める上でも非常に重要です。 図表2：Cody導入による開発者のタスク内容の変化（概念図） よくある質問（FAQ） ここでは、Sourcegraph Codyに関して多くの方が抱くであろう疑問について、簡潔にお答えします。 Codyは主要なIDEを幅広くサポートしている Q1: Sourcegraph Codyの料金体系はどうなっていますか？ A: 2025年10月現在、Codyはエンタープライズ向けの製品となっており、具体的な価格は問い合わせが必要です。以前提供されていた個人向けのFreeプランとProプランは、2025年7月23日をもって新規受付を終了し、将来的にはサービスが終了する予定です。個人や小規模チーム向けには、後継製品として「Amp」が提供されています 。 Q2: CodyとAmpの違いは何ですか？ A: Codyは、既存の巨大なコードベースを深く理解し、開発者の質問に答えたり、コードを補完したりする「AIアシスタント」です。エンタープライズ環境でのコード理解とナビゲーションに重点を置いています。一方、Ampはより自律的にタスクを計画・実行する「AIエージェント」と位置づけられており、個々のタスクを完遂する能力に焦点を当てています。 Q3: CodyはどのようなLLMを使用していますか？ A: Codyの大きな特徴は、特定のLLMにロックインされない柔軟性です。デフォルトではAnthropic社のClaude 3.5 Sonnetなどが利用されますが、企業はOpenAI (GPT-4oなど)、他のAnthropicモデル、さらにはオープンソースのLLMを選択できます。また、Azure OpenAIやAmazon Bedrockといったクラウドサービス経由で、自社専用のLLMに接続することも可能です 。 Q4: コードのプライバシーとセキュリティはどのように保護されますか？ A: Codyはエンタープライズグレードのセキュリティを最優先に設計されています。SaaS版では、顧客のコードがLLMの学習データとして使用されることはなく、ゼロリテンション（データを保持しない）ポリシーが保証されています。さらに、機密性の高い情報を扱う企業向けに、自社のインフラでCodyを運用するセルフホスト型や、外部ネットワークから隔離されたAir-Gap環境でのデプロイメントも可能です 。 Q5: どのIDEでCodyを利用できますか？ A: Codyは、開発者が普段使用している環境で利用できるよう、幅広いIDEをサポートしています。主要な対応IDEは、VS Code、JetBrains系のIDE（IntelliJ, PyCharm, GoLandなど）、Neovimです。また、Visual Studioのサポートもプレビュー版として提供されています。もちろん、SourcegraphのWebインターフェース上でもCodyのチャット機能を利用できます 。 図表1：CodyとAmpの役割分担 図表2：Cody Enterpriseが提供するセキュリティ機能 まとめと今後の展望 本記事では、Sourcegraph Codyについて、その核心技術から競合との違い、実践的な使い方、そして背景にある戦略まで、多角的に深掘りしてきました。 結論として、Sourcegraph Codyは単なるコード生成ツールではありません。それは、Sourcegraphが長年培ってきた「コードグラフ」という強力な武器を手に、巨大で複雑なエンタープライズのコードベースを真に理解し、開発者と対話できるAIコーディングアシスタントです。その深いコンテキスト理解能力こそが、他のツールとの決定的な差別化要因であり、特に大規模組織において、開発者の生産性を劇的に向上させる可能性を秘めています。 AIが開発者を代替するのではないか、という議論は常にありますが、Codyのようなツールの登場は、むしろ逆の未来を示唆しています。AIは、開発者を退屈で反復的な作業から解放し、より創造的で、より本質的な問題解決に集中させるための「能力拡張ツール（Augmentation Tool）」となるでしょう。Codyは、その未来を体現する最も先進的なツールの一つです。 もしあなたが大規模な開発組織のリーダーであり、チームの生産性とコード品質の向上に課題を感じているなら、Sourcegraphに問い合わせてみる価値は十分にあります。もしあなたが個人開発者で、AIエージェントの最前線を体験したいのであれば、その後継製品である「Amp」を試してみることをお勧めします。 AIと共にコーディングする時代は、もう始まっています。この変化の波に乗り遅れないために、ぜひSourcegraphのコミュニティに参加し、最新の情報を追いかけてみてはいかがでしょうか。 本レポートは情報提供および教育目的のみに作成されたものです。 記載されている情報は、記事公開時点（2025-10-31）のものであり、将来的に変更される可能性があります。 本記事の内容に基づいて行われたいかなる判断についても、筆者および発行元は一切の責任を負いません。 参考資料 [1] How to Use Sourcegraph Cody - Vibe Coding Retreat https://www.vibecodingretreat.com/tools/sourcegraph-cody/use [2] Copilot vs. Cody: Why context matters for code AI | Sourcegraph Blog https://sourcegraph.com/blog/copilot-vs-cody-why-context-matters-for-code-ai [3] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [4] Report: Sourcegraph Business Breakdown &amp; Founding Story https://research.contrary.com/company/sourcegraph [5] The power user&#39;s guide to Cody AI for Visual Studio Code https://sourcegraph.com/blog/power-users-guide-to-cody-ai-for-visual-studio-code [6] Cody: The AI-powered tool helping support engineers unblock ... https://sourcegraph.com/blog/cody-the-ai-powered-tool-helping-support-engineers-unblock-themselves [7] Sourcegraph Comparisons | Cody vs Copilot https://sourcegraph.com/compare/copilot-vs-cody [8] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [9] Accelerate your work with the new Prompt Library - Sourcegraph https://sourcegraph.com/changelog/prompt-library [10] GitHub Copilot Vs CodeWhisperer Vs Tabnine Vs Cursor - AI https://aicompetence.org/github-copilot-vs-codewhisperer-vs-tabnine-vs-cursor/ [11] Amazon CodeWhisperer Tutorial: Boost Coding Efficiency https://aws.amazon.com/awstv/watch/2b6a0014a34/ [12] Guide to Cody | Software.com https://www.software.com/ai-index/tools/cody [13] Compare - Sourcegraph https://sourcegraph.com/compare [14] How Cody provides remote repository awareness for codebases of ... https://sourcegraph.com/blog/how-cody-provides-remote-repository-context [15] AI-Powered Development: A Comparative Study of Amazon ... https://medium.com/@kaushikvikas/ai-powered-development-a-comparative-study-of-amazon-codewhisperer-github-copilot-and-tabnine-df21c0649f76 [16] A Comparative Analysis of GitHub Copilot, Tabnine, Amazon ... https://waresix.engineering/a-comparative-analysis-of-github-copilot-tabnine-amazon-codewhisperer-and-codeium-6109b4165e5e [17] AWS CodeWhisperer creates computer code from natural language https://www.amazon.science/latest-news/aws-codewhisperer-creates-computer-code-from-natural-language [18] Tabnine AI Code Assistant | Smarter AI Coding Agents. Total ... https://www.tabnine.com/ [19] Compare - Sourcegraph https://sourcegraph.com/compare [20] Is There a Future for Software Engineers? The Impact of AI [2025] https://brainhub.eu/library/software-developer-age-of-ai [21] The power user&#39;s guide to Cody AI for Visual Studio Code https://sourcegraph.com/blog/power-users-guide-to-cody-ai-for-visual-studio-code [22] Introducing enhancements to Code Search and Cody, including a 2x ... https://sourcegraph.com/blog/feature-release-october-2023 [23] Impact of AI Assistants: Sourcegraph&#39;s Cody and the Future of Coding https://medium.com/@ShawnBasquiat/impact-of-ai-assistants-sourcegraphs-cody-and-the-future-of-coding-450a99185c22 [24] Cody Prompting Guide - Sourcegraph docs https://sourcegraph.com/docs/cody/prompts-guide [25] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [26] Opening access to Cody for Sourcegraph.com https://sourcegraph.com/blog/cody-for-open-source [27] Amp by Sourcegraph - - Crush With AI https://crushwithai.net/amp-sourcegraph-review/ [28] How Sourcegraph hit $50M revenue with a 209 person team in 2025. https://getlatka.com/companies/sourcegraph [29] The intersection of AI in technical support - Sourcegraph https://sourcegraph.com/blog/the-intersection-of-ai-in-technical-support [30] Sourcegraph Cody vs Cursor vs Augment Code for Enterprise ... https://www.augmentcode.com/guides/sourcegraph-cody-vs-cursor-vs-augment-code-for-enterprise-development [31] Sourcegraph makes core repository private, co-founder complains ... https://devclass.com/2024/08/21/sourcegraph-makes-core-repository-private-co-founder-complains-open-source-means-extra-work-and-risk/ [32] Security update: Incident involving unauthorized admin access https://sourcegraph.com/blog/security-update-august-2023 [33] Cody + Leidos: Maximizing efficiency with heightened security in the ... https://sourcegraph.com/case-studies/cody-leidos-maximizing-efficiency-heightened-security-ai-race [34] Qualtrics speeds up unit test creation and understanding code with ... https://sourcegraph.com/case-studies/qualtrics-speeds-up-unit-tests-and-code-understanding-with-cody [35] Amp Reviews 2025: Details, Pricing, &amp; Features - G2 https://www.g2.com/products/amp-2025-08-06/reviews [36] Will AI Make Software Engineers Obsolete? Here&#39;s the Reality https://bootcamps.cs.cmu.edu/blog/will-ai-replace-software-engineers-reality-check [37] Sourcegraph - Crunchbase Company Profile &amp; Funding https://www.crunchbase.com/organization/sourcegraph [38] How Cody understands your codebase | Sourcegraph Blog https://sourcegraph.com/blog/how-cody-understands-your-codebase [39] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [40] Changelog - Sourcegraph https://sourcegraph.com/changelog [41] Sourcegraph Comparisons | Cody vs Copilot https://sourcegraph.com/compare/copilot-vs-cody [42] Copilot vs. Cody: Why context matters for code AI | Sourcegraph Blog https://sourcegraph.com/blog/copilot-vs-cody-why-context-matters-for-code-ai [43] Sourcegraph Cody vs Cursor vs Augment Code for Enterprise ... https://www.augmentcode.com/guides/sourcegraph-cody-vs-cursor-vs-augment-code-for-enterprise-development [44] Cody Prompting Guide - Sourcegraph docs https://sourcegraph.com/docs/cody/prompts-guide [45] The power user&#39;s guide to Cody AI for Visual Studio Code https://sourcegraph.com/blog/power-users-guide-to-cody-ai-for-visual-studio-code [46] RAG to Riches | Sourcegraph Blog https://sourcegraph.com/blog/rag-to-riches [47] Sourcegraph makes core repository private, co-founder complains ... https://devclass.com/2024/08/21/sourcegraph-makes-core-repository-private-co-founder-complains-open-source-means-extra-work-and-risk/ [48] Changes to Cody Free, Pro, and Enterprise Starter plans https://sourcegraph.com/blog/changes-to-cody-free-pro-and-enterprise-starter-plans [49] Introducing enhancements to Code Search and Cody, including a 2x ... https://sourcegraph.com/blog/feature-release-october-2023 [50] Community - Sourcegraph https://sourcegraph.com/community\n\n"},"metadata":{"arguments":"{\"link_id\":17}","display_result":"","duration":"13s","id":"call_wmcfimUFgZ","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【17†Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底†https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704】\nTitle: Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底解説と実践\n\nURL Source: https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704\n\nMarkdown Content:\nSourcegraph Codyとは？- コードを「知る」AIアシスタントの全貌\n----------------------------------------\n\n### 核心的な特性「コード認識（Code-Awareness）」\n\n### 主要機能の紹介\n\n### ターゲットユーザー\n\n競合製品との徹底比較：Codyはなぜ選ばれるのか？\n-------------------------\n\n### 総合比較表\n\n### vs. GitHub Copilot\n\n### vs. Amazon CodeWhisperer (現 Amazon Q Developer)\n\n### vs. Tabnine\n\n### vs. Cursor\n\nSourcegraph Cody実践活用ガイド：明日から使えるTips＆テクニック\n-----------------------------------------\n\n### Step 1: インストールと初期設定\n\n### Step 2: 基本機能を使ってみる\n\n### Step 3: 実践的なユースケース\n\n### Step 4: パワーユーザー向けTips\n\nSourcegraphの戦略とAIの未来：Codyの進化と業界の動向\n----------------------------------\n\n### Sourcegraphの歩みと戦略的転換\n\n### 業界全体のトレンドとCodyの位置づけ\n\n### 課題と論点\n\nCodyが開発者と組織にもたらす変革\n------------------\n\n### 技術リーダー/マネージャーへの示唆\n\n### 開発者への示唆\n\nよくある質問（FAQ）\n-----------\n\nまとめと今後の展望\n---------\n\n目次 導入：なぜ今、AIコーディングアシスタント「Cody」に注目すべきなのか？ Sourcegraph Codyとは？- コードを「知る」AIアシスタントの全貌 核心的な特性「コード認識（Code-Awareness）」 主要機能の紹介 ターゲットユーザー 競合製品との徹底比較：Codyはなぜ選ばれるのか？ 総合比較表 vs. GitHub Copilot vs. Amazon CodeWhisperer (現 Amazon Q Developer) vs. Tabnine vs. Cursor Sourcegraph Cody実践活用ガイド：明日から使えるTips＆テクニック Step 1: インストールと初期設定 Step 2: 基本機能を使ってみる Step 3: 実践的なユースケース Step 4: パワーユーザー向けTips Sourcegraphの戦略とAIの未来：Codyの進化と業界の動向 Sourcegraphの歩みと戦略的転換 業界全体のトレンドとCodyの位置づけ 課題と論点 Codyが開発者と組織にもたらす変革 技術リーダー/マネージャーへの示唆 開発者への示唆 よくある質問（FAQ） まとめと今後の展望 導入：なぜ今、AIコーディングアシスタント「Cody」に注目すべきなのか？ 現代のソフトウェア開発は、かつてないほどの複雑さに直面しています。コードベースは巨大化し、マイクロサービスアーキテクチャは依存関係を複雑に絡ませ、市場は絶えず迅速な機能リリースを要求します。私たち開発者は、コードを書く時間よりも、既存のコードを理解し、デバッグし、技術的負債と格闘する時間の方が長い、と感じることも少なくないでしょう。 IDEに統合され、開発者を支援するSourcegraph Cody このような課題に対する強力な解決策として、AIコーディングアシスタントが登場しました。当初は単純なコード補完ツールでしたが、今やその能力は飛躍的に進化しています。そして、その進化の最前線にいるのが、本記事で深掘りする「Sourcegraph Cody」です。 Codyは、単なるコードスニペットの提案者ではありません。それは、あなたの組織が持つコードベース全体を理解し、文脈に基づいた対話ができる真の「相棒」です。この記事では、Codyがなぜ「コードを理解する」とまで言われるのか、その核心技術から、GitHub Copilotなどの競合製品との違い、明日から使える実践的な活用法、そしてSourcegraph社の戦略とAI開発の未来まで、徹底的に解説していきます。 図表1：現代の開発者が直面する時間の使い方 この記事を読み終える頃には、Codyがあなたの開発ワークフローをどのように変革し、チームの生産性をいかにして新たなレベルへと引き上げる可能性があるのか、明確なビジョンを描けるようになっているはずです。 図表2：AIコーディングアシスタントの進化段階 Sourcegraph Codyとは？- コードを「知る」AIアシスタントの全貌 Sourcegraph Codyは、一言で言えば「コードを深く理解するAIコーディングアシスタント」です。これは、2013年に創業されたSourcegraph社 が長年培ってきた「コードインテリジェンスプラットフォーム」の技術を基盤としています。Codyは単体で存在するのではなく、Sourcegraphの強力なコード検索・分析能力の上に成り立っているのです。 CodyのチャットUI。複数のファイル（例：Read 16 files）を文脈として読み込み、的確な回答を生成する。 核心的な特性「コード認識（Code-Awareness）」 Codyが他の多くのAIツールと一線を画す最大の理由は、その「コード認識（Code-Awareness）」能力にあります。これは、Sourcegraph独自の「コードグラフ（Code Graph）」技術によって実現されています。 多くのAIアシスタントは、現在開いているファイルや、限定的なプロジェクト内の情報しか文脈として利用できません。しかしCodyは、コードグラフを用いて、組織内に存在するすべてのリポジトリ、ライブラリ間の依存関係、関数の定義元と呼び出し先といった関係性を網羅的に把握します。いわば、コードベース全体の地図を持っているようなものです。 そして、この広大な地図から最適な情報を引き出すために、CodyはRAG（Retrieval-Augmented Generation）という技術を駆使します。ユーザーからの質問（プロンプト）を受け取ると、Codyはまずコードグラフを検索し、関連性の高いコードスニペットやドキュメントを「文脈」として収集します。そして、その豊富な文脈情報と共にプロンプトを大規模言語モデル（LLM）に渡すことで、驚くほど正確で、文脈に即した回答を生成するのです 。 図表2：CodyのRAG（Retrieval-Augmented Generation）アーキテクチャ概念図 主要機能の紹介 Codyの強力な基盤技術は、開発者の日常業務を支援する多彩な機能として結実しています。 コンテキストを考慮したチャット： 「このプロジェクトの認証ロジックはどこで実装されていますか？」といった抽象的な質問に対し、Codyは複数のリポジトリを横断して関連ファイルを探し出し、具体的なコードを引用しながら回答します。これは、新しいチームメンバーが巨大なコードベースを理解する上で絶大な効果を発揮します。 高精度な自動補完： コードグラフから得られる文脈のおかげで、Codyのコード補完は、存在しない関数名を提案したり、型エラーを含むコードを生成したりする「ハルシネーション（幻覚）」が大幅に抑制されています。Sourcegraphは、このアプローチにより30%以上の補完受け入れ率（Completion Acceptance Rate）を達成したと報告しています 。 コマンドとPrompt Library： /explain（コード説明）や/test（単体テスト生成）といった便利な組み込みコマンドが用意されています。さらに強力なのが「Prompt Library」機能で、チーム独自のコーディング規約やレビュー観点をカスタムプロンプトとして保存・共有できます。これにより、AIアシスタントをチームの「標準」に合わせて教育することが可能になります 。 コードの理解とデバッグ支援： 複雑な正規表現の解説、バグ報告からの原因特定、レガシーコードのリファクタリング提案など、開発ライフサイクルのあらゆる場面で開発者の認知負荷を軽減します。 図表1：Sourcegraph Codyの主要機能一覧 動画：Sourcegraph Codyの初心者向けチュートリアル ターゲットユーザー これらの特性から、Codyの主なターゲットユーザーは明確です。それは、大規模で複雑、かつ分散したコードベースを扱うエンタープライズ（大企業）です。特に、以下のようなニーズを持つ組織にとって、Codyは強力な選択肢となります 。 複数のコードホスト（GitHub, GitLabなど）にリポジトリが分散している。 マイクロサービスアーキテクチャを採用しており、サービス間の依存関係を理解するのが難しい。 AIが生成するコードの精度と信頼性を重視する。 セキュリティ要件が厳しく、セルフホストや使用するLLMを自社でコントロールしたい。 競合製品との徹底比較：Codyはなぜ選ばれるのか？ AIコーディングアシスタント市場は活況を呈しており、多くの優れたツールが存在します。ここでは、技術選定を行う読者のために、Codyを主要な競合製品であるGitHub Copilot、Amazon CodeWhisperer（現Amazon Q Developer）、Tabnine、Cursorと比較し、その独自性を明らかにします。 AIコーディングアシスタント市場の主要プレイヤー 総合比較表 まず、各ツールの特徴を一覧で比較してみましょう。これにより、全体像を素早く把握できます。 機能/特性 Sourcegraph Cody GitHub Copilot Amazon Q (CodeWhisperer) Tabnine Cursor コンテキスト理解 コードベース全体（複数リポジトリ）、コードグラフ 主に単一リポジトリ、開いているファイル 主に開いているファイル、AWS SDKに最適化 プロジェクト全体、自己学習 手動でのファイル/フォルダ指定 核心技術 コードグラフ + RAG OpenAI Codex/GPT Amazon独自LLM Tabnine独自LLM OpenAI/Anthropic LLM ターゲット層 エンタープライズ、大規模チーム 個人〜エンタープライズ（GitHub中心） 個人（AWSユーザー）〜エンタープライズ 個人〜エンタープライズ 個人開発者、小規模チーム LLM柔軟性 非常に高い（OpenAI, Anthropic, OSS, Azure, Bedrock対応） 限定的（OpenAIモデル） 限定的（Amazonモデル） 高い（自社モデル + 3rd party） 高い（OpenAI, Anthropic） セキュリティ 高い（セルフホスト、Air-Gap対応可） Enterprise版で強化 AWSセキュリティ基準 高い（セルフホスト可） SOC 2 Type II、SaaS中心 IDEサポート VS Code, JetBrains, Neovim, Web VS Code, JetBrains, Visual Studio VS Code, JetBrains, AWS Cloud9等 多数のIDEに対応 IDEそのもの（VS Codeフォーク） 図表1：主要AIコーディングアシスタント機能比較表 図表2：各ツールの特性レーダーチャート vs. GitHub Copilot GitHub Copilotは市場で最も知名度が高く、特にGitHubエコシステム内で作業する開発者にとっては非常に強力です。コード生成の速さと手軽さでは右に出るものはいません。 しかし、両者の決定的な違いは「コンテキストの深さ」にあります。Copilotのコンテキストは主に開いているファイルや単一のリポジトリに限定されがちです。一方、Codyは前述の通り、コードグラフを用いて組織全体のコードを理解します。 Sourcegraphが公開した比較記事では、新しいコードベースのセットアップ方法を質問した際、Copilotは一般的なnpm startコマンドを提案しましたが、そのプロジェクトには存在しないコマンドでした。対してCodyは、12個の関連ファイルを読み込み、.envファイルの設定やデータベースのマイグレーションを含む正確な手順を提示しました 。これは、Codyが単に「推測」するのではなく、「事実に基づいて」回答する能力の証左です。 Codyの強み： 複数リポジトリにまたがる複雑なエンタープライズ環境での深いコード理解と、回答の根拠を提示する透明性。 vs. Amazon CodeWhisperer (現 Amazon Q Developer) Amazon CodeWhisperer（現在はAmazon Q Developerに統合）のユニークな点は、AWSのAPIやベストプラクティスに最適化されていることです 。AWS上で開発を行う開発者にとっては、非常に的確なコード提案が期待できます。 Codyの優位性は、その汎用性とインフラの柔軟性にあります。Codyは特定のクラウドプラットフォームに依存せず、あらゆる種類のコードベースに対応できます。また、企業が自社のセキュリティポリシーに合わせてLLMをAzure OpenAIやAmazon Bedrock上でホストしたり、完全にセルフホストしたりできる選択肢の広さは、多くのエンタープライズにとって重要な要素です。 Codyの強み： 特定のベンダーにロックインされない汎用性と、エンタープライズの要求に応えるデプロイメントの柔軟性。 vs. Tabnine TabnineはAIコード補完の草分け的存在であり、特にプライバシーを重視する企業から支持されています。AIモデルをローカルマシンや自社サーバーで完全に実行できるオプションは大きな特徴です 。 Codyとの違いは、ツールの主眼にあります。Tabnineが主に「コード補完」というタスクに特化しているのに対し、Codyはコード補完に加えて、チャットを通じてコードベース全体と対話し、理解を深める「アシスタント」としての役割をより重視しています。Codyは「書く」だけでなく、「読む」「理解する」「修正する」という開発サイクル全体をサポートするツールと言えるでしょう。 Codyの強み： コード補完に留まらない、チャットを通じた対話的なコードベース全体の理解と分析能力。 vs. Cursor Cursorは「AI-first」を掲げるエディタそのものであり、VS Codeのフォークとして開発されています。UIにAI機能が深く統合されており、特に個人開発者や小規模チームから熱狂的な支持を得ています。手動で@メンションを使ってコンテキストを指定する操作感は直感的です。 Codyは既存のワークフローを尊重するアプローチを取ります。開発者が使い慣れたVS CodeやJetBrains IDEにプラグインとして追加するため、IDEの乗り換えを強制しません。これは、多様な開発環境が混在するエンタープライズ組織にとって、導入の障壁を大きく下げる要因となります 。 Codyの強み： 既存の開発環境やワークフローを妨げないシームレスな統合と、エンタープライズ規模での導入のしやすさ。 図表3：あなたのニーズに合ったAIアシスタント選択フローチャート Sourcegraph Cody実践活用ガイド：明日から使えるTips＆テクニック Codyの真価は、実際に使ってみて初めて実感できます。ここでは、Codyをあなたの「最強の相棒」にするための、具体的なステップとパワーユーザー向けのテクニックを紹介します。 Step 1: インストールと初期設定 Codyを始めるのは非常に簡単です。ここではVS Codeを例に説明します。 VS Code拡張機能のインストール： VS CodeのMarketplaceで「Cody AI Code Assistant」を検索し、インストールします。 アカウントへのサインイン： インストール後、Codyのサイドバーが表示されます。Sourcegraph.comのアカウント（GitHub, GitLab, Googleアカウントでサインイン可能）でログインします。エンタープライズ版を利用する場合は、自社のSourcegraphインスタンスのURLとアクセストークンを入力します。 準備完了： これだけで、Codyのチャットや自動補完機能が使えるようになります。 VS Code Marketplaceで公開されているCody AIアシスタント 【ポイント】JetBrains系のIDE（IntelliJ, PyCharmなど）やNeovimにも対応しています。お使いの環境に合わせて公式ドキュメントを参照してください 。 Step 2: 基本機能を使ってみる まずは基本的な機能に慣れましょう。 AIチャット： サイドバーのチャットウィンドウに、人間と話すように質問を投げかけてみましょう。例えば、開いているファイルについて「この関数の役割を教えてください」と尋ねるだけで、Codyが詳細な説明を返してくれます。 自動補完： コードを書き始めると、Codyが灰色の文字で補完候補を提案します。Tabキーを押すだけで、その提案を受け入れることができます。単一行だけでなく、関数全体を補完してくれることもあります。 インラインチャット： エディタから離れたくない場合は、コード上でCommand + Shift + C（Mac）またはCtrl + Shift + C（Windows/Linux）を押すと、その場にチャットウィンドウが現れます。特定のコードブロックを選択して実行すれば、そのコードだけを文脈にした対話が可能です。 エディタ内で直接対話できるインラインチャット機能 Step 3: 実践的なユースケース Codyの真価は、リアルな開発シナリオで発揮されます。Sourcegraphのブログで紹介されていたシナリオを参考に、Codyの実力を試してみましょう。 シナリオ1：新しいコードベースの理解 新しいプロジェクトに参加したとします。まずはCodyに「このアプリケーションは何をするものですか？」と聞いてみましょう。CodyはREADMEファイルだけでなく、ソースコード全体をスキャンし、使用されている技術スタック、主要な機能、外部APIの利用状況などをまとめた、非常に詳細な概要を生成してくれます。 シナリオ2：開発環境のセットアップ 次に、「開発モードでこのアプリを起動する方法を教えてください」と質問します。Codyはpackage.jsonや設定ファイルを解析し、依存関係のインストール、環境変数ファイル（.env）の作成、データベースのマイグレーション、そして正しい起動コマンド（例：npm run dev）まで、具体的な手順をステップバイステップで教えてくれます。 シナリオ3：新機能の追加 「ミリ秒をSMPTEタイムコード形式（HH:MM:SS:FF）に変換するJavaScript関数を書いてください」と依頼します。Codyは、単にコードを生成するだけでなく、既存のコードスタイルや規約に合わせて、適切な場所に配置できる品質のコードを提案してくれます。 具体的な要求に対し、Reactコンポーネントのコードを生成するCody Step 4: パワーユーザー向けTips Codyをさらに使いこなすための秘訣をいくつか紹介します。 効果的なプロンプトの書き方： Codyを「何も知らない新人のチームメンバー」だと思って接するのがコツです。「この関数を修正して」ではなく、「このcalculatePrice関数に、顧客がプレミアム会員の場合は10%割引を適用するロジックを追加してください。価格は小数点以下2桁に丸める必要があります」のように、役割、文脈、具体例、制約条件を明確に伝えましょう 。 Prompt Libraryの活用： チームで頻繁に行うタスク（例：「このコンポーネントに我々の標準的なStorybookファイルを作成して」）をカスタムコマンドとして「Prompt Library」に登録しましょう。これにより、チーム全体の生産性が向上し、コーディング標準も自然と守られるようになります。 IDEのカスタマイズ： 私は、CodyのパネルをVS Codeの左側のメインサイドバーから右側のセカンダリサイドバーにドラッグ＆ドロップして使っています。これにより、左側でファイルエクスプローラーを開きながら、右側でCodyと常に対話できるため、作業が非常にスムーズになります 。 図表1：効果的なCodyプロンプトの構成要素 動画：Cody、Copilot、Cursorの比較デモ 図表2：Codyを活用した開発ワークフローの変化 Sourcegraphの戦略とAIの未来：Codyの進化と業界の動向 Codyを理解するためには、開発元であるSourcegraph社の戦略と、AI開発業界全体の大きな潮流を把握することが不可欠です。 Sourcegraphの歩みと戦略的転換 2013年に創業したSourcegraphは、もともと「ユニバーサルコード検索」をミッションに掲げ、開発者が巨大なコードベースを人間がナビゲートするためのツールを提供してきました 。このコード検索技術と、コードの構造を理解する「コードグラフ」が、後のCodyの強力な基盤となります。 しかし、AIの波が押し寄せる中で、Sourcegraphは大きな戦略転換を決断します。それが、エンタープライズ市場への集中です。 2024年6月、SourcegraphはCodyのFreeプランおよびProプランの新規受付を停止し、2025年7月23日をもってサービスを終了することを発表しました 。これは、Codyを大規模で複雑なコードベースを持つエンタープライズ向けの高度なソリューションとして磨き上げることにリソースを集中させるための決断です。 そして、個人開発者や最先端のAI機能を求めるユーザー向けには、新たな後継製品として「Amp」を発表しました。Codyが「コードを理解するアシスタント」であるのに対し、Ampはより自律的にタスクを計画・実行する「AIエージェント」と位置づけられています。この二本柱の戦略は、Sourcegraphが市場の異なるセグメントに最適化された製品を提供しようとしていることを示しています。 Codyの後継として個人開発者やエージェント機能を求めるユーザー向けに投入された「Amp」 図表1：Sourcegraph社の製品ポートフォリオ（2025年時点） 業界全体のトレンドとCodyの位置づけ 現在のAI開発ツール業界には、二つの大きなトレンドがあります。 「アシスタント」から「エージェント」へ： 単にコードを提案する「アシスタント」から、より複雑なタスク（例：「このバグを修正して、テストを書いて、プルリクエストを作成して」）を自律的に実行する「エージェント」への進化です。Sourcegraphは、Cody（特にDeep Cody構想）でアシスタント能力を深めつつ、Ampでエージェントの領域に踏み込むことで、このトレンドに対応しています。 コンテキストの重要性の認識： AIの性能は、基盤となるLLMの賢さだけでなく、「いかに質の高い、的確なコンテキストを与えられるか」で決まるという認識が業界の共通理解となっています。この点で、Sourcegraphが長年培ってきたコード検索とコードグラフ技術は、CodyのRAG（検索拡張生成）における圧倒的な優位性の源泉となっており、同社の最大の競争力と言えるでしょう 。 図表2：AIコーディングツールの進化段階と各製品の位置づけ 課題と論点 一方で、Sourcegraphの歩みは順風満帆なだけではありません。信頼性（Trustworthiness）を評価する上で、いくつかの課題にも触れておく必要があります。 オープンソース戦略の変更： かつて「100%オープンに開発する」文化を誇っていたSourcegraphですが、2023年頃から主要なリポジトリを非公開に転換しました。これには、ビジネス上の理由（競合による模倣の防止など）がありましたが、一部のコミュニティからは失望の声も上がりました 。これは、オープンソースとビジネスの両立の難しさを示す一例です。 セキュリティインシデント： 2023年8月、開発者が誤って公開リポジトリにコミットした管理者アクセストークンが不正利用されるインシデントが発生しました 。Sourcegraphは迅速にインシデントを検知・公表し、影響範囲を限定しましたが、この出来事は、いかに厳重なセキュリティ体制が求められるかを浮き彫りにしました。 これらの課題に透明性をもって対応し、エンタープライズ顧客からの信頼をいかに維持・向上させていくかが、同社の今後の成長の鍵を握っています。 図表3：SourcegraphおよびCodyに関連する主要な出来事のタイムライン Codyが開発者と組織にもたらす変革 Codyは単なるツールではなく、開発の文化そのものを変革するポテンシャルを秘めています。ここでは、Codyがもたらす具体的な価値を、技術リーダーと開発者、それぞれの視点から探ります。 CodyはLeidos、Qualtrics、Coinbaseなど多くの先進的企業で採用されている 技術リーダー/マネージャーへの示唆 経営層やチームリーダーにとって、Codyは投資対効果（ROI）の高い戦略的ツールとなり得ます。 測定可能な生産性向上： 導入企業からは、具体的な成果が報告されています。例えば、Qualtrics社では、Codyを利用するエンジニアはコード理解速度が25%向上し、Web検索の頻度が28%減少、1日あたり10〜30分の時間を節約していると報告しています 。防衛・IT大手のLeidos社では、シニア開発者がジュニア開発者を指導する時間が週8時間から2時間に短縮されたといいます 。 コード品質と標準化の推進： 「Prompt Library」機能は、単なる効率化ツールではありません。チームのコーディング規約やセキュリティのベストプラクティスをカスタムコマンドとして組み込むことで、Codyを「品質ゲートキーパー」として機能させることができます。これにより、コードレビューの負担を軽減し、組織全体のコード品質を底上げすることが可能です。 鉄壁のセキュリティとコンプライアンス： エンタープライズにとってセキュリティは最優先事項です。Codyは、セルフホストやAir-Gap（閉鎖網）環境へのデプロイメントオプションを提供し、企業の機密コードが外部に出ることを完全に防ぎます。また、RBAC（ロールベースのアクセス制御）により、開発者がアクセス権のないリポジトリの情報をCody経由で閲覧することも防げるため、厳格なコンプライアンス要件にも対応できます。 図表1：Qualtrics社のケーススタディに見るCody導入による生産性向上効果 開発者への示唆 開発者個人にとっては、Codyは日々の業務の質を劇的に向上させるパートナーとなります。 認知負荷の劇的な軽減： 巨大で複雑なレガシーコードや、初めて触るマイクロサービスのコードを理解するのは、多大な精神的エネルギーを消耗します。Codyがあれば、コードの海を泳ぎ回る代わりに、「このAPIのエンドポイントは何？」「このエラーの原因は？」と尋ねるだけで済みます。Leidos社で生まれた「まだCodyに聞いてないなら、私に聞くな（If you haven&#39;t yet asked Cody, don&#39;t ask me.）」というルールは、Codyが開発者の認知負荷をいかに軽減するかを象徴しています。 超高速なスキルアップツール： 新しいプログラミング言語、フレームワーク、あるいは社内ライブラリを学ぶ際、Codyは最高の家庭教師になります。ドキュメントを探し回る代わりに、実際のコード例を生成させたり、既存の実装を解説させたりすることで、実践的にスキルを習得できます。 「面白い仕事」への集中： 定型的なコードの記述、単体テストの生成、ドキュメント作成といった退屈な作業をCodyに任せることで、開発者はより創造的で、本質的な問題解決、つまり「面白い仕事」に集中できるようになります。これは、開発者の満足度とエンゲージメントを高める上でも非常に重要です。 図表2：Cody導入による開発者のタスク内容の変化（概念図） よくある質問（FAQ） ここでは、Sourcegraph Codyに関して多くの方が抱くであろう疑問について、簡潔にお答えします。 Codyは主要なIDEを幅広くサポートしている Q1: Sourcegraph Codyの料金体系はどうなっていますか？ A: 2025年10月現在、Codyはエンタープライズ向けの製品となっており、具体的な価格は問い合わせが必要です。以前提供されていた個人向けのFreeプランとProプランは、2025年7月23日をもって新規受付を終了し、将来的にはサービスが終了する予定です。個人や小規模チーム向けには、後継製品として「Amp」が提供されています 。 Q2: CodyとAmpの違いは何ですか？ A: Codyは、既存の巨大なコードベースを深く理解し、開発者の質問に答えたり、コードを補完したりする「AIアシスタント」です。エンタープライズ環境でのコード理解とナビゲーションに重点を置いています。一方、Ampはより自律的にタスクを計画・実行する「AIエージェント」と位置づけられており、個々のタスクを完遂する能力に焦点を当てています。 Q3: CodyはどのようなLLMを使用していますか？ A: Codyの大きな特徴は、特定のLLMにロックインされない柔軟性です。デフォルトではAnthropic社のClaude 3.5 Sonnetなどが利用されますが、企業はOpenAI (GPT-4oなど)、他のAnthropicモデル、さらにはオープンソースのLLMを選択できます。また、Azure OpenAIやAmazon Bedrockといったクラウドサービス経由で、自社専用のLLMに接続することも可能です 。 Q4: コードのプライバシーとセキュリティはどのように保護されますか？ A: Codyはエンタープライズグレードのセキュリティを最優先に設計されています。SaaS版では、顧客のコードがLLMの学習データとして使用されることはなく、ゼロリテンション（データを保持しない）ポリシーが保証されています。さらに、機密性の高い情報を扱う企業向けに、自社のインフラでCodyを運用するセルフホスト型や、外部ネットワークから隔離されたAir-Gap環境でのデプロイメントも可能です 。 Q5: どのIDEでCodyを利用できますか？ A: Codyは、開発者が普段使用している環境で利用できるよう、幅広いIDEをサポートしています。主要な対応IDEは、VS Code、JetBrains系のIDE（IntelliJ, PyCharm, GoLandなど）、Neovimです。また、Visual Studioのサポートもプレビュー版として提供されています。もちろん、SourcegraphのWebインターフェース上でもCodyのチャット機能を利用できます 。 図表1：CodyとAmpの役割分担 図表2：Cody Enterpriseが提供するセキュリティ機能 まとめと今後の展望 本記事では、Sourcegraph Codyについて、その核心技術から競合との違い、実践的な使い方、そして背景にある戦略まで、多角的に深掘りしてきました。 結論として、Sourcegraph Codyは単なるコード生成ツールではありません。それは、Sourcegraphが長年培ってきた「コードグラフ」という強力な武器を手に、巨大で複雑なエンタープライズのコードベースを真に理解し、開発者と対話できるAIコーディングアシスタントです。その深いコンテキスト理解能力こそが、他のツールとの決定的な差別化要因であり、特に大規模組織において、開発者の生産性を劇的に向上させる可能性を秘めています。 AIが開発者を代替するのではないか、という議論は常にありますが、Codyのようなツールの登場は、むしろ逆の未来を示唆しています。AIは、開発者を退屈で反復的な作業から解放し、より創造的で、より本質的な問題解決に集中させるための「能力拡張ツール（Augmentation Tool）」となるでしょう。Codyは、その未来を体現する最も先進的なツールの一つです。 もしあなたが大規模な開発組織のリーダーであり、チームの生産性とコード品質の向上に課題を感じているなら、Sourcegraphに問い合わせてみる価値は十分にあります。もしあなたが個人開発者で、AIエージェントの最前線を体験したいのであれば、その後継製品である「Amp」を試してみることをお勧めします。 AIと共にコーディングする時代は、もう始まっています。この変化の波に乗り遅れないために、ぜひSourcegraphのコミュニティに参加し、最新の情報を追いかけてみてはいかがでしょうか。 本レポートは情報提供および教育目的のみに作成されたものです。 記載されている情報は、記事公開時点（2025-10-31）のものであり、将来的に変更される可能性があります。 本記事の内容に基づいて行われたいかなる判断についても、筆者および発行元は一切の責任を負いません。 参考資料 [1] How to Use Sourcegraph Cody - Vibe Coding Retreat https://www.vibecodingretreat.com/tools/sourcegraph-cody/use [2] Copilot vs. Cody: Why context matters for code AI | Sourcegraph Blog https://sourcegraph.com/blog/copilot-vs-cody-why-context-matters-for-code-ai [3] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [4] Report: Sourcegraph Business Breakdown &amp; Founding Story https://research.contrary.com/company/sourcegraph [5] The power user&#39;s guide to Cody AI for Visual Studio Code https://sourcegraph.com/blog/power-users-guide-to-cody-ai-for-visual-studio-code [6] Cody: The AI-powered tool helping support engineers unblock ... https://sourcegraph.com/blog/cody-the-ai-powered-tool-helping-support-engineers-unblock-themselves [7] Sourcegraph Comparisons | Cody vs Copilot https://sourcegraph.com/compare/copilot-vs-cody [8] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [9] Accelerate your work with the new Prompt Library - Sourcegraph https://sourcegraph.com/changelog/prompt-library [10] GitHub Copilot Vs CodeWhisperer Vs Tabnine Vs Cursor - AI https://aicompetence.org/github-copilot-vs-codewhisperer-vs-tabnine-vs-cursor/ [11] Amazon CodeWhisperer Tutorial: Boost Coding Efficiency https://aws.amazon.com/awstv/watch/2b6a0014a34/ [12] Guide to Cody | Software.com https://www.software.com/ai-index/tools/cody [13] Compare - Sourcegraph https://sourcegraph.com/compare [14] How Cody provides remote repository awareness for codebases of ... https://sourcegraph.com/blog/how-cody-provides-remote-repository-context [15] AI-Powered Development: A Comparative Study of Amazon ... https://medium.com/@kaushikvikas/ai-powered-development-a-comparative-study-of-amazon-codewhisperer-github-copilot-and-tabnine-df21c0649f76 [16] A Comparative Analysis of GitHub Copilot, Tabnine, Amazon ... https://waresix.engineering/a-comparative-analysis-of-github-copilot-tabnine-amazon-codewhisperer-and-codeium-6109b4165e5e [17] AWS CodeWhisperer creates computer code from natural language https://www.amazon.science/latest-news/aws-codewhisperer-creates-computer-code-from-natural-language [18] Tabnine AI Code Assistant | Smarter AI Coding Agents. Total ... https://www.tabnine.com/ [19] Compare - Sourcegraph https://sourcegraph.com/compare [20] Is There a Future for Software Engineers? The Impact of AI [2025] https://brainhub.eu/library/software-developer-age-of-ai [21] The power user&#39;s guide to Cody AI for Visual Studio Code https://sourcegraph.com/blog/power-users-guide-to-cody-ai-for-visual-studio-code [22] Introducing enhancements to Code Search and Cody, including a 2x ... https://sourcegraph.com/blog/feature-release-october-2023 [23] Impact of AI Assistants: Sourcegraph&#39;s Cody and the Future of Coding https://medium.com/@ShawnBasquiat/impact-of-ai-assistants-sourcegraphs-cody-and-the-future-of-coding-450a99185c22 [24] Cody Prompting Guide - Sourcegraph docs https://sourcegraph.com/docs/cody/prompts-guide [25] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [26] Opening access to Cody for Sourcegraph.com https://sourcegraph.com/blog/cody-for-open-source [27] Amp by Sourcegraph - - Crush With AI https://crushwithai.net/amp-sourcegraph-review/ [28] How Sourcegraph hit $50M revenue with a 209 person team in 2025. https://getlatka.com/companies/sourcegraph [29] The intersection of AI in technical support - Sourcegraph https://sourcegraph.com/blog/the-intersection-of-ai-in-technical-support [30] Sourcegraph Cody vs Cursor vs Augment Code for Enterprise ... https://www.augmentcode.com/guides/sourcegraph-cody-vs-cursor-vs-augment-code-for-enterprise-development [31] Sourcegraph makes core repository private, co-founder complains ... https://devclass.com/2024/08/21/sourcegraph-makes-core-repository-private-co-founder-complains-open-source-means-extra-work-and-risk/ [32] Security update: Incident involving unauthorized admin access https://sourcegraph.com/blog/security-update-august-2023 [33] Cody + Leidos: Maximizing efficiency with heightened security in the ... https://sourcegraph.com/case-studies/cody-leidos-maximizing-efficiency-heightened-security-ai-race [34] Qualtrics speeds up unit test creation and understanding code with ... https://sourcegraph.com/case-studies/qualtrics-speeds-up-unit-tests-and-code-understanding-with-cody [35] Amp Reviews 2025: Details, Pricing, &amp; Features - G2 https://www.g2.com/products/amp-2025-08-06/reviews [36] Will AI Make Software Engineers Obsolete? Here&#39;s the Reality https://bootcamps.cs.cmu.edu/blog/will-ai-replace-software-engineers-reality-check [37] Sourcegraph - Crunchbase Company Profile &amp; Funding https://www.crunchbase.com/organization/sourcegraph [38] How Cody understands your codebase | Sourcegraph Blog https://sourcegraph.com/blog/how-cody-understands-your-codebase [39] Sourcegraph Cody: My Deep Dive into the AI Assistant That Actually ... https://skywork.ai/skypage/en/Sourcegraph-Cody-My-Deep-Dive-into-the-AI-Assistant-That-Actually-Understands-Your-Codebase/1972866066541113344 [40] Changelog - Sourcegraph https://sourcegraph.com/changelog [41] Sourcegraph Comparisons | Cody vs Copilot https://sourcegraph.com/compare/copilot-vs-cody [42] Copilot vs. Cody: Why context matters for code AI | Sourcegraph Blog https://sourcegraph.com/blog/copilot-vs-cody-why-context-matters-for-code-ai [43] Sourcegraph Cody vs Cursor vs Augment Code for Enterprise ... https://www.augmentcode.com/guides/sourcegraph-cody-vs-cursor-vs-augment-code-for-enterprise-development [44] Cody Prompting Guide - Sourcegraph docs https://sourcegraph.com/docs/cody/prompts-guide [45] The power user&#39;s guide to Cody AI for Visual Studio Code https://sourcegraph.com/blog/power-users-guide-to-cody-ai-for-visual-studio-code [46] RAG to Riches | Sourcegraph Blog https://sourcegraph.com/blog/rag-to-riches [47] Sourcegraph makes core repository private, co-founder complains ... https://devclass.com/2024/08/21/sourcegraph-makes-core-repository-private-co-founder-complains-open-source-means-extra-work-and-risk/ [48] Changes to Cody Free, Pro, and Enterprise Starter plans https://sourcegraph.com/blog/changes-to-cody-free-pro-and-enterprise-starter-plans [49] Introducing enhancements to Code Search and Cody, including a 2x ... https://sourcegraph.com/blog/feature-release-october-2023 [50] Community - Sourcegraph https://sourcegraph.com/community\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://zenn.dev/querypie/articles/aa04b4bcf8dd21","title":"AI開発の効率を爆発的に高める方法","content":"【10†AI開発の効率を爆発的に高める方法†https://zenn.dev/querypie/articles/aa04b4bcf8dd21】\nTitle: AI開発の効率を爆発的に高める方法\n\nURL Source: https://zenn.dev/querypie/articles/aa04b4bcf8dd21\n\nMarkdown Content:\n4つの核心ツールとともに\n------------\n\nAI開発分野で生産性革命が起こっています。開発者がもはや反復的な作業とコンテキスト管理、そして一貫性のないコーディングパターンに悩む必要がなくなりました。SpecKit、TaskMaster-AI、Context7、Sequential Thinkingという4つの革新的なツールがAI開発の効率性を10倍以上向上させているからです。\n\nこれらのツールは、それぞれ異なる領域の問題を解決しながらも、一緒に使用する時にシナジー効果が最大化されます。まるでオーケストラの各楽器が調和を成して美しい音楽を作り出すように、この4つのツールはAI開発の全体ワークフローを完全に革新します。\n\nSpecKit：仕様ベース開発の革命\n------------------\n\n**GitHubのオープンソース革新、SpecKit**\n\nGitHubが公開したSpecKitは、AIコーディングエージェントのための仕様駆動開発（Spec-Driven Development）を標準化したツールです。既存の「感情に依存したコーディング（Vibe Coding）」から脱却し、体系的で検証可能な開発ワークフローを提供します。\n\n**核心特徴：**\n\n*   **4段階ゲートシステム**: Specify → Plan → Tasks → Implement\n*   **多様なAIツールサポート**: GitHub Copilot、Claude Code、Gemini CLIなど\n*   **テンプレートとプロンプト提供**: 即座に使用可能な構造化開発テンプレート\n*   **幻覚現象最小化**: '[NEEDS CLARIFICATION]'マーカーによる不明確部分の自動表示\n\n**実戦適用事例：**\n\n あるスタートアップが分析ダッシュボードを開発する際にSpecKitを活用した結果：\n\n*   複雑なデータ視覚化要件を明確な仕様に分解\n*   リアルタイム更新とマルチテナントアーキテクチャを体系的に設計\n*   AI生成コードの品質が一貫して維持\n*   技術的負債を著しく減少\n\n**使用法：**\n\n```\n# SpecKit インストールと初期化\nnpx speckit init my-project\n# 仕様定義段階開始\nspeckit specify\n# 計画策定\nspeckit plan\n# 作業分解\nspeckit tasks\n# 実装実行\nspeckit implement\n```\n\nTaskMaster-AI：プロジェクトオーケストレーションのマスター\n-----------------------------------\n\n**コンテキストを失わないAIエージェント管理者**\n\nTaskMaster-AIは、大規模ソフトウェア開発プロジェクトでAIエージェントがコンテキストを失わず一貫して作業できるようにオーケストレーションするツールです。従来のAIツールが大きなプロジェクトで文脈を失ってしまう問題を解決します。\n\n**核心機能：**\n\n*   **長期コンテキスト維持**: プロジェクト全体にわたる一貫した文脈管理\n*   **自動PRD生成**: 製品要件文書自動作成\n*   **作業分解と計画**: 複雑な作業を管理可能な単位に分解\n*   **多重AIプロバイダサポート**: OpenAI、Anthropic、Google Geminiなど\n*   **多重役割構成**: メイン、研究、フォールバック役割分担\n\n**実戦ワークフロー：**\n\n```\n# 1. 新しいプロジェクト初期化\ntaskmaster init new-feature\n\n# 2. AIモデル構成（メイン、研究、フォールバック）\ntaskmaster config --main gpt-4 --research claude-3 --fallback gemini\n\n# 3. PRDから自動作業生成\ntaskmaster generate-tasks --from-prd requirements.md\n\n# 4. 作業をサブタスクに細分化\ntaskmaster breakdown --task \"user-authentication\"\n\n# 5. 対話型CLIでプロジェクト管理\ntaskmaster interactive\n```\n\n**性能改善事例：**\n\n*   ある開発チームがマイクロサービスアーキテクチャマイグレーションプロジェクトでTaskMaster-AIを使用\n*   200個以上の詳細作業を体系的に管理\n*   作業間依存性自動追跡でボトルネック現象を70%減少\n*   全体プロジェクト完了時間40%短縮\n\nContext7：最新ドキュメントのリアルタイム注入\n--------------------------\n\n**AI幻覚現象のキラーソリューション**\n\nUpstashで開発されたContext7は、AIツールが古い学習データにより誤ったコードを生成する問題を解決します。リアルタイムで最新バージョンのドキュメントとコード例をAIのプロンプトコンテキストに注入し、正確なコード生成を保証します。\n\n**サポートライブラリ：**\n\n*   **Next.js**: App Routerパターン含む最新機能\n*   **TailwindCSS**: 3.4バージョンユーティリティクラス\n*   **TanStack Query**: React Query v5最新API\n*   **Zod**: スキーマ検証最新パターン\n*   **Bootstrap 5**: 最新コンポーネントとユーティリティ\n\n**MCP（Model Context Protocol）統合：**\n\n Context7はMCPサーバーとして実装され、様々なAIツールとスムーズに統合されます：\n\n*   Cursor、Windsurf、VS CodeなどAIコードエディタ\n*   Claude Desktopと直接連動\n*   リアルタイムドキュメントフェッチで常に最新情報提供\n\n**使用例：**\n\n```\n// Context7なし（間違った古いパターン）\n// 🚫 廃止されたNext.js 12パターン\nexport default function Page() {\n  return <div>Old pattern</div>\n}\n\n// Context7使用後（正しい最新パターン）\n// ✅ Next.js 14 App Routerパターン\nexport default function Page() {\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-between p-24\">\n      <div>Latest Next.js 14 pattern</div>\n    </main>\n  )\n}\n```\n\n**インストールと設定：**\n\n```\n# NPXでインストール\nnpx @context7/cli\n\n# Bunでインストール\nbunx @context7/cli\n\n# Denoでインストール\ndeno run --allow-all npm:@context7/cli\n\n# プロンプトで使用\nuse context7 for Next.js App Router patterns\n```\n\nSequential Thinking：体系的思考プロセスの実装\n--------------------------------\n\n**AIの推論過程を透明にするツール**\n\nSequential ThinkingはAIが複雑な問題を解決する際に段階的思考過程を明示的に示すMCPサーバーです。Extended ThinkingがAIが一人で考えることなら、Sequential ThinkingはAIが声に出して段階的に考えることです。\n\n**核心原理：**\n\n*   **分解（Decomposition）**: 複雑な問題を管理可能な段階に分解\n*   **反省（Reflection）**: 各段階でアプローチを再評価\n*   **状態維持推論**: 前の思考過程を記憶しながら発展\n*   **透明性**: すべての推論段階を文書化して監査可能\n\n**実戦活用事例：**\n\n**自動化コーディングエージェント例：**\n\n```\nThought 1: 現在のrequirements.txtファイルを読んで依存性を把握する必要があります。\nAction: filesystemサーバーを通じてrequirements.txt読み取り\n\nThought 2: リファクタリング計画を文書化する新しいファイルが必要です。\nAction: refactor_plan.mdファイル生成\n\nThought 3: 分析された依存性を基にリファクタリング計画を作成します。\nAction: 計画をファイルに作成\n\nThought 4: 計画を検討し、漏れた部分があるか確認します。\nReflection: データベースマイグレーション部分が欠落していることを発見\n```\n\n**他のMCPサーバーとの統合：**\n\n Sequential Thinkingは他のMCPサーバーと一緒に使用される時に真のエージェントワークフローを作ります：\n\n*   **計画策定**: Sequential Thinkingで段階別計画\n*   **実行**: filesystem、web-searchなどアクションサーバーで実際作業実行\n*   **検証**: 各段階結果を再びSequential Thinkingで評価\n\n4つのツールのシナジー効果：統合ワークフロー\n----------------------\n\n**完璧なAI開発エコシステム構築**\n\nこの4つのツールを一緒に使用すると、AI開発のすべての段階で最適化されたワークフローを構築できます：\n\n### 1段階：プロジェクト初期化と計画（SpecKit + TaskMaster-AI）\n\n```\n# SpecKitでプロジェクト構造生成\nspeckit init ai-dashboard --template webapp\n\n# TaskMaster-AIでプロジェクトオーケストレーション設定\ntaskmaster init ai-dashboard\ntaskmaster config --main gpt-4 --research claude-3\n```\n\n### 2段階：仕様定義と作業分解（SpecKit + Sequential Thinking）\n\n*   SpecKitのSpecify段階でSequential Thinking活用\n*   複雑な要件を体系的に分析し仕様作成\n*   各思考段階が文書化されて後で参照可能\n\n### 3段階：実装時最新コンテキスト注入（Context7）\n\n```\n// プロンプトにContext7活用指示\n\"use context7 for Next.js App Router and TailwindCSS latest patterns\n- Create a responsive dashboard component\n- Use latest Next.js 14 server components\n- Apply TailwindCSS 3.4 container queries\"\n```\n\n### 4段階：持続的品質管理（TaskMaster-AI + SpecKit）\n\n*   TaskMaster-AIが全体プロジェクトコンテキスト維持\n*   SpecKitのゲートシステムで各段階品質検証\n*   コードレビューとテスト自動化\n\n実際の成果測定：ツール導入前後比較\n-----------------\n\n**生産性指標改善：**\n\n| 指標 | 導入前 | 導入後 | 改善率 |\n| --- | --- | --- | --- |\n| 初期設定時間 | 2-3日 | 30分 | **90%短縮** |\n| コード一貫性 | 60% | 95% | **58%向上** |\n| デバッグ時間 | 40% | 10% | **75%減少** |\n| プロジェクト完了速度 | 100% | 60% | **40%短縮** |\n| コード品質スコア | 7.2/10 | 9.1/10 | **26%向上** |\n\n**開発者満足度：**\n\n*   反復作業からの解放：85%改善\n*   創造的作業集中度：70%向上\n*   学習曲線：既存ツール比50%減少\n\n導入時考慮事項とベストプラクティス\n-----------------\n\n**段階的導入戦略：**\n\n**1段階**（Week 1-2）：Context7導入\n\n*   最も即座に効果を見ることができるツール\n*   既存ワークフロー変更最小化\n*   AIツールの精度即座に改善\n\n**2段階**（Week 3-4）：SpecKit適用\n\n*   新しいプロジェクトから段階的適用\n*   チーム単位教育およびテンプレートカスタマイズ\n*   既存プロジェクトはメンテナンス段階でのみ適用\n\n**3段階**（Week 5-8）：TaskMaster-AI導入\n\n*   複雑なプロジェクトに優先適用\n*   AIプロバイダ別最適役割分担実験\n*   チームワークフロー最適化\n\n**4段階**（Week 9-12）：Sequential Thinking統合\n\n*   複雑な問題解決が必要な領域に適用\n*   他のツールとの統合ワークフロー完成\n*   成果測定と継続的改善\n\n**注意事項：**\n\n*   **セキュリティ考慮**：すべてのツールで機密コード処理時注意\n*   **チーム教育**：効果的活用のための十分な教育時間確保\n*   **段階的適用**：一度にすべてのツールを導入せず段階的に適用\n*   **成果測定**：定量的指標による効果検証\n\n未来展望：AI開発ツールの進化方向\n-----------------\n\n**統合エコシステムへの発展**\n\nこの4つのツールは各々独立的にも強力ですが、未来にはより密接に統合されると予想されます：\n\n*   **自動化ワークフロー**：プロジェクト開始からデプロイまで完全自動化\n*   **知的コンテキスト管理**：プロジェクト全体文脈を理解する統合AI\n*   **予測的問題解決**：問題発生前に事前に解決策提示\n*   **個人化開発体験**：開発者別嗜好とパターンを学習したカスタマイズツール\n\n結論：AI開発効率性の新たな次元\n----------------\n\n**生産性革命の始まり**\n\nSpecKit、TaskMaster-AI、Context7、Sequential Thinkingは単純なツールを超えて、AI開発パラダイムの転換を導く変化の動力です。これらは開発者が反復的で機械的な作業から解放され、真の創造的問題解決に集中できるようにします。\n\n**核心成果：**\n\n*   **生産性**：全体的に3-5倍向上\n*   **品質**：一貫して安定したコード品質\n*   **速度**：プロジェクト完了時間40-60%短縮\n*   **満足度**：開発者業務満足度大幅向上\n\n**アクションプラン：**\n\n1.   **今日から開始**：Context7を既存AIツールに連動\n2.   **次のプロジェクト**：SpecKitで体系的開発開始\n3.   **チーム次元**：TaskMaster-AIでプロジェクト管理革新\n4.   **高度化**：Sequential ThinkingでAI推論透明性確保\n\nAI開発の未来はもはや「より多くのコーディング」ではなく「よりスマートな思考」にかかっています。この4つのツールは、そのスマートな思考を現実にしてくれる強力なパートナーとなるでしょう。\n\n今すぐ始めてください。皆さんの開発ワークフローが完全に変化することを体験するでしょう。\n\n"},"metadata":{"arguments":"{\"link_id\":10}","display_result":"","duration":"5s","id":"call_F3kFhKA3ow","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【10†AI開発の効率を爆発的に高める方法†https://zenn.dev/querypie/articles/aa04b4bcf8dd21】\nTitle: AI開発の効率を爆発的に高める方法\n\nURL Source: https://zenn.dev/querypie/articles/aa04b4bcf8dd21\n\nMarkdown Content:\n4つの核心ツールとともに\n------------\n\nAI開発分野で生産性革命が起こっています。開発者がもはや反復的な作業とコンテキスト管理、そして一貫性のないコーディングパターンに悩む必要がなくなりました。SpecKit、TaskMaster-AI、Context7、Sequential Thinkingという4つの革新的なツールがAI開発の効率性を10倍以上向上させているからです。\n\nこれらのツールは、それぞれ異なる領域の問題を解決しながらも、一緒に使用する時にシナジー効果が最大化されます。まるでオーケストラの各楽器が調和を成して美しい音楽を作り出すように、この4つのツールはAI開発の全体ワークフローを完全に革新します。\n\nSpecKit：仕様ベース開発の革命\n------------------\n\n**GitHubのオープンソース革新、SpecKit**\n\nGitHubが公開したSpecKitは、AIコーディングエージェントのための仕様駆動開発（Spec-Driven Development）を標準化したツールです。既存の「感情に依存したコーディング（Vibe Coding）」から脱却し、体系的で検証可能な開発ワークフローを提供します。\n\n**核心特徴：**\n\n*   **4段階ゲートシステム**: Specify → Plan → Tasks → Implement\n*   **多様なAIツールサポート**: GitHub Copilot、Claude Code、Gemini CLIなど\n*   **テンプレートとプロンプト提供**: 即座に使用可能な構造化開発テンプレート\n*   **幻覚現象最小化**: '[NEEDS CLARIFICATION]'マーカーによる不明確部分の自動表示\n\n**実戦適用事例：**\n\n あるスタートアップが分析ダッシュボードを開発する際にSpecKitを活用した結果：\n\n*   複雑なデータ視覚化要件を明確な仕様に分解\n*   リアルタイム更新とマルチテナントアーキテクチャを体系的に設計\n*   AI生成コードの品質が一貫して維持\n*   技術的負債を著しく減少\n\n**使用法：**\n\n```\n# SpecKit インストールと初期化\nnpx speckit init my-project\n# 仕様定義段階開始\nspeckit specify\n# 計画策定\nspeckit plan\n# 作業分解\nspeckit tasks\n# 実装実行\nspeckit implement\n```\n\nTaskMaster-AI：プロジェクトオーケストレーションのマスター\n-----------------------------------\n\n**コンテキストを失わないAIエージェント管理者**\n\nTaskMaster-AIは、大規模ソフトウェア開発プロジェクトでAIエージェントがコンテキストを失わず一貫して作業できるようにオーケストレーションするツールです。従来のAIツールが大きなプロジェクトで文脈を失ってしまう問題を解決します。\n\n**核心機能：**\n\n*   **長期コンテキスト維持**: プロジェクト全体にわたる一貫した文脈管理\n*   **自動PRD生成**: 製品要件文書自動作成\n*   **作業分解と計画**: 複雑な作業を管理可能な単位に分解\n*   **多重AIプロバイダサポート**: OpenAI、Anthropic、Google Geminiなど\n*   **多重役割構成**: メイン、研究、フォールバック役割分担\n\n**実戦ワークフロー：**\n\n```\n# 1. 新しいプロジェクト初期化\ntaskmaster init new-feature\n\n# 2. AIモデル構成（メイン、研究、フォールバック）\ntaskmaster config --main gpt-4 --research claude-3 --fallback gemini\n\n# 3. PRDから自動作業生成\ntaskmaster generate-tasks --from-prd requirements.md\n\n# 4. 作業をサブタスクに細分化\ntaskmaster breakdown --task \"user-authentication\"\n\n# 5. 対話型CLIでプロジェクト管理\ntaskmaster interactive\n```\n\n**性能改善事例：**\n\n*   ある開発チームがマイクロサービスアーキテクチャマイグレーションプロジェクトでTaskMaster-AIを使用\n*   200個以上の詳細作業を体系的に管理\n*   作業間依存性自動追跡でボトルネック現象を70%減少\n*   全体プロジェクト完了時間40%短縮\n\nContext7：最新ドキュメントのリアルタイム注入\n--------------------------\n\n**AI幻覚現象のキラーソリューション**\n\nUpstashで開発されたContext7は、AIツールが古い学習データにより誤ったコードを生成する問題を解決します。リアルタイムで最新バージョンのドキュメントとコード例をAIのプロンプトコンテキストに注入し、正確なコード生成を保証します。\n\n**サポートライブラリ：**\n\n*   **Next.js**: App Routerパターン含む最新機能\n*   **TailwindCSS**: 3.4バージョンユーティリティクラス\n*   **TanStack Query**: React Query v5最新API\n*   **Zod**: スキーマ検証最新パターン\n*   **Bootstrap 5**: 最新コンポーネントとユーティリティ\n\n**MCP（Model Context Protocol）統合：**\n\n Context7はMCPサーバーとして実装され、様々なAIツールとスムーズに統合されます：\n\n*   Cursor、Windsurf、VS CodeなどAIコードエディタ\n*   Claude Desktopと直接連動\n*   リアルタイムドキュメントフェッチで常に最新情報提供\n\n**使用例：**\n\n```\n// Context7なし（間違った古いパターン）\n// 🚫 廃止されたNext.js 12パターン\nexport default function Page() {\n  return <div>Old pattern</div>\n}\n\n// Context7使用後（正しい最新パターン）\n// ✅ Next.js 14 App Routerパターン\nexport default function Page() {\n  return (\n    <main className=\"flex min-h-screen flex-col items-center justify-between p-24\">\n      <div>Latest Next.js 14 pattern</div>\n    </main>\n  )\n}\n```\n\n**インストールと設定：**\n\n```\n# NPXでインストール\nnpx @context7/cli\n\n# Bunでインストール\nbunx @context7/cli\n\n# Denoでインストール\ndeno run --allow-all npm:@context7/cli\n\n# プロンプトで使用\nuse context7 for Next.js App Router patterns\n```\n\nSequential Thinking：体系的思考プロセスの実装\n--------------------------------\n\n**AIの推論過程を透明にするツール**\n\nSequential ThinkingはAIが複雑な問題を解決する際に段階的思考過程を明示的に示すMCPサーバーです。Extended ThinkingがAIが一人で考えることなら、Sequential ThinkingはAIが声に出して段階的に考えることです。\n\n**核心原理：**\n\n*   **分解（Decomposition）**: 複雑な問題を管理可能な段階に分解\n*   **反省（Reflection）**: 各段階でアプローチを再評価\n*   **状態維持推論**: 前の思考過程を記憶しながら発展\n*   **透明性**: すべての推論段階を文書化して監査可能\n\n**実戦活用事例：**\n\n**自動化コーディングエージェント例：**\n\n```\nThought 1: 現在のrequirements.txtファイルを読んで依存性を把握する必要があります。\nAction: filesystemサーバーを通じてrequirements.txt読み取り\n\nThought 2: リファクタリング計画を文書化する新しいファイルが必要です。\nAction: refactor_plan.mdファイル生成\n\nThought 3: 分析された依存性を基にリファクタリング計画を作成します。\nAction: 計画をファイルに作成\n\nThought 4: 計画を検討し、漏れた部分があるか確認します。\nReflection: データベースマイグレーション部分が欠落していることを発見\n```\n\n**他のMCPサーバーとの統合：**\n\n Sequential Thinkingは他のMCPサーバーと一緒に使用される時に真のエージェントワークフローを作ります：\n\n*   **計画策定**: Sequential Thinkingで段階別計画\n*   **実行**: filesystem、web-searchなどアクションサーバーで実際作業実行\n*   **検証**: 各段階結果を再びSequential Thinkingで評価\n\n4つのツールのシナジー効果：統合ワークフロー\n----------------------\n\n**完璧なAI開発エコシステム構築**\n\nこの4つのツールを一緒に使用すると、AI開発のすべての段階で最適化されたワークフローを構築できます：\n\n### 1段階：プロジェクト初期化と計画（SpecKit + TaskMaster-AI）\n\n```\n# SpecKitでプロジェクト構造生成\nspeckit init ai-dashboard --template webapp\n\n# TaskMaster-AIでプロジェクトオーケストレーション設定\ntaskmaster init ai-dashboard\ntaskmaster config --main gpt-4 --research claude-3\n```\n\n### 2段階：仕様定義と作業分解（SpecKit + Sequential Thinking）\n\n*   SpecKitのSpecify段階でSequential Thinking活用\n*   複雑な要件を体系的に分析し仕様作成\n*   各思考段階が文書化されて後で参照可能\n\n### 3段階：実装時最新コンテキスト注入（Context7）\n\n```\n// プロンプトにContext7活用指示\n\"use context7 for Next.js App Router and TailwindCSS latest patterns\n- Create a responsive dashboard component\n- Use latest Next.js 14 server components\n- Apply TailwindCSS 3.4 container queries\"\n```\n\n### 4段階：持続的品質管理（TaskMaster-AI + SpecKit）\n\n*   TaskMaster-AIが全体プロジェクトコンテキスト維持\n*   SpecKitのゲートシステムで各段階品質検証\n*   コードレビューとテスト自動化\n\n実際の成果測定：ツール導入前後比較\n-----------------\n\n**生産性指標改善：**\n\n| 指標 | 導入前 | 導入後 | 改善率 |\n| --- | --- | --- | --- |\n| 初期設定時間 | 2-3日 | 30分 | **90%短縮** |\n| コード一貫性 | 60% | 95% | **58%向上** |\n| デバッグ時間 | 40% | 10% | **75%減少** |\n| プロジェクト完了速度 | 100% | 60% | **40%短縮** |\n| コード品質スコア | 7.2/10 | 9.1/10 | **26%向上** |\n\n**開発者満足度：**\n\n*   反復作業からの解放：85%改善\n*   創造的作業集中度：70%向上\n*   学習曲線：既存ツール比50%減少\n\n導入時考慮事項とベストプラクティス\n-----------------\n\n**段階的導入戦略：**\n\n**1段階**（Week 1-2）：Context7導入\n\n*   最も即座に効果を見ることができるツール\n*   既存ワークフロー変更最小化\n*   AIツールの精度即座に改善\n\n**2段階**（Week 3-4）：SpecKit適用\n\n*   新しいプロジェクトから段階的適用\n*   チーム単位教育およびテンプレートカスタマイズ\n*   既存プロジェクトはメンテナンス段階でのみ適用\n\n**3段階**（Week 5-8）：TaskMaster-AI導入\n\n*   複雑なプロジェクトに優先適用\n*   AIプロバイダ別最適役割分担実験\n*   チームワークフロー最適化\n\n**4段階**（Week 9-12）：Sequential Thinking統合\n\n*   複雑な問題解決が必要な領域に適用\n*   他のツールとの統合ワークフロー完成\n*   成果測定と継続的改善\n\n**注意事項：**\n\n*   **セキュリティ考慮**：すべてのツールで機密コード処理時注意\n*   **チーム教育**：効果的活用のための十分な教育時間確保\n*   **段階的適用**：一度にすべてのツールを導入せず段階的に適用\n*   **成果測定**：定量的指標による効果検証\n\n未来展望：AI開発ツールの進化方向\n-----------------\n\n**統合エコシステムへの発展**\n\nこの4つのツールは各々独立的にも強力ですが、未来にはより密接に統合されると予想されます：\n\n*   **自動化ワークフロー**：プロジェクト開始からデプロイまで完全自動化\n*   **知的コンテキスト管理**：プロジェクト全体文脈を理解する統合AI\n*   **予測的問題解決**：問題発生前に事前に解決策提示\n*   **個人化開発体験**：開発者別嗜好とパターンを学習したカスタマイズツール\n\n結論：AI開発効率性の新たな次元\n----------------\n\n**生産性革命の始まり**\n\nSpecKit、TaskMaster-AI、Context7、Sequential Thinkingは単純なツールを超えて、AI開発パラダイムの転換を導く変化の動力です。これらは開発者が反復的で機械的な作業から解放され、真の創造的問題解決に集中できるようにします。\n\n**核心成果：**\n\n*   **生産性**：全体的に3-5倍向上\n*   **品質**：一貫して安定したコード品質\n*   **速度**：プロジェクト完了時間40-60%短縮\n*   **満足度**：開発者業務満足度大幅向上\n\n**アクションプラン：**\n\n1.   **今日から開始**：Context7を既存AIツールに連動\n2.   **次のプロジェクト**：SpecKitで体系的開発開始\n3.   **チーム次元**：TaskMaster-AIでプロジェクト管理革新\n4.   **高度化**：Sequential ThinkingでAI推論透明性確保\n\nAI開発の未来はもはや「より多くのコーディング」ではなく「よりスマートな思考」にかかっています。この4つのツールは、そのスマートな思考を現実にしてくれる強力なパートナーとなるでしょう。\n\n今すぐ始めてください。皆さんの開発ワークフローが完全に変化することを体験するでしょう。\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="8" view="" last_tool_call_name="click">
> 大規模プロジェクトでバイブコーディングの精度を最大化するためのワークフローを提案する。具体的には、プロジェクトの理解、ドキュメント化、AIツールの選定、計画、実装、テスト、リファクタリングのステップを含む。重要な要素として、コンテキスト管理、バージョン管理、テストの自動化、コードの標準化、継続的な改善を挙げる。特に、大規模プロジェクトでは、ファイルの分割や依存関係の管理が重要となる。具体的なツールや手法も交えて、ユーザーが実際に適用できるように説明する。
</details>

<glm_block view="" tool_call_name="finish">{"data":{"metadata":{"arguments":"{}","display_result":"","duration":"1s","id":"call_U3nbMiDKm3","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"finish","result":"","status":"completed"}},"type":"mcp"}</glm_block>

# 50フォルダ超の大規模開発を成功させるバイブコーディング精度最大化ワークフロー

## はじめに：混沌を制御するための羅針盤

現代のソフトウェア開発は、AIの力によって以前とは比べ物にならないほどの速度と効率を手に入れました。特に「バイブコーディング（Vibe Coding）」と呼ばれる、開発者が自然言語で指示を出すだけでAIがコードを生成するというアプローチは、開発のパラダイムそのものを変えつつあります[[11](https://note.com/ogawa_ramo/n/n6d6e65742c14)]。この手法により、アイデアを迅速にプロトタイプに落とし込むことが可能になり、開発のスピード感は劇的に向上しました。しかし、その自由度と速さの裏に潜む落とし穴もまた、無視できないものとなっています。特に、50フォルダを超えるような大規模で複雑な開発プロジェクトにおいて、無計画なバイブコーディングは、時に致命的な結果を招くことがあります。

大規模プロジェクトは、無数のファイル、フォルダ、そしてそれらが織りなす複雑な依存関係の集合体です。AIコーディングアシスタントに「ユーザー認証機能を実装して」と漠然と指示を出したとしましょう。AIは確かにコードを生成するかもしれません。しかし、そのコードが既存の認証基盤と競合しないか、セキュリティポリシーを遵守しているか、あるいはプロジェクト全体のアーキテクチャに適合しているかという保証はどこにもありません。結果として、一見すると動作するものの、プロジェクトの他の部分と整合性が取れず、後々になって膨大な手直しを強いられる「技術的負債」を生み出してしまう可能性が极高です。これは、AIが「コンテキスト（文脈）」、すなわちプロジェクト全体の背景や意図を十分に理解できていないことに起因します。AIは与えられた情報の中で最も適切だと判断するコードを生成しますが、その情報が不十分であれば、出力もまた不十分なものとなってしまうのです。

本レポートが提示するワークフローは、この「混沌」としか思えない大規模プロジェクトのバイブコーディングを、一つの「制御された創造活動」へと昇華させるための羅釦盤です。これは、AIに「何を（What）」作るかを指示するだけでなく、「なぜ（Why）それを作るのか」「どのように（How）作るのか」という背景までをも含めてAIに理解させ、精度の高い出力を引き出すための体系的なアプローチです。本ワークフローは、計画（Plan）、実装（Implement）、実行・検証（Run）という3つの主要フェーズを核とした「Plan-Implement-Runパターン」[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]を基盤としながらも、大規模プロジェクト特有の課題を克服するための具体的な戦略を組み合わせたものです。

具体的には、プロジェクトの全容をAIに理解させるための「コンテキストの構築」、AIとの対話を効率化するための「プロンプトの設計」、大規模な変更を管理可能な単位に分割するための「タスクの分割」、そして生成されたコードの品質を保証するための「検証とフィードバックのループ」といった、複数の重要な要素が統合されています。これは、単なるツールの使い方の解説ではありません。AIを「指示待ちの部下」ではなく、「高度な知識を持つが、プロジェクトのことは何も知らない新しいチームメンバー」[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]として扱い、その能力を最大限に引き出すための「思考法」と「作業プロセス」の設計図です。本レポートを通じて、大規模プロジェクトという荒海を航海するすべての開発者が、バイブコーディングという強力なエンジンを安全かつ高速に駆使し、かつてない生産性とコード品質を実現するための具体的な道筋を得られることを目指します。

## 根幹をなす思想：計画、文脈、反復が生み出す精度

大規模プロジェクトでバイブコーディングの精度を最大化するためのワークフローを理解する上で、その根幹をなす三つの柱を最初に明確にしておくことが不可欠です。それは「計画（Plan）」「文脈（Context）」「反復（Iteration）」です。これら三つの要素が有機的に連携することで、AIの生成するコードは、単なる機能の羅列から、プロジェクトの意図に沿った、高品質で保守性の高い資産へと変貌を遂げます。多くの開発者が陥りがちな「とりあえずAIに指示を出してみる」という無計画なアプローチは、小規模なタスクではたまたまうまくいくこともありますが、50フォルダを超えるような複雑なプロジェクトでは、必ずと言っていいほど破綻します。なぜなら、AIは人間のような直感やプロジェクト全体の暗黙知を持たないからです。AIが持つのは、膨大なデータから学習したパターン認識能力です。この能力を最大限に活かすためには、AIが理解できる形で、明確かつ具体的な指針を与え続ける必要があります。そのための具体的なアプローチとして、まず「仕様駆動開発（Spec-Driven Development, SDD）」の考え方を取り入れます。これは、GitHubが提唱した開発手法で、AIに「何か」を生成させる前に、人間とAIが協力して「何を作るのか」を明確な仕様として定義するプロセスを重視します[[15](https://qiita.com/nogataka/items/b2c2cb475fa28333b56a)]。このアプローチにより、AIの出力が「雰囲気」で決まるのではなく、検証可能な仕様に基づいて決まるため、品質と一貫性が劇的に向上します。

次に、AIを効果的に導くための具体的な思考フレームワークとして「Plan-Implement-Runパターン」を導入します[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]。これは、AIとの対話を三つの段階に明確に分けることで、思考の飛躍や実装の漏れを防ぎ、予測可能な開発サイクルを実現するためのものです。第一段階の「Plan（計画）」では、AIに実装計画を立てさせます。ここでは、実際のコードを生成させるのではなく、「どのようなファイルを」「どのような手順で」「何を実現するために」作成するのかという、設計図に相当する計画書をマークダウン形式で作成させます。この段階で、AIはプロジェクトの仕様や既存のコードベースを参照しながら、実装の全体像を把握し、潜在的な問題点や依存関係を洗い出します。第二段階の「Implement（実装）」では、第一段階で作成した計画書をAIに渡し、それに従って実際のコードを生成させます。計画が明確なので、AIは迷うことなく、プロジェクトのコンテキストに即したコードを生成できます。最後の「Run（実行・検証）」では、生成されたコードを実際に実行し、期待通りに動作するかを確認します。もし問題が発生すれば、その原因をAIに分析させ、修正させます。この「計画→実装→検証」というサイクルを回すことで、開発プロセスは透明化され、AIの出力に対する人間の管理可能性（コントローラビリティ）が格段に向上します。

最後に、大規模プロジェクト特有の複雑さに対処するための戦略として「タスクの分割」と「コンテキストの提供」が不可欠です。大規模プロジェクトを一度にAIに理解させ、完璧なコードを生成させることは、現時点のAI技術では不可能です。そのため、プロジェクト全体を「垂直スライス（Vertical Slice）」[[3](https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l)]という考え方に基づいて、小さな管理可能な単位に分解していきます。垂直スライスとは、データベースのスキーマ定義から、バックエンドのAPIロジック、フロントエンドのUIコンポーネントまで、一つの機能を貫通する縦方向のスライスのことです。例えば「ユーザー登録機能」という一つのスライスを定義し、その実装をAIに任せます。これにより、AIが一度に考慮すべき情報量が劇的に減り、精度の高いコード生成が可能になります。さらに、各タスクをAIに任せる際には、そのタスクに関連する「コンテキスト」を徹底的に提供します。コンテキストとは、関連するコードファイル、設計ドキュメント、コーディング規約、データベーススキーマなど、AIが正しい判断を下すために必要なすべての情報です。大規模プロジェクトでは、このコンテキストの質と量がAIの出力精度を直接左右します。Sourcegraph Codyのような、コードベース全体を理解することに特化したAIアシスタントは、このコンテキスト提供を自動化・効率化する上で非常に有効です[[17](https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704)]。これらの思想を組み合わせることで、大規模プロジェクトという混沌とした状況の中でも、AIの能力を冷静かつ的確にコントロールし、高い精度で開発を進めることが可能になるのです。

## 大規模プロジェクトにおけるバイブコーディング精度最大化ワークフロー

ここでは、50フォルダ以上の大規模な開発プロジェクトにおいて、バイブコーディングの精度を最大化するための具体的なワークフローを、フェーズごとに詳細に解説します。このワークフローは、プロジェクトの初期準備から、実際のコーディング、そして最終的な品質保証までを網羅する、統合的なアプローチです。各ステップは、前述の「計画、文脈、反復」という根幹をなす思想を具体化したものであり、これらを一連のプロセスとして忠実に実行することが、成功の鍵となります。

### フェーズ1：プロジェクトの理解と基盤整備 (Foundation & Contextualization)

大規模プロジェクトでバイブコーディングを成功させるための最初の、そして最も重要なステップは、AIに対してプロジェクトに関する十分な情報を与え、共通認識を持たせることです。AIを「何も知らない新しいチームメンバー」[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]だと考えるならば、まずは彼にプロジェクトの全体像を理解させるための「オンボーディング」が必要不可欠です。このフェーズを疎かにすると、AIはプロジェクトの意図を理解できず、不適切なコードを生成し続け、結果として開発の遅延と品質の低下を招きます。

まず最初に行うべきは、プロジェクトに関するあらゆる情報を集約した「ドキュメントハブ」を作成することです。具体的には、プロジェクトのルートディレクトリに `docs` というフォルダを作成し、その中に重要なドキュメントをマークダウン形式で整理していきます[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]。50フォルダ以上もある大規模プロジェクトでは、ファイル構造自体が非常に複雑であり、どこに何があるのかを把握するだけでも一苦労です。そのため、まずは `docs/file_structure.md` というファイルを作成し、プロジェクト全体のファイルとフォルダ構造、および各フォルダの役割を詳細に記述します。これは、AIがプロジェクト内をナビゲートするための地図として機能します。次に、`docs/specs/` フォルダを作成し、その中に `architecture.md`（アーキテクチャ仕様）、`db_schema.md`（データベーススキーマ）、`specifications.md`（機能仕様）といった、プロジェクトの根幹をなす技術仕様書を格納します。さらに、コーディング規約や命名規則などを記述した `coding-standards.md` も `docs/` フォルダ内、あるいは `.github/prompt-snippets/` のような場所に配置します[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]。これらのドキュメントは、AIがプロジェクトの「憲法」として従うべきルールを理解するための基盤となります。

次に、AIがこれらのドキュメントを確実に参照するように仕向けるための「システムプロンプト」の設定が重要です。多くのAIコーディングツール（例: GitHub Copilot, Cursor）は、プロジェクト固有の指示を記述したシステムプロンプトファイルをサポートしています[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]。このファイルに、以下のような指示を明記します。

```
# システムプロンプト例 (.github/copilot-instructions.md)

## コアルール
### ファイルとフォルダ構造の理解
プロジェクトのファイルやフォルダの役割を理解するために、常に [file_structure](/docs/file_structure.md) を参照すること。

### 仕様の確認
実装を開始する前に、関連する仕様を /docs/specs/ フォルダ内から必ず参照すること。

### コーディング規約の遵守
コードを記述する際は、必ず [coding-standards](/.github/prompt-snippets/coding-standards.md) に従うこと。
```

このように指示することで、AIは毎回プロンプト内で明示的に指示されなくても、自動的に関連ドキュメントを参照するようになります。これにより、AIが生成するコードの一貫性と品質が大幅に向上します。また、大規模プロジェクトでは、使用している技術スタック（フレームワーク、ライブラリなど）のバージョンが古いことが原因で、AIが時代遅れのコードを生成してしまうリスクがあります。この問題を解決するために、Context7のようなツールが非常に有効です[[10](https://zenn.dev/querypie/articles/aa04b4bcf8dd21)]。Context7は、AIのプロンプトに対して、指定したライブラリの最新版の公式ドキュメントをリアルタイムで注入してくれるツールです。これにより、AIは常に最新かつ正確な情報に基づいてコードを生成できるようになり、「幻覚（Hallucination）」と呼ばれる事実に反する出力を大幅に削減できます。

最後に、プロジェクトの基盤となる技術選定も重要な要素です。特にフルスタック開発においては、Wasp（JavaScript/Node.js）やLaravel（PHP）のような「バッテリー同梱（batteries-included）」型のフレームワークを採用することを強く推奨します[[3](https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l)]。これらのフレームワークは、プロジェクトの構造や設定にある程度の「意見」を持っているため、AIが一からアーキテクチャを設計する手間を省き、ビジネスロジックの実装に集中できます。また、UI（ユーザーインターフェース）に関しても、一貫性を保つためにUIコンポーネントライブラリやボイラープレートテンプレートを導入することが効果的です[[3](https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l)]。これにより、AIはデザインの詳細を気にすることなく、コンポーネントを組み合わせることでUIを構築できるようになり、開発効率と品質の両方が向上します。このフェーズでしっかりと基盤を固めることで、後続の開発フェーズが格段にスムーズになり、AIの能力を最大限に引き出すことが可能になります。

### フェーズ2：計画と仕様化 (Planning & Specification)

基盤が整ったら、次は「何を作るのか」を明確に定義する「計画と仕様化」のフェーズに移ります。このフェーズは、大規模プロジェクトにおけるバイブコーディングの精度を左右する、最も重要なプロセスの一つです。ここでの目標は、AIが迷うことなく実装できるほど、詳細かつ明確な設計図を作成することです。このフェーズを疎かにして、いきなりコード生成を始めると、AIはプロジェクトの意図から乖離したコードを生成し、後で大きな手戻りを招く原因となります。

まず、開発したい機能や要件について、AIと対話しながら「製品要求文書（Product Requirements Document, PRD）」を作成します[[5](https://addyosmani.com/blog/ai-coding-workflow)]。このPRDには、機能の目的、ユーザーストーリー、受け入れ条件、非機能要件（パフォーマンス、セキュリティなど）を可能な限り詳細に記述します。この段階では、AIに「この要件について理解するために、何か質問はありますか？」と尋ね、AIから質問を引き出すことが重要です。AIの質問を通じて、人間が見落としていた要件や、曖昧な点を洗い出し、PRDをより堅牢なものにしていきます。このプロセスは、まさに「15分で行うウォーターフォール開発」[[5](https://addyosmani.com/blog/ai-coding-workflow)]であり、事前に計画を立てることで、後の開発プロセスを劇的にスムーズにします。

PRDが完成したら、次にそれを実装可能なタスクに分解していきます。ここで有効なのが「垂直スライス（Vertical Slice）」アプローチです[[3](https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l)]。水平スライス（レイヤー）ごとに開発を進めるのではなく、一つの機能をデータベースからUIまで縦方向に切り取り、そのスライスを一つの単位として開発を進めます。例えば、「ユーザーがプロフィール画像をアップロードできるようにする」という機能であれば、画像アップロード用のAPIエンドポイントの作成、画像を保存するためのデータベーススキーマの変更、アップロードUIの実装、といった一連の変更を一つのスライスとして扱います。このアプローチにより、各スライスが独立して動作可能な状態になるため、開発の進捗が分かりやすく、テストも容易になります。AIにとっても、一度に考慮すべき範囲が限定されるため、より正確なコードを生成できます。

タスクの分解が終わったら、いよいよ具体的な「実装計画」を作成します。ここでは、Plan-Implement-Runパターン[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]の「Plan」フェーズを実行します。AIに対して、以下のような詳細なプロンプトを与え、実装計画書を生成させます。

```
# 実装計画作成プロンプト例

## 目的
以下のPRDに基づき、AIが実装を進めるための詳細な実装計画を作成してください。

## 入力情報
- PRD: [PRDのファイルパス]
- データベーススキーマ: [db_schema.mdのファイルパス]
- アーキテクチャ仕様: [architecture.mdのファイルパス]

## ルール
1.  実装計画は、`docs/plans/<feature_name>.plan.md` というマークダウンファイルとして作成すること。
2.  計画は、以下のフォーマットに従って構成すること。
    - **ステップ**: [実装するステップの簡潔なタイトル]
    - **目的**: [このステップで何を達成するのかの詳細な説明]
    - **対象ファイル**: [修正・作成するファイルのパスと、そのファイルでの具体的な変更内容。擬似コードでも可。]
    - **依存関係**: [このステップが依存している他のステップや外部コンポーネント。]
3.  計画には、各ステップの実装後に、その機能が正しく動作することを検証するための「検証ステップ」を必ず含めること。
4.  実装はシンプルに保ち、過剰な設計（オーバーエンジニアリング）は避けること。

## 出力
上記のフォーマットに従った、実装可能な詳細な実装計画。
```

このプロンプトを実行することで、AIはPRDとプロジェクトのドキュメントを参照しながら、具体的なファイル単位での変更内容を含む実装計画を生成します。生成された計画は、必ず人間がレビューし、必要に応じて修正や追加を行います。このレビュープロセスは、AIが誤った前提に基づいて計画を立てていないか、重要な手順が抜けていないかを確認するために不可欠です。また、Sequential Thinkingのようなツールを活用することで、AIが計画を立てる際の思考過程を可視化し、より論理的で網羅的な計画を作成する支援を受けることもできます[[10](https://zenn.dev/querypie/articles/aa04b4bcf8dd21)]。このフェーズでしっかりとした計画を作成することで、次の実装フェーズを自動化に近い形で進めることができ、開発の効率と品質を同時に最大化することが可能になります。

### フェーズ3：反復的な実装と検証 (Implementation & Verification)

計画が固まったら、いよいよ実装と検証のフェーズに入ります。このフェーズでは、前のステップで作成した詳細な実装計画をAIに渡し、実際のコードを生成させ、その品質を検証していくというサイクルを反復的に行います。大規模プロジェクトでは、一度にすべてを実装しようとせず、計画を分割し、小さな単位で「実装→検証」のサイクルを回すことが、問題の早期発見と修正の効率化に繋がります。

まず、Plan-Implement-Runパターン[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]の「Implement（実装）」フェーズを開始します。AIに対して、以下のようなプロンプトで実装を指示します。

```
# 実行プロンプト例

## タスク
`docs/plans/<feature_name>.plan.md` に記述されている実装計画に従って、コードを実装してください。

## 指示
- 計画はあくまでガイドラインです。もし計画に矛盾や非効率な点があれば、より良い方法を提案してください。
- 各ステップを実装したら、計画ファイルの該当ステップにチェックマークをつけ、進捗を管理してください。
- コードを記述する際は、必ずプロジェクトのコーディング規約（[coding-standards](/.github/prompt-snippets/coding-standards.md)）に従ってください。
- 実装が完了したら、自己レビューを行い、コードの品質を確認してください。
```

このプロンプトにより、AIは計画書に基づいてコードを生成していきます。CursorのようなAIエディタは、Composer機能を使って複数のファイルにまたがる変更を一度に指示でき、この実装フェーズを非常に効率的に進めることができます[[8](https://almcorp.com/blog/vibe-coding-complete-guide)]。AIがコードを生成したら、次は「Run（実行・検証）」フェーズです。まずは、ローカル環境でアプリケーションを起動し、生成されたコードが期待通りに動作するかを手動で確認します[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]。ここでエラーが発生した場合は、そのエラーメッセージをAIに提示し、原因の分析と修正を依頼します。AIはデバッグも得意としているため、人間が時間をかけて調査するよりも迅速に問題を解決できることが多いです。

手動での確認が終わったら、次に自動化されたテストを実行します。大規模プロジェクトでは、コードの品質を担保し、意図しない回帰（リグレッション）を防ぐために、自動テストは不可欠です[[4](https://zencoder.ai/blog/vibe-coding-best-practices)]。CI（継続的インテグレーション）ツール（例: Jenkins, GitHub Actions）を活用し、コードがリポジトリにプッシュされるたびに、自動的にユニットテストや統合テストが実行されるように設定しておきます。もしテストが失敗したら、AIにテストコードや失敗したログを提示し、テストが通るようにコードを修正させます。この「実装→手動テスト→自動テスト」というサイクルを、計画の各ステップ、あるいは各垂直スライスごとに反復的に行うことが重要です。

この反復的なプロセスを支援するために、TaskMaster-AIのようなツールが非常に有効です[[10](https://zenn.dev/querypie/articles/aa04b4bcf8dd21)]。TaskMaster-AIは、大規模な開発プロジェクト全体を管理するためのオーケストレーションツールです。PRDからタスクを自動生成し、タスク間の依存関係を管理しながら、AIに実装を指示していきます。これにより、開発者は個々のタスクの進捗を追跡しやすくなり、プロジェクト全体のボトルネックを早期に発見することができます。また、Gitによるバージョン管理もこのフェーズで重要な役割を果たします[[4](https://zencoder.ai/blog/vibe-coding-best-practices)]。各垂直スライスや機能単位でGitブランチを作成し、そのブランチ上でAIとの対話による開発を進めます。実装と検証が完了し、コードの品質が保証されたら、メインブランチへのマージリクエスト（プルリクエスト）を作成します。この際、AIに生成させたコードの変更点を要約させ、それをマージリクエストの説明文として利用することで、コードレビューの効率を向上させることができます。このように、計画的かつ反復的なアプローチを取ることで、大規模プロジェクトにおいても、バイブコーディングのスピードを活かしつつ、高い品質を維持することが可能になります。

### フェーズ4：文書化と知識資産化 (Documentation & Knowledge Capitalization)

大規模プロジェクトでは、コードそのものと同じくらい、あるいはそれ以上に「なぜそのコードがそう書かれたのか」という背景や意図を記録したドキュメントが重要になります。特に、AIが生成したコードは、人間が書いたコードとは異なり、その意図が分かりにくいことがあります。そのため、実装フェーズと並行して、または実装が完了した機能単位で、AIを活用した文書化を進めることが、プロジェクトの長期的な保守性を高める上で不可欠です。

実装が完了した機能やモジュールについて、AIにその内容を説明させるプロンプトを投げかけます。例えば、「`src/features/auth` ディレクトリ以下に実装した認証機能について、その設計思想、主要な関数の役割、そして外部ライブラリとの連携方法をまとめたドキュメントを `docs/features/auth.md` として作成してください」といった指示を出します。AIはコードを静的解析し、その構造や処理の流れを理解して、人間が読める形式のドキュメントを生成します。生成されたドキュメントは、必ず人間がレビューし、必要に応じて手を加えて、より分かりやすく、正確な内容に仕上げます。このプロセスにより、新しくプロジェクトに参加したメンバーでも、AIが生成したコードの意図を迅速に理解できるようになり、チーム全体の生産性が向上します。

さらに、AIとの対話の中で得られた「気づき」や「ベストプラクティス」も、積極的に知識資産として蓄積していくべきです。例えば、特定のタスクを解決するために非常に効果的だったプロンプトは、再利用可能な形で保存しておきます。Cursorであれば `.cursor/rules/` ディレクトリに、Sourcegraph Codyであれば「Prompt Library」[[17](https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704)]に保存しておくことで、チームの誰もがそのプロンプトを再利用し、一貫した品質でAIを活用できるようになります。また、プロジェクトのルールファイル（例: `.cursorrules`）自体も、開発を進める中で得られた知見をもとに継続的に改善していくことが重要です[[3](https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l)]。AIが頻繁に間違えるパターンや、プロジェクト特有の注意点などをルールファイルに追加していくことで、AIの出力精度は時間と共に向上していきます。

この文書化と知識資産化のプロセスは、単なる事後作業ではありません。これは、AIとの協働をより効率的にするための「投資」です。しっかりと文書化されたプロジェクトは、AIにとってより理解しやすいものとなり、次に新たな機能を開発する際には、より少ない手間でより高品質なコードを生成できるようになります。また、チーム内の知識が個人の頭の中に閉じられることなく、プロジェクトの資産として蓄積されていくため、チームのレジリエンス（回復力）が高まります。AIが生成したコードを「使い捨て」のものと考えるのではなく、それを「保守し、成長させていくべき資産」と考えるために、この文書化のフェーズは不可欠なのです。

## まとめ：AIを「相棒」にするための最終解

本レポートで提示したワークフローは、50フォルダを超える大規模な開発プロジェクトにおいて、バイブコーディングの精度を最大化し、その力を信頼できるものに変えるための体系的なアプローチです。このワークフローの核心は、AIを「魔法の道具」ではなく、「高度な能力を持つが、プロジェクトのことは何も知らない新しいチームメンバー」[[1](https://raffertyuy.com/raztype/vibe-coding-plan-implement-run)]として扱い、その能力を最大限に引き出すための「共通言語」と「作業プロセス」を人間側が提供することにあります。プロジェクトの基盤を整備し、詳細な計画を立て、反復的に実装と検証を行い、その過程で得られた知見を文書化していく。この一連のプロセスを忠実に実行することで、AIの生成するコードは、プロジェクトの意図から乖離した「不安定なもの」から、プロジェクトの一部としてしっかりと機能する「信頼できる資産」へと変貌を遂げます。

このワークフローがもたらす最大の価値は、開発の「生産性」と「品質」の両立を実現できる点にあります。AIを活用することで、開発者は反復的で機械的なコーディング作業から解放され、より創造的で本質的な問題解決に集中できるようになります[[17](https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704)]。一方で、計画と検証のサイクルをしっかりと回すことで、AIが生成するコードの品質を保証し、大規模プロジェクトが陥りがちな「技術的負債の爆発」を防ぐことができます。結果として、プロジェクトの開発速度は飛躍的に向上し、かつ保守性の高い、クリーンなコードベースを維持することが可能になります。AIが開発者を「代替」するのではなく、開発者の「能力を拡張（Augment）」するツールとして機能するのです。

AIを活用した開発の未来は、もはや「より多くのコードを、より速く書くこと」ではありません。それは、「より少ない労力で、より高い価値を持つソフトウェアを、より賢く作ること」へとシフトしつつあります。本レポートで示したワークフローは、その未来を実現するための一つの具体的な道筋です。今日からでも、このワークフローの一部をあなたのプロジェクトに取り入れてみてください。まずは、プロジェクトのドキュメントを整備するところから始めても良いし、次の小さなタスクから「Plan-Implement-Run」のサイクルを試してみても良いでしょう。小さな一歩が、やがてあなたとあなたのチームの開発体験を劇的に変え、AIを真の意味での「最強の相棒」にしてくれるはずです。

## 参考文献

[1] Increase Vibe Coding Accuracy with the Plan-Implement-Run Pattern. https://raffertyuy.com/raztype/vibe-coding-plan-implement-run.

[3] A Structured Workflow for "Vibe Coding" Full-Stack Apps. https://dev.to/wasp/a-structured-workflow-for-vibe-coding-full-stack-apps-352l.

[4] 5 Vibe Coding Best Practices to Implement in Your Workflow. https://zencoder.ai/blog/vibe-coding-best-practices.

[5] My LLM coding workflow going into 2026. https://addyosmani.com/blog/ai-coding-workflow.

[8] Vibe Coding: The Complete Guide to AI-Assisted Software Development. https://almcorp.com/blog/vibe-coding-complete-guide.

[10] AI開発の効率を爆発的に高める方法. https://zenn.dev/querypie/articles/aa04b4bcf8dd21.

[11] 最近目にする「Vibe Coding」解説~ AIを活用した新しい. https://note.com/ogawa_ramo/n/n6d6e65742c14.

[15] AI時代の新常識：「Vibe Codingの限界」と「SDD - 仕様駆動. https://qiita.com/nogataka/items/b2c2cb475fa28333b56a.

[17] Sourcegraph Cody：AI時代のプログラミングアシスタント、徹底解説と実践. https://skywork.ai/skypage/ja/sourcegraph-cody-ai-programming-assistant/1984086800521416704.