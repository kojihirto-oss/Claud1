### USER
あなたは「ツール統合アーキテクト（2026最新の実務最適化）」です。
添付テキスト（設計書の一部）を前提に、
IDE/CLI/エージェント/MCP/ZAI/RAG をどう組み合わせると
“精度・コスパ・事故防止・スピード”が最大になるかを調査して提案してください。

# 目的
- 役割分担を決める：
  (1) ローカルCLI（例：コード編集/検索/テスト/差分） 
  (2) IDEエージェント（例：実装支援/リファクタ/修正提案）
  (3) MCP（例：外部公式情報の取得、仕様確認、根拠集め）
  (4) RAG（例：リポジトリ内SSOTの参照精度を上げる）
- 2026年時点の “最新の推奨運用” を一次情報ベースで整理
- 具体的に「どの作業を、どのツールに投げるか」テンプレを作る

# 情報源ルール
- 一次情報（公式ドキュメント/公式GitHub/標準化団体）を最優先
- SNS（YouTube/note/X）は「新情報の発見」用途でOK。ただし採用判断は一次情報で裏取り
- MCPについては公式ドキュメントを根拠に説明（remote/localの違い、活用例など）

# 出力フォーマット（厳守）
1) ツール別の最適担当表（作業→推奨ツール→理由）
2) MCP活用で “抜けを埋める” 具体プロンプト例（3〜5本）
3) RAG/ナレッジ運用の強化案（更新・検証・証跡）
4) 設計書へ追記する文章案（そのまま貼れる）
5) 導入リスクと回避策（API費用、誤情報、権限、再現性）


### ASSISTANT
<details type="reasoning" done="true" duration="8" view="" last_tool_call_name="">
> このドキュメントは、VCG/VIBE 2026プロジェクトのためのSingle Source of Truth (SSOT)設計マスターのようです。ドキュメントはPart00からPart04まで含まれており、プロジェクトの目的、用語定義、AIの役割、作業管理などが詳細に定義されています。
> 
> 主要なポイント:
> 1. SSOT (Single Source of Truth) の概念と運用ルール
> 2. プロジェクトの目的と成功条件
> 3. 用語集と共通語彙の定義
> 4. AI Pack (Core4/Antigravity/MCP) の役割分担
> 5. 作業管理 (TICKET/VIBEKANBAN/WIP制限)
> 
> このドキュメントを基に、IDE/CLI/エージェント/MCP/ZAI/RAGをどう組み合わせるかを提案する必要があります。各ツールの役割分担、MCP活用プロンプト、RAG運用強化案、設計書への追記文章案、導入リスクと回避策を検討します。
> 
> まず、各ツールの特性を理解し、ドキュメントで定義されているAI Pack (Core4) との整合性を考慮する必要があります。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"}]},"metadata":{"arguments":"{\"query\":\"Model Context Protocol MCP 2026 official documentation\"}","display_result":"","duration":"1s","id":"call_fG9YjNMUiZ","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【0†MCP Docs†https://modelcontextprotocol.info/docs】\nWelcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...\n\n【1†What is the Model Context Protocol (MCP)? - Model Context†https://modelcontextprotocol.io】\nMCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...\n\n【2†Specification and documentation for the Model Context†https://github.com/modelcontextprotocol/modelcontextprotocol】\nThe official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...\n\n【3†Specification†https://modelcontextprotocol.io/specification/2025-03-26】\nModel Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.\n\n【4†Model Context Protocol†https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol】\nModel Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).\n\n【5†What is Model Context Protocol (MCP)?†https://www.ibm.com/think/topics/model-context-protocol】\nThe Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...\n\n【6†Model Context Protocol - Support - runZero†https://help.runzero.com/docs/mcp】\nModel Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.\n\n【7†Model Context Protocol (MCP)†https://www.librechat.ai/docs/features/mcp】\nModel Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).\n\n【8†Model Context Protocol (MCP) :: Spring AI Reference†https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html】\nThe Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.\n\n【9†Model Context Protocol (MCP) Spec Updates from June 2025†https://auth0.com/blog/mcp-specs-update-all-about-auth】\nGuide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> MCPに関する公式ドキュメントが見つかりました。2026年時点の最新情報を確認するために、MCPの公式ドキュメントを詳しく見てみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://modelcontextprotocol.info/docs","title":"MCP Docs","content":"【0†MCP Docs†https://modelcontextprotocol.info/docs】\nTitle: MCP Docs\n\nURL Source: https://modelcontextprotocol.info/docs\n\nMarkdown Content:\nMCP Docs – Model Context Protocol （MCP）\n===============\n\nModel Context Protocol （MCP）Home Documentation Specification Tools Blog\n\nCTRL K\n\nCTRL K\n\n*   MCP Docs\n    *   Quick Start\n    *   Core Concepts\n    *   Why Choose MCP?\n\n    *   Understanding Model Context Protocol (MCP)\n    *   MCP Learning Path: From Zero to Hero\n    *   Quickstart\n\n        *   Guide\n        *   For Server Developers\n        *   For Client Developers\n        *   Your First MCP Experience: 5-Minute Setup\n        *   Quickstart\n\n    *   Core Concepts\n\n        *   MCP Architecture: Design Philosophy & Engineering Principles\n        *   Prompts\n        *   Resources\n        *   Roots\n        *   Sampling\n        *   Tools\n        *   Transports\n\n    *   MCP Tutorials: From Concept to Production\n\n        *   Building MCP with LLMs\n        *   Building MCP clients-Python\n        *   Building MCP clients-Node.js\n        *   Writing Effective Tools for Agents: Complete MCP Development Guide\n\n    *   MCP Server Ecosystem: From Proof-of-Concept to Production\n    *   Clients\n    *   MCP FAQ: Expert Answers to Real-World Questions\n    *   MCP Best Practices: Architecture & Implementation Guide\n    *   SDK\n\n        *   Java SDK\n\n            *   Overview\n            *   MCP Server\n            *   MCP Client\n\n    *   Build an MCP Client (Core)\n\n*   Tools\n\n    *   MCP Registry\n\n        *   Publish Your MCP Server\n        *   Registry CLI Tool\n        *   GitHub Actions 自动化发布\n        *   消费 Registry 数据\n        *   Registry FAQ\n\n    *   Debugging\n    *   Inspector\n    *   测试\n\n*   Specification\n\n    *   Specification (Draft)\n\n        *   Architecture\n        *   Base Protocol\n\n            *   Transports\n            *   Authorization\n            *   Messages\n            *   Lifecycle\n            *   Versioning\n            *   Utilities\n\n                *   Ping\n                *   Cancellation\n                *   Progress\n\n        *   Server Features\n\n            *   Prompts\n            *   Resources\n            *   Tools\n            *   Utilities\n\n                *   Completion\n                *   Logging\n                *   Pagination\n\n        *   Client Features\n\n            *   Roots\n            *   Sampling\n\n        *   Contributions\n        *   Revisions\n\n            *   2024-11-05 (Current)\n\n    *   Specification (Latest)\n\n        *   Architecture\n        *   Base Protocol\n\n            *   Messages\n            *   Lifecycle\n            *   Transports\n            *   Versioning\n            *   Utilities\n\n                *   Ping\n                *   Cancellation\n                *   Progress\n\n        *   Server Features\n\n            *   Prompts\n            *   Resources\n            *   Tools\n            *   Utilities\n\n                *   Completion\n                *   Logging\n                *   Pagination\n\n        *   Client Features\n\n            *   Roots\n            *   Sampling\n\n        *   Contributions\n        *   Revisions\n\n            *   2024-11-05 (Current)\n\n*   MCP Protocol Blog\n\n    *   Mastering MCP Tool Development: Unlocking AI Agent Potential\n    *   Update on the Next MCP Protocol Release\n    *   Chrome DevTools MCP: Giving AI Coding Assistants Eyes to See Beyond Blind Programming\n    *   Model Context Protocol (MCP): A New Standard for AI Application and External Data Integration\n    *   一文读懂MCP协议：大模型AI-Agent的USB-C接口\n\n*   About\n*   More\n*   Docs ↗\n*   Specification ↗\n*   About\n\n*   Understanding Model Context Protocol (MCP)\n*   MCP Learning Path: From Zero to Hero\n*   Quickstart\n\n    *   Guide\n    *   For Server Developers\n    *   For Client Developers\n    *   Your First MCP Experience: 5-Minute Setup\n    *   Quickstart\n\n*   Core Concepts\n\n    *   MCP Architecture: Design Philosophy & Engineering Principles\n    *   Prompts\n    *   Resources\n    *   Roots\n    *   Sampling\n    *   Tools\n    *   Transports\n\n*   MCP Tutorials: From Concept to Production\n\n    *   Building MCP with LLMs\n    *   Building MCP clients-Python\n    *   Building MCP clients-Node.js\n    *   Writing Effective Tools for Agents: Complete MCP Development Guide\n\n*   MCP Server Ecosystem: From Proof-of-Concept to Production\n*   Clients\n*   MCP FAQ: Expert Answers to Real-World Questions\n*   MCP Best Practices: Architecture & Implementation Guide\n*   SDK\n\n    *   Java SDK\n\n        *   Overview\n        *   MCP Server\n        *   MCP Client\n\n*   Build an MCP Client (Core)\n*   More\n*   Docs ↗\n*   Specification ↗\n*   About\n\nEnglish\n\n*   English\n*   简体中文\n*   繁體中文\n*   한국어\n\n*   Light\n\n*   Dark\n\n*   System\n\nOn this page\n\n*   Quick Start\n*   Core Concepts\n*   Why Choose MCP?\n\nScroll to top\n\nMCP Docs\n\nMCP Docs\n========\n\nModel Context Protocol (MCP)\n============================\n\nWelcome to the Model Context Protocol documentation!\n\nMCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and applications by providing structured context management.\n\nQuick Start\n-----------\n\n*   **Quick Start** - Get started with MCP in 5 minutes\n*   **Client** - Installation and usage guides for different language clients\n*   **Build an MCP Client (Core)** - Minimal viable implementation with official examples\n\nCore Concepts\n-------------\n\nMCP’s core features and concepts include:\n\n*   **Sampling** - Understanding MCP’s sampling mechanisms and strategies\n*   **Transport** - Data transport and communication protocols\n*   **Tools** - MCP toolset and usage guidelines\n*   **Architecture** - System architecture and design principles\n*   **Prompts** - Prompt engineering and best practices\n*   **Resources** - Related resources and references\n\nWhy Choose MCP?\n---------------\n\n*   **Standardization**: Unified interfaces and protocols to simplify development\n*   **Efficiency**: Optimized context management for enhanced model interactions\n*   **Extensibility**: Flexible architecture supporting custom extensions\n*   **Ease of Use**: Simple and intuitive APIs with low barrier to entry\n\nModel Context Protocol Hub MCP 中文站 A2A Protocol AP2 Lab ACP Protocol Agent2Agent 文档 AI to Sora ChatGPT 中文\n\nPowered by ModelContextProtocol\n\n© 2024 ModelContextProtocol.Info.\n\n"},"metadata":{"arguments":"{\"link_id\":0}","display_result":"","duration":"5s","id":"call_vCQ8iTcaS7","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【0†MCP Docs†https://modelcontextprotocol.info/docs】\nTitle: MCP Docs\n\nURL Source: https://modelcontextprotocol.info/docs\n\nMarkdown Content:\nMCP Docs – Model Context Protocol （MCP）\n===============\n\nModel Context Protocol （MCP）Home Documentation Specification Tools Blog\n\nCTRL K\n\nCTRL K\n\n*   MCP Docs\n    *   Quick Start\n    *   Core Concepts\n    *   Why Choose MCP?\n\n    *   Understanding Model Context Protocol (MCP)\n    *   MCP Learning Path: From Zero to Hero\n    *   Quickstart\n\n        *   Guide\n        *   For Server Developers\n        *   For Client Developers\n        *   Your First MCP Experience: 5-Minute Setup\n        *   Quickstart\n\n    *   Core Concepts\n\n        *   MCP Architecture: Design Philosophy & Engineering Principles\n        *   Prompts\n        *   Resources\n        *   Roots\n        *   Sampling\n        *   Tools\n        *   Transports\n\n    *   MCP Tutorials: From Concept to Production\n\n        *   Building MCP with LLMs\n        *   Building MCP clients-Python\n        *   Building MCP clients-Node.js\n        *   Writing Effective Tools for Agents: Complete MCP Development Guide\n\n    *   MCP Server Ecosystem: From Proof-of-Concept to Production\n    *   Clients\n    *   MCP FAQ: Expert Answers to Real-World Questions\n    *   MCP Best Practices: Architecture & Implementation Guide\n    *   SDK\n\n        *   Java SDK\n\n            *   Overview\n            *   MCP Server\n            *   MCP Client\n\n    *   Build an MCP Client (Core)\n\n*   Tools\n\n    *   MCP Registry\n\n        *   Publish Your MCP Server\n        *   Registry CLI Tool\n        *   GitHub Actions 自动化发布\n        *   消费 Registry 数据\n        *   Registry FAQ\n\n    *   Debugging\n    *   Inspector\n    *   测试\n\n*   Specification\n\n    *   Specification (Draft)\n\n        *   Architecture\n        *   Base Protocol\n\n            *   Transports\n            *   Authorization\n            *   Messages\n            *   Lifecycle\n            *   Versioning\n            *   Utilities\n\n                *   Ping\n                *   Cancellation\n                *   Progress\n\n        *   Server Features\n\n            *   Prompts\n            *   Resources\n            *   Tools\n            *   Utilities\n\n                *   Completion\n                *   Logging\n                *   Pagination\n\n        *   Client Features\n\n            *   Roots\n            *   Sampling\n\n        *   Contributions\n        *   Revisions\n\n            *   2024-11-05 (Current)\n\n    *   Specification (Latest)\n\n        *   Architecture\n        *   Base Protocol\n\n            *   Messages\n            *   Lifecycle\n            *   Transports\n            *   Versioning\n            *   Utilities\n\n                *   Ping\n                *   Cancellation\n                *   Progress\n\n        *   Server Features\n\n            *   Prompts\n            *   Resources\n            *   Tools\n            *   Utilities\n\n                *   Completion\n                *   Logging\n                *   Pagination\n\n        *   Client Features\n\n            *   Roots\n            *   Sampling\n\n        *   Contributions\n        *   Revisions\n\n            *   2024-11-05 (Current)\n\n*   MCP Protocol Blog\n\n    *   Mastering MCP Tool Development: Unlocking AI Agent Potential\n    *   Update on the Next MCP Protocol Release\n    *   Chrome DevTools MCP: Giving AI Coding Assistants Eyes to See Beyond Blind Programming\n    *   Model Context Protocol (MCP): A New Standard for AI Application and External Data Integration\n    *   一文读懂MCP协议：大模型AI-Agent的USB-C接口\n\n*   About\n*   More\n*   Docs ↗\n*   Specification ↗\n*   About\n\n*   Understanding Model Context Protocol (MCP)\n*   MCP Learning Path: From Zero to Hero\n*   Quickstart\n\n    *   Guide\n    *   For Server Developers\n    *   For Client Developers\n    *   Your First MCP Experience: 5-Minute Setup\n    *   Quickstart\n\n*   Core Concepts\n\n    *   MCP Architecture: Design Philosophy & Engineering Principles\n    *   Prompts\n    *   Resources\n    *   Roots\n    *   Sampling\n    *   Tools\n    *   Transports\n\n*   MCP Tutorials: From Concept to Production\n\n    *   Building MCP with LLMs\n    *   Building MCP clients-Python\n    *   Building MCP clients-Node.js\n    *   Writing Effective Tools for Agents: Complete MCP Development Guide\n\n*   MCP Server Ecosystem: From Proof-of-Concept to Production\n*   Clients\n*   MCP FAQ: Expert Answers to Real-World Questions\n*   MCP Best Practices: Architecture & Implementation Guide\n*   SDK\n\n    *   Java SDK\n\n        *   Overview\n        *   MCP Server\n        *   MCP Client\n\n*   Build an MCP Client (Core)\n*   More\n*   Docs ↗\n*   Specification ↗\n*   About\n\nEnglish\n\n*   English\n*   简体中文\n*   繁體中文\n*   한국어\n\n*   Light\n\n*   Dark\n\n*   System\n\nOn this page\n\n*   Quick Start\n*   Core Concepts\n*   Why Choose MCP?\n\nScroll to top\n\nMCP Docs\n\nMCP Docs\n========\n\nModel Context Protocol (MCP)\n============================\n\nWelcome to the Model Context Protocol documentation!\n\nMCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and applications by providing structured context management.\n\nQuick Start\n-----------\n\n*   **Quick Start** - Get started with MCP in 5 minutes\n*   **Client** - Installation and usage guides for different language clients\n*   **Build an MCP Client (Core)** - Minimal viable implementation with official examples\n\nCore Concepts\n-------------\n\nMCP’s core features and concepts include:\n\n*   **Sampling** - Understanding MCP’s sampling mechanisms and strategies\n*   **Transport** - Data transport and communication protocols\n*   **Tools** - MCP toolset and usage guidelines\n*   **Architecture** - System architecture and design principles\n*   **Prompts** - Prompt engineering and best practices\n*   **Resources** - Related resources and references\n\nWhy Choose MCP?\n---------------\n\n*   **Standardization**: Unified interfaces and protocols to simplify development\n*   **Efficiency**: Optimized context management for enhanced model interactions\n*   **Extensibility**: Flexible architecture supporting custom extensions\n*   **Ease of Use**: Simple and intuitive APIs with low barrier to entry\n\nModel Context Protocol Hub MCP 中文站 A2A Protocol AP2 Lab ACP Protocol Agent2Agent 文档 AI to Sora ChatGPT 中文\n\nPowered by ModelContextProtocol\n\n© 2024 ModelContextProtocol.Info.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> MCPの公式ドキュメントを確認しました。次に、MCPの仕様についてより詳細な情報を得るために、GitHubの仕様ページを確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://github.com/modelcontextprotocol/modelcontextprotocol","title":"Specification and documentation for the Model Context","content":"【2†Specification and documentation for the Model Context†https://github.com/modelcontextprotocol/modelcontextprotocol】\nTitle: GitHub - modelcontextprotocol/modelcontextprotocol: Specification and documentation for the Model Context Protocol\n\nURL Source: https://github.com/modelcontextprotocol/modelcontextprotocol\n\nMarkdown Content:\nGitHub - modelcontextprotocol/modelcontextprotocol: Specification and documentation for the Model Context Protocol\n===============\n\nSkip to content\nNavigation Menu\n---------------\n\nToggle navigation\n\nSign in\n\nAppearance settings\n\n*   \nPlatform\n\n    *   \nAI CODE CREATION\n        *   GitHub Copilot Write better code with AI\n        *   GitHub Spark Build and deploy intelligent apps\n        *   GitHub Models Manage and compare prompts\n        *   MCP Registry New Integrate external tools\n\n    *   \nDEVELOPER WORKFLOWS\n        *   Actions Automate any workflow\n        *   Codespaces Instant dev environments\n        *   Issues Plan and track work\n        *   Code Review Manage code changes\n\n    *   \nAPPLICATION SECURITY\n        *   GitHub Advanced Security Find and fix vulnerabilities\n        *   Code security Secure your code as you build\n        *   Secret protection Stop leaks before they start\n\n    *   \nEXPLORE\n        *   Why GitHub\n        *   Documentation\n        *   Blog\n        *   Changelog\n        *   Marketplace\n\nView all features\n\n*   \nSolutions\n\n    *   \nBY COMPANY SIZE\n        *   Enterprises\n        *   Small and medium teams\n        *   Startups\n        *   Nonprofits\n\n    *   \nBY USE CASE\n        *   App Modernization\n        *   DevSecOps\n        *   DevOps\n        *   CI/CD\n        *   View all use cases\n\n    *   \nBY INDUSTRY\n        *   Healthcare\n        *   Financial services\n        *   Manufacturing\n        *   Government\n        *   View all industries\n\nView all solutions\n\n*   \nResources\n\n    *   \nEXPLORE BY TOPIC\n        *   AI\n        *   Software Development\n        *   DevOps\n        *   Security\n        *   View all topics\n\n    *   \nEXPLORE BY TYPE\n        *   Customer stories\n        *   Events & webinars\n        *   Ebooks & reports\n        *   Business insights\n        *   GitHub Skills\n\n    *   \nSUPPORT & SERVICES\n        *   Documentation\n        *   Customer support\n        *   Community forum\n        *   Trust center\n        *   Partners\n\n*   \nOpen Source\n\n    *   \nCOMMUNITY\n        *   GitHub Sponsors Fund open source developers\n\n    *   \nPROGRAMS\n        *   Security Lab\n        *   Maintainer Community\n        *   Accelerator\n        *   Archive Program\n\n    *   \nREPOSITORIES\n        *   Topics\n        *   Trending\n        *   Collections\n\n*   \nEnterprise\n\n    *   \nENTERPRISE SOLUTIONS\n        *   Enterprise platform AI-powered developer platform\n\n    *   \nAVAILABLE ADD-ONS\n        *   GitHub Advanced Security Enterprise-grade security features\n        *   Copilot for Business Enterprise-grade AI features\n        *   Premium Support Enterprise-grade 24/7 support\n\n*   Pricing\n\nSearch or jump to...\n\nSearch code, repositories, users, issues, pull requests...\n==========================================================\n\n Search  \n\nClear\n\nSearch syntax tips\n\nProvide feedback\n================\n\nWe read every piece of feedback, and take your input very seriously.\n\n- [x] Include my email address so I can be contacted \n\n Cancel  Submit feedback \n\nSaved searches\n==============\n\nUse saved searches to filter your results more quickly\n------------------------------------------------------\n\nName \n\nQuery \n\nTo see all available qualifiers, see our documentation.\n\n Cancel  Create saved search \n\nSign in\n\nSign up\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\nmodelcontextprotocol/**modelcontextprotocol**Public\n\n*   Notifications You must be signed in to change notification settings\n*   Fork 1.2k\n*   Star 6.9k \n\nSpecification and documentation for the Model Context Protocol\n\nmodelcontextprotocol.io\n\n### License\n\nView license\n\n6.9k stars 1.2k forks Branches Tags Activity\n\nStar\n\nNotifications You must be signed in to change notification settings\n\n*   Code\n*   Issues 249\n*   Pull requests 87\n*   Discussions\n*   Actions\n*   Projects 1\n*   Security### Uh oh!\nThere was an error while loading.Please reload this page.    \n*   Insights\n\nAdditional navigation options\n\n*   Code\n*   Issues\n*   Pull requests\n*   Discussions\n*   Actions\n*   Projects\n*   Security\n*   Insights\n\nmodelcontextprotocol/modelcontextprotocol\n=========================================\n\nmain\n\n**55**Branches**7**Tags\n\nGo to file\n\nCode\n\nOpen more actions menu\n\nFolders and files\n-----------------\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| Latest commit ------------- dsp-ant add Konstantin to Kotlin maintainers success Jan 9, 2026 b438f60·Jan 9, 2026 History ------- 2,878 Commits Open commit details |\n| .github | .github | Add core-maintainers to /docs/ CODEOWNERS | Nov 4, 2025 |\n| blog | blog | Fix MCP spec links | Dec 20, 2025 |\n| docs | docs | Merge pull request#2063 from olaservo/olaservo-patch-2 | Jan 7, 2026 |\n| schema | schema | Add example for progress token usage | Dec 31, 2025 |\n| scripts | scripts | Add script to validate JSON examples against schema | Dec 30, 2025 |\n| seps | seps | Add blog post announcing SEP process migration to PRs (#1851) | Nov 28, 2025 |\n| .gitattributes | .gitattributes | Add schema reference page | Jul 14, 2025 |\n| .gitignore | .gitignore | add .idea/ to .gitignore (#1864) | Nov 21, 2025 |\n| .npmrc | .npmrc | Add .npmrc | Oct 31, 2024 |\n| .nvmrc | .nvmrc | Make examples on schema reference page collapsible | Dec 30, 2025 |\n| .prettierignore | .prettierignore | Add schema reference page | Jul 14, 2025 |\n| .prettierrc.json | .prettierrc.json | feat: add eslint and format typescript with prettier (#1782) | Nov 7, 2025 |\n| AGENTS.md | AGENTS.md | Document schema examples convention in `{AGENTS,CLAUDE}.md` | Dec 30, 2025 |\n| ANTITRUST.md | ANTITRUST.md | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| CLAUDE.md | CLAUDE.md | Add `{AGENTS,CLAUDE}.md` with documentation structure overview | Dec 15, 2025 |\n| CODE_OF_CONDUCT.md | CODE_OF_CONDUCT.md | chore: add markdown format check workflow and format all docs | Jan 20, 2025 |\n| CONTRIBUTING.md | CONTRIBUTING.md | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| GOVERNANCE.md | GOVERNANCE.md | Add general project policies to governance documentation | Dec 11, 2025 |\n| LICENSE | LICENSE | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| MAINTAINERS.md | MAINTAINERS.md | add Konstantin to Kotlin maintainers | Jan 9, 2026 |\n| README.md | README.md | docs: update version references to 2025-11-25 and use /specification/… | Dec 2, 2025 |\n| SECURITY.md | SECURITY.md | chore: add markdown format check workflow and format all docs | Jan 20, 2025 |\n| eslint.config.mjs | eslint.config.mjs | feat: add eslint and format typescript with prettier (#1782) | Nov 7, 2025 |\n| package-lock.json | package-lock.json | Make examples on schema reference page collapsible | Dec 30, 2025 |\n| package.json | package.json | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| tsconfig.json | tsconfig.json | De-zoddify | Nov 14, 2025 |\n| typedoc.config.mjs | typedoc.config.mjs | Add `@example` tag support for schema page | Dec 30, 2025 |\n| typedoc.plugin.mjs | typedoc.plugin.mjs | Add `*ResultResponse` interfaces for typed JSON-RPC responses | Dec 31, 2025 |\n| View all files |\n\nRepository files navigation\n---------------------------\n\n*   README\n*   Code of conduct\n*   Contributing\n*   License\n*   Security\n\nModel Context Protocol (MCP)\n============================\n\n_Just heard of MCP and not sure where to start? Check out our documentation website._\n\nThis repo contains the:\n\n*   MCP specification\n*   MCP protocol schema\n*   Official MCP documentation\n\nThe schema is defined in TypeScript first, but made available as JSON Schema as well, for wider compatibility.\n\nThe official MCP documentation is built using Mintlify and available at modelcontextprotocol.io.\n\nAuthors\n-------\n\nThe Model Context Protocol was created by David Soria Parra (@dsp) and Justin Spahr-Summers (@jspahrsummers).\n\nContributing\n------------\n\nSee CONTRIBUTING.md.\n\nLicense\n-------\n\nThis project is licensed under the MIT License.\n\nAbout\n-----\n\nSpecification and documentation for the Model Context Protocol\n\nmodelcontextprotocol.io\n\n### Resources\n\nReadme\n\n### License\n\nView license\n\n### Code of conduct\n\nCode of conduct\n\n### Contributing\n\nContributing\n\n### Security policy\n\nSecurity policy\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\nActivity\n\nCustom properties\n\n### Stars\n\n**6.9k** stars\n\n### Watchers\n\n**160** watching\n\n### Forks\n\n**1.2k** forks\n\nReport repository\n\nReleases 7\n----------\n\n2025-11-25 Latest Nov 25, 2025\n\n+ 6 releases\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\nContributors 322\n----------------\n\n+ 308 contributors\n\nLanguages\n---------\n\n*   TypeScript 92.3%\n*   JavaScript 3.4%\n*   MDX 2.2%\n*   HTML 2.0%\n*   CSS 0.1%\n\nFooter\n------\n\n © 2026 GitHub,Inc. \n\n### Footer navigation\n\n*   Terms\n*   Privacy\n*   Security\n*   Status\n*   Community\n*   Docs\n*   Contact\n*    Manage cookies \n*    Do not share my personal information \n\n You can’t perform that action at this time.\n\n"},"metadata":{"arguments":"{\"link_id\":2}","display_result":"","duration":"5s","id":"call_FfQ8oUdpVu","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【2†Specification and documentation for the Model Context†https://github.com/modelcontextprotocol/modelcontextprotocol】\nTitle: GitHub - modelcontextprotocol/modelcontextprotocol: Specification and documentation for the Model Context Protocol\n\nURL Source: https://github.com/modelcontextprotocol/modelcontextprotocol\n\nMarkdown Content:\nGitHub - modelcontextprotocol/modelcontextprotocol: Specification and documentation for the Model Context Protocol\n===============\n\nSkip to content\nNavigation Menu\n---------------\n\nToggle navigation\n\nSign in\n\nAppearance settings\n\n*   \nPlatform\n\n    *   \nAI CODE CREATION\n        *   GitHub Copilot Write better code with AI\n        *   GitHub Spark Build and deploy intelligent apps\n        *   GitHub Models Manage and compare prompts\n        *   MCP Registry New Integrate external tools\n\n    *   \nDEVELOPER WORKFLOWS\n        *   Actions Automate any workflow\n        *   Codespaces Instant dev environments\n        *   Issues Plan and track work\n        *   Code Review Manage code changes\n\n    *   \nAPPLICATION SECURITY\n        *   GitHub Advanced Security Find and fix vulnerabilities\n        *   Code security Secure your code as you build\n        *   Secret protection Stop leaks before they start\n\n    *   \nEXPLORE\n        *   Why GitHub\n        *   Documentation\n        *   Blog\n        *   Changelog\n        *   Marketplace\n\nView all features\n\n*   \nSolutions\n\n    *   \nBY COMPANY SIZE\n        *   Enterprises\n        *   Small and medium teams\n        *   Startups\n        *   Nonprofits\n\n    *   \nBY USE CASE\n        *   App Modernization\n        *   DevSecOps\n        *   DevOps\n        *   CI/CD\n        *   View all use cases\n\n    *   \nBY INDUSTRY\n        *   Healthcare\n        *   Financial services\n        *   Manufacturing\n        *   Government\n        *   View all industries\n\nView all solutions\n\n*   \nResources\n\n    *   \nEXPLORE BY TOPIC\n        *   AI\n        *   Software Development\n        *   DevOps\n        *   Security\n        *   View all topics\n\n    *   \nEXPLORE BY TYPE\n        *   Customer stories\n        *   Events & webinars\n        *   Ebooks & reports\n        *   Business insights\n        *   GitHub Skills\n\n    *   \nSUPPORT & SERVICES\n        *   Documentation\n        *   Customer support\n        *   Community forum\n        *   Trust center\n        *   Partners\n\n*   \nOpen Source\n\n    *   \nCOMMUNITY\n        *   GitHub Sponsors Fund open source developers\n\n    *   \nPROGRAMS\n        *   Security Lab\n        *   Maintainer Community\n        *   Accelerator\n        *   Archive Program\n\n    *   \nREPOSITORIES\n        *   Topics\n        *   Trending\n        *   Collections\n\n*   \nEnterprise\n\n    *   \nENTERPRISE SOLUTIONS\n        *   Enterprise platform AI-powered developer platform\n\n    *   \nAVAILABLE ADD-ONS\n        *   GitHub Advanced Security Enterprise-grade security features\n        *   Copilot for Business Enterprise-grade AI features\n        *   Premium Support Enterprise-grade 24/7 support\n\n*   Pricing\n\nSearch or jump to...\n\nSearch code, repositories, users, issues, pull requests...\n==========================================================\n\n Search  \n\nClear\n\nSearch syntax tips\n\nProvide feedback\n================\n\nWe read every piece of feedback, and take your input very seriously.\n\n- [x] Include my email address so I can be contacted \n\n Cancel  Submit feedback \n\nSaved searches\n==============\n\nUse saved searches to filter your results more quickly\n------------------------------------------------------\n\nName \n\nQuery \n\nTo see all available qualifiers, see our documentation.\n\n Cancel  Create saved search \n\nSign in\n\nSign up\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\nmodelcontextprotocol/**modelcontextprotocol**Public\n\n*   Notifications You must be signed in to change notification settings\n*   Fork 1.2k\n*   Star 6.9k \n\nSpecification and documentation for the Model Context Protocol\n\nmodelcontextprotocol.io\n\n### License\n\nView license\n\n6.9k stars 1.2k forks Branches Tags Activity\n\nStar\n\nNotifications You must be signed in to change notification settings\n\n*   Code\n*   Issues 249\n*   Pull requests 87\n*   Discussions\n*   Actions\n*   Projects 1\n*   Security### Uh oh!\nThere was an error while loading.Please reload this page.    \n*   Insights\n\nAdditional navigation options\n\n*   Code\n*   Issues\n*   Pull requests\n*   Discussions\n*   Actions\n*   Projects\n*   Security\n*   Insights\n\nmodelcontextprotocol/modelcontextprotocol\n=========================================\n\nmain\n\n**55**Branches**7**Tags\n\nGo to file\n\nCode\n\nOpen more actions menu\n\nFolders and files\n-----------------\n\n| Name | Name | Last commit message | Last commit date |\n| --- | --- | --- | --- |\n| Latest commit ------------- dsp-ant add Konstantin to Kotlin maintainers success Jan 9, 2026 b438f60·Jan 9, 2026 History ------- 2,878 Commits Open commit details |\n| .github | .github | Add core-maintainers to /docs/ CODEOWNERS | Nov 4, 2025 |\n| blog | blog | Fix MCP spec links | Dec 20, 2025 |\n| docs | docs | Merge pull request#2063 from olaservo/olaservo-patch-2 | Jan 7, 2026 |\n| schema | schema | Add example for progress token usage | Dec 31, 2025 |\n| scripts | scripts | Add script to validate JSON examples against schema | Dec 30, 2025 |\n| seps | seps | Add blog post announcing SEP process migration to PRs (#1851) | Nov 28, 2025 |\n| .gitattributes | .gitattributes | Add schema reference page | Jul 14, 2025 |\n| .gitignore | .gitignore | add .idea/ to .gitignore (#1864) | Nov 21, 2025 |\n| .npmrc | .npmrc | Add .npmrc | Oct 31, 2024 |\n| .nvmrc | .nvmrc | Make examples on schema reference page collapsible | Dec 30, 2025 |\n| .prettierignore | .prettierignore | Add schema reference page | Jul 14, 2025 |\n| .prettierrc.json | .prettierrc.json | feat: add eslint and format typescript with prettier (#1782) | Nov 7, 2025 |\n| AGENTS.md | AGENTS.md | Document schema examples convention in `{AGENTS,CLAUDE}.md` | Dec 30, 2025 |\n| ANTITRUST.md | ANTITRUST.md | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| CLAUDE.md | CLAUDE.md | Add `{AGENTS,CLAUDE}.md` with documentation structure overview | Dec 15, 2025 |\n| CODE_OF_CONDUCT.md | CODE_OF_CONDUCT.md | chore: add markdown format check workflow and format all docs | Jan 20, 2025 |\n| CONTRIBUTING.md | CONTRIBUTING.md | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| GOVERNANCE.md | GOVERNANCE.md | Add general project policies to governance documentation | Dec 11, 2025 |\n| LICENSE | LICENSE | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| MAINTAINERS.md | MAINTAINERS.md | add Konstantin to Kotlin maintainers | Jan 9, 2026 |\n| README.md | README.md | docs: update version references to 2025-11-25 and use /specification/… | Dec 2, 2025 |\n| SECURITY.md | SECURITY.md | chore: add markdown format check workflow and format all docs | Jan 20, 2025 |\n| eslint.config.mjs | eslint.config.mjs | feat: add eslint and format typescript with prettier (#1782) | Nov 7, 2025 |\n| package-lock.json | package-lock.json | Make examples on schema reference page collapsible | Dec 30, 2025 |\n| package.json | package.json | chore: update licensing to Apache 2.0 for new contributions (#1994) | Jan 5, 2026 |\n| tsconfig.json | tsconfig.json | De-zoddify | Nov 14, 2025 |\n| typedoc.config.mjs | typedoc.config.mjs | Add `@example` tag support for schema page | Dec 30, 2025 |\n| typedoc.plugin.mjs | typedoc.plugin.mjs | Add `*ResultResponse` interfaces for typed JSON-RPC responses | Dec 31, 2025 |\n| View all files |\n\nRepository files navigation\n---------------------------\n\n*   README\n*   Code of conduct\n*   Contributing\n*   License\n*   Security\n\nModel Context Protocol (MCP)\n============================\n\n_Just heard of MCP and not sure where to start? Check out our documentation website._\n\nThis repo contains the:\n\n*   MCP specification\n*   MCP protocol schema\n*   Official MCP documentation\n\nThe schema is defined in TypeScript first, but made available as JSON Schema as well, for wider compatibility.\n\nThe official MCP documentation is built using Mintlify and available at modelcontextprotocol.io.\n\nAuthors\n-------\n\nThe Model Context Protocol was created by David Soria Parra (@dsp) and Justin Spahr-Summers (@jspahrsummers).\n\nContributing\n------------\n\nSee CONTRIBUTING.md.\n\nLicense\n-------\n\nThis project is licensed under the MIT License.\n\nAbout\n-----\n\nSpecification and documentation for the Model Context Protocol\n\nmodelcontextprotocol.io\n\n### Resources\n\nReadme\n\n### License\n\nView license\n\n### Code of conduct\n\nCode of conduct\n\n### Contributing\n\nContributing\n\n### Security policy\n\nSecurity policy\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\nActivity\n\nCustom properties\n\n### Stars\n\n**6.9k** stars\n\n### Watchers\n\n**160** watching\n\n### Forks\n\n**1.2k** forks\n\nReport repository\n\nReleases 7\n----------\n\n2025-11-25 Latest Nov 25, 2025\n\n+ 6 releases\n\n### Uh oh!\n\nThere was an error while loading. Please reload this page.\n\nContributors 322\n----------------\n\n+ 308 contributors\n\nLanguages\n---------\n\n*   TypeScript 92.3%\n*   JavaScript 3.4%\n*   MDX 2.2%\n*   HTML 2.0%\n*   CSS 0.1%\n\nFooter\n------\n\n © 2026 GitHub,Inc. \n\n### Footer navigation\n\n*   Terms\n*   Privacy\n*   Security\n*   Status\n*   Community\n*   Docs\n*   Contact\n*    Manage cookies \n*    Do not share my personal information \n\n You can’t perform that action at this time.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> MCPのGitHubリポジトリを確認しました。次に、MCPの具体的な仕様について、2025-03-26バージョンの仕様を確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://modelcontextprotocol.io/specification/2025-03-26","title":"Specification","content":"【3†Specification†https://modelcontextprotocol.io/specification/2025-03-26】\nTitle: Specification - Model Context Protocol\n\nURL Source: https://modelcontextprotocol.io/specification/2025-03-26\n\nMarkdown Content:\nModel Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you’re building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.This specification defines the authoritative protocol requirements, based on the TypeScript schema in schema.ts.For implementation guides and examples, visit modelcontextprotocol.io.The key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “NOT RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all capitals, as shown here.\n\nOverview\n--------\n\nMCP provides a standardized way for applications to:\n\n*   Share contextual information with language models\n*   Expose tools and capabilities to AI systems\n*   Build composable integrations and workflows\n\nThe protocol uses JSON-RPC 2.0 messages to establish communication between:\n\n*   **Hosts**: LLM applications that initiate connections\n*   **Clients**: Connectors within the host application\n*   **Servers**: Services that provide context and capabilities\n\nMCP takes some inspiration from the Language Server Protocol, which standardizes how to add support for programming languages across a whole ecosystem of development tools. In a similar way, MCP standardizes how to integrate additional context and tools into the ecosystem of AI applications.\n\nKey Details\n-----------\n\n### Base Protocol\n\n*   JSON-RPC message format\n*   Stateful connections\n*   Server and client capability negotiation\n\n### Features\n\nServers offer any of the following features to clients:\n\n*   **Resources**: Context and data, for the user or the AI model to use\n*   **Prompts**: Templated messages and workflows for users\n*   **Tools**: Functions for the AI model to execute\n\nClients may offer the following feature to servers:\n\n*   **Sampling**: Server-initiated agentic behaviors and recursive LLM interactions\n\n### Additional Utilities\n\n*   Configuration\n*   Progress tracking\n*   Cancellation\n*   Error reporting\n*   Logging\n\nSecurity and Trust & Safety\n---------------------------\n\nThe Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important security and trust considerations that all implementors must carefully address.\n\n### Key Principles\n\n1.   **User Consent and Control**\n    *   Users must explicitly consent to and understand all data access and operations\n    *   Users must retain control over what data is shared and what actions are taken\n    *   Implementors should provide clear UIs for reviewing and authorizing activities\n\n2.   **Data Privacy**\n    *   Hosts must obtain explicit user consent before exposing user data to servers\n    *   Hosts must not transmit resource data elsewhere without user consent\n    *   User data should be protected with appropriate access controls\n\n3.   **Tool Safety**\n    *   Tools represent arbitrary code execution and must be treated with appropriate caution. \n        *   In particular, descriptions of tool behavior such as annotations should be considered untrusted, unless obtained from a trusted server.\n\n    *   Hosts must obtain explicit user consent before invoking any tool\n    *   Users should understand what each tool does before authorizing its use\n\n4.   **LLM Sampling Controls**\n    *   Users must explicitly approve any LLM sampling requests\n    *   Users should control: \n        *   Whether sampling occurs at all\n        *   The actual prompt that will be sent\n        *   What results the server can see\n\n    *   The protocol intentionally limits server visibility into prompts\n\n### Implementation Guidelines\n\nWhile MCP itself cannot enforce these security principles at the protocol level, implementors **SHOULD**:\n\n1.   Build robust consent and authorization flows into their applications\n2.   Provide clear documentation of security implications\n3.   Implement appropriate access controls and data protections\n4.   Follow security best practices in their integrations\n5.   Consider privacy implications in their feature designs\n\nLearn More\n----------\n\nExplore the detailed specification for each protocol component:\n\n"},"metadata":{"arguments":"{\"link_id\":3}","display_result":"","duration":"4s","id":"call_NsVlIPNabW","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【3†Specification†https://modelcontextprotocol.io/specification/2025-03-26】\nTitle: Specification - Model Context Protocol\n\nURL Source: https://modelcontextprotocol.io/specification/2025-03-26\n\nMarkdown Content:\nModel Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools. Whether you’re building an AI-powered IDE, enhancing a chat interface, or creating custom AI workflows, MCP provides a standardized way to connect LLMs with the context they need.This specification defines the authoritative protocol requirements, based on the TypeScript schema in schema.ts.For implementation guides and examples, visit modelcontextprotocol.io.The key words “MUST”, “MUST NOT”, “REQUIRED”, “SHALL”, “SHALL NOT”, “SHOULD”, “SHOULD NOT”, “RECOMMENDED”, “NOT RECOMMENDED”, “MAY”, and “OPTIONAL” in this document are to be interpreted as described in BCP 14 [RFC2119] [RFC8174] when, and only when, they appear in all capitals, as shown here.\n\nOverview\n--------\n\nMCP provides a standardized way for applications to:\n\n*   Share contextual information with language models\n*   Expose tools and capabilities to AI systems\n*   Build composable integrations and workflows\n\nThe protocol uses JSON-RPC 2.0 messages to establish communication between:\n\n*   **Hosts**: LLM applications that initiate connections\n*   **Clients**: Connectors within the host application\n*   **Servers**: Services that provide context and capabilities\n\nMCP takes some inspiration from the Language Server Protocol, which standardizes how to add support for programming languages across a whole ecosystem of development tools. In a similar way, MCP standardizes how to integrate additional context and tools into the ecosystem of AI applications.\n\nKey Details\n-----------\n\n### Base Protocol\n\n*   JSON-RPC message format\n*   Stateful connections\n*   Server and client capability negotiation\n\n### Features\n\nServers offer any of the following features to clients:\n\n*   **Resources**: Context and data, for the user or the AI model to use\n*   **Prompts**: Templated messages and workflows for users\n*   **Tools**: Functions for the AI model to execute\n\nClients may offer the following feature to servers:\n\n*   **Sampling**: Server-initiated agentic behaviors and recursive LLM interactions\n\n### Additional Utilities\n\n*   Configuration\n*   Progress tracking\n*   Cancellation\n*   Error reporting\n*   Logging\n\nSecurity and Trust & Safety\n---------------------------\n\nThe Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important security and trust considerations that all implementors must carefully address.\n\n### Key Principles\n\n1.   **User Consent and Control**\n    *   Users must explicitly consent to and understand all data access and operations\n    *   Users must retain control over what data is shared and what actions are taken\n    *   Implementors should provide clear UIs for reviewing and authorizing activities\n\n2.   **Data Privacy**\n    *   Hosts must obtain explicit user consent before exposing user data to servers\n    *   Hosts must not transmit resource data elsewhere without user consent\n    *   User data should be protected with appropriate access controls\n\n3.   **Tool Safety**\n    *   Tools represent arbitrary code execution and must be treated with appropriate caution. \n        *   In particular, descriptions of tool behavior such as annotations should be considered untrusted, unless obtained from a trusted server.\n\n    *   Hosts must obtain explicit user consent before invoking any tool\n    *   Users should understand what each tool does before authorizing its use\n\n4.   **LLM Sampling Controls**\n    *   Users must explicitly approve any LLM sampling requests\n    *   Users should control: \n        *   Whether sampling occurs at all\n        *   The actual prompt that will be sent\n        *   What results the server can see\n\n    *   The protocol intentionally limits server visibility into prompts\n\n### Implementation Guidelines\n\nWhile MCP itself cannot enforce these security principles at the protocol level, implementors **SHOULD**:\n\n1.   Build robust consent and authorization flows into their applications\n2.   Provide clear documentation of security implications\n3.   Implement appropriate access controls and data protections\n4.   Follow security best practices in their integrations\n5.   Consider privacy implications in their feature designs\n\nLearn More\n----------\n\nExplore the detailed specification for each protocol component:\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> MCPの仕様を確認しました。次に、MCPの最新仕様（2025-11-25）を確認してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"}]},"metadata":{"arguments":"{\"query\":\"Model Context Protocol specification 2025-11-25\"}","display_result":"","duration":"2s","id":"call_LDudxrWG1s","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【10†Specification†https://modelcontextprotocol.io/specification/2025-11-25】\nThe Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...\n\n【11†Overview†https://modelcontextprotocol.io/specification/2025-11-25/basic】\nMCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...\n\n【12†Specification and documentation for the Model Context†https://github.com/modelcontextprotocol/modelcontextprotocol】\nSpecification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!\n\n【13†Key Changes†https://modelcontextprotocol.io/specification/2025-11-25/changelog】\nVersion 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...\n\n【14†What's New In The 2025-11-25 MCP Authorization Spec†https://den.dev/blog/mcp-november-authorization-spec】\nWe're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.\n\n【15†MCP 2025-11-25 is here: async Tasks, better OAuth,†https://workos.com/blog/mcp-2025-11-25-spec-update】\nYesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.\n\n【16†Update on the Next MCP Protocol Release†https://modelcontextprotocol.info/blog/mcp-next-version-update】\nThe next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...\n\n【17†What the New MCP Specification Means to You, and Your†https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents】\nThe new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...\n\n【18†One Year of MCP: November 2025 Spec Release†http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary】\n“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...\n\n【19†MCP Enterprise Readiness: How the 2025-11-25 Spec Closes†https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap】\nJust over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="search">
> MCPの最新仕様（2025-11-25）についての情報が見つかりました。次に、具体的な変更点を確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","title":"Key Changes","content":"【13†Key Changes†https://modelcontextprotocol.io/specification/2025-11-25/changelog】\nTitle: Key Changes - Model Context Protocol\n\nURL Source: https://modelcontextprotocol.io/specification/2025-11-25/changelog\n\nMarkdown Content:\nThis document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, 2025-06-18.\n\nMajor changes\n-------------\n\n1.   Enhance authorization server discovery with support for OpenID Connect Discovery 1.0. (PR #797)\n2.   Allow servers to expose icons as additional metadata for tools, resources, resource templates, and prompts (SEP-973).\n3.   Enhance authorization flows with incremental scope consent via `WWW-Authenticate` (SEP-835)\n4.   Provide guidance on tool names (SEP-986)\n5.   Update `ElicitResult` and `EnumSchema` to use a more standards-based approach and support titled, untitled, single-select, and multi-select enums (SEP-1330).\n6.   Added support for URL mode elicitation (SEP-1036)\n7.   Add tool calling support to sampling via `tools` and `toolChoice` parameters (SEP-1577)\n8.   Add support for OAuth Client ID Metadata Documents as a recommended client registration mechanism (SEP-991, PR #1296)\n9.   Add experimental support for tasks to enable tracking durable requests with polling and deferred result retrieval (SEP-1686).\n\nMinor changes\n-------------\n\n1.   Clarify that servers using stdio transport may use stderr for all types of logging, not just error messages (PR #670).\n2.   Add optional `description` field to `Implementation` interface to align with MCP registry server.json format and provide human-readable context during initialization.\n3.   Clarify that servers must respond with HTTP 403 Forbidden for invalid Origin headers in Streamable HTTP transport. (PR #1439)\n4.   Updated the Security Best Practices guidance.\n5.   Clarify that input validation errors should be returned as Tool Execution Errors rather than Protocol Errors to enable model self-correction (SEP-1303).\n6.   Support polling SSE streams by allowing servers to disconnect at will (SEP-1699).\n7.   Clarify SEP-1699: GET streams support polling, resumption always via GET regardless of stream origin, event IDs should encode stream identity, disconnection includes server-initiated closure (Issue #1847).\n8.   Align OAuth 2.0 Protected Resource Metadata discovery with RFC 9728, making `WWW-Authenticate` header optional with fallback to `.well-known` endpoint (SEP-985).\n9.   Add support for default values in all primitive types (string, number, enum) for elicitation schemas (SEP-1034).\n10.   Establish JSON Schema 2020-12 as the default dialect for MCP schema definitions (SEP-1613).\n\nOther schema changes\n--------------------\n\n1.   Decouple request payloads from RPC method definitions into standalone parameter schemas. (SEP-1319, PR #1284)\n\nGovernance and process updates\n------------------------------\n\n1.   Formalize Model Context Protocol governance structure (SEP-932).\n2.   Establish shared communication practices and guidelines for the MCP community (SEP-994).\n3.   Formalize Working Groups and Interest Groups in MCP governance (SEP-1302).\n4.   Establish SDK tiering system with clear requirements for feature support and maintenance commitments (SEP-1730).\n\nFull changelog\n--------------\n\nFor a complete list of all changes that have been made since the last protocol revision, see GitHub.\n\n"},"metadata":{"arguments":"{\"link_id\":13}","display_result":"","duration":"4s","id":"call_wMWOFY62A8","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【13†Key Changes†https://modelcontextprotocol.io/specification/2025-11-25/changelog】\nTitle: Key Changes - Model Context Protocol\n\nURL Source: https://modelcontextprotocol.io/specification/2025-11-25/changelog\n\nMarkdown Content:\nThis document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, 2025-06-18.\n\nMajor changes\n-------------\n\n1.   Enhance authorization server discovery with support for OpenID Connect Discovery 1.0. (PR #797)\n2.   Allow servers to expose icons as additional metadata for tools, resources, resource templates, and prompts (SEP-973).\n3.   Enhance authorization flows with incremental scope consent via `WWW-Authenticate` (SEP-835)\n4.   Provide guidance on tool names (SEP-986)\n5.   Update `ElicitResult` and `EnumSchema` to use a more standards-based approach and support titled, untitled, single-select, and multi-select enums (SEP-1330).\n6.   Added support for URL mode elicitation (SEP-1036)\n7.   Add tool calling support to sampling via `tools` and `toolChoice` parameters (SEP-1577)\n8.   Add support for OAuth Client ID Metadata Documents as a recommended client registration mechanism (SEP-991, PR #1296)\n9.   Add experimental support for tasks to enable tracking durable requests with polling and deferred result retrieval (SEP-1686).\n\nMinor changes\n-------------\n\n1.   Clarify that servers using stdio transport may use stderr for all types of logging, not just error messages (PR #670).\n2.   Add optional `description` field to `Implementation` interface to align with MCP registry server.json format and provide human-readable context during initialization.\n3.   Clarify that servers must respond with HTTP 403 Forbidden for invalid Origin headers in Streamable HTTP transport. (PR #1439)\n4.   Updated the Security Best Practices guidance.\n5.   Clarify that input validation errors should be returned as Tool Execution Errors rather than Protocol Errors to enable model self-correction (SEP-1303).\n6.   Support polling SSE streams by allowing servers to disconnect at will (SEP-1699).\n7.   Clarify SEP-1699: GET streams support polling, resumption always via GET regardless of stream origin, event IDs should encode stream identity, disconnection includes server-initiated closure (Issue #1847).\n8.   Align OAuth 2.0 Protected Resource Metadata discovery with RFC 9728, making `WWW-Authenticate` header optional with fallback to `.well-known` endpoint (SEP-985).\n9.   Add support for default values in all primitive types (string, number, enum) for elicitation schemas (SEP-1034).\n10.   Establish JSON Schema 2020-12 as the default dialect for MCP schema definitions (SEP-1613).\n\nOther schema changes\n--------------------\n\n1.   Decouple request payloads from RPC method definitions into standalone parameter schemas. (SEP-1319, PR #1284)\n\nGovernance and process updates\n------------------------------\n\n1.   Formalize Model Context Protocol governance structure (SEP-932).\n2.   Establish shared communication practices and guidelines for the MCP community (SEP-994).\n3.   Formalize Working Groups and Interest Groups in MCP governance (SEP-1302).\n4.   Establish SDK tiering system with clear requirements for feature support and maintenance commitments (SEP-1730).\n\nFull changelog\n--------------\n\nFor a complete list of all changes that have been made since the last protocol revision, see GitHub.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="click">
> MCPの最新仕様の変更点を確認しました。次に、ZAIについての情報を収集してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"}]},"metadata":{"arguments":"{\"query\":\"Z.ai AI assistant 2026 official documentation\"}","display_result":"","duration":"3s","id":"call_0k2yVxWFTY","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【20†Quick Start - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/guides/overview/quick-start】\nAfter preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...\n\n【21†Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/guides/overview/overview】\nZ.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.\n\n【22†Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6†https://z.ai】\nChat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.\n\n【23†Introduction - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/api-reference/introduction】\nZ.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.\n\n【24†Official Python SDK - Overview†https://docs.z.ai/guides/develop/python/introduction】\nZ.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.\n\n【25†Z.ai - Inspiring AGI to Benefit Humanity†https://z.ai/model-api】\nAt Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...\n\n【26†Z.ai (@Zai_org) / Posts / X†https://x.com/Zai_org】\nIn 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...\n\n【27†zai-org/z-ai-sdk-python†https://github.com/zai-org/z-ai-sdk-python】\nThe official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.\n\n【28†New Released - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/release-notes/new-released】\nWe've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.\n\n【29†My LLM coding workflow going into 2026†https://addyosmani.com/blog/ai-coding-workflow】\nCustomize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> Z.aiの公式ドキュメントを確認しました。次に、具体的なAPIリファレンスを確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://docs.z.ai/api-reference/introduction","title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","content":"【23†Introduction - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/api-reference/introduction】\nTitle: Introduction - Overview - Z.AI DEVELOPER DOCUMENT\n\nURL Source: https://docs.z.ai/api-reference/introduction\n\nMarkdown Content:\nZ.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available.\n\nAPI Endpoint\n------------\n\nZ.ai Platform’s general API endpoint is as follows:\n\n```\nhttps://api.z.ai/api/paas/v4\n```\n\nAuthentication\n--------------\n\nThe Z.AI API uses the standard **HTTP Bearer** for authentication. An API key is required, which you can create or manage on the API Keys Page.API keys should be provided via HTTP Bearer Authentication in HTTP Request Headers.\n\n```\nAuthorization: Bearer ZAI_API_KEY\n```\n\nPlayground\n----------\n\nThe API Playground allows developers to quickly try out API calls. Simply click **Try it** on the API details page to get started.\n\n*   On the API details page, there are many interactive options, such as **switching input types**, **switching tabs**, and **adding new content**.\n*   You can click **Add an item** or **Add new property** to add more properties the API need.\n*   **Note** that when switching the tabs, the previous properties value you need re-input or re-switch.\n\nCall Examples\n-------------\n\n*   cURL\n\n*   Official Python SDK\n\n*   Official Java SDK\n\n*   OpenAI Python SDK\n\n*   OpenAI NodeJs SDK\n\n*   OpenAI Java SDK\n\n```\ncurl -X POST \"https://api.z.ai/api/paas/v4/chat/completions\" \\\n-H \"Content-Type: application/json\" \\\n-H \"Accept-Language: en-US,en\" \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-d '{\n    \"model\": \"glm-4.7\",\n    \"messages\": [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful AI assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello, please introduce yourself.\"\n        }\n    ],\n    \"temperature\": 1.0,\n    \"stream\": true\n}'\n```\n\n**Install SDK**\n\n```\n# Install latest version\npip install zai-sdk\n\n# Or specify version\npip install zai-sdk==0.1.0\n```\n\n**Verify Installation**\n\n```\nimport zai\nprint(zai.__version__)\n```\n\n**Usage Example**\n\n```\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"YOUR_API_KEY\")\n\n# Create chat completion request\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful AI assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello, please introduce yourself.\"\n        }\n    ]\n)\n\n# Get response\nprint(response.choices[0].message.content)\n```\n\n**Install SDK****Maven**\n\n```\n<dependency>\n    <groupId>ai.z.openapi</groupId>\n    <artifactId>zai-sdk</artifactId>\n    <version>0.3.0</version>\n</dependency>\n```\n\n**Gradle (Groovy)**\n\n```\nimplementation 'ai.z.openapi:zai-sdk:0.3.0'\n```\n\n**Usage Example**\n\n```\nimport ai.z.openapi.ZaiClient;\nimport ai.z.openapi.service.model.*;\nimport java.util.Arrays;\n\npublic class QuickStart {\n    public static void main(String[] args) {\n        // Initialize client\n        ZaiClient client = ZaiClient.builder().ofZAI()\n            .apiKey(\"YOUR_API_KEY\")\n            .build();\n\n        // Create chat completion request\n        ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()\n            .model(\"glm-4.7\")\n            .messages(Arrays.asList(\n                ChatMessage.builder()\n                    .role(ChatMessageRole.USER.value())\n                    .content(\"Hello, who are you?\")\n                    .build()\n            ))\n            .stream(false)\n            .build();\n\n        // Send request\n        ChatCompletionResponse response = client.chat().createChatCompletion(request);\n\n        // Get response\n        System.out.println(response.getData().getChoices().get(0).getMessage().getContent());\n    }\n}\n```\n\n**Install SDK**\n\n```\n# Install or upgrade to latest version\npip install --upgrade 'openai>=1.0'\n```\n\n**Verify Installation**\n\n```\npython -c \"import openai; print(openai.__version__)\"\n```\n\n**Usage Example**\n\n```\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"your-Z.AI-api-key\",\n    base_url=\"https://api.z.ai/api/paas/v4/\"\n)\n\ncompletion = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a smart and creative novelist\"},\n        {\"role\": \"user\", \"content\": \"Please write a short fairy tale story as a fairy tale master\"}\n    ]\n)\n\nprint(completion.choices[0].message.content)\n```\n\n**Install SDK**\n\n```\n# Install or upgrade to latest version\nnpm install openai\n\n# Or using yarn\nyarn add openai\n```\n\n**Usage Example**\n\n```\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n    apiKey: \"your-Z.AI-api-key\",\n    baseURL: \"https://api.z.ai/api/paas/v4/\"\n});\n\nasync function main() {\n    const completion = await client.chat.completions.create({\n        model: \"glm-4.7\",\n        messages: [\n            { role: \"system\", content: \"You are a helpful AI assistant.\" },\n            { role: \"user\", content: \"Hello, please introduce yourself.\" }\n        ]\n    });\n\n    console.log(completion.choices[0].message.content);\n}\n\nmain();\n```\n\n**Install SDK****Maven**\n\n```\n<dependency>\n    <groupId>com.openai</groupId>\n    <artifactId>openai-java</artifactId>\n    <version>2.20.1</version>\n</dependency>\n```\n\n**Gradle (Groovy)**\n\n```\nimplementation 'com.openai:openai-java:2.20.1'\n```\n\n**Usage Example**\n\n```\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\npublic class QuickStart {\n    public static void main(String[] args) {\n        // Initialize client\n        OpenAIClient client = OpenAIOkHttpClient.builder()\n            .apiKey(\"your-Z.AI-api-key\")\n            .baseUrl(\"https://api.z.ai/api/paas/v4/\")\n            .build();\n\n        // Create chat completion request\n        ChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n            .addSystemMessage(\"You are a helpful AI assistant.\")\n            .addUserMessage(\"Hello, please introduce yourself.\")\n            .model(\"glm-4.7\")\n            .build();\n\n        // Send request and get response\n        ChatCompletion chatCompletion = client.chat().completions().create(params);\n        Object response = chatCompletion.choices().get(0).message().content();\n\n        System.out.println(response);\n    }\n}\n```\n\n"},"metadata":{"arguments":"{\"link_id\":23}","display_result":"","duration":"2s","id":"call_X0IckJsZ5n","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【23†Introduction - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/api-reference/introduction】\nTitle: Introduction - Overview - Z.AI DEVELOPER DOCUMENT\n\nURL Source: https://docs.z.ai/api-reference/introduction\n\nMarkdown Content:\nZ.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available.\n\nAPI Endpoint\n------------\n\nZ.ai Platform’s general API endpoint is as follows:\n\n```\nhttps://api.z.ai/api/paas/v4\n```\n\nAuthentication\n--------------\n\nThe Z.AI API uses the standard **HTTP Bearer** for authentication. An API key is required, which you can create or manage on the API Keys Page.API keys should be provided via HTTP Bearer Authentication in HTTP Request Headers.\n\n```\nAuthorization: Bearer ZAI_API_KEY\n```\n\nPlayground\n----------\n\nThe API Playground allows developers to quickly try out API calls. Simply click **Try it** on the API details page to get started.\n\n*   On the API details page, there are many interactive options, such as **switching input types**, **switching tabs**, and **adding new content**.\n*   You can click **Add an item** or **Add new property** to add more properties the API need.\n*   **Note** that when switching the tabs, the previous properties value you need re-input or re-switch.\n\nCall Examples\n-------------\n\n*   cURL\n\n*   Official Python SDK\n\n*   Official Java SDK\n\n*   OpenAI Python SDK\n\n*   OpenAI NodeJs SDK\n\n*   OpenAI Java SDK\n\n```\ncurl -X POST \"https://api.z.ai/api/paas/v4/chat/completions\" \\\n-H \"Content-Type: application/json\" \\\n-H \"Accept-Language: en-US,en\" \\\n-H \"Authorization: Bearer YOUR_API_KEY\" \\\n-d '{\n    \"model\": \"glm-4.7\",\n    \"messages\": [\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful AI assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello, please introduce yourself.\"\n        }\n    ],\n    \"temperature\": 1.0,\n    \"stream\": true\n}'\n```\n\n**Install SDK**\n\n```\n# Install latest version\npip install zai-sdk\n\n# Or specify version\npip install zai-sdk==0.1.0\n```\n\n**Verify Installation**\n\n```\nimport zai\nprint(zai.__version__)\n```\n\n**Usage Example**\n\n```\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"YOUR_API_KEY\")\n\n# Create chat completion request\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\n            \"role\": \"system\",\n            \"content\": \"You are a helpful AI assistant.\"\n        },\n        {\n            \"role\": \"user\",\n            \"content\": \"Hello, please introduce yourself.\"\n        }\n    ]\n)\n\n# Get response\nprint(response.choices[0].message.content)\n```\n\n**Install SDK****Maven**\n\n```\n<dependency>\n    <groupId>ai.z.openapi</groupId>\n    <artifactId>zai-sdk</artifactId>\n    <version>0.3.0</version>\n</dependency>\n```\n\n**Gradle (Groovy)**\n\n```\nimplementation 'ai.z.openapi:zai-sdk:0.3.0'\n```\n\n**Usage Example**\n\n```\nimport ai.z.openapi.ZaiClient;\nimport ai.z.openapi.service.model.*;\nimport java.util.Arrays;\n\npublic class QuickStart {\n    public static void main(String[] args) {\n        // Initialize client\n        ZaiClient client = ZaiClient.builder().ofZAI()\n            .apiKey(\"YOUR_API_KEY\")\n            .build();\n\n        // Create chat completion request\n        ChatCompletionCreateParams request = ChatCompletionCreateParams.builder()\n            .model(\"glm-4.7\")\n            .messages(Arrays.asList(\n                ChatMessage.builder()\n                    .role(ChatMessageRole.USER.value())\n                    .content(\"Hello, who are you?\")\n                    .build()\n            ))\n            .stream(false)\n            .build();\n\n        // Send request\n        ChatCompletionResponse response = client.chat().createChatCompletion(request);\n\n        // Get response\n        System.out.println(response.getData().getChoices().get(0).getMessage().getContent());\n    }\n}\n```\n\n**Install SDK**\n\n```\n# Install or upgrade to latest version\npip install --upgrade 'openai>=1.0'\n```\n\n**Verify Installation**\n\n```\npython -c \"import openai; print(openai.__version__)\"\n```\n\n**Usage Example**\n\n```\nfrom openai import OpenAI\n\nclient = OpenAI(\n    api_key=\"your-Z.AI-api-key\",\n    base_url=\"https://api.z.ai/api/paas/v4/\"\n)\n\ncompletion = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\"role\": \"system\", \"content\": \"You are a smart and creative novelist\"},\n        {\"role\": \"user\", \"content\": \"Please write a short fairy tale story as a fairy tale master\"}\n    ]\n)\n\nprint(completion.choices[0].message.content)\n```\n\n**Install SDK**\n\n```\n# Install or upgrade to latest version\nnpm install openai\n\n# Or using yarn\nyarn add openai\n```\n\n**Usage Example**\n\n```\nimport OpenAI from \"openai\";\n\nconst client = new OpenAI({\n    apiKey: \"your-Z.AI-api-key\",\n    baseURL: \"https://api.z.ai/api/paas/v4/\"\n});\n\nasync function main() {\n    const completion = await client.chat.completions.create({\n        model: \"glm-4.7\",\n        messages: [\n            { role: \"system\", content: \"You are a helpful AI assistant.\" },\n            { role: \"user\", content: \"Hello, please introduce yourself.\" }\n        ]\n    });\n\n    console.log(completion.choices[0].message.content);\n}\n\nmain();\n```\n\n**Install SDK****Maven**\n\n```\n<dependency>\n    <groupId>com.openai</groupId>\n    <artifactId>openai-java</artifactId>\n    <version>2.20.1</version>\n</dependency>\n```\n\n**Gradle (Groovy)**\n\n```\nimplementation 'com.openai:openai-java:2.20.1'\n```\n\n**Usage Example**\n\n```\nimport com.openai.client.OpenAIClient;\nimport com.openai.client.okhttp.OpenAIOkHttpClient;\nimport com.openai.models.chat.completions.ChatCompletion;\nimport com.openai.models.chat.completions.ChatCompletionCreateParams;\n\npublic class QuickStart {\n    public static void main(String[] args) {\n        // Initialize client\n        OpenAIClient client = OpenAIOkHttpClient.builder()\n            .apiKey(\"your-Z.AI-api-key\")\n            .baseUrl(\"https://api.z.ai/api/paas/v4/\")\n            .build();\n\n        // Create chat completion request\n        ChatCompletionCreateParams params = ChatCompletionCreateParams.builder()\n            .addSystemMessage(\"You are a helpful AI assistant.\")\n            .addUserMessage(\"Hello, please introduce yourself.\")\n            .model(\"glm-4.7\")\n            .build();\n\n        // Send request and get response\n        ChatCompletion chatCompletion = client.chat().completions().create(params);\n        Object response = chatCompletion.choices().get(0).message().content();\n\n        System.out.println(response);\n    }\n}\n```\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="click">
> Z.aiのAPIリファレンスを確認しました。次に、Z.aiのモデル情報を確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://docs.z.ai/guides/overview/overview","title":"Overview - Z.AI DEVELOPER DOCUMENT","content":"【21†Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/guides/overview/overview】\nTitle: Overview - Overview - Z.AI DEVELOPER DOCUMENT\n\nURL Source: https://docs.z.ai/guides/overview/overview\n\nMarkdown Content:\nFeatured Models\n---------------\n\nModels, Agents and Tools\n------------------------\n\nTo help you find the best fit for your use case, we’ve created a table outlining the core features and strengths of each model in the Z.AI family.\n\n### Text Models\n\nOur model matrix includes text models with built-in reasoning capabilities, as well as vision-language models (VLMs) that extend the same reasoning power to multimodal understanding.\n\n| Model | Strength | Language | Context | Resourse |\n| --- | --- | --- | --- | --- |\n| GLM-4.7 | SOTA Performance Enhanced General Capabilities Optimized Agentic Coding | English & Chinese | 200K | Guide API Reference |\n| GLM-4.6 | High Performance Strong Coding More Versatile | English & Chinese | 200K | Guide API Reference |\n| GLM-4.6V(vlm) | Native Function Call Support Thinking Mode Switch Support | English & Chinese | 128K | Guide API Reference |\n| GLM-4.6V-FlashX(vlm) | Native Function Call Support Thinking Mode Switch Support Lightweight & High-Speed | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5 | Better Performance Strong Reasoning More Versatile | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5V(vlm) | Multimodal Flexible Reasoning | English & Chinese | 64K | Guide API Reference |\n| GLM-4.5-X | Good Performance Strong Reasoning Ultra-Fast Response | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5-Air | Cost-Effective Lightweight High Performance | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5-AirX | Lightweight High Performance Ultra-Fast Response | English & Chinese | 128K | Guide API Reference |\n| GLM-4-32B-0414-128K | High intelligence at unmatched cost-efficiency | English & Chinese | 128K | Guide API Reference |\n| GLM-4.6V-Flash | Native Function Call Support | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5-Flash | Lightweight High Performance | English & Chinese | 128K | Guide API Reference |\n\n### Built-in Tools\n\nA suite of built-in tools designed to streamline workflows and boost productivity.\n\n| Tool | Capability |\n| --- | --- |\n| Web Search | - Provide real-time, concise, direct answers - Accurately parse complex HTML and converts it into clean Markdown or JSON |\n\n### Image Generation Models\n\nImage Generation Models learn from massive image data to automatically generate high-quality images from text.\n\n| Model | Strength | Language | Resolution | Resourse |\n| --- | --- | --- | --- | --- |\n| CogView-4 | - High-quality image generation - Diverse styles - Rich in detail | English & Chinese | multiple resolutions | Guide API Reference |\n\n### Video Generation Models\n\nVideo Generation Models turn text, images, or clips into dynamic video content, accelerating creativity for film, virtual avatars, animation, and marketing.\n\n| Model | Strength | Language | Resolution | Resourse |\n| --- | --- | --- | --- | --- |\n| CogVideoX-3 | Significant improvements in image quality, stability, and physical realism simulation | English & Chinese | multiple resolutions | Guide API Reference |\n| ViduQ1 | Theatrical quality with seamless temporal flow | English & Chinese | 1080P | Guide API Reference |\n| Vidu2 | Fast delivery with smart style preservation | English & Chinese | 720P | Guide API Reference |\n\n### Audio Models\n\nAudio models are a class of multimodal models that process audio and video signals, enabling the understanding, generation, or editing of audiovisual content.\n\n| Model | Strength | Multimodal Support | Resourse |\n| --- | --- | --- | --- |\n| GLM-ASR-2512 | - CER as low as 0.0717 - Support user-defined vocabularies - Support multiple mainstream languages and dialects | Audio | Guide API Reference |\n\n### Agents\n\nA set of ready-made agents empower users to create and communicate effortlessly.\n\n| Tool | Capability | Resource |\n| --- | --- | --- |\n| GLM Slide/Poster Agent(beta) | Combine content generation with professional design | Guide |\n| General-Purpose Translation | Support 40+ languages, flexible strategies, and terminology customization | Guide |\n| Popular Special Effects Video Templates | Special effects video templates like French_Kiss, BodyShake, and Sexy_Me | Guide |\n\n"},"metadata":{"arguments":"{\"link_id\":21}","display_result":"","duration":"1s","id":"call_MXrxrWLfMa","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【21†Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/guides/overview/overview】\nTitle: Overview - Overview - Z.AI DEVELOPER DOCUMENT\n\nURL Source: https://docs.z.ai/guides/overview/overview\n\nMarkdown Content:\nFeatured Models\n---------------\n\nModels, Agents and Tools\n------------------------\n\nTo help you find the best fit for your use case, we’ve created a table outlining the core features and strengths of each model in the Z.AI family.\n\n### Text Models\n\nOur model matrix includes text models with built-in reasoning capabilities, as well as vision-language models (VLMs) that extend the same reasoning power to multimodal understanding.\n\n| Model | Strength | Language | Context | Resourse |\n| --- | --- | --- | --- | --- |\n| GLM-4.7 | SOTA Performance Enhanced General Capabilities Optimized Agentic Coding | English & Chinese | 200K | Guide API Reference |\n| GLM-4.6 | High Performance Strong Coding More Versatile | English & Chinese | 200K | Guide API Reference |\n| GLM-4.6V(vlm) | Native Function Call Support Thinking Mode Switch Support | English & Chinese | 128K | Guide API Reference |\n| GLM-4.6V-FlashX(vlm) | Native Function Call Support Thinking Mode Switch Support Lightweight & High-Speed | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5 | Better Performance Strong Reasoning More Versatile | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5V(vlm) | Multimodal Flexible Reasoning | English & Chinese | 64K | Guide API Reference |\n| GLM-4.5-X | Good Performance Strong Reasoning Ultra-Fast Response | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5-Air | Cost-Effective Lightweight High Performance | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5-AirX | Lightweight High Performance Ultra-Fast Response | English & Chinese | 128K | Guide API Reference |\n| GLM-4-32B-0414-128K | High intelligence at unmatched cost-efficiency | English & Chinese | 128K | Guide API Reference |\n| GLM-4.6V-Flash | Native Function Call Support | English & Chinese | 128K | Guide API Reference |\n| GLM-4.5-Flash | Lightweight High Performance | English & Chinese | 128K | Guide API Reference |\n\n### Built-in Tools\n\nA suite of built-in tools designed to streamline workflows and boost productivity.\n\n| Tool | Capability |\n| --- | --- |\n| Web Search | - Provide real-time, concise, direct answers - Accurately parse complex HTML and converts it into clean Markdown or JSON |\n\n### Image Generation Models\n\nImage Generation Models learn from massive image data to automatically generate high-quality images from text.\n\n| Model | Strength | Language | Resolution | Resourse |\n| --- | --- | --- | --- | --- |\n| CogView-4 | - High-quality image generation - Diverse styles - Rich in detail | English & Chinese | multiple resolutions | Guide API Reference |\n\n### Video Generation Models\n\nVideo Generation Models turn text, images, or clips into dynamic video content, accelerating creativity for film, virtual avatars, animation, and marketing.\n\n| Model | Strength | Language | Resolution | Resourse |\n| --- | --- | --- | --- | --- |\n| CogVideoX-3 | Significant improvements in image quality, stability, and physical realism simulation | English & Chinese | multiple resolutions | Guide API Reference |\n| ViduQ1 | Theatrical quality with seamless temporal flow | English & Chinese | 1080P | Guide API Reference |\n| Vidu2 | Fast delivery with smart style preservation | English & Chinese | 720P | Guide API Reference |\n\n### Audio Models\n\nAudio models are a class of multimodal models that process audio and video signals, enabling the understanding, generation, or editing of audiovisual content.\n\n| Model | Strength | Multimodal Support | Resourse |\n| --- | --- | --- | --- |\n| GLM-ASR-2512 | - CER as low as 0.0717 - Support user-defined vocabularies - Support multiple mainstream languages and dialects | Audio | Guide API Reference |\n\n### Agents\n\nA set of ready-made agents empower users to create and communicate effortlessly.\n\n| Tool | Capability | Resource |\n| --- | --- | --- |\n| GLM Slide/Poster Agent(beta) | Combine content generation with professional design | Guide |\n| General-Purpose Translation | Support 40+ languages, flexible strategies, and terminology customization | Guide |\n| Popular Special Effects Video Templates | Special effects video templates like French_Kiss, BodyShake, and Sexy_Me | Guide |\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> Z.aiのモデル情報を確認しました。次に、RAG（Retrieval-Augmented Generation）についての最新情報を収集してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"},{"title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","text":"Sources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.","index":31,"favicon":"","host_name":"www.techment.com"},{"title":"Retrieval-augmented generation (RAG) for business","url":"https://www.meilisearch.com/blog/rag-for-business","text":"Best practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...","index":32,"favicon":"","host_name":"www.meilisearch.com"},{"title":"What Is RAG (Retrieval-Augmented Generation)? A Full","url":"https://www.snowflake.com/en/fundamentals/rag","text":"RAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.","index":33,"favicon":"","host_name":"www.snowflake.com"},{"title":"How Retrieval-Augmented Generation Powers Enterprise AI","url":"https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag","text":"Discover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...","index":34,"favicon":"","host_name":"www.grazitti.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"RAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...","index":35,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Title: RAG (Retrieval-Augmented Generation) Best Practices","url":"https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m","text":"Great overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...","index":36,"favicon":"","host_name":"www.linkedin.com"},{"title":"Documentation best practices for RAG applications","url":"https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html","text":"Learn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.","index":37,"favicon":"","host_name":"docs.aws.amazon.com"},{"title":"Retrieval best practices : r/Rag","url":"https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices","text":"My impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...","index":38,"favicon":"","host_name":"www.reddit.com"},{"title":"How Retrieval-Augmented Generation (RAG) Builds","url":"https://qat.com/rag-for-business-leaders","text":"Get proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.","index":39,"favicon":"","host_name":"qat.com"},{"title":"Enterprise-Grade AI: A Visual Deep-Dive into Advanced","url":"https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a","text":"Retrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.","index":40,"favicon":"","host_name":"itsjb13.medium.com"}]},"metadata":{"arguments":"{\"query\":\"RAG Retrieval-Augmented Generation 2026 best practices enterprise\"}","display_result":"","duration":"2s","id":"call_JzrRiBUbVT","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【30†RAG Models in 2026: Strategic Guide for Smarter, Accurate†https://www.techment.com/blogs/rag-models-2026-enterprise-ai】\nSources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.\n\n【31†Retrieval-augmented generation (RAG) for business†https://www.meilisearch.com/blog/rag-for-business】\nBest practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...\n\n【32†What Is RAG (Retrieval-Augmented Generation)? A Full†https://www.snowflake.com/en/fundamentals/rag】\nRAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.\n\n【33†How Retrieval-Augmented Generation Powers Enterprise AI†https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag】\nDiscover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...\n\n【34†Best RAG Tools, Frameworks, and Libraries in 2026†https://research.aimultiple.com/retrieval-augmented-generation】\nRAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...\n\n【35†Title: RAG (Retrieval-Augmented Generation) Best Practices†https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m】\nGreat overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...\n\n【36†Documentation best practices for RAG applications†https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html】\nLearn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.\n\n【37†Retrieval best practices : r/Rag†https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices】\nMy impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...\n\n【38†How Retrieval-Augmented Generation (RAG) Builds†https://qat.com/rag-for-business-leaders】\nGet proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.\n\n【39†Enterprise-Grade AI: A Visual Deep-Dive into Advanced†https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a】\nRetrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="search">
> RAGに関する最新情報を収集しました。次に、具体的なベストプラクティスを確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","content":"【30†RAG Models in 2026: Strategic Guide for Smarter, Accurate†https://www.techment.com/blogs/rag-models-2026-enterprise-ai】\nTitle: RAG Models in 2026: Strategic Guide for Smarter, Accurate Enterprise AI\n\nURL Source: https://www.techment.com/blogs/rag-models-2026-enterprise-ai\n\nPublished Time: 2026-01-08T06:07:17+00:00\n\nMarkdown Content:\nIntroduction\n------------\n\nBy 2026, enterprise AI leaders — CTOs, data architects, and data executives — face mounting pressure to deliver AI systems that are not only powerful but deeply trustworthy. As LLM adoption accelerates, so does a fundamental limitation: most models operate on static training data, frozen in time. They cannot naturally access the latest regulatory updates, proprietary internal documents, or fast-changing enterprise knowledge bases.\n\nThis has created widespread concern around hallucinations, outdated outputs, and inability to cite authoritative sources — all of which increase risk, reduce trust, and limit enterprise deployment.\n\nThis is where RAG models(Retrieval-Augmented Generation models) become essential.\n\nInstead of relying solely on what an LLM “remembers,” a RAG system retrieves the most relevant, up-to-date documents from trusted data sources — such as enterprise knowledge repositories, vector databases, and regulatory archives — and then uses them to**augment the context**provided to the generative model. The result:**accurate, contextual, and explainable AI outputs**.\n\nLet’s begin.\n\nStrengthen your AI data foundation with our guide on Data Management for Enterprises: Roadmap.\n\nTL;DR(Summary Box)\n------------------\n\n*   RAG models combine retrieval systems with generative AI to deliver accurate, up-to-date, and source-grounded answers.\n\n*   In 2026, enterprises increasingly adopt RAG to improve factual reliability,leverage proprietary data, and reduce hallucinations.\n\n*   RAG is more scalable and cost-efficient than frequent fine-tuning — especially when knowledge changes regularly.\n\n*   This guide delivers a clear, practical, and strategic understanding of RAG architecture, benefits, risks, and enterprise adoption best practices.\n\n*   Techment provides end-to-end RAG consulting, implementation, and optimization for data-heavy organizations.\n\nWhat Are RAG Models?\n--------------------\n\nRetrieval-Augmented Generation (RAG)is an AI architecture that enhances large language models by pairing them with an external retrieval system. Instead of generating answers solely from internal parameters, the model actively retrieves relevant supporting documents — such as PDFs, enterprise knowledge bases, or structured data — and uses them to produce grounded,accurate responses.\n\n**Simple Definition**\n\nA RAG model =Retriever + Generator\n\n*   The retriever searches a document database or vector store for the most relevant information.\n\n*   The generator(an LLM) uses that retrieved context to craft an accurate answer.\n\nThis enables RAG systems to overcome the limitations of traditional LLMs trained on static datasets.RAG ensures that model outputs stay grounded in real, verifiable information while reducing hallucination rates.\n\n### Why RAG Matters for Enterprises\n\nTraditional LLMs:\n\n*   Cannot access real-time or proprietary data\n\n*   Tend to hallucinate facts, especially in niche domains\n\n*   Are expensive to retrain whenever data changes\n\nRAG-powered systems address these issues by:\n\n*   Using dynamic retrieval, so knowledge can be updated instantly\n\n*   Enabling domain-specific reasoning from internal data\n\n*   Reducing hallucinations with factual grounding\n\n*   Avoiding costly retraining cycles\n\nSources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.\n\n### Strategic Insight for Data Leaders\n\nRAG is not just an AI technique — it is a systems architecture choice that reshapes how enterprises operationalize knowledge. For CTOs and data architects, the shift from model-centric to data-centric AI is one of the defining transformations of the decade.\n\nRead more on why enterprises must adopt a 2025 AI Data Quality Framework spanning acquisition, preprocessing, feature engineering, governance, and continuous monitoring.\n\nHow RAG Works: Architecture & Pipeline in 2026\n----------------------------------------------\n\nRAG architecture is composed of four key components working together to deliver accurate, context-aware outputs. The 2026 pipeline reflects advances in vector databases, embedding models, and hybrid retrieval methods.\n\n### Indexing & Embeddings: Preparing Your Knowledge Base\n\nThe first step in RAG architecture is creating embeddings — numerical vector representations of text — using models such as BERT, OpenAI embeddings, or domain-specific embeddings. These embeddings are stored in a**vector database**(like Pinecone, Milvus, or Weaviate)optimized for high-speed similarity search.\n\nThis step:\n\n*   Transforms raw documents into searchable vectors\n\n*   Enables deep semantic search\n\n*   Makes retrieval scalable across millions of documents\n\n### Retrieval: Finding the Right Context\n\nWhen a user submits a query, the system retrieves the most relevant documents using search techniques:\n\n*   Semantic search(embedding similarity)\n\n*   Keyword search(BM25, Elasticsearch)\n\n*   Hybrid search(best of both worlds; widely adopted in 2025–26)\n\nAdvanced retrieval and re-ranking innovations — described by platforms include cross-encoders, multi-stage retrievers, and contextual filtering to ensure higher precision.\n\n### Augmentation: Injecting Retrieved Data into the Prompt\n\nThe selected documents are appended to the user prompt as grounding context. This augmentation gives the LLM the factual basis needed to generate reliable answers.\n\n### Generation: Producing the Final Answer\n\nThe LLM synthesizes:\n\n*   Retrieved documents\n\n*   Its trained internal knowledge\n\n*   The user’s query\n\nThis leads to transparent, source-backed responses — a major requirement for enterprise-grade trustworthiness.\n\nRAG vs Fine-Tuning vs Prompt Engineering\n----------------------------------------\n\n**Technique****When It Works Best****Limitations**\n**RAG**Dynamic knowledge, proprietary data, accuracy-critical tasks Requires quality retrieval; infrastructure-heavy\n**Fine-Tuning**Stable, domain-specific tasks where knowledge doesn’t change often Expensive, static, time-consuming\n**Prompt Engineering**Light use cases, small prototypes, creative tasks Limited depth, lacks factual grounding\n\nSources like Microsoft Learn reinforce that RAG is more flexible, scalable, and cost-efficient than constant fine-tuning — especially in rapidly changing domains.\n\nExplore scalable architectures in AI-Powered Automation: The Competitive Edge in Data Quality Management\n\nWhy Use RAG: Key Benefits for Enterprise AI\n-------------------------------------------\n\nIn 2026, RAG models have become a foundational pattern for enterprise AI because they deliver three strategic advantages: factual accuracy, up-to-date knowledge, and customization on proprietary data.\n\nImproved Factual Accuracy & Reduced Hallucinations\n\nBy grounding outputs in retrieved context, RAG significantly reduces hallucinations. While it doesn’t eliminate them entirely, research shows RAG consistently outperforms baseline LLMs in truthfulness.\n\nKey benefits:\n\n*   Transparent, source-backed answers\n\n*   Higher reliability for regulated industries\n\n*   Traceability for audit and compliance workflows\n\nStay Up-to-Date Without Retraining\n\nBecause RAG relies on retrieval rather than internal model weights, updates are instant:\n\n*   Update documents → update model knowledge\n\n*   No retraining needed\n\n*   No GPU-intensive fine-tuning\n\n*   No downtime\n\nThis makes RAG ideal for enterprises where knowledge changes frequently— such as finance, healthcare, and legal.\n\nDomain-Specific Intelligence from Proprietary Data\n\nRAG enables LLMs to operate on:\n\n*   Internal documents\n\n*   Policies and SOPs\n\n*   Product manuals\n\n*   Customer interactions\n\n*   Compliance archives\n\nThis allows the LLM to behave like an expert in _your organization’s_ unique context — without exposing proprietary data during training.\n\nCost & Scalability Advantages Of RAG\n------------------------------------\n\nCompared to fine-tuning, RAG offers:\n\n*   Lower operational cost\n\n*   Faster deployment\n\n*   Less maintenance\n\n*   Better scalability\n\nRead more on how Microsoft Fabric AI solutions fundamentally transform how enterprises unify data, automate intelligence, and deploy AI at scale in our blog.\n\nBest Use Cases for RAG Models in 2026\n-------------------------------------\n\nRAG models excel in high-value enterprise scenarios that require accuracy, context, and up-to-date knowledge.\n\nBelow are the most impactful use cases for data leaders and AI architects.\n\n**Enterprise Knowledge Management & Internal Search**\n\nRAG empowers employees to query vast troves of internal documents and receive precise, reference-backed answers.\n\nApplications:\n\n*   QA systems for internal SOPs\n\n*   Search across Confluence, SharePoint, Jira\n\n*   Knowledge bots for engineering & support\n\n*   Onboarding assistants\n\n*   Contextual search for data catalogs\n\nStudies note that knowledge-intensive industries have seen the fastest adoption.\n\n**Customer Support & Virtual Assistants**\n\nRAG-powered assistants improve resolution accuracy by retrieving the latest product manuals, ticket histories, and troubleshooting guides.\n\nBenefits:\n\n*   Faster customer response\n\n*   Reduced agent burden\n\n*   Consistent answers\n\n*   Integration into CRM workflows\n\nResearch reports identify customer support as one of the top ROI-driving RAG use cases.\n\nLegal, Compliance & Regulatory Intelligence\n-------------------------------------------\n\nRAG enables precise retrieval across thousands of pages of regulatory text, ensuring outputs cite the correct clauses and versions.\n\nUse cases:\n\n*   Compliance QA\n\n*   Regulation comparison\n\n*   Policy summarization\n\n*   Contract analysis\n\n**Business Intelligence & Analytics**\n\nRAG can turn structured and semi-structured data into narrative insights.\n\nExamples:\n\n*   Executive reports\n\n*   KPI explanations\n\n*   Trend analysis\n\n*   Analytical summaries\n\n**“****The New Data Analyst: Transforming BI in the Age of AI****”**highlights how analysts shift from generic prompting to embedding**models within BI pipelines**, emphasizing**data + context + generative output**\n\n**Research, Summarization & Content Generation**\n\nRAG improves content accuracy by grounding outputs in real, recent documents.\n\nApplications:\n\n*   Research assistance\n\n*   Summaries of long documents\n\n*   Technical documentation\n\n*   Product requirement drafts\n\nSources emphasize that RAG is essential for high-stakes research workflows.\n\nUnpack the massive shift organizations are experiencing as AI moves from experimentation to everyday operation in our latest whitepaper.\n\nChallenges, Risks & Limitations\n-------------------------------\n\nWhile RAG is powerful, it is not a silver bullet. CTOs and data architects must be aware of its challenges to ensure secure, trusted, and effective deployment.\n\n**RAG Reduces but Does Not Eliminate Hallucinations**\n\nWhile retrieved documents provide factual grounding, LLMs may still:\n\n*   Misinterpret context\n\n*   Miscombine facts\n\n*   Over-generalize conclusions\n\nAs experts note, fact quality still depends heavily on retrieval quality and prompt structuring.\n\n**Retrieval Quality Determines Output Quality**\n\nYour RAG system is only as good as what it can retrieve.\n\nChallenges include:\n\n*   Poorly structured document pools\n\n*   Outdated content\n\n*   Noisy or redundant data\n\n*   Incorrect embeddings\n\n*   Vector drift over time\n\nSources stress the importance of high-quality indexing and constant dataset hygiene.\n\n**Data Governance, Privacy & Compliance Risks**\n\nEnterprises must ensure safeguards around:\n\n*   PII redaction\n\n*   Access controls\n\n*   Secure vector databases\n\n*   SOC2/ISO-compliant retrieval systems\n\n*   Permissioned retrieval by user role\n\n**Implementation Complexity**\n\nBuilding RAG at enterprise scale requires:\n\n*   Embedding pipelines\n\n*   Vector database orchestration\n\n*   Re-ranking models\n\n*   Chunking & document splitting strategies\n\n*   Evaluation pipelines\n\nWithout expertise, performance can degrade quickly.\n\n**Trade-Offs vs Fine-Tuning & Other Methods**\n\nNot all tasks need RAG; in some cases, fine-tuning or prompt engineering may be better.\n\nExamples:\n\n*   Tasks requiring stylistic consistency\n\n*   Static knowledge use cases\n\n*   Highly structured classification tasks\n\nRead our blog on Augmented Analytics: Using AI to Automate Insights in Dashboards\n\nWhat’s New in RAG in 26: Trends, Innovations & Future Directions\n----------------------------------------------------------------\n\nRAG has evolved dramatically between 2024 and 2026. What once began as a relatively simple retriever–generator pipeline has now matured into a**sophisticated enterprise intelligence architecture**with multimodal capabilities, hybrid retrieval engines, and advanced filtering layers.\n\nHere are the most influential trends shaping RAG in 2025–26.\n\n**Hybrid Retrieval: The New Enterprise Standard**\n\nTraditional semantic search alone is no longer enough. Leading research and enterprise implementations now use hybrid retrieval— combining:\n\n*   BM25 keyword matching\n\n*   Dense semantic vector search\n\n*   Metadata filtering\n\n*   Context-aware re-ranking\n\nAs highlighted in _Medium_ and _Signity Solutions_, hybrid retrieval consistently outperforms single-method pipelines for accuracy, especially in noisy enterprise datasets.\n\n**Why it matters:**\n\n*   Improves precision for niche queries\n\n*   Reduces irrelevant document retrieval\n\n*   Handles both structured and semi-structured data\n\n*   Enables better traceability for regulated industries\n\n**Multimodal RAG: Beyond Text**\n\nIn 2026, enterprises increasingly store knowledge in formats beyond plain text:\n\n*   PDFs with images\n\n*   Scanned documents\n\n*   Product diagrams\n\n*   Dashboards and BI visualizations\n\n*   Multimedia logs\n\n*   Videos of expert demonstrations\n\nMultimodal RAG integrates image, audio, tabular, and video embeddings to create more holistic reasoning.\n\nFor example:\n\nA maintenance engineer could ask,“Show me the failure pattern for turbine blade anomalies over the past year and explain the root cause.”\n\nThe system retrieves:\n\n*   Sensor logs\n\n*   Images\n\n*   Technical documents\n\n*   Past troubleshooting videos\n\nThis evolution is backed by advances referenced in _Medium_ and _Signity Solutions_.\n\n**Smarter Retrievers & Reranking Models**\n\nRetrievers now incorporate transformer-based cross-encoders, late interaction models, and deep fusion methods. These enhancements significantly improve precision, as noted by _Orq.ai_.\n\nCapabilities include:\n\n*   Context-aware ranking\n\n*   Query reformulation\n\n*   Adaptive chunking\n\n*   Continuous index refresh\n\n*   Entity-aware retrieval for domain-specific queries\n\n**Enterprise-Grade RAG Platforms**\n\nMajor leaps in enterprise infrastructure — highlighted by _Microsoft Learn_— include:\n\n*   Role-based access-controlled retrieval\n\n*   Integrated vector DBs + enterprise search\n\n*   Audit logs for every retrieval event\n\n*   Built-in PII masking\n\n*   SOC2, HIPAA, and GDPR-compliant RAG pipelines\n\n*   Air-gapped RAG deployments for sensitive data\n\nRAG has officially moved from experimentation to production-grade enterprise architecture.\n\n**Growing Cross-Industry Adoption**\n\nIndustries driving RAG adoption in 2026 include:\n\n*   Healthcare(clinical QA, regulatory compliance)\n\n*   Finance(policy search, risk modeling, regulatory analysis)\n\n\n"},"metadata":{"arguments":"{\"link_id\":30}","display_result":"","duration":"5s","id":"call_jPAMx4z8Fe","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【30†RAG Models in 2026: Strategic Guide for Smarter, Accurate†https://www.techment.com/blogs/rag-models-2026-enterprise-ai】\nTitle: RAG Models in 2026: Strategic Guide for Smarter, Accurate Enterprise AI\n\nURL Source: https://www.techment.com/blogs/rag-models-2026-enterprise-ai\n\nPublished Time: 2026-01-08T06:07:17+00:00\n\nMarkdown Content:\nIntroduction\n------------\n\nBy 2026, enterprise AI leaders — CTOs, data architects, and data executives — face mounting pressure to deliver AI systems that are not only powerful but deeply trustworthy. As LLM adoption accelerates, so does a fundamental limitation: most models operate on static training data, frozen in time. They cannot naturally access the latest regulatory updates, proprietary internal documents, or fast-changing enterprise knowledge bases.\n\nThis has created widespread concern around hallucinations, outdated outputs, and inability to cite authoritative sources — all of which increase risk, reduce trust, and limit enterprise deployment.\n\nThis is where RAG models(Retrieval-Augmented Generation models) become essential.\n\nInstead of relying solely on what an LLM “remembers,” a RAG system retrieves the most relevant, up-to-date documents from trusted data sources — such as enterprise knowledge repositories, vector databases, and regulatory archives — and then uses them to**augment the context**provided to the generative model. The result:**accurate, contextual, and explainable AI outputs**.\n\nLet’s begin.\n\nStrengthen your AI data foundation with our guide on Data Management for Enterprises: Roadmap.\n\nTL;DR(Summary Box)\n------------------\n\n*   RAG models combine retrieval systems with generative AI to deliver accurate, up-to-date, and source-grounded answers.\n\n*   In 2026, enterprises increasingly adopt RAG to improve factual reliability,leverage proprietary data, and reduce hallucinations.\n\n*   RAG is more scalable and cost-efficient than frequent fine-tuning — especially when knowledge changes regularly.\n\n*   This guide delivers a clear, practical, and strategic understanding of RAG architecture, benefits, risks, and enterprise adoption best practices.\n\n*   Techment provides end-to-end RAG consulting, implementation, and optimization for data-heavy organizations.\n\nWhat Are RAG Models?\n--------------------\n\nRetrieval-Augmented Generation (RAG)is an AI architecture that enhances large language models by pairing them with an external retrieval system. Instead of generating answers solely from internal parameters, the model actively retrieves relevant supporting documents — such as PDFs, enterprise knowledge bases, or structured data — and uses them to produce grounded,accurate responses.\n\n**Simple Definition**\n\nA RAG model =Retriever + Generator\n\n*   The retriever searches a document database or vector store for the most relevant information.\n\n*   The generator(an LLM) uses that retrieved context to craft an accurate answer.\n\nThis enables RAG systems to overcome the limitations of traditional LLMs trained on static datasets.RAG ensures that model outputs stay grounded in real, verifiable information while reducing hallucination rates.\n\n### Why RAG Matters for Enterprises\n\nTraditional LLMs:\n\n*   Cannot access real-time or proprietary data\n\n*   Tend to hallucinate facts, especially in niche domains\n\n*   Are expensive to retrain whenever data changes\n\nRAG-powered systems address these issues by:\n\n*   Using dynamic retrieval, so knowledge can be updated instantly\n\n*   Enabling domain-specific reasoning from internal data\n\n*   Reducing hallucinations with factual grounding\n\n*   Avoiding costly retraining cycles\n\nSources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.\n\n### Strategic Insight for Data Leaders\n\nRAG is not just an AI technique — it is a systems architecture choice that reshapes how enterprises operationalize knowledge. For CTOs and data architects, the shift from model-centric to data-centric AI is one of the defining transformations of the decade.\n\nRead more on why enterprises must adopt a 2025 AI Data Quality Framework spanning acquisition, preprocessing, feature engineering, governance, and continuous monitoring.\n\nHow RAG Works: Architecture & Pipeline in 2026\n----------------------------------------------\n\nRAG architecture is composed of four key components working together to deliver accurate, context-aware outputs. The 2026 pipeline reflects advances in vector databases, embedding models, and hybrid retrieval methods.\n\n### Indexing & Embeddings: Preparing Your Knowledge Base\n\nThe first step in RAG architecture is creating embeddings — numerical vector representations of text — using models such as BERT, OpenAI embeddings, or domain-specific embeddings. These embeddings are stored in a**vector database**(like Pinecone, Milvus, or Weaviate)optimized for high-speed similarity search.\n\nThis step:\n\n*   Transforms raw documents into searchable vectors\n\n*   Enables deep semantic search\n\n*   Makes retrieval scalable across millions of documents\n\n### Retrieval: Finding the Right Context\n\nWhen a user submits a query, the system retrieves the most relevant documents using search techniques:\n\n*   Semantic search(embedding similarity)\n\n*   Keyword search(BM25, Elasticsearch)\n\n*   Hybrid search(best of both worlds; widely adopted in 2025–26)\n\nAdvanced retrieval and re-ranking innovations — described by platforms include cross-encoders, multi-stage retrievers, and contextual filtering to ensure higher precision.\n\n### Augmentation: Injecting Retrieved Data into the Prompt\n\nThe selected documents are appended to the user prompt as grounding context. This augmentation gives the LLM the factual basis needed to generate reliable answers.\n\n### Generation: Producing the Final Answer\n\nThe LLM synthesizes:\n\n*   Retrieved documents\n\n*   Its trained internal knowledge\n\n*   The user’s query\n\nThis leads to transparent, source-backed responses — a major requirement for enterprise-grade trustworthiness.\n\nRAG vs Fine-Tuning vs Prompt Engineering\n----------------------------------------\n\n**Technique****When It Works Best****Limitations**\n**RAG**Dynamic knowledge, proprietary data, accuracy-critical tasks Requires quality retrieval; infrastructure-heavy\n**Fine-Tuning**Stable, domain-specific tasks where knowledge doesn’t change often Expensive, static, time-consuming\n**Prompt Engineering**Light use cases, small prototypes, creative tasks Limited depth, lacks factual grounding\n\nSources like Microsoft Learn reinforce that RAG is more flexible, scalable, and cost-efficient than constant fine-tuning — especially in rapidly changing domains.\n\nExplore scalable architectures in AI-Powered Automation: The Competitive Edge in Data Quality Management\n\nWhy Use RAG: Key Benefits for Enterprise AI\n-------------------------------------------\n\nIn 2026, RAG models have become a foundational pattern for enterprise AI because they deliver three strategic advantages: factual accuracy, up-to-date knowledge, and customization on proprietary data.\n\nImproved Factual Accuracy & Reduced Hallucinations\n\nBy grounding outputs in retrieved context, RAG significantly reduces hallucinations. While it doesn’t eliminate them entirely, research shows RAG consistently outperforms baseline LLMs in truthfulness.\n\nKey benefits:\n\n*   Transparent, source-backed answers\n\n*   Higher reliability for regulated industries\n\n*   Traceability for audit and compliance workflows\n\nStay Up-to-Date Without Retraining\n\nBecause RAG relies on retrieval rather than internal model weights, updates are instant:\n\n*   Update documents → update model knowledge\n\n*   No retraining needed\n\n*   No GPU-intensive fine-tuning\n\n*   No downtime\n\nThis makes RAG ideal for enterprises where knowledge changes frequently— such as finance, healthcare, and legal.\n\nDomain-Specific Intelligence from Proprietary Data\n\nRAG enables LLMs to operate on:\n\n*   Internal documents\n\n*   Policies and SOPs\n\n*   Product manuals\n\n*   Customer interactions\n\n*   Compliance archives\n\nThis allows the LLM to behave like an expert in _your organization’s_ unique context — without exposing proprietary data during training.\n\nCost & Scalability Advantages Of RAG\n------------------------------------\n\nCompared to fine-tuning, RAG offers:\n\n*   Lower operational cost\n\n*   Faster deployment\n\n*   Less maintenance\n\n*   Better scalability\n\nRead more on how Microsoft Fabric AI solutions fundamentally transform how enterprises unify data, automate intelligence, and deploy AI at scale in our blog.\n\nBest Use Cases for RAG Models in 2026\n-------------------------------------\n\nRAG models excel in high-value enterprise scenarios that require accuracy, context, and up-to-date knowledge.\n\nBelow are the most impactful use cases for data leaders and AI architects.\n\n**Enterprise Knowledge Management & Internal Search**\n\nRAG empowers employees to query vast troves of internal documents and receive precise, reference-backed answers.\n\nApplications:\n\n*   QA systems for internal SOPs\n\n*   Search across Confluence, SharePoint, Jira\n\n*   Knowledge bots for engineering & support\n\n*   Onboarding assistants\n\n*   Contextual search for data catalogs\n\nStudies note that knowledge-intensive industries have seen the fastest adoption.\n\n**Customer Support & Virtual Assistants**\n\nRAG-powered assistants improve resolution accuracy by retrieving the latest product manuals, ticket histories, and troubleshooting guides.\n\nBenefits:\n\n*   Faster customer response\n\n*   Reduced agent burden\n\n*   Consistent answers\n\n*   Integration into CRM workflows\n\nResearch reports identify customer support as one of the top ROI-driving RAG use cases.\n\nLegal, Compliance & Regulatory Intelligence\n-------------------------------------------\n\nRAG enables precise retrieval across thousands of pages of regulatory text, ensuring outputs cite the correct clauses and versions.\n\nUse cases:\n\n*   Compliance QA\n\n*   Regulation comparison\n\n*   Policy summarization\n\n*   Contract analysis\n\n**Business Intelligence & Analytics**\n\nRAG can turn structured and semi-structured data into narrative insights.\n\nExamples:\n\n*   Executive reports\n\n*   KPI explanations\n\n*   Trend analysis\n\n*   Analytical summaries\n\n**“****The New Data Analyst: Transforming BI in the Age of AI****”**highlights how analysts shift from generic prompting to embedding**models within BI pipelines**, emphasizing**data + context + generative output**\n\n**Research, Summarization & Content Generation**\n\nRAG improves content accuracy by grounding outputs in real, recent documents.\n\nApplications:\n\n*   Research assistance\n\n*   Summaries of long documents\n\n*   Technical documentation\n\n*   Product requirement drafts\n\nSources emphasize that RAG is essential for high-stakes research workflows.\n\nUnpack the massive shift organizations are experiencing as AI moves from experimentation to everyday operation in our latest whitepaper.\n\nChallenges, Risks & Limitations\n-------------------------------\n\nWhile RAG is powerful, it is not a silver bullet. CTOs and data architects must be aware of its challenges to ensure secure, trusted, and effective deployment.\n\n**RAG Reduces but Does Not Eliminate Hallucinations**\n\nWhile retrieved documents provide factual grounding, LLMs may still:\n\n*   Misinterpret context\n\n*   Miscombine facts\n\n*   Over-generalize conclusions\n\nAs experts note, fact quality still depends heavily on retrieval quality and prompt structuring.\n\n**Retrieval Quality Determines Output Quality**\n\nYour RAG system is only as good as what it can retrieve.\n\nChallenges include:\n\n*   Poorly structured document pools\n\n*   Outdated content\n\n*   Noisy or redundant data\n\n*   Incorrect embeddings\n\n*   Vector drift over time\n\nSources stress the importance of high-quality indexing and constant dataset hygiene.\n\n**Data Governance, Privacy & Compliance Risks**\n\nEnterprises must ensure safeguards around:\n\n*   PII redaction\n\n*   Access controls\n\n*   Secure vector databases\n\n*   SOC2/ISO-compliant retrieval systems\n\n*   Permissioned retrieval by user role\n\n**Implementation Complexity**\n\nBuilding RAG at enterprise scale requires:\n\n*   Embedding pipelines\n\n*   Vector database orchestration\n\n*   Re-ranking models\n\n*   Chunking & document splitting strategies\n\n*   Evaluation pipelines\n\nWithout expertise, performance can degrade quickly.\n\n**Trade-Offs vs Fine-Tuning & Other Methods**\n\nNot all tasks need RAG; in some cases, fine-tuning or prompt engineering may be better.\n\nExamples:\n\n*   Tasks requiring stylistic consistency\n\n*   Static knowledge use cases\n\n*   Highly structured classification tasks\n\nRead our blog on Augmented Analytics: Using AI to Automate Insights in Dashboards\n\nWhat’s New in RAG in 26: Trends, Innovations & Future Directions\n----------------------------------------------------------------\n\nRAG has evolved dramatically between 2024 and 2026. What once began as a relatively simple retriever–generator pipeline has now matured into a**sophisticated enterprise intelligence architecture**with multimodal capabilities, hybrid retrieval engines, and advanced filtering layers.\n\nHere are the most influential trends shaping RAG in 2025–26.\n\n**Hybrid Retrieval: The New Enterprise Standard**\n\nTraditional semantic search alone is no longer enough. Leading research and enterprise implementations now use hybrid retrieval— combining:\n\n*   BM25 keyword matching\n\n*   Dense semantic vector search\n\n*   Metadata filtering\n\n*   Context-aware re-ranking\n\nAs highlighted in _Medium_ and _Signity Solutions_, hybrid retrieval consistently outperforms single-method pipelines for accuracy, especially in noisy enterprise datasets.\n\n**Why it matters:**\n\n*   Improves precision for niche queries\n\n*   Reduces irrelevant document retrieval\n\n*   Handles both structured and semi-structured data\n\n*   Enables better traceability for regulated industries\n\n**Multimodal RAG: Beyond Text**\n\nIn 2026, enterprises increasingly store knowledge in formats beyond plain text:\n\n*   PDFs with images\n\n*   Scanned documents\n\n*   Product diagrams\n\n*   Dashboards and BI visualizations\n\n*   Multimedia logs\n\n*   Videos of expert demonstrations\n\nMultimodal RAG integrates image, audio, tabular, and video embeddings to create more holistic reasoning.\n\nFor example:\n\nA maintenance engineer could ask,“Show me the failure pattern for turbine blade anomalies over the past year and explain the root cause.”\n\nThe system retrieves:\n\n*   Sensor logs\n\n*   Images\n\n*   Technical documents\n\n*   Past troubleshooting videos\n\nThis evolution is backed by advances referenced in _Medium_ and _Signity Solutions_.\n\n**Smarter Retrievers & Reranking Models**\n\nRetrievers now incorporate transformer-based cross-encoders, late interaction models, and deep fusion methods. These enhancements significantly improve precision, as noted by _Orq.ai_.\n\nCapabilities include:\n\n*   Context-aware ranking\n\n*   Query reformulation\n\n*   Adaptive chunking\n\n*   Continuous index refresh\n\n*   Entity-aware retrieval for domain-specific queries\n\n**Enterprise-Grade RAG Platforms**\n\nMajor leaps in enterprise infrastructure — highlighted by _Microsoft Learn_— include:\n\n*   Role-based access-controlled retrieval\n\n*   Integrated vector DBs + enterprise search\n\n*   Audit logs for every retrieval event\n\n*   Built-in PII masking\n\n*   SOC2, HIPAA, and GDPR-compliant RAG pipelines\n\n*   Air-gapped RAG deployments for sensitive data\n\nRAG has officially moved from experimentation to production-grade enterprise architecture.\n\n**Growing Cross-Industry Adoption**\n\nIndustries driving RAG adoption in 2026 include:\n\n*   Healthcare(clinical QA, regulatory compliance)\n\n*   Finance(policy search, risk modeling, regulatory analysis)\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> RAGの2026年におけるベストプラクティスを確認しました。次に、IDE/CLI/エージェントの統合についての最新情報を収集してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"},{"title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","text":"Sources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.","index":31,"favicon":"","host_name":"www.techment.com"},{"title":"Retrieval-augmented generation (RAG) for business","url":"https://www.meilisearch.com/blog/rag-for-business","text":"Best practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...","index":32,"favicon":"","host_name":"www.meilisearch.com"},{"title":"What Is RAG (Retrieval-Augmented Generation)? A Full","url":"https://www.snowflake.com/en/fundamentals/rag","text":"RAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.","index":33,"favicon":"","host_name":"www.snowflake.com"},{"title":"How Retrieval-Augmented Generation Powers Enterprise AI","url":"https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag","text":"Discover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...","index":34,"favicon":"","host_name":"www.grazitti.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"RAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...","index":35,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Title: RAG (Retrieval-Augmented Generation) Best Practices","url":"https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m","text":"Great overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...","index":36,"favicon":"","host_name":"www.linkedin.com"},{"title":"Documentation best practices for RAG applications","url":"https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html","text":"Learn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.","index":37,"favicon":"","host_name":"docs.aws.amazon.com"},{"title":"Retrieval best practices : r/Rag","url":"https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices","text":"My impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...","index":38,"favicon":"","host_name":"www.reddit.com"},{"title":"How Retrieval-Augmented Generation (RAG) Builds","url":"https://qat.com/rag-for-business-leaders","text":"Get proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.","index":39,"favicon":"","host_name":"qat.com"},{"title":"Enterprise-Grade AI: A Visual Deep-Dive into Advanced","url":"https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a","text":"Retrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.","index":40,"favicon":"","host_name":"itsjb13.medium.com"},{"title":"GitHub Copilot vs Cursor : AI Code Editor Review for 2026","url":"https://www.digitalocean.com/resources/articles/github-copilot-vs-cursor","text":"Copilot excels in inline code completion, tight GitHub/IDE integration, and quick turnaround for common coding tasks. Cursor focuses on ...","index":41,"favicon":"","host_name":"www.digitalocean.com"},{"title":"Cursor vs Copilot vs Clark: Which Is the Best in 2026?","url":"https://www.superblocks.com/blog/cursor-vs-copilot","text":"Cursor and Copilot are great for in-IDE AI assistance, but Clark is the best for building enterprise internal apps.","index":42,"favicon":"","host_name":"www.superblocks.com"},{"title":"Visual Studio + GitHub Copilot vs Cursor : r/dotnet","url":"https://www.reddit.com/r/dotnet/comments/1pndbtt/visual_studio_github_copilot_vs_cursor","text":"I use Visual Studio 2026 with GitHub Copilot linked to Claude Sonnet 4.5 and am relatively happy with it. I use CONTRIBUTING.md to describe ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Best AI Coding Agents for 2026: Real-World Developer","url":"https://www.faros.ai/blog/best-ai-coding-agents-2026","text":"A developer-focused look at the best AI coding agents in 2026, comparing Claude Code, Cursor, Codex, Copilot, Cline, and more—with guidance ...","index":44,"favicon":"","host_name":"www.faros.ai"},{"title":"Best AI Coding Assistants as of January 2026","url":"https://www.shakudo.io/blog/best-ai-coding-assistants","text":"The most famous AI pair-programmer, Copilot integrates into VS Code, Visual Studio, JetBrains, etc. It's powered by OpenAI's Codex and GPT-4 ...","index":45,"favicon":"","host_name":"www.shakudo.io"},{"title":"Battle of the AI agents: Cursor vs. Copilot","url":"https://nearform.com/digital-community/battle-of-the-ai-agents","text":"At the time of this post's writing, Github's Copilot agent mode feature is in preview, and only available via the Insiders version of VS Code.","index":46,"favicon":"","host_name":"nearform.com"},{"title":"Best AI Code Editors 2026 (I Tested 10+)","url":"https://playcode.io/blog/best-ai-code-editors-2026","text":"I tested 10+ AI code editors in 2026. Compare Cursor, VS Code + Copilot, PlayCode, Windsurf, Zed, and more. Find the best AI-powered editor ...","index":47,"favicon":"","host_name":"playcode.io"},{"title":"Cursor vs GitHub Copilot: Which AI Coding Tool Is Better in","url":"https://byclaritytech.com/cursor-vs-github-copilot","text":"In 2026, Cursor AI will represent the future of AI-native software development. GitHub Copilot will continue to be the best, most reliable and ...","index":48,"favicon":"","host_name":"byclaritytech.com"},{"title":"Visual Studio With GitHub Copilot - AI Pair Programming","url":"https://visualstudio.microsoft.com/github-copilot","text":"GitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other ...","index":49,"favicon":"","host_name":"visualstudio.microsoft.com"},{"title":"Cursor vs VS Code: AI Coding Editor Showdown","url":"https://www.augmentcode.com/tools/cursor-vs-vscode-comparison-guide","text":"Workflow Integration Depth: Cursor requires switching to a VS Code fork with custom UI modifications. GitHub Copilot integrates with existing ...","index":50,"favicon":"","host_name":"www.augmentcode.com"}]},"metadata":{"arguments":"{\"query\":\"IDE AI agents integration 2026 VS Code Cursor GitHub Copilot\"}","display_result":"","duration":"2s","id":"call_dW1BztGgZS","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【40†GitHub Copilot vs Cursor : AI Code Editor Review for 2026†https://www.digitalocean.com/resources/articles/github-copilot-vs-cursor】\nCopilot excels in inline code completion, tight GitHub/IDE integration, and quick turnaround for common coding tasks. Cursor focuses on ...\n\n【41†Cursor vs Copilot vs Clark: Which Is the Best in 2026?†https://www.superblocks.com/blog/cursor-vs-copilot】\nCursor and Copilot are great for in-IDE AI assistance, but Clark is the best for building enterprise internal apps.\n\n【42†Visual Studio + GitHub Copilot vs Cursor : r/dotnet†https://www.reddit.com/r/dotnet/comments/1pndbtt/visual_studio_github_copilot_vs_cursor】\nI use Visual Studio 2026 with GitHub Copilot linked to Claude Sonnet 4.5 and am relatively happy with it. I use CONTRIBUTING.md to describe ...\n\n【43†Best AI Coding Agents for 2026: Real-World Developer†https://www.faros.ai/blog/best-ai-coding-agents-2026】\nA developer-focused look at the best AI coding agents in 2026, comparing Claude Code, Cursor, Codex, Copilot, Cline, and more—with guidance ...\n\n【44†Best AI Coding Assistants as of January 2026†https://www.shakudo.io/blog/best-ai-coding-assistants】\nThe most famous AI pair-programmer, Copilot integrates into VS Code, Visual Studio, JetBrains, etc. It's powered by OpenAI's Codex and GPT-4 ...\n\n【45†Battle of the AI agents: Cursor vs. Copilot†https://nearform.com/digital-community/battle-of-the-ai-agents】\nAt the time of this post's writing, Github's Copilot agent mode feature is in preview, and only available via the Insiders version of VS Code.\n\n【46†Best AI Code Editors 2026 (I Tested 10+)†https://playcode.io/blog/best-ai-code-editors-2026】\nI tested 10+ AI code editors in 2026. Compare Cursor, VS Code + Copilot, PlayCode, Windsurf, Zed, and more. Find the best AI-powered editor ...\n\n【47†Cursor vs GitHub Copilot: Which AI Coding Tool Is Better in†https://byclaritytech.com/cursor-vs-github-copilot】\nIn 2026, Cursor AI will represent the future of AI-native software development. GitHub Copilot will continue to be the best, most reliable and ...\n\n【48†Visual Studio With GitHub Copilot - AI Pair Programming†https://visualstudio.microsoft.com/github-copilot】\nGitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other ...\n\n【49†Cursor vs VS Code: AI Coding Editor Showdown†https://www.augmentcode.com/tools/cursor-vs-vscode-comparison-guide】\nWorkflow Integration Depth: Cursor requires switching to a VS Code fork with custom UI modifications. GitHub Copilot integrates with existing ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> IDE/AIエージェントの統合に関する最新情報を収集しました。次に、具体的な比較情報を確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://www.faros.ai/blog/best-ai-coding-agents-2026","title":"Best AI Coding Agents for 2026: Real-World Developer","content":"【43†Best AI Coding Agents for 2026: Real-World Developer†https://www.faros.ai/blog/best-ai-coding-agents-2026】\nTitle: Best AI Coding Agents for Developers in 2026 (Real-World Reviews)\n\nURL Source: https://www.faros.ai/blog/best-ai-coding-agents-2026\n\nPublished Time: Jan 02, 2026\n\nMarkdown Content:\n15\n\nmin read\n\nBrowse Chapters\n\nJanuary 2, 2026\n\nOver the last five years, AI coding tools have become a standard part of software development. By the end of 2025, roughly 85% of developers regularly use AI tools for coding—whether to speed up routine tasks, get suggestions for the next line of code, or answer specific technical questions.\n\nMore recently, AI coding assistants are no longer limited to autocomplete or chat-based assistance. AI tools like Claude Code, Codex, Cursor, and GitHub Copilot are increasingly capable of acting as autonomous agents that understand repositories, make multi-file changes, run tests, and iterate on tasks with minimal human input.\n\nWith so many AI coding tools on the market, developers test tools firsthand and rely on community discussion to guide adoption decisions. This article synthesizes recent Reddit and forum discussions, alongside insights from what developers in our own circles are actively using, to break down what matters most when evaluating AI coding agents and which tools are emerging as top choices heading into 2026.\n\nWhat matters most when evaluating AI coding agents?\n---------------------------------------------------\n\nAs AI coding tools mature, developer evaluation has become more disciplined. Instead of focusing on raw capability, engineers now judge agents across a consistent set of practical dimensions that determine real-world usefulness.\n\n| What devs care about | The simple question they ask | Why it matters |\n| --- | --- | --- |\n| Token efficiency and price | “Will this burn my tokens?” | Wasted runs and hallucinations turn directly into higher costs |\n| Productivity impact | “Does this actually make me faster?” | Tools that add friction or noise cancel out any AI benefit |\n| Code quality & hallucination control | “Can I trust the output?” | Messy or wrong code creates long-term maintenance debt |\n| Context window & repo understanding | “Does it understand my whole repo?” | File-by-file tools break down on real-world codebases |\n| Privacy, security & data control | “Where does my code go?” | Privacy concerns will block adoption no matter how good the tool is |\n\nAI coding agent considerations summary\n\n### 1. Cost, pricing models & token efficiency\n\nOne of the loudest conversations among developers is no longer _“which tool is smartest?”_ Now it’s _“which tool won’t torch my credits?”_\n\nAs AI assistants and agentic coding tools become more powerful, they also become more expensive to run, so cost-effectiveness is a top consideration. In fact, pricing models are now debated almost as intensely as capabilities, especially as more tools move toward usage-based billing and tighter limits.\n\nA clear flashpoint came earlier this year when Anthropic introduced new rate limits to curb users running Claude Code continuously in the background. Developers suddenly found themselves hitting caps mid-workstream and locked out until resets.\n\nThis is why **token efficiency** matters. Every misinterpretation, hallucination, or failed agent run is wasted money. Looking ahead to 2026, developers are gravitating toward tools that deliver more per token: better context management, fewer retries, and stronger first passes.\n\n### 2. Real productivity impact: Speed, overhead & the importance of a strong UI\n\nA growing number of Reddit threads challenge the assumption that AI tools automatically make developers faster. While there are real developer productivity gains in some cases, other posts like _“I stopped using Copilot and didn’t notice a decrease in productivity”_ capture a sentiment that’s echoed repeatedly across the platform.\n\nWhat developers increasingly care about is net productivity—the entire workflow, not isolated moments of assistance. AI tools like Claude Code that generate correct code on the first pass and fit naturally into existing workflows earn praise; whereas tools that require constant correction quickly lose favor.\n\nUI and UX also play a major role here. The best AI coding tools have an intuitive feel that boosts speed and invites continued use. Conversely, when a tool's UI introduces even minor friction points, those inefficiencies compound and developers simply stop using it. This signals a conversation shifting from “AI writes code” to “AI helps me finish real work faster, without getting in the way.”\n\nAI Is Everywhere. Impact Isn’t.\n\n75% of engineers use AI tools—yet most organizations see no measurable performance gains.\n\nRead the report to uncover what’s holding teams back—and how to fix it fast.\n\n### 3. Code quality, hallucinations & long-term maintainability\n\nAt this advanced stage of adoption, developers are getting more concerned with _quality_ than pure generation speed. Afterall, what does fast matter if the output is wrong?\n\nReddit is full of cautionary tales: _“It’s incredibly exhausting trying to get these models to operate correctly, even when I provide extensive context for them to follow. The codebase becomes messy, filled with unnecessary code, duplicated files, excessive comments, and frequent commits after every single change.”_ This is where trust in the AI coding agent becomes a differentiator.\n\nDevs want assistants that explain their changes, avoid hallucinations, and help maintain quality code. As codebases evolve, small AI shortcuts can quickly turn into maintenance debt and other bottlenecks, pushing developers toward tools that act like careful collaborators rather than overeager generators.\n\n### 4. Repo understanding, context management & workflow fit\n\nOne of the clearest dividing lines between AI coding tools is how well they understand the entire project, not just the file currently being edited. Agentic tools like Cursor, Cline, Aider, and Windsurf are frequently praised for their ability to index repositories, track dependencies, link related files, and maintain multi-step reasoning across tasks.\n\nReddit threads often dissect semantic search, embeddings, context window limits, and IDE integration, but these discussions increasingly converge on what is now often described as _context engineering_ _._ The underlying requirement is straightforward: tools must reliably maintain, retrieve, and update relevant project context as work progresses. In both large monoliths and distributed microservice environments, effective context engineering has become a key differentiator.\n\n### 5. Privacy, security & control over data\n\nAs AI coding agents become fully integrated into core development workflows, privacy has also become a major differentiator, especially in professional environments.\n\nOn Reddit, developers frequently ask whether a tool trains on their code, stores telemetry, or sends sensitive snippets to the cloud. Some companies outright block cloud-based assistants over IP or compliance concerns, while others mandate internal LLMs or self-hosted agents as a condition of use.\n\nWhy does this matter? Because trust is foundational. If developers feel uneasy about sharing proprietary logic, architecture, or client data, they simply won’t use the tool, no matter how powerful it is. The more AI becomes part of the day-to-day development process, the more control teams want over where their code goes and how it’s used.\n\nWhat are the best AI coding agents for 2026?\n--------------------------------------------\n\nWith 2026 on the horizon, developer consensus has largely settled on one point: there is no single “best” AI coding agent in isolation. Instead, developers evaluate tools based on where they want leverage: speed and flow inside the editor, control and reliability on large codebases, or greater autonomy higher up the stack. That said, a small number of tools have clearly emerged as front-runners.\n\nThe following section outlines the best AI coding agents on the market, informed by recent Reddit threads and developer forum conversations, as well as firsthand usage across our own networks. It spans widely adopted and praised tools, followed by more niche runner-ups with sharper trade-offs, and then a set of emerging tools that developers should keep an eye out for.\n\n| Adoption & Maturity | Representative Tools |\n| --- | --- |\n| Front-Runners | Cursor, Claude Code, Codex, GitHub Copilot, Cline |\n| Runner Ups | RooCode, Windsurf, Aider, Augment, JetBrains Junie, Gemini CLI |\n| Emerging | AWS Kiro, Kilo Code, Zencoder |\n\nBest AI coding tools summary\n\nLet’s start with the top choices:\n\n### Cursor: the default AI IDE for everyday shipping\n\nAt the time of writing this, Cursor remains the most broadly adopted AI coding tool among individual developers and small teams according to Reddit. In 2025 threads, it’s often treated as the baseline: even when people prefer other agents, Cursor is still what they compare against.\n\nCursor’s main strength is flow. Autocomplete feels fast and useful, chat lives directly inside the editor, and small-to-medium scoped tasks (feature tweaks, refactors, tests, bug fixes) are handled with minimal friction. Many developers describe Cursor as the tool that “just stays out of the way” while quietly making them faster.\n\nWhere Cursor draws criticism is on larger, more complex changes. Recent threads still report issues with long-running refactors, looping behavior, or incomplete repo-wide understanding.\n\nCursor pricing and plan changes are also a top concern, with _“Cursor: pay more, get less, and don’t ask how it works”_ and similar threads garnering ample community engagement.\n\n### Claude Code: the strongest “coding brain”\n\nIf Cursor is about flow, Claude Code is about intelligence. Across late-2025 discussions, Claude Code (and Claude-powered setups more generally) is repeatedly described as the most capable model for deep reasoning, debugging, and architectural changes. So if you’ve been wondering, _is Claude Code worth it?_ The answer is a resounding yes.\n\nDevelopers often say they trust Claude Code with the hardest problems: unraveling subtle bugs, reasoning about unfamiliar codebases, or making design-level changes. In many setups, Claude Code is not the primary IDE, but the escalation path when other tools fail. The developers at Faros AI echo this sentiment. Many developers use Claude Code almost exclusively, impressed by its speed, intelligence, and overall ease of use.\n\nThe drawbacks are practical rather than philosophical. Cost comes up frequently, and some users feel Claude performs better when accessed through other tools, like Cline or Aider, which give more explicit control over context and prompts. Still, when people talk about “best AI for coding” in abstract terms, Claude remains the most agreed-upon answer.\n\n### Codex: a first-class, agent-native coding platform\n\nCodex has re-emerged in 2025 as a serious, agent-first coding tool rather than just a legacy model name. In newer Reddit threads, it’s increasingly discussed alongside Claude Code as a standalone agent you run against real repositories, and no longer just a passive autocomplete assistant.\n\nDevelopers like Codex for its follow-through. It’s often described as more deterministic on multi-step tasks: understanding repo structure, making coordinated changes, running tests, and iterating without drifting. Codex shows up most often in CLI- and workflow-oriented discussions, where people treat it as something you aim at a task and let work, rather than something that lives permanently in the editor.\n\nThe main drawbacks are adoption and clarity. Codex doesn’t yet have the “default IDE” mindshare of Cursor or Copilot, and some developers say pricing and long-running agent costs can feel opaque. As a result, Codex is usually chosen deliberately by developers who want an agent they can trust with bigger jobs, rather than discovered accidentally as part of an editor setup.\n\n### GitHub Copilot (Agent Mode): the pragmatic default\n\nCopilot continues to dominate by sheer presence. For many developers, especially those working for companies considered “Microsoft shops”, it’s already installed, approved, and integrated into existing workflows. In 2025, the conversation shifted away from basic autocomplete and toward Copilot’s newer agent and workspace features.\n\nWhat keeps Copilot near the top is frictionlessness. Copilot’s inline suggestions are fast, agent mode is “good enough” for many repo-level tasks, and it fits cleanly into enterprise environments. For a large segment of developers, Copilot may not be the best tool, but it is one of the easiest.\n\nCriticism tends to come from power users. Compared to Claude Code agents, some developers describe Copilot as less impressive on complex reasoning. Quotas, opaque model choices, and limits on customization also surface when developers push it harder.\n\n### Cline: VS Code agent for developers who want control\n\nCline shows up consistently in newer threads as the tool people adopt once they decide they want more than an AI IDE can offer. It’s commonly framed as the VS Code-native way to run serious agent workflows without being locked into a single provider.\n\n\n"},"metadata":{"arguments":"{\"link_id\":43}","display_result":"","duration":"7s","id":"call_0H7P9OepA1","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【43†Best AI Coding Agents for 2026: Real-World Developer†https://www.faros.ai/blog/best-ai-coding-agents-2026】\nTitle: Best AI Coding Agents for Developers in 2026 (Real-World Reviews)\n\nURL Source: https://www.faros.ai/blog/best-ai-coding-agents-2026\n\nPublished Time: Jan 02, 2026\n\nMarkdown Content:\n15\n\nmin read\n\nBrowse Chapters\n\nJanuary 2, 2026\n\nOver the last five years, AI coding tools have become a standard part of software development. By the end of 2025, roughly 85% of developers regularly use AI tools for coding—whether to speed up routine tasks, get suggestions for the next line of code, or answer specific technical questions.\n\nMore recently, AI coding assistants are no longer limited to autocomplete or chat-based assistance. AI tools like Claude Code, Codex, Cursor, and GitHub Copilot are increasingly capable of acting as autonomous agents that understand repositories, make multi-file changes, run tests, and iterate on tasks with minimal human input.\n\nWith so many AI coding tools on the market, developers test tools firsthand and rely on community discussion to guide adoption decisions. This article synthesizes recent Reddit and forum discussions, alongside insights from what developers in our own circles are actively using, to break down what matters most when evaluating AI coding agents and which tools are emerging as top choices heading into 2026.\n\nWhat matters most when evaluating AI coding agents?\n---------------------------------------------------\n\nAs AI coding tools mature, developer evaluation has become more disciplined. Instead of focusing on raw capability, engineers now judge agents across a consistent set of practical dimensions that determine real-world usefulness.\n\n| What devs care about | The simple question they ask | Why it matters |\n| --- | --- | --- |\n| Token efficiency and price | “Will this burn my tokens?” | Wasted runs and hallucinations turn directly into higher costs |\n| Productivity impact | “Does this actually make me faster?” | Tools that add friction or noise cancel out any AI benefit |\n| Code quality & hallucination control | “Can I trust the output?” | Messy or wrong code creates long-term maintenance debt |\n| Context window & repo understanding | “Does it understand my whole repo?” | File-by-file tools break down on real-world codebases |\n| Privacy, security & data control | “Where does my code go?” | Privacy concerns will block adoption no matter how good the tool is |\n\nAI coding agent considerations summary\n\n### 1. Cost, pricing models & token efficiency\n\nOne of the loudest conversations among developers is no longer _“which tool is smartest?”_ Now it’s _“which tool won’t torch my credits?”_\n\nAs AI assistants and agentic coding tools become more powerful, they also become more expensive to run, so cost-effectiveness is a top consideration. In fact, pricing models are now debated almost as intensely as capabilities, especially as more tools move toward usage-based billing and tighter limits.\n\nA clear flashpoint came earlier this year when Anthropic introduced new rate limits to curb users running Claude Code continuously in the background. Developers suddenly found themselves hitting caps mid-workstream and locked out until resets.\n\nThis is why **token efficiency** matters. Every misinterpretation, hallucination, or failed agent run is wasted money. Looking ahead to 2026, developers are gravitating toward tools that deliver more per token: better context management, fewer retries, and stronger first passes.\n\n### 2. Real productivity impact: Speed, overhead & the importance of a strong UI\n\nA growing number of Reddit threads challenge the assumption that AI tools automatically make developers faster. While there are real developer productivity gains in some cases, other posts like _“I stopped using Copilot and didn’t notice a decrease in productivity”_ capture a sentiment that’s echoed repeatedly across the platform.\n\nWhat developers increasingly care about is net productivity—the entire workflow, not isolated moments of assistance. AI tools like Claude Code that generate correct code on the first pass and fit naturally into existing workflows earn praise; whereas tools that require constant correction quickly lose favor.\n\nUI and UX also play a major role here. The best AI coding tools have an intuitive feel that boosts speed and invites continued use. Conversely, when a tool's UI introduces even minor friction points, those inefficiencies compound and developers simply stop using it. This signals a conversation shifting from “AI writes code” to “AI helps me finish real work faster, without getting in the way.”\n\nAI Is Everywhere. Impact Isn’t.\n\n75% of engineers use AI tools—yet most organizations see no measurable performance gains.\n\nRead the report to uncover what’s holding teams back—and how to fix it fast.\n\n### 3. Code quality, hallucinations & long-term maintainability\n\nAt this advanced stage of adoption, developers are getting more concerned with _quality_ than pure generation speed. Afterall, what does fast matter if the output is wrong?\n\nReddit is full of cautionary tales: _“It’s incredibly exhausting trying to get these models to operate correctly, even when I provide extensive context for them to follow. The codebase becomes messy, filled with unnecessary code, duplicated files, excessive comments, and frequent commits after every single change.”_ This is where trust in the AI coding agent becomes a differentiator.\n\nDevs want assistants that explain their changes, avoid hallucinations, and help maintain quality code. As codebases evolve, small AI shortcuts can quickly turn into maintenance debt and other bottlenecks, pushing developers toward tools that act like careful collaborators rather than overeager generators.\n\n### 4. Repo understanding, context management & workflow fit\n\nOne of the clearest dividing lines between AI coding tools is how well they understand the entire project, not just the file currently being edited. Agentic tools like Cursor, Cline, Aider, and Windsurf are frequently praised for their ability to index repositories, track dependencies, link related files, and maintain multi-step reasoning across tasks.\n\nReddit threads often dissect semantic search, embeddings, context window limits, and IDE integration, but these discussions increasingly converge on what is now often described as _context engineering_ _._ The underlying requirement is straightforward: tools must reliably maintain, retrieve, and update relevant project context as work progresses. In both large monoliths and distributed microservice environments, effective context engineering has become a key differentiator.\n\n### 5. Privacy, security & control over data\n\nAs AI coding agents become fully integrated into core development workflows, privacy has also become a major differentiator, especially in professional environments.\n\nOn Reddit, developers frequently ask whether a tool trains on their code, stores telemetry, or sends sensitive snippets to the cloud. Some companies outright block cloud-based assistants over IP or compliance concerns, while others mandate internal LLMs or self-hosted agents as a condition of use.\n\nWhy does this matter? Because trust is foundational. If developers feel uneasy about sharing proprietary logic, architecture, or client data, they simply won’t use the tool, no matter how powerful it is. The more AI becomes part of the day-to-day development process, the more control teams want over where their code goes and how it’s used.\n\nWhat are the best AI coding agents for 2026?\n--------------------------------------------\n\nWith 2026 on the horizon, developer consensus has largely settled on one point: there is no single “best” AI coding agent in isolation. Instead, developers evaluate tools based on where they want leverage: speed and flow inside the editor, control and reliability on large codebases, or greater autonomy higher up the stack. That said, a small number of tools have clearly emerged as front-runners.\n\nThe following section outlines the best AI coding agents on the market, informed by recent Reddit threads and developer forum conversations, as well as firsthand usage across our own networks. It spans widely adopted and praised tools, followed by more niche runner-ups with sharper trade-offs, and then a set of emerging tools that developers should keep an eye out for.\n\n| Adoption & Maturity | Representative Tools |\n| --- | --- |\n| Front-Runners | Cursor, Claude Code, Codex, GitHub Copilot, Cline |\n| Runner Ups | RooCode, Windsurf, Aider, Augment, JetBrains Junie, Gemini CLI |\n| Emerging | AWS Kiro, Kilo Code, Zencoder |\n\nBest AI coding tools summary\n\nLet’s start with the top choices:\n\n### Cursor: the default AI IDE for everyday shipping\n\nAt the time of writing this, Cursor remains the most broadly adopted AI coding tool among individual developers and small teams according to Reddit. In 2025 threads, it’s often treated as the baseline: even when people prefer other agents, Cursor is still what they compare against.\n\nCursor’s main strength is flow. Autocomplete feels fast and useful, chat lives directly inside the editor, and small-to-medium scoped tasks (feature tweaks, refactors, tests, bug fixes) are handled with minimal friction. Many developers describe Cursor as the tool that “just stays out of the way” while quietly making them faster.\n\nWhere Cursor draws criticism is on larger, more complex changes. Recent threads still report issues with long-running refactors, looping behavior, or incomplete repo-wide understanding.\n\nCursor pricing and plan changes are also a top concern, with _“Cursor: pay more, get less, and don’t ask how it works”_ and similar threads garnering ample community engagement.\n\n### Claude Code: the strongest “coding brain”\n\nIf Cursor is about flow, Claude Code is about intelligence. Across late-2025 discussions, Claude Code (and Claude-powered setups more generally) is repeatedly described as the most capable model for deep reasoning, debugging, and architectural changes. So if you’ve been wondering, _is Claude Code worth it?_ The answer is a resounding yes.\n\nDevelopers often say they trust Claude Code with the hardest problems: unraveling subtle bugs, reasoning about unfamiliar codebases, or making design-level changes. In many setups, Claude Code is not the primary IDE, but the escalation path when other tools fail. The developers at Faros AI echo this sentiment. Many developers use Claude Code almost exclusively, impressed by its speed, intelligence, and overall ease of use.\n\nThe drawbacks are practical rather than philosophical. Cost comes up frequently, and some users feel Claude performs better when accessed through other tools, like Cline or Aider, which give more explicit control over context and prompts. Still, when people talk about “best AI for coding” in abstract terms, Claude remains the most agreed-upon answer.\n\n### Codex: a first-class, agent-native coding platform\n\nCodex has re-emerged in 2025 as a serious, agent-first coding tool rather than just a legacy model name. In newer Reddit threads, it’s increasingly discussed alongside Claude Code as a standalone agent you run against real repositories, and no longer just a passive autocomplete assistant.\n\nDevelopers like Codex for its follow-through. It’s often described as more deterministic on multi-step tasks: understanding repo structure, making coordinated changes, running tests, and iterating without drifting. Codex shows up most often in CLI- and workflow-oriented discussions, where people treat it as something you aim at a task and let work, rather than something that lives permanently in the editor.\n\nThe main drawbacks are adoption and clarity. Codex doesn’t yet have the “default IDE” mindshare of Cursor or Copilot, and some developers say pricing and long-running agent costs can feel opaque. As a result, Codex is usually chosen deliberately by developers who want an agent they can trust with bigger jobs, rather than discovered accidentally as part of an editor setup.\n\n### GitHub Copilot (Agent Mode): the pragmatic default\n\nCopilot continues to dominate by sheer presence. For many developers, especially those working for companies considered “Microsoft shops”, it’s already installed, approved, and integrated into existing workflows. In 2025, the conversation shifted away from basic autocomplete and toward Copilot’s newer agent and workspace features.\n\nWhat keeps Copilot near the top is frictionlessness. Copilot’s inline suggestions are fast, agent mode is “good enough” for many repo-level tasks, and it fits cleanly into enterprise environments. For a large segment of developers, Copilot may not be the best tool, but it is one of the easiest.\n\nCriticism tends to come from power users. Compared to Claude Code agents, some developers describe Copilot as less impressive on complex reasoning. Quotas, opaque model choices, and limits on customization also surface when developers push it harder.\n\n### Cline: VS Code agent for developers who want control\n\nCline shows up consistently in newer threads as the tool people adopt once they decide they want more than an AI IDE can offer. It’s commonly framed as the VS Code-native way to run serious agent workflows without being locked into a single provider.\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> AIコーディングエージェントの比較情報を確認しました。次に、具体的なツールの特性を理解するために、Cursorの情報を収集してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"},{"title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","text":"Sources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.","index":31,"favicon":"","host_name":"www.techment.com"},{"title":"Retrieval-augmented generation (RAG) for business","url":"https://www.meilisearch.com/blog/rag-for-business","text":"Best practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...","index":32,"favicon":"","host_name":"www.meilisearch.com"},{"title":"What Is RAG (Retrieval-Augmented Generation)? A Full","url":"https://www.snowflake.com/en/fundamentals/rag","text":"RAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.","index":33,"favicon":"","host_name":"www.snowflake.com"},{"title":"How Retrieval-Augmented Generation Powers Enterprise AI","url":"https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag","text":"Discover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...","index":34,"favicon":"","host_name":"www.grazitti.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"RAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...","index":35,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Title: RAG (Retrieval-Augmented Generation) Best Practices","url":"https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m","text":"Great overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...","index":36,"favicon":"","host_name":"www.linkedin.com"},{"title":"Documentation best practices for RAG applications","url":"https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html","text":"Learn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.","index":37,"favicon":"","host_name":"docs.aws.amazon.com"},{"title":"Retrieval best practices : r/Rag","url":"https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices","text":"My impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...","index":38,"favicon":"","host_name":"www.reddit.com"},{"title":"How Retrieval-Augmented Generation (RAG) Builds","url":"https://qat.com/rag-for-business-leaders","text":"Get proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.","index":39,"favicon":"","host_name":"qat.com"},{"title":"Enterprise-Grade AI: A Visual Deep-Dive into Advanced","url":"https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a","text":"Retrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.","index":40,"favicon":"","host_name":"itsjb13.medium.com"},{"title":"GitHub Copilot vs Cursor : AI Code Editor Review for 2026","url":"https://www.digitalocean.com/resources/articles/github-copilot-vs-cursor","text":"Copilot excels in inline code completion, tight GitHub/IDE integration, and quick turnaround for common coding tasks. Cursor focuses on ...","index":41,"favicon":"","host_name":"www.digitalocean.com"},{"title":"Cursor vs Copilot vs Clark: Which Is the Best in 2026?","url":"https://www.superblocks.com/blog/cursor-vs-copilot","text":"Cursor and Copilot are great for in-IDE AI assistance, but Clark is the best for building enterprise internal apps.","index":42,"favicon":"","host_name":"www.superblocks.com"},{"title":"Visual Studio + GitHub Copilot vs Cursor : r/dotnet","url":"https://www.reddit.com/r/dotnet/comments/1pndbtt/visual_studio_github_copilot_vs_cursor","text":"I use Visual Studio 2026 with GitHub Copilot linked to Claude Sonnet 4.5 and am relatively happy with it. I use CONTRIBUTING.md to describe ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Best AI Coding Agents for 2026: Real-World Developer","url":"https://www.faros.ai/blog/best-ai-coding-agents-2026","text":"A developer-focused look at the best AI coding agents in 2026, comparing Claude Code, Cursor, Codex, Copilot, Cline, and more—with guidance ...","index":44,"favicon":"","host_name":"www.faros.ai"},{"title":"Best AI Coding Assistants as of January 2026","url":"https://www.shakudo.io/blog/best-ai-coding-assistants","text":"The most famous AI pair-programmer, Copilot integrates into VS Code, Visual Studio, JetBrains, etc. It's powered by OpenAI's Codex and GPT-4 ...","index":45,"favicon":"","host_name":"www.shakudo.io"},{"title":"Battle of the AI agents: Cursor vs. Copilot","url":"https://nearform.com/digital-community/battle-of-the-ai-agents","text":"At the time of this post's writing, Github's Copilot agent mode feature is in preview, and only available via the Insiders version of VS Code.","index":46,"favicon":"","host_name":"nearform.com"},{"title":"Best AI Code Editors 2026 (I Tested 10+)","url":"https://playcode.io/blog/best-ai-code-editors-2026","text":"I tested 10+ AI code editors in 2026. Compare Cursor, VS Code + Copilot, PlayCode, Windsurf, Zed, and more. Find the best AI-powered editor ...","index":47,"favicon":"","host_name":"playcode.io"},{"title":"Cursor vs GitHub Copilot: Which AI Coding Tool Is Better in","url":"https://byclaritytech.com/cursor-vs-github-copilot","text":"In 2026, Cursor AI will represent the future of AI-native software development. GitHub Copilot will continue to be the best, most reliable and ...","index":48,"favicon":"","host_name":"byclaritytech.com"},{"title":"Visual Studio With GitHub Copilot - AI Pair Programming","url":"https://visualstudio.microsoft.com/github-copilot","text":"GitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other ...","index":49,"favicon":"","host_name":"visualstudio.microsoft.com"},{"title":"Cursor vs VS Code: AI Coding Editor Showdown","url":"https://www.augmentcode.com/tools/cursor-vs-vscode-comparison-guide","text":"Workflow Integration Depth: Cursor requires switching to a VS Code fork with custom UI modifications. GitHub Copilot integrates with existing ...","index":50,"favicon":"","host_name":"www.augmentcode.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor integrated within GitHub, showing AI-powered code review and debugging assistance. The interface is displayed over a scenic ...","index":51,"favicon":"","host_name":"cursor.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":52,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":53,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":54,"favicon":"","host_name":"medium.com"},{"title":"Changelog","url":"https://cursor.com/changelog","text":"This release introduces new CLI controls for models, MCP management, rules and commands, alongside major hooks performance improvements and ...","index":55,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":56,"favicon":"","host_name":"daily.dev"},{"title":"How To Use Cursor AI: A Complete Guide With Practical","url":"https://www.codecademy.com/article/how-to-use-cursor-ai-a-complete-guide-with-practical-examples","text":"Features and use cases of cursor AI · AI chat interface · Code generation and autocomplete · Codebase understanding and navigation · Code improvement and ...","index":57,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":58,"favicon":"","host_name":"monday.com"},{"title":"Cursor IDE AI: A Beginner's Guide to Coding","url":"https://www.mindbowser.com/cursor-ide-ai-guide","text":"Cursor IDE AI is an AI-powered code editor that helps you write, debug, and refactor code faster with built-in intelligence.","index":59,"favicon":"","host_name":"www.mindbowser.com"},{"title":"@ Mentions | Cursor Docs","url":"https://cursor.com/docs/context/mentions","text":"The @Docs feature lets you use documentation to help write code. Cursor includes popular documentation and you can add your own. Using existing documentation.","index":60,"favicon":"","host_name":"cursor.com"}]},"metadata":{"arguments":"{\"query\":\"Cursor AI IDE 2026 official documentation features\"}","display_result":"","duration":"2s","id":"call_XLBtgXkxO9","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【50†Features · Cursor†https://cursor.com/features】\nIt's a demonstration of Cursor integrated within GitHub, showing AI-powered code review and debugging assistance. The interface is displayed over a scenic ...\n\n【51†Cursor IDE†https://cursor.com】\nIt's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...\n\n【52†Cursor Docs†https://cursor.com/docs】\nCursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.\n\n【53†Cursor AI-IDE Functional Overview and Implementation†https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76】\nKey Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...\n\n【54†Changelog†https://cursor.com/changelog】\nThis release introduces new CLI controls for models, MCP management, rules and commands, alongside major hooks performance improvements and ...\n\n【55†Cursor AI Explained: Features, Pricing & Honest Review†https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place】\nMain features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...\n\n【56†How To Use Cursor AI: A Complete Guide With Practical†https://www.codecademy.com/article/how-to-use-cursor-ai-a-complete-guide-with-practical-examples】\nFeatures and use cases of cursor AI · AI chat interface · Code generation and autocomplete · Codebase understanding and navigation · Code improvement and ...\n\n【57†Cursor AI Integration for Developers: The Ultimate 2026†https://monday.com/blog/rnd/cursor-ai-integration】\nThis guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...\n\n【58†Cursor IDE AI: A Beginner's Guide to Coding†https://www.mindbowser.com/cursor-ide-ai-guide】\nCursor IDE AI is an AI-powered code editor that helps you write, debug, and refactor code faster with built-in intelligence.\n\n【59†@ Mentions | Cursor Docs†https://cursor.com/docs/context/mentions】\nThe @Docs feature lets you use documentation to help write code. Cursor includes popular documentation and you can add your own. Using existing documentation.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="search">
> Cursorの公式ドキュメントを確認しました。次に、具体的な機能を確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://cursor.com/docs","title":"Cursor Docs","content":"【52†Cursor Docs†https://cursor.com/docs】\nTitle: Cursor Docs\n\nURL Source: https://cursor.com/docs\n\nMarkdown Content:\nGet Started\n\nCursor Documentation\n--------------------\n\nCursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language. Just describe what you want to build or change and Cursor will generate the code for you.\n\nModels\n------\n\nSee all models attributes in the Models page.\n\n| Name | Default Context | Max Mode |  |\n| --- | --- | --- | --- |\n| Claude 4.5 Opus | 200k | 200k |  |\n| Claude 4.5 Sonnet | 200k | 1M |  |\n| Composer 1 | 200k | - |  |\n| Gemini 3 Flash | 200k | 1M |  |\n| Gemini 3 Pro | 200k | 1M |  |\n| GPT-5.1 Codex Max | 272k | - |  |\n| GPT-5.2 | 272k | - |  |\n| Grok Code | 256k | - |  |\n\nLearn more\n----------\n\nGet started Download, install, and start building with Cursor in minutes Changelog Stay up to date with the latest features and improvements Concepts Understand core concepts and features that power Cursor Downloads Get Cursor for your computer Forum For technical queries and to share experiences, visit our forum Support For account and billing questions, email our support team\n\n"},"metadata":{"arguments":"{\"link_id\":52}","display_result":"","duration":"7s","id":"call_Z7rcHIQNmA","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【52†Cursor Docs†https://cursor.com/docs】\nTitle: Cursor Docs\n\nURL Source: https://cursor.com/docs\n\nMarkdown Content:\nGet Started\n\nCursor Documentation\n--------------------\n\nCursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language. Just describe what you want to build or change and Cursor will generate the code for you.\n\nModels\n------\n\nSee all models attributes in the Models page.\n\n| Name | Default Context | Max Mode |  |\n| --- | --- | --- | --- |\n| Claude 4.5 Opus | 200k | 200k |  |\n| Claude 4.5 Sonnet | 200k | 1M |  |\n| Composer 1 | 200k | - |  |\n| Gemini 3 Flash | 200k | 1M |  |\n| Gemini 3 Pro | 200k | 1M |  |\n| GPT-5.1 Codex Max | 272k | - |  |\n| GPT-5.2 | 272k | - |  |\n| Grok Code | 256k | - |  |\n\nLearn more\n----------\n\nGet started Download, install, and start building with Cursor in minutes Changelog Stay up to date with the latest features and improvements Concepts Understand core concepts and features that power Cursor Downloads Get Cursor for your computer Forum For technical queries and to share experiences, visit our forum Support For account and billing questions, email our support team\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="click">
> Cursorのドキュメントを確認しました。次に、具体的な概念ページを確認してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"},{"title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","text":"Sources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.","index":31,"favicon":"","host_name":"www.techment.com"},{"title":"Retrieval-augmented generation (RAG) for business","url":"https://www.meilisearch.com/blog/rag-for-business","text":"Best practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...","index":32,"favicon":"","host_name":"www.meilisearch.com"},{"title":"What Is RAG (Retrieval-Augmented Generation)? A Full","url":"https://www.snowflake.com/en/fundamentals/rag","text":"RAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.","index":33,"favicon":"","host_name":"www.snowflake.com"},{"title":"How Retrieval-Augmented Generation Powers Enterprise AI","url":"https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag","text":"Discover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...","index":34,"favicon":"","host_name":"www.grazitti.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"RAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...","index":35,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Title: RAG (Retrieval-Augmented Generation) Best Practices","url":"https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m","text":"Great overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...","index":36,"favicon":"","host_name":"www.linkedin.com"},{"title":"Documentation best practices for RAG applications","url":"https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html","text":"Learn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.","index":37,"favicon":"","host_name":"docs.aws.amazon.com"},{"title":"Retrieval best practices : r/Rag","url":"https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices","text":"My impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...","index":38,"favicon":"","host_name":"www.reddit.com"},{"title":"How Retrieval-Augmented Generation (RAG) Builds","url":"https://qat.com/rag-for-business-leaders","text":"Get proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.","index":39,"favicon":"","host_name":"qat.com"},{"title":"Enterprise-Grade AI: A Visual Deep-Dive into Advanced","url":"https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a","text":"Retrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.","index":40,"favicon":"","host_name":"itsjb13.medium.com"},{"title":"GitHub Copilot vs Cursor : AI Code Editor Review for 2026","url":"https://www.digitalocean.com/resources/articles/github-copilot-vs-cursor","text":"Copilot excels in inline code completion, tight GitHub/IDE integration, and quick turnaround for common coding tasks. Cursor focuses on ...","index":41,"favicon":"","host_name":"www.digitalocean.com"},{"title":"Cursor vs Copilot vs Clark: Which Is the Best in 2026?","url":"https://www.superblocks.com/blog/cursor-vs-copilot","text":"Cursor and Copilot are great for in-IDE AI assistance, but Clark is the best for building enterprise internal apps.","index":42,"favicon":"","host_name":"www.superblocks.com"},{"title":"Visual Studio + GitHub Copilot vs Cursor : r/dotnet","url":"https://www.reddit.com/r/dotnet/comments/1pndbtt/visual_studio_github_copilot_vs_cursor","text":"I use Visual Studio 2026 with GitHub Copilot linked to Claude Sonnet 4.5 and am relatively happy with it. I use CONTRIBUTING.md to describe ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Best AI Coding Agents for 2026: Real-World Developer","url":"https://www.faros.ai/blog/best-ai-coding-agents-2026","text":"A developer-focused look at the best AI coding agents in 2026, comparing Claude Code, Cursor, Codex, Copilot, Cline, and more—with guidance ...","index":44,"favicon":"","host_name":"www.faros.ai"},{"title":"Best AI Coding Assistants as of January 2026","url":"https://www.shakudo.io/blog/best-ai-coding-assistants","text":"The most famous AI pair-programmer, Copilot integrates into VS Code, Visual Studio, JetBrains, etc. It's powered by OpenAI's Codex and GPT-4 ...","index":45,"favicon":"","host_name":"www.shakudo.io"},{"title":"Battle of the AI agents: Cursor vs. Copilot","url":"https://nearform.com/digital-community/battle-of-the-ai-agents","text":"At the time of this post's writing, Github's Copilot agent mode feature is in preview, and only available via the Insiders version of VS Code.","index":46,"favicon":"","host_name":"nearform.com"},{"title":"Best AI Code Editors 2026 (I Tested 10+)","url":"https://playcode.io/blog/best-ai-code-editors-2026","text":"I tested 10+ AI code editors in 2026. Compare Cursor, VS Code + Copilot, PlayCode, Windsurf, Zed, and more. Find the best AI-powered editor ...","index":47,"favicon":"","host_name":"playcode.io"},{"title":"Cursor vs GitHub Copilot: Which AI Coding Tool Is Better in","url":"https://byclaritytech.com/cursor-vs-github-copilot","text":"In 2026, Cursor AI will represent the future of AI-native software development. GitHub Copilot will continue to be the best, most reliable and ...","index":48,"favicon":"","host_name":"byclaritytech.com"},{"title":"Visual Studio With GitHub Copilot - AI Pair Programming","url":"https://visualstudio.microsoft.com/github-copilot","text":"GitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other ...","index":49,"favicon":"","host_name":"visualstudio.microsoft.com"},{"title":"Cursor vs VS Code: AI Coding Editor Showdown","url":"https://www.augmentcode.com/tools/cursor-vs-vscode-comparison-guide","text":"Workflow Integration Depth: Cursor requires switching to a VS Code fork with custom UI modifications. GitHub Copilot integrates with existing ...","index":50,"favicon":"","host_name":"www.augmentcode.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor integrated within GitHub, showing AI-powered code review and debugging assistance. The interface is displayed over a scenic ...","index":51,"favicon":"","host_name":"cursor.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":52,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":53,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":54,"favicon":"","host_name":"medium.com"},{"title":"Changelog","url":"https://cursor.com/changelog","text":"This release introduces new CLI controls for models, MCP management, rules and commands, alongside major hooks performance improvements and ...","index":55,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":56,"favicon":"","host_name":"daily.dev"},{"title":"How To Use Cursor AI: A Complete Guide With Practical","url":"https://www.codecademy.com/article/how-to-use-cursor-ai-a-complete-guide-with-practical-examples","text":"Features and use cases of cursor AI · AI chat interface · Code generation and autocomplete · Codebase understanding and navigation · Code improvement and ...","index":57,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":58,"favicon":"","host_name":"monday.com"},{"title":"Cursor IDE AI: A Beginner's Guide to Coding","url":"https://www.mindbowser.com/cursor-ide-ai-guide","text":"Cursor IDE AI is an AI-powered code editor that helps you write, debug, and refactor code faster with built-in intelligence.","index":59,"favicon":"","host_name":"www.mindbowser.com"},{"title":"@ Mentions | Cursor Docs","url":"https://cursor.com/docs/context/mentions","text":"The @Docs feature lets you use documentation to help write code. Cursor includes popular documentation and you can add your own. Using existing documentation.","index":60,"favicon":"","host_name":"cursor.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":61,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":62,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":63,"favicon":"","host_name":"monday.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":64,"favicon":"","host_name":"daily.dev"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. This element contains an interactive demo for sighted users showing ...","index":65,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":66,"favicon":"","host_name":"medium.com"},{"title":"Concepts | Cursor Docs","url":"https://cursor.com/docs/get-started/concepts","text":"Understand core Cursor concepts including Agent, Inline Edit, Tab autocomplete, and how AI models work. Learn the fundamentals of AI-assisted coding.","index":67,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Changelog: What's coming next in 2026?","url":"https://blog.promptlayer.com/cursor-changelog-whats-coming-next-in-2026","text":"Cursor 1.7's ability to read workspace images was just the start. In 2026, expect full multimodal support, agents that can understand diagrams, ...","index":68,"favicon":"","host_name":"blog.promptlayer.com"},{"title":"Cursor 2.0: New AI Model Explained","url":"https://www.codecademy.com/article/cursor-2-0-new-ai-model-explained","text":"Explore Cursor 2.0 to code faster with Composer, run multi-agent workflows, and try its new agent-first interface.","index":69,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Review 2026: Honest Pros, Cons & Is It Worth $20","url":"https://www.nxcode.io/resources/news/cursor-review-2026","text":"Unlike GitHub Copilot (which adds AI to VS Code), Cursor rebuilt the editor around AI. Every feature is designed for AI-assisted development.","index":70,"favicon":"","host_name":"www.nxcode.io"}]},"metadata":{"arguments":"{\"query\":\"Cursor AI IDE concepts features documentation 2026\"}","display_result":"","duration":"2s","id":"call_dxzc4ye8Jt","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【60†Features · Cursor†https://cursor.com/features】\nIt's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...\n\n【61†Cursor Docs†https://cursor.com/docs】\nCursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.\n\n【62†Cursor AI Integration for Developers: The Ultimate 2026†https://monday.com/blog/rnd/cursor-ai-integration】\nThis guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...\n\n【63†Cursor AI Explained: Features, Pricing & Honest Review†https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place】\nMain features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...\n\n【64†Cursor IDE†https://cursor.com】\nBuilt to make you extraordinarily productive, Cursor is the best way to code with AI. This element contains an interactive demo for sighted users showing ...\n\n【65†Cursor AI-IDE Functional Overview and Implementation†https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76】\nKey Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...\n\n【66†Concepts | Cursor Docs†https://cursor.com/docs/get-started/concepts】\nUnderstand core Cursor concepts including Agent, Inline Edit, Tab autocomplete, and how AI models work. Learn the fundamentals of AI-assisted coding.\n\n【67†Cursor Changelog: What's coming next in 2026?†https://blog.promptlayer.com/cursor-changelog-whats-coming-next-in-2026】\nCursor 1.7's ability to read workspace images was just the start. In 2026, expect full multimodal support, agents that can understand diagrams, ...\n\n【68†Cursor 2.0: New AI Model Explained†https://www.codecademy.com/article/cursor-2-0-new-ai-model-explained】\nExplore Cursor 2.0 to code faster with Composer, run multi-agent workflows, and try its new agent-first interface.\n\n【69†Cursor AI Review 2026: Honest Pros, Cons & Is It Worth $20†https://www.nxcode.io/resources/news/cursor-review-2026】\nUnlike GitHub Copilot (which adds AI to VS Code), Cursor rebuilt the editor around AI. Every feature is designed for AI-assisted development.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> Cursorのコンセプトページを確認しました。次に、具体的な機能を理解するために、機能ページを確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://cursor.com/docs/get-started/concepts","title":"Concepts | Cursor Docs","content":"【66†Concepts | Cursor Docs†https://cursor.com/docs/get-started/concepts】\nTitle: Concepts | Cursor Docs\n\nURL Source: https://cursor.com/docs/get-started/concepts\n\nMarkdown Content:\nGet Started\n\nCheck out our learning guides covering AI models, context, agents, and more.\n\nTab ---\nCode completion that predicts multi-line edits. Press Tab to accept suggestions based on your current code and recent changes.\n\nAgent -----\nAn AI that can read and modify code across multiple files. Describe changes in natural language and Agent executes them.\n\nInline Edit -----------\nEdit selected code with natural language. Press Cmd+K Ctrl+K to describe changes and see them applied in place.\n\nChat ----\nInterface for AI conversations. Supports multiple tabs, conversation history, checkpoints, and export functionality.\n\nRules -----\nCustom instructions that define AI behavior. Set coding standards, framework preferences, and project-specific conventions.\n\nCodebase Indexing -----------------\nSemantic analysis of your codebase. Enables code search, reference finding, and context-aware suggestions.\n\nMCP ---\nModel Context Protocol for integrating external tools. Connects to databases, APIs, and documentation sources.\n\nContext -------\nInformation provided to AI models during code generation. Includes files, symbols, and conversation history.\n\nModels ------\nDifferent AI models available for code generation. Each model has different speed and capability characteristics.\n\n"},"metadata":{"arguments":"{\"link_id\":66}","display_result":"","duration":"7s","id":"call_oolKTWBz5E","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【66†Concepts | Cursor Docs†https://cursor.com/docs/get-started/concepts】\nTitle: Concepts | Cursor Docs\n\nURL Source: https://cursor.com/docs/get-started/concepts\n\nMarkdown Content:\nGet Started\n\nCheck out our learning guides covering AI models, context, agents, and more.\n\nTab ---\nCode completion that predicts multi-line edits. Press Tab to accept suggestions based on your current code and recent changes.\n\nAgent -----\nAn AI that can read and modify code across multiple files. Describe changes in natural language and Agent executes them.\n\nInline Edit -----------\nEdit selected code with natural language. Press Cmd+K Ctrl+K to describe changes and see them applied in place.\n\nChat ----\nInterface for AI conversations. Supports multiple tabs, conversation history, checkpoints, and export functionality.\n\nRules -----\nCustom instructions that define AI behavior. Set coding standards, framework preferences, and project-specific conventions.\n\nCodebase Indexing -----------------\nSemantic analysis of your codebase. Enables code search, reference finding, and context-aware suggestions.\n\nMCP ---\nModel Context Protocol for integrating external tools. Connects to databases, APIs, and documentation sources.\n\nContext -------\nInformation provided to AI models during code generation. Includes files, symbols, and conversation history.\n\nModels ------\nDifferent AI models available for code generation. Each model has different speed and capability characteristics.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="click">
> Cursorのコンセプトを確認しました。次に、Claude Codeについての情報を収集してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"},{"title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","text":"Sources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.","index":31,"favicon":"","host_name":"www.techment.com"},{"title":"Retrieval-augmented generation (RAG) for business","url":"https://www.meilisearch.com/blog/rag-for-business","text":"Best practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...","index":32,"favicon":"","host_name":"www.meilisearch.com"},{"title":"What Is RAG (Retrieval-Augmented Generation)? A Full","url":"https://www.snowflake.com/en/fundamentals/rag","text":"RAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.","index":33,"favicon":"","host_name":"www.snowflake.com"},{"title":"How Retrieval-Augmented Generation Powers Enterprise AI","url":"https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag","text":"Discover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...","index":34,"favicon":"","host_name":"www.grazitti.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"RAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...","index":35,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Title: RAG (Retrieval-Augmented Generation) Best Practices","url":"https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m","text":"Great overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...","index":36,"favicon":"","host_name":"www.linkedin.com"},{"title":"Documentation best practices for RAG applications","url":"https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html","text":"Learn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.","index":37,"favicon":"","host_name":"docs.aws.amazon.com"},{"title":"Retrieval best practices : r/Rag","url":"https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices","text":"My impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...","index":38,"favicon":"","host_name":"www.reddit.com"},{"title":"How Retrieval-Augmented Generation (RAG) Builds","url":"https://qat.com/rag-for-business-leaders","text":"Get proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.","index":39,"favicon":"","host_name":"qat.com"},{"title":"Enterprise-Grade AI: A Visual Deep-Dive into Advanced","url":"https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a","text":"Retrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.","index":40,"favicon":"","host_name":"itsjb13.medium.com"},{"title":"GitHub Copilot vs Cursor : AI Code Editor Review for 2026","url":"https://www.digitalocean.com/resources/articles/github-copilot-vs-cursor","text":"Copilot excels in inline code completion, tight GitHub/IDE integration, and quick turnaround for common coding tasks. Cursor focuses on ...","index":41,"favicon":"","host_name":"www.digitalocean.com"},{"title":"Cursor vs Copilot vs Clark: Which Is the Best in 2026?","url":"https://www.superblocks.com/blog/cursor-vs-copilot","text":"Cursor and Copilot are great for in-IDE AI assistance, but Clark is the best for building enterprise internal apps.","index":42,"favicon":"","host_name":"www.superblocks.com"},{"title":"Visual Studio + GitHub Copilot vs Cursor : r/dotnet","url":"https://www.reddit.com/r/dotnet/comments/1pndbtt/visual_studio_github_copilot_vs_cursor","text":"I use Visual Studio 2026 with GitHub Copilot linked to Claude Sonnet 4.5 and am relatively happy with it. I use CONTRIBUTING.md to describe ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Best AI Coding Agents for 2026: Real-World Developer","url":"https://www.faros.ai/blog/best-ai-coding-agents-2026","text":"A developer-focused look at the best AI coding agents in 2026, comparing Claude Code, Cursor, Codex, Copilot, Cline, and more—with guidance ...","index":44,"favicon":"","host_name":"www.faros.ai"},{"title":"Best AI Coding Assistants as of January 2026","url":"https://www.shakudo.io/blog/best-ai-coding-assistants","text":"The most famous AI pair-programmer, Copilot integrates into VS Code, Visual Studio, JetBrains, etc. It's powered by OpenAI's Codex and GPT-4 ...","index":45,"favicon":"","host_name":"www.shakudo.io"},{"title":"Battle of the AI agents: Cursor vs. Copilot","url":"https://nearform.com/digital-community/battle-of-the-ai-agents","text":"At the time of this post's writing, Github's Copilot agent mode feature is in preview, and only available via the Insiders version of VS Code.","index":46,"favicon":"","host_name":"nearform.com"},{"title":"Best AI Code Editors 2026 (I Tested 10+)","url":"https://playcode.io/blog/best-ai-code-editors-2026","text":"I tested 10+ AI code editors in 2026. Compare Cursor, VS Code + Copilot, PlayCode, Windsurf, Zed, and more. Find the best AI-powered editor ...","index":47,"favicon":"","host_name":"playcode.io"},{"title":"Cursor vs GitHub Copilot: Which AI Coding Tool Is Better in","url":"https://byclaritytech.com/cursor-vs-github-copilot","text":"In 2026, Cursor AI will represent the future of AI-native software development. GitHub Copilot will continue to be the best, most reliable and ...","index":48,"favicon":"","host_name":"byclaritytech.com"},{"title":"Visual Studio With GitHub Copilot - AI Pair Programming","url":"https://visualstudio.microsoft.com/github-copilot","text":"GitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other ...","index":49,"favicon":"","host_name":"visualstudio.microsoft.com"},{"title":"Cursor vs VS Code: AI Coding Editor Showdown","url":"https://www.augmentcode.com/tools/cursor-vs-vscode-comparison-guide","text":"Workflow Integration Depth: Cursor requires switching to a VS Code fork with custom UI modifications. GitHub Copilot integrates with existing ...","index":50,"favicon":"","host_name":"www.augmentcode.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor integrated within GitHub, showing AI-powered code review and debugging assistance. The interface is displayed over a scenic ...","index":51,"favicon":"","host_name":"cursor.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":52,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":53,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":54,"favicon":"","host_name":"medium.com"},{"title":"Changelog","url":"https://cursor.com/changelog","text":"This release introduces new CLI controls for models, MCP management, rules and commands, alongside major hooks performance improvements and ...","index":55,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":56,"favicon":"","host_name":"daily.dev"},{"title":"How To Use Cursor AI: A Complete Guide With Practical","url":"https://www.codecademy.com/article/how-to-use-cursor-ai-a-complete-guide-with-practical-examples","text":"Features and use cases of cursor AI · AI chat interface · Code generation and autocomplete · Codebase understanding and navigation · Code improvement and ...","index":57,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":58,"favicon":"","host_name":"monday.com"},{"title":"Cursor IDE AI: A Beginner's Guide to Coding","url":"https://www.mindbowser.com/cursor-ide-ai-guide","text":"Cursor IDE AI is an AI-powered code editor that helps you write, debug, and refactor code faster with built-in intelligence.","index":59,"favicon":"","host_name":"www.mindbowser.com"},{"title":"@ Mentions | Cursor Docs","url":"https://cursor.com/docs/context/mentions","text":"The @Docs feature lets you use documentation to help write code. Cursor includes popular documentation and you can add your own. Using existing documentation.","index":60,"favicon":"","host_name":"cursor.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":61,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":62,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":63,"favicon":"","host_name":"monday.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":64,"favicon":"","host_name":"daily.dev"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. This element contains an interactive demo for sighted users showing ...","index":65,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":66,"favicon":"","host_name":"medium.com"},{"title":"Concepts | Cursor Docs","url":"https://cursor.com/docs/get-started/concepts","text":"Understand core Cursor concepts including Agent, Inline Edit, Tab autocomplete, and how AI models work. Learn the fundamentals of AI-assisted coding.","index":67,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Changelog: What's coming next in 2026?","url":"https://blog.promptlayer.com/cursor-changelog-whats-coming-next-in-2026","text":"Cursor 1.7's ability to read workspace images was just the start. In 2026, expect full multimodal support, agents that can understand diagrams, ...","index":68,"favicon":"","host_name":"blog.promptlayer.com"},{"title":"Cursor 2.0: New AI Model Explained","url":"https://www.codecademy.com/article/cursor-2-0-new-ai-model-explained","text":"Explore Cursor 2.0 to code faster with Composer, run multi-agent workflows, and try its new agent-first interface.","index":69,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Review 2026: Honest Pros, Cons & Is It Worth $20","url":"https://www.nxcode.io/resources/news/cursor-review-2026","text":"Unlike GitHub Copilot (which adds AI to VS Code), Cursor rebuilt the editor around AI. Every feature is designed for AI-assisted development.","index":70,"favicon":"","host_name":"www.nxcode.io"},{"title":"Claude Code overview - Claude Code Docs","url":"https://code.claude.com/docs/en/overview","text":"Learn about Claude Code, Anthropic's agentic coding tool that lives in your terminal and helps you turn ideas into code faster than ever before.","index":71,"favicon":"","host_name":"code.claude.com"},{"title":"Claude Code Documentation | Claude Insider Resources","url":"https://www.claudeinsider.com/resources/claude-code-docs","text":"Official documentation for Claude Code CLI tool - the AI-powered coding assistant.","index":72,"favicon":"","host_name":"www.claudeinsider.com"},{"title":"Claude.ai","url":"https://claude.ai","text":"Claude is a next generation AI assistant built by Anthropic and trained to be safe, accurate, and secure to help you do your best work. · Create with Claude.","index":73,"favicon":"","host_name":"claude.ai"},{"title":"Documentation - Claude Docs","url":"https://platform.claude.com/docs/en/home","text":"Get started with Claude Code. Claude Code reference. Consult the Claude Code reference documentation for details on feature implementation and configuration.","index":74,"favicon":"","host_name":"platform.claude.com"},{"title":"A complete overview of Claude AI coding software","url":"https://www.eesel.ai/en/blog/claude-ai-coding-software","text":"Claude Code is a tool for users who want to build a custom AI assistant. It provides the foundational components for developers to create ...","index":75,"favicon":"","host_name":"www.eesel.ai"},{"title":"The 5 best Claude AI developer tools in 2026 (I tested them","url":"https://www.eesel.ai/en/blog/claude-ai-developer-tools","text":"Claude Code is Anthropic's official developer tool. It is a flexible agent that works in the terminal, IDE (VS Code and JetBrains), Slack, or on ...","index":76,"favicon":"","host_name":"www.eesel.ai"},{"title":"Claude Code: Best practices for agentic coding","url":"https://www.anthropic.com/engineering/claude-code-best-practices","text":"Our comprehensive documentation at claude.ai/code covers all the features mentioned in this post and provides additional examples ...","index":77,"favicon":"","host_name":"www.anthropic.com"},{"title":"How To Use Claude? A Next-Generation AI Assistant","url":"https://www.techcompanynews.com/how-to-use-claude-a-next-generation-ai-assistant","text":"Claude AI is an accessible, safety oriented AI assistant, excelling in tasks like writing, analysis, coding, and problem solving.","index":78,"favicon":"","host_name":"www.techcompanynews.com"},{"title":"AI Coding Assistants in 2026: Understanding Claude","url":"https://dev.to/asad1/ai-coding-assistants-in-2026-understanding-claude-code-and-googles-tools-1a2h","text":"A technical comparison to help you choose the right AI coding tool for your workflow ; Claude Code takes an agentic approach. You delegate tasks ...","index":79,"favicon":"","host_name":"dev.to"},{"title":"Claude Code Skills: Customize your AI Coding Assistant","url":"https://srivatssan.medium.com/claude-code-skills-customize-your-ai-coding-assistant-deep-dive-24e0f578a887","text":"*Claude Code Documentation*. https://code.claude.com ... The Complete Claude Code Guide for Your New Year Resolution: Code Smarter in 2026 ...","index":80,"favicon":"","host_name":"srivatssan.medium.com"}]},"metadata":{"arguments":"{\"query\":\"Claude Code AI assistant 2026 official documentation\"}","display_result":"","duration":"3s","id":"call_Ln8xNXKsy2","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【70†Claude Code overview - Claude Code Docs†https://code.claude.com/docs/en/overview】\nLearn about Claude Code, Anthropic's agentic coding tool that lives in your terminal and helps you turn ideas into code faster than ever before.\n\n【71†Claude Code Documentation | Claude Insider Resources†https://www.claudeinsider.com/resources/claude-code-docs】\nOfficial documentation for Claude Code CLI tool - the AI-powered coding assistant.\n\n【72†Claude.ai†https://claude.ai】\nClaude is a next generation AI assistant built by Anthropic and trained to be safe, accurate, and secure to help you do your best work. · Create with Claude.\n\n【73†Documentation - Claude Docs†https://platform.claude.com/docs/en/home】\nGet started with Claude Code. Claude Code reference. Consult the Claude Code reference documentation for details on feature implementation and configuration.\n\n【74†A complete overview of Claude AI coding software†https://www.eesel.ai/en/blog/claude-ai-coding-software】\nClaude Code is a tool for users who want to build a custom AI assistant. It provides the foundational components for developers to create ...\n\n【75†The 5 best Claude AI developer tools in 2026 (I tested them†https://www.eesel.ai/en/blog/claude-ai-developer-tools】\nClaude Code is Anthropic's official developer tool. It is a flexible agent that works in the terminal, IDE (VS Code and JetBrains), Slack, or on ...\n\n【76†Claude Code: Best practices for agentic coding†https://www.anthropic.com/engineering/claude-code-best-practices】\nOur comprehensive documentation at claude.ai/code covers all the features mentioned in this post and provides additional examples ...\n\n【77†How To Use Claude? A Next-Generation AI Assistant†https://www.techcompanynews.com/how-to-use-claude-a-next-generation-ai-assistant】\nClaude AI is an accessible, safety oriented AI assistant, excelling in tasks like writing, analysis, coding, and problem solving.\n\n【78†AI Coding Assistants in 2026: Understanding Claude†https://dev.to/asad1/ai-coding-assistants-in-2026-understanding-claude-code-and-googles-tools-1a2h】\nA technical comparison to help you choose the right AI coding tool for your workflow ; Claude Code takes an agentic approach. You delegate tasks ...\n\n【79†Claude Code Skills: Customize your AI Coding Assistant†https://srivatssan.medium.com/claude-code-skills-customize-your-ai-coding-assistant-deep-dive-24e0f578a887】\n*Claude Code Documentation*. https://code.claude.com ... The Complete Claude Code Guide for Your New Year Resolution: Code Smarter in 2026 ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="search">
> Claude Codeの公式ドキュメントを確認しました。次に、具体的な概要ページを確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://code.claude.com/docs/en/overview","title":"Claude Code overview - Claude Code Docs","content":"【70†Claude Code overview - Claude Code Docs†https://code.claude.com/docs/en/overview】\nTitle: Claude Code overview - Claude Code Docs\n\nURL Source: https://code.claude.com/docs/en/overview\n\nMarkdown Content:\nGet started in 30 seconds\n-------------------------\n\nPrerequisites:\n\n*   A Claude subscription (Pro, Max, Teams, or Enterprise) or Claude Console account\n\n**Install Claude Code:**To install Claude Code, use one of the following methods:\n\n*   Native Install (Recommended)\n\n*   Homebrew\n\n*   NPM\n\n**macOS, Linux, WSL:**\n\n```\ncurl -fsSL https://claude.ai/install.sh | bash\n```\n\n**Windows PowerShell:**\n\n```\nirm https://claude.ai/install.ps1 | iex\n```\n\n**Windows CMD:**\n\n```\ncurl -fsSL https://claude.ai/install.cmd -o install.cmd && install.cmd && del install.cmd\n```\n\n```\nbrew install --cask claude-code\n```\n\n**Start using Claude Code:**\n\n```\ncd your-project\nclaude\n```\n\nYou’ll be prompted to log in on first use. That’s it! Continue with Quickstart (5 minutes) →\n\nWhat Claude Code does for you\n-----------------------------\n\n*   **Build features from descriptions**: Tell Claude what you want to build in plain English. It will make a plan, write the code, and ensure it works.\n*   **Debug and fix issues**: Describe a bug or paste an error message. Claude Code will analyze your codebase, identify the problem, and implement a fix.\n*   **Navigate any codebase**: Ask anything about your team’s codebase, and get a thoughtful answer back. Claude Code maintains awareness of your entire project structure, can find up-to-date information from the web, and with MCP can pull from external data sources like Google Drive, Figma, and Slack.\n*   **Automate tedious tasks**: Fix fiddly lint issues, resolve merge conflicts, and write release notes. Do all this in a single command from your developer machines, or automatically in CI.\n\nWhy developers love Claude Code\n-------------------------------\n\n*   **Works in your terminal**: Not another chat window. Not another IDE. Claude Code meets you where you already work, with the tools you already love.\n*   **Takes action**: Claude Code can directly edit files, run commands, and create commits. Need more? MCP lets Claude read your design docs in Google Drive, update your tickets in Jira, or use _your_ custom developer tooling.\n*   **Unix philosophy**: Claude Code is composable and scriptable. `tail -f app.log | claude -p \"Slack me if you see any anomalies appear in this log stream\"`_works_. Your CI can run `claude -p \"If there are new text strings, translate them into French and raise a PR for @lang-fr-team to review\"`.\n*   **Enterprise-ready**: Use the Claude API, or host on AWS or GCP. Enterprise-grade security, privacy, and compliance is built-in.\n\nNext steps\n----------\n\nAdditional resources\n--------------------\n\n"},"metadata":{"arguments":"{\"link_id\":70}","display_result":"","duration":"2s","id":"call_lCnpX6HpYd","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【70†Claude Code overview - Claude Code Docs†https://code.claude.com/docs/en/overview】\nTitle: Claude Code overview - Claude Code Docs\n\nURL Source: https://code.claude.com/docs/en/overview\n\nMarkdown Content:\nGet started in 30 seconds\n-------------------------\n\nPrerequisites:\n\n*   A Claude subscription (Pro, Max, Teams, or Enterprise) or Claude Console account\n\n**Install Claude Code:**To install Claude Code, use one of the following methods:\n\n*   Native Install (Recommended)\n\n*   Homebrew\n\n*   NPM\n\n**macOS, Linux, WSL:**\n\n```\ncurl -fsSL https://claude.ai/install.sh | bash\n```\n\n**Windows PowerShell:**\n\n```\nirm https://claude.ai/install.ps1 | iex\n```\n\n**Windows CMD:**\n\n```\ncurl -fsSL https://claude.ai/install.cmd -o install.cmd && install.cmd && del install.cmd\n```\n\n```\nbrew install --cask claude-code\n```\n\n**Start using Claude Code:**\n\n```\ncd your-project\nclaude\n```\n\nYou’ll be prompted to log in on first use. That’s it! Continue with Quickstart (5 minutes) →\n\nWhat Claude Code does for you\n-----------------------------\n\n*   **Build features from descriptions**: Tell Claude what you want to build in plain English. It will make a plan, write the code, and ensure it works.\n*   **Debug and fix issues**: Describe a bug or paste an error message. Claude Code will analyze your codebase, identify the problem, and implement a fix.\n*   **Navigate any codebase**: Ask anything about your team’s codebase, and get a thoughtful answer back. Claude Code maintains awareness of your entire project structure, can find up-to-date information from the web, and with MCP can pull from external data sources like Google Drive, Figma, and Slack.\n*   **Automate tedious tasks**: Fix fiddly lint issues, resolve merge conflicts, and write release notes. Do all this in a single command from your developer machines, or automatically in CI.\n\nWhy developers love Claude Code\n-------------------------------\n\n*   **Works in your terminal**: Not another chat window. Not another IDE. Claude Code meets you where you already work, with the tools you already love.\n*   **Takes action**: Claude Code can directly edit files, run commands, and create commits. Need more? MCP lets Claude read your design docs in Google Drive, update your tickets in Jira, or use _your_ custom developer tooling.\n*   **Unix philosophy**: Claude Code is composable and scriptable. `tail -f app.log | claude -p \"Slack me if you see any anomalies appear in this log stream\"`_works_. Your CI can run `claude -p \"If there are new text strings, translate them into French and raise a PR for @lang-fr-team to review\"`.\n*   **Enterprise-ready**: Use the Claude API, or host on AWS or GCP. Enterprise-grade security, privacy, and compliance is built-in.\n\nNext steps\n----------\n\nAdditional resources\n--------------------\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> Claude Codeの概要を確認しました。次に、MCP（Model Context Protocol）の具体的な活用方法について、公式ドキュメントを確認してみましょう。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"MCP Docs","url":"https://modelcontextprotocol.info/docs","text":"Welcome to the Model Context Protocol documentation! MCP is a standardized protocol designed to enhance the interaction between Large Language Models (LLMs) and ...","index":1,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What is the Model Context Protocol (MCP)? - Model Context","url":"https://modelcontextprotocol.io","text":"MCP (Model Context Protocol) is an open-source standard for connecting AI applications to external systems. Using MCP, AI applications like Claude or ...","index":2,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"The official MCP documentation is built using Mintlify and available at modelcontextprotocol.io. Authors. The Model Context Protocol was created by David ...","index":3,"favicon":"","host_name":"github.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-03-26","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":4,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Model Context Protocol","url":"https://learn.microsoft.com/en-us/agent-framework/user-guide/model-context-protocol","text":"Model Context Protocol is an open standard that defines how applications provide tools and contextual data to large language models (LLMs).","index":5,"favicon":"","host_name":"learn.microsoft.com"},{"title":"What is Model Context Protocol (MCP)?","url":"https://www.ibm.com/think/topics/model-context-protocol","text":"The Model Context Protocol (MCP) serves as a standardization layer for AI applications to communicate effectively with external services such as tools, ...","index":6,"favicon":"","host_name":"www.ibm.com"},{"title":"Model Context Protocol - Support - runZero","url":"https://help.runzero.com/docs/mcp","text":"Model Context Protocol (MCP) is an open protocol that enables seamless integration between LLM applications and external data sources and tools.","index":7,"favicon":"","host_name":"help.runzero.com"},{"title":"Model Context Protocol (MCP)","url":"https://www.librechat.ai/docs/features/mcp","text":"Model Context Protocol (MCP) is an open protocol that standardizes how applications provide context to Large Language Models (LLMs).","index":8,"favicon":"","host_name":"www.librechat.ai"},{"title":"Model Context Protocol (MCP) :: Spring AI Reference","url":"https://docs.spring.io/spring-ai/reference/api/mcp/mcp-overview.html","text":"The Model Context Protocol (MCP) is a standardized protocol that enables AI models to interact with external tools and resources in a structured way.","index":9,"favicon":"","host_name":"docs.spring.io"},{"title":"Model Context Protocol (MCP) Spec Updates from June 2025","url":"https://auth0.com/blog/mcp-specs-update-all-about-auth","text":"Guide to the June 2025 MCP spec updates: Learn about OAuth Resource Servers, mandatory Resource Indicators (RFC 8707), and new security ...","index":10,"favicon":"","host_name":"auth0.com"},{"title":"Specification","url":"https://modelcontextprotocol.io/specification/2025-11-25","text":"The Model Context Protocol enables powerful capabilities through arbitrary data access and code execution paths. With this power comes important ...","index":11,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Overview","url":"https://modelcontextprotocol.io/specification/2025-11-25/basic","text":"MCP provides an Authorization framework for use with HTTP. Implementations using an HTTP-based transport SHOULD conform to this specification, ...","index":12,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"Specification and documentation for the Model Context","url":"https://github.com/modelcontextprotocol/modelcontextprotocol","text":"Specification and documentation for the Model Context Protocol - modelcontextprotocol ... Releases 7 · 2025-11-25 Latest. on Nov 25, 2025 · + 6 releases. Uh oh!","index":13,"favicon":"","host_name":"github.com"},{"title":"Key Changes","url":"https://modelcontextprotocol.io/specification/2025-11-25/changelog","text":"Version 2025-11-25 (latest) ... This document lists changes made to the Model Context Protocol (MCP) specification since the previous revision, ...","index":14,"favicon":"","host_name":"modelcontextprotocol.io"},{"title":"What's New In The 2025-11-25 MCP Authorization Spec","url":"https://den.dev/blog/mcp-november-authorization-spec","text":"We're less than twenty four hours away from the new MCP specification dropping - it will mark the first anniversary of the protocol.","index":15,"favicon":"","host_name":"den.dev"},{"title":"MCP 2025-11-25 is here: async Tasks, better OAuth,","url":"https://workos.com/blog/mcp-2025-11-25-spec-update","text":"Yesterday, the Model Context Protocol (MCP) shipped a new spec revision: 2025-11-25—right on the one-year anniversary of MCP going public.","index":16,"favicon":"","host_name":"workos.com"},{"title":"Update on the Next MCP Protocol Release","url":"https://modelcontextprotocol.info/blog/mcp-next-version-update","text":"The next version of the Model Context Protocol specification will be released on November 25th, 2025, with a release candidate (RC) available on ...","index":17,"favicon":"","host_name":"modelcontextprotocol.info"},{"title":"What the New MCP Specification Means to You, and Your","url":"https://www.lakera.ai/blog/what-the-new-mcp-specification-means-to-you-and-your-agents","text":"The new MCP spec changes how AI agents identify servers, authenticate, run tasks, and manage risk. See what's new and what it means for ...","index":18,"favicon":"","host_name":"www.lakera.ai"},{"title":"One Year of MCP: November 2025 Spec Release","url":"http://blog.modelcontextprotocol.io/posts/2025-11-25-first-mcp-anniversary","text":"“In just one year, the Model Context Protocol has proven to be a critical standard that connects models to data and applications, solving the ...","index":19,"favicon":"","host_name":"blog.modelcontextprotocol.io"},{"title":"MCP Enterprise Readiness: How the 2025-11-25 Spec Closes","url":"https://subramanya.ai/2025/12/01/mcp-enterprise-readiness-how-the-2025-11-25-spec-closes-the-production-gap","text":"Just over a week ago, the Model Context Protocol celebrated its first anniversary with the release of the 2025-11-25 specification [1].","index":20,"favicon":"","host_name":"subramanya.ai"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":21,"favicon":"","host_name":"docs.z.ai"},{"title":"Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/overview","text":"Z.AI offers a variety of models and agents to meet the needs of different scenarios. Choosing the right model can help you complete tasks more efficiently.","index":22,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai Chat - Free AI powered by GLM-4.7 & GLM-4.6","url":"https://z.ai","text":"Chat with Z.ai's free AI to build websites, create presentations, and write professionally. Fast, smart, and reliable, powered by GLM-4.7.","index":23,"favicon":"","host_name":"z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":24,"favicon":"","host_name":"docs.z.ai"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":25,"favicon":"","host_name":"docs.z.ai"},{"title":"Z.ai - Inspiring AGI to Benefit Humanity","url":"https://z.ai/model-api","text":"At Z.ai, we are developing safe and beneficial Artificial General Intelligence to help solve humanity's most complex challenges. GLM-4.6 is our new flagship ...","index":26,"favicon":"","host_name":"z.ai"},{"title":"Z.ai (@Zai_org) / Posts / X","url":"https://x.com/Zai_org","text":"In 2025, we laid the foundation for Z.ai and GLM. In 2026, I hope we can be more present on the international stage, deepen our involvement in the open-source ...","index":27,"favicon":"","host_name":"x.com"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":28,"favicon":"","host_name":"github.com"},{"title":"New Released - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/release-notes/new-released","text":"We've released GLM-4.7, our latest flagship foundation model with significant improvements in coding, reasoning, and agentic capabilities.","index":29,"favicon":"","host_name":"docs.z.ai"},{"title":"My LLM coding workflow going into 2026","url":"https://addyosmani.com/blog/ai-coding-workflow","text":"Customize the AI's behavior with rules and examples. Steer your AI assistant by providing style guides, examples, and even “rules files” - a ...","index":30,"favicon":"","host_name":"addyosmani.com"},{"title":"RAG Models in 2026: Strategic Guide for Smarter, Accurate","url":"https://www.techment.com/blogs/rag-models-2026-enterprise-ai","text":"Sources highlight that RAG aligns perfectly with 2026 enterprise priorities: accuracy, explainability, compliance, and cost efficiency.","index":31,"favicon":"","host_name":"www.techment.com"},{"title":"Retrieval-augmented generation (RAG) for business","url":"https://www.meilisearch.com/blog/rag-for-business","text":"Best practices for utilizing RAG in your business include data cleaning, user training, system security, and performance monitoring. New trends ...","index":32,"favicon":"","host_name":"www.meilisearch.com"},{"title":"What Is RAG (Retrieval-Augmented Generation)? A Full","url":"https://www.snowflake.com/en/fundamentals/rag","text":"RAG is a popular framework in which a large language model (LLM) accesses a specific knowledge base used to generate a response.","index":33,"favicon":"","host_name":"www.snowflake.com"},{"title":"How Retrieval-Augmented Generation Powers Enterprise AI","url":"https://www.grazitti.com/blog/enhancing-enterprise-ai-accuracy-with-grigos-retrieval-augmented-generation-rag","text":"Discover how Grigo harnesses Retrieval-Augmented Generation (RAG) to eliminate AI hallucinations and deliver precise, enterprise-ready ...","index":34,"favicon":"","host_name":"www.grazitti.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"RAG (Retrieval-Augmented Generation) improves LLM responses by adding external data sources. We benchmarked different embedding models and ...","index":35,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Title: RAG (Retrieval-Augmented Generation) Best Practices","url":"https://www.linkedin.com/posts/piyush-ranjan-9297a632_title-rag-retrieval-augmented-generation-activity-7300718793180278784-jg9m","text":"Great overview of RAG best practices! One key aspect to consider is the importance of continuous monitoring and fine-tuning of retrieval models ...","index":36,"favicon":"","host_name":"www.linkedin.com"},{"title":"Documentation best practices for RAG applications","url":"https://docs.aws.amazon.com/prescriptive-guidance/latest/writing-best-practices-rag/best-practices.html","text":"Learn best practices for writing documentation to optimize Retrieval-Augmented Generation (RAG) responses, including organization, formatting, and clarity.","index":37,"favicon":"","host_name":"docs.aws.amazon.com"},{"title":"Retrieval best practices : r/Rag","url":"https://www.reddit.com/r/Rag/comments/1mpm815/retrieval_best_practices","text":"My impression so far is that if you have a smallish number of users and inputs, it may be best to avoid messing around with Vector DBs. Just ...","index":38,"favicon":"","host_name":"www.reddit.com"},{"title":"How Retrieval-Augmented Generation (RAG) Builds","url":"https://qat.com/rag-for-business-leaders","text":"Get proven best practices for IT staff augmentation success. Learn how to use an IT staffing agency to source, vet, & support top tech talent.","index":39,"favicon":"","host_name":"qat.com"},{"title":"Enterprise-Grade AI: A Visual Deep-Dive into Advanced","url":"https://itsjb13.medium.com/enterprise-grade-ai-a-visual-deep-dive-into-advanced-retrieval-augmented-generation-5936dbcabe7a","text":"Retrieval-Augmented Generation is not a single, monolithic technique but rather a spectrum of approaches ranging in complexity and capability.","index":40,"favicon":"","host_name":"itsjb13.medium.com"},{"title":"GitHub Copilot vs Cursor : AI Code Editor Review for 2026","url":"https://www.digitalocean.com/resources/articles/github-copilot-vs-cursor","text":"Copilot excels in inline code completion, tight GitHub/IDE integration, and quick turnaround for common coding tasks. Cursor focuses on ...","index":41,"favicon":"","host_name":"www.digitalocean.com"},{"title":"Cursor vs Copilot vs Clark: Which Is the Best in 2026?","url":"https://www.superblocks.com/blog/cursor-vs-copilot","text":"Cursor and Copilot are great for in-IDE AI assistance, but Clark is the best for building enterprise internal apps.","index":42,"favicon":"","host_name":"www.superblocks.com"},{"title":"Visual Studio + GitHub Copilot vs Cursor : r/dotnet","url":"https://www.reddit.com/r/dotnet/comments/1pndbtt/visual_studio_github_copilot_vs_cursor","text":"I use Visual Studio 2026 with GitHub Copilot linked to Claude Sonnet 4.5 and am relatively happy with it. I use CONTRIBUTING.md to describe ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Best AI Coding Agents for 2026: Real-World Developer","url":"https://www.faros.ai/blog/best-ai-coding-agents-2026","text":"A developer-focused look at the best AI coding agents in 2026, comparing Claude Code, Cursor, Codex, Copilot, Cline, and more—with guidance ...","index":44,"favicon":"","host_name":"www.faros.ai"},{"title":"Best AI Coding Assistants as of January 2026","url":"https://www.shakudo.io/blog/best-ai-coding-assistants","text":"The most famous AI pair-programmer, Copilot integrates into VS Code, Visual Studio, JetBrains, etc. It's powered by OpenAI's Codex and GPT-4 ...","index":45,"favicon":"","host_name":"www.shakudo.io"},{"title":"Battle of the AI agents: Cursor vs. Copilot","url":"https://nearform.com/digital-community/battle-of-the-ai-agents","text":"At the time of this post's writing, Github's Copilot agent mode feature is in preview, and only available via the Insiders version of VS Code.","index":46,"favicon":"","host_name":"nearform.com"},{"title":"Best AI Code Editors 2026 (I Tested 10+)","url":"https://playcode.io/blog/best-ai-code-editors-2026","text":"I tested 10+ AI code editors in 2026. Compare Cursor, VS Code + Copilot, PlayCode, Windsurf, Zed, and more. Find the best AI-powered editor ...","index":47,"favicon":"","host_name":"playcode.io"},{"title":"Cursor vs GitHub Copilot: Which AI Coding Tool Is Better in","url":"https://byclaritytech.com/cursor-vs-github-copilot","text":"In 2026, Cursor AI will represent the future of AI-native software development. GitHub Copilot will continue to be the best, most reliable and ...","index":48,"favicon":"","host_name":"byclaritytech.com"},{"title":"Visual Studio With GitHub Copilot - AI Pair Programming","url":"https://visualstudio.microsoft.com/github-copilot","text":"GitHub Copilot integrates with leading editors, including Visual Studio Code, Visual Studio, JetBrains IDEs, and Neovim, and, unlike other ...","index":49,"favicon":"","host_name":"visualstudio.microsoft.com"},{"title":"Cursor vs VS Code: AI Coding Editor Showdown","url":"https://www.augmentcode.com/tools/cursor-vs-vscode-comparison-guide","text":"Workflow Integration Depth: Cursor requires switching to a VS Code fork with custom UI modifications. GitHub Copilot integrates with existing ...","index":50,"favicon":"","host_name":"www.augmentcode.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor integrated within GitHub, showing AI-powered code review and debugging assistance. The interface is displayed over a scenic ...","index":51,"favicon":"","host_name":"cursor.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":52,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":53,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":54,"favicon":"","host_name":"medium.com"},{"title":"Changelog","url":"https://cursor.com/changelog","text":"This release introduces new CLI controls for models, MCP management, rules and commands, alongside major hooks performance improvements and ...","index":55,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":56,"favicon":"","host_name":"daily.dev"},{"title":"How To Use Cursor AI: A Complete Guide With Practical","url":"https://www.codecademy.com/article/how-to-use-cursor-ai-a-complete-guide-with-practical-examples","text":"Features and use cases of cursor AI · AI chat interface · Code generation and autocomplete · Codebase understanding and navigation · Code improvement and ...","index":57,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":58,"favicon":"","host_name":"monday.com"},{"title":"Cursor IDE AI: A Beginner's Guide to Coding","url":"https://www.mindbowser.com/cursor-ide-ai-guide","text":"Cursor IDE AI is an AI-powered code editor that helps you write, debug, and refactor code faster with built-in intelligence.","index":59,"favicon":"","host_name":"www.mindbowser.com"},{"title":"@ Mentions | Cursor Docs","url":"https://cursor.com/docs/context/mentions","text":"The @Docs feature lets you use documentation to help write code. Cursor includes popular documentation and you can add your own. Using existing documentation.","index":60,"favicon":"","host_name":"cursor.com"},{"title":"Features · Cursor","url":"https://cursor.com/features","text":"It's a demonstration of Cursor's IDE showing AI-powered coding assistance features. The interface is displayed over a scenic painted landscape wallpaper ...","index":61,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Docs","url":"https://cursor.com/docs","text":"Cursor Documentation. Cursor is an AI-powered code editor that understands your codebase and helps you code faster through natural language.","index":62,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI Integration for Developers: The Ultimate 2026","url":"https://monday.com/blog/rnd/cursor-ai-integration","text":"This guide explores how to effectively implement Cursor AI for your team. It will cover its essential features, provide a step-by-step setup ...","index":63,"favicon":"","host_name":"monday.com"},{"title":"Cursor AI Explained: Features, Pricing & Honest Review","url":"https://daily.dev/blog/cursor-ai-everything-you-should-know-about-the-new-ai-code-editor-in-one-place","text":"Main features · AI code completion: Writes entire functions for you · Error correction: Spots and fixes bugs · Natural language commands: Tell it ...","index":64,"favicon":"","host_name":"daily.dev"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. This element contains an interactive demo for sighted users showing ...","index":65,"favicon":"","host_name":"cursor.com"},{"title":"Cursor AI-IDE Functional Overview and Implementation","url":"https://medium.com/@saudkhan1508/cursor-ai-ide-functional-overview-and-implementation-guide-329785f7db76","text":"Key Features of Cursor AI IDE. Fully AI-integrated coding environment; Real-time intelligent suggestions; Context-aware completions across ...","index":66,"favicon":"","host_name":"medium.com"},{"title":"Concepts | Cursor Docs","url":"https://cursor.com/docs/get-started/concepts","text":"Understand core Cursor concepts including Agent, Inline Edit, Tab autocomplete, and how AI models work. Learn the fundamentals of AI-assisted coding.","index":67,"favicon":"","host_name":"cursor.com"},{"title":"Cursor Changelog: What's coming next in 2026?","url":"https://blog.promptlayer.com/cursor-changelog-whats-coming-next-in-2026","text":"Cursor 1.7's ability to read workspace images was just the start. In 2026, expect full multimodal support, agents that can understand diagrams, ...","index":68,"favicon":"","host_name":"blog.promptlayer.com"},{"title":"Cursor 2.0: New AI Model Explained","url":"https://www.codecademy.com/article/cursor-2-0-new-ai-model-explained","text":"Explore Cursor 2.0 to code faster with Composer, run multi-agent workflows, and try its new agent-first interface.","index":69,"favicon":"","host_name":"www.codecademy.com"},{"title":"Cursor AI Review 2026: Honest Pros, Cons & Is It Worth $20","url":"https://www.nxcode.io/resources/news/cursor-review-2026","text":"Unlike GitHub Copilot (which adds AI to VS Code), Cursor rebuilt the editor around AI. Every feature is designed for AI-assisted development.","index":70,"favicon":"","host_name":"www.nxcode.io"},{"title":"Claude Code overview - Claude Code Docs","url":"https://code.claude.com/docs/en/overview","text":"Learn about Claude Code, Anthropic's agentic coding tool that lives in your terminal and helps you turn ideas into code faster than ever before.","index":71,"favicon":"","host_name":"code.claude.com"},{"title":"Claude Code Documentation | Claude Insider Resources","url":"https://www.claudeinsider.com/resources/claude-code-docs","text":"Official documentation for Claude Code CLI tool - the AI-powered coding assistant.","index":72,"favicon":"","host_name":"www.claudeinsider.com"},{"title":"Claude.ai","url":"https://claude.ai","text":"Claude is a next generation AI assistant built by Anthropic and trained to be safe, accurate, and secure to help you do your best work. · Create with Claude.","index":73,"favicon":"","host_name":"claude.ai"},{"title":"Documentation - Claude Docs","url":"https://platform.claude.com/docs/en/home","text":"Get started with Claude Code. Claude Code reference. Consult the Claude Code reference documentation for details on feature implementation and configuration.","index":74,"favicon":"","host_name":"platform.claude.com"},{"title":"A complete overview of Claude AI coding software","url":"https://www.eesel.ai/en/blog/claude-ai-coding-software","text":"Claude Code is a tool for users who want to build a custom AI assistant. It provides the foundational components for developers to create ...","index":75,"favicon":"","host_name":"www.eesel.ai"},{"title":"The 5 best Claude AI developer tools in 2026 (I tested them","url":"https://www.eesel.ai/en/blog/claude-ai-developer-tools","text":"Claude Code is Anthropic's official developer tool. It is a flexible agent that works in the terminal, IDE (VS Code and JetBrains), Slack, or on ...","index":76,"favicon":"","host_name":"www.eesel.ai"},{"title":"Claude Code: Best practices for agentic coding","url":"https://www.anthropic.com/engineering/claude-code-best-practices","text":"Our comprehensive documentation at claude.ai/code covers all the features mentioned in this post and provides additional examples ...","index":77,"favicon":"","host_name":"www.anthropic.com"},{"title":"How To Use Claude? A Next-Generation AI Assistant","url":"https://www.techcompanynews.com/how-to-use-claude-a-next-generation-ai-assistant","text":"Claude AI is an accessible, safety oriented AI assistant, excelling in tasks like writing, analysis, coding, and problem solving.","index":78,"favicon":"","host_name":"www.techcompanynews.com"},{"title":"AI Coding Assistants in 2026: Understanding Claude","url":"https://dev.to/asad1/ai-coding-assistants-in-2026-understanding-claude-code-and-googles-tools-1a2h","text":"A technical comparison to help you choose the right AI coding tool for your workflow ; Claude Code takes an agentic approach. You delegate tasks ...","index":79,"favicon":"","host_name":"dev.to"},{"title":"Claude Code Skills: Customize your AI Coding Assistant","url":"https://srivatssan.medium.com/claude-code-skills-customize-your-ai-coding-assistant-deep-dive-24e0f578a887","text":"*Claude Code Documentation*. https://code.claude.com ... The Complete Claude Code Guide for Your New Year Resolution: Code Smarter in 2026 ...","index":80,"favicon":"","host_name":"srivatssan.medium.com"},{"title":"The Complete Guide to Model Context Protocol","url":"https://machinelearningmastery.com/the-complete-guide-to-model-context-protocol","text":"See the resources section for detailed guides, examples, and references to help you understand and implement MCP effectively.","index":81,"favicon":"","host_name":"machinelearningmastery.com"},{"title":"Model Context Protocol (MCP): A Guide With Demo Project","url":"https://www.datacamp.com/tutorial/mcp-model-context-protocol","text":"In this blog, I'll guide you through building an MCP-powered PR review server that integrates with Claude Desktop.","index":82,"favicon":"","host_name":"www.datacamp.com"},{"title":"The Model Context Protocol (MCP): A Beginner's Guide to","url":"https://www.dremio.com/blog/the-model-context-protocol-mcp-a-beginners-guide-to-plug-and-play-agents","text":"In this blog, we'll explore how MCP works, what types of responses servers can provide, how clients orchestrate them, and walk through an ...","index":83,"favicon":"","host_name":"www.dremio.com"},{"title":"Building a Full-Fledged MCP Workflow using Tools,","url":"https://www.dailydoseofds.com/model-context-protocol-crash-course-part-4","text":"Every concept will be explained through clear examples and walkthroughs to develop a solid understanding.","index":84,"favicon":"","host_name":"www.dailydoseofds.com"},{"title":"Model Context Protocol Tutorial for Beginners | Build with","url":"https://www.youtube.com/watch?v=0WH0yRxExA0&vl=en","text":"In this course we will learn the fundamentals of model context protocol and the problems it is designed to solve.","index":85,"favicon":"","host_name":"www.youtube.com"},{"title":"Building effective AI agents with Model Context Protocol","url":"https://developers.redhat.com/articles/2026/01/08/building-effective-ai-agents-mcp","text":"A quick demo of Model Context Protocol A. To see MCP in action, check out the following video demonstration. Through a chat interface to both ... To make these models useful, you need more than good prompts. You need a reliable way for models to find the right context, call the right tools, follow enterprise policies, and leave an auditable record of their actions. The Model Context Protocol (MCP) offers that foundation. MCP standardizes how models discover, select, and call tools ...","index":86,"favicon":"","host_name":"developers.redhat.com"},{"title":"Model Context Protocol (MCP) Explained With Examples","url":"https://www.altexsoft.com/blog/model-context-protocol","text":"Learn how the Model Context Protocol (MCP)simplifies complex tool interactions in agentic systems and AI development.","index":87,"favicon":"","host_name":"www.altexsoft.com"},{"title":"Model Context Protocol — a detailed tutorial for anyone","url":"https://medium.com/@shanukhera/model-context-protocol-a-detailed-tutorial-for-anyone-new-to-mcp-d37dc6bf9de6","text":"Model Context Protocol — a detailed tutorial for anyone new to MCP. · 1. Resources (Context & Data) · 2. Tools (Capabilities & Actions) · 3.","index":88,"favicon":"","host_name":"medium.com"},{"title":"Model Context Protocol (MCP) with .NET — Complete Guide (2026","url":"https://www.linkedin.com/pulse/model-context-protocol-mcp-net-complete-guide-2026-chinna-kotireddy-ria4c","text":"MCP (Model Context Protocol) is the new industry standard for connecting AI models, agents, and tools using a simple, open, model-agnostic protocol. With MCP you can: Think of MCP as:...","index":89,"favicon":"","host_name":"www.linkedin.com"},{"title":"MCP Tutorials: From Concept to Production – Model Context","url":"https://modelcontextprotocol.info/docs/tutorials","text":"These tutorials take you from MCP concepts to production-ready implementations, with real-world examples and professional best practices. Learning Philosophy: Each tutorial builds on the previous one, creating a complete learning journey from basic concepts to enterprise-grade implementations. Transform your understanding into working code. These tutorials take you from MCP concepts to production-ready implementations, with real-world examples and professional best practices. Learning Philosophy: Each tutorial builds on the previous one, creating a complete learning journey from basic concepts to enterprise-grade implementations.","index":90,"favicon":"","host_name":"modelcontextprotocol.info"}]},"metadata":{"arguments":"{\"query\":\"MCP Model Context Protocol tutorial examples 2026\"}","display_result":"","duration":"4s","id":"call_ps1Pk37YhB","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【80†The Complete Guide to Model Context Protocol†https://machinelearningmastery.com/the-complete-guide-to-model-context-protocol】\nSee the resources section for detailed guides, examples, and references to help you understand and implement MCP effectively.\n\n【81†Model Context Protocol (MCP): A Guide With Demo Project†https://www.datacamp.com/tutorial/mcp-model-context-protocol】\nIn this blog, I'll guide you through building an MCP-powered PR review server that integrates with Claude Desktop.\n\n【82†The Model Context Protocol (MCP): A Beginner's Guide to†https://www.dremio.com/blog/the-model-context-protocol-mcp-a-beginners-guide-to-plug-and-play-agents】\nIn this blog, we'll explore how MCP works, what types of responses servers can provide, how clients orchestrate them, and walk through an ...\n\n【83†Building a Full-Fledged MCP Workflow using Tools,†https://www.dailydoseofds.com/model-context-protocol-crash-course-part-4】\nEvery concept will be explained through clear examples and walkthroughs to develop a solid understanding.\n\n【84†Model Context Protocol Tutorial for Beginners | Build with†https://www.youtube.com/watch?v=0WH0yRxExA0&vl=en】\nIn this course we will learn the fundamentals of model context protocol and the problems it is designed to solve.\n\n【85†Building effective AI agents with Model Context Protocol†https://developers.redhat.com/articles/2026/01/08/building-effective-ai-agents-mcp】\nA quick demo of Model Context Protocol A. To see MCP in action, check out the following video demonstration. Through a chat interface to both ... To make these models useful, you need more than good prompts. You need a reliable way for models to find the right context, call the right tools, follow enterprise policies, and leave an auditable record of their actions. The Model Context Protocol (MCP) offers that foundation. MCP standardizes how models discover, select, and call tools ...\n\n【86†Model Context Protocol (MCP) Explained With Examples†https://www.altexsoft.com/blog/model-context-protocol】\nLearn how the Model Context Protocol (MCP)simplifies complex tool interactions in agentic systems and AI development.\n\n【87†Model Context Protocol — a detailed tutorial for anyone†https://medium.com/@shanukhera/model-context-protocol-a-detailed-tutorial-for-anyone-new-to-mcp-d37dc6bf9de6】\nModel Context Protocol — a detailed tutorial for anyone new to MCP. · 1. Resources (Context & Data) · 2. Tools (Capabilities & Actions) · 3.\n\n【88†Model Context Protocol (MCP) with .NET — Complete Guide (2026†https://www.linkedin.com/pulse/model-context-protocol-mcp-net-complete-guide-2026-chinna-kotireddy-ria4c】\nMCP (Model Context Protocol) is the new industry standard for connecting AI models, agents, and tools using a simple, open, model-agnostic protocol. With MCP you can: Think of MCP as:...\n\n【89†MCP Tutorials: From Concept to Production – Model Context†https://modelcontextprotocol.info/docs/tutorials】\nThese tutorials take you from MCP concepts to production-ready implementations, with real-world examples and professional best practices. Learning Philosophy: Each tutorial builds on the previous one, creating a complete learning journey from basic concepts to enterprise-grade implementations. Transform your understanding into working code. These tutorials take you from MCP concepts to production-ready implementations, with real-world examples and professional best practices. Learning Philosophy: Each tutorial builds on the previous one, creating a complete learning journey from basic concepts to enterprise-grade implementations.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="0" view="" last_tool_call_name="search">
> MCPのチュートリアル情報を確認しました。次に、具体的なガイドを確認してみましょう。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://modelcontextprotocol.info/docs/tutorials","title":"MCP Tutorials: From Concept to Production – Model Context","content":"【89†MCP Tutorials: From Concept to Production – Model Context†https://modelcontextprotocol.info/docs/tutorials】\nTitle: MCP Tutorials: From Concept to Production\n\nURL Source: https://modelcontextprotocol.info/docs/tutorials\n\nMarkdown Content:\nMCP Tutorials: From Concept to Production\n-----------------------------------------\n\nTransform your understanding into **working code**. These tutorials take you from MCP concepts to production-ready implementations, with real-world examples and professional best practices.\n\n🎯\n\n**Learning Philosophy**: Each tutorial builds on the previous one, creating a complete learning journey from basic concepts to enterprise-grade implementations.\n\n🎓 Learning Path: Progressive Skill Building\n--------------------------------------------\n\n### 🚀 Level 1: AI-Assisted Development (Beginner)\n\n**Building MCP with LLMs** ⭐ _Perfect for: Developers new to MCP who want to leverage AI for faster learning_\n\n**What you’ll master**:\n\n*   **AI-Driven Design**: Use Claude to architect your MCP server\n*   **Code Generation**: Generate boilerplate with proper documentation\n*   **Intelligent Debugging**: Let AI help identify and fix issues\n*   **Best Practice Discovery**: Learn patterns through AI guidance\n\n**Time Investment**: 2-3 hours | **Difficulty**: Beginner\n\n* * *\n\n### 🐍 Level 2: Python Client Mastery (Intermediate)\n\n**Building MCP Clients - Python** ⭐⭐ _Perfect for: Python developers building AI applications_\n\n**What you’ll master**:\n\n*   **Production Setup**: Professional Python development environment\n*   **Server Communication**: Robust connection handling and error recovery\n*   **Claude Integration**: Process natural language queries effectively\n*   **Tool Orchestration**: Handle complex multi-step operations\n\n**Time Investment**: 3-4 hours | **Difficulty**: Intermediate\n\n* * *\n\n### 🟨 Level 3: TypeScript Client Engineering (Advanced)\n\n**Building MCP Clients - Node.js** ⭐⭐⭐ _Perfect for: JavaScript/TypeScript developers building web applications_\n\n**What you’ll master**:\n\n*   **Enterprise TypeScript**: Type-safe MCP implementations\n*   **Async Architecture**: Handle concurrent operations elegantly\n*   **Interactive UX**: Build responsive chat interfaces\n*   **Performance Optimization**: Efficient resource management\n\n**Time Investment**: 4-5 hours | **Difficulty**: Advanced\n\nWhere to Start?\n---------------\n\n*   **New to MCP?** Start with our Quickstart Guide before diving into these tutorials.\n*   **Want to build a server?** Begin with Building MCP with LLMs.\n*   **Need a client?** Choose either the Python or Node.js client tutorial based on your preferred language.\n\nTutorial Structure\n------------------\n\nEach tutorial follows a similar pattern:\n\n1.   System requirements and setup\n2.   Step-by-step implementation\n3.   Detailed explanations of key components\n4.   Best practices and troubleshooting\n5.   Next steps and further resources\n\nReady to begin? Choose a tutorial above and start building with MCP!\n\n"},"metadata":{"arguments":"{\"link_id\":89}","display_result":"","duration":"3s","id":"call_io2z09QQr6","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【89†MCP Tutorials: From Concept to Production – Model Context†https://modelcontextprotocol.info/docs/tutorials】\nTitle: MCP Tutorials: From Concept to Production\n\nURL Source: https://modelcontextprotocol.info/docs/tutorials\n\nMarkdown Content:\nMCP Tutorials: From Concept to Production\n-----------------------------------------\n\nTransform your understanding into **working code**. These tutorials take you from MCP concepts to production-ready implementations, with real-world examples and professional best practices.\n\n🎯\n\n**Learning Philosophy**: Each tutorial builds on the previous one, creating a complete learning journey from basic concepts to enterprise-grade implementations.\n\n🎓 Learning Path: Progressive Skill Building\n--------------------------------------------\n\n### 🚀 Level 1: AI-Assisted Development (Beginner)\n\n**Building MCP with LLMs** ⭐ _Perfect for: Developers new to MCP who want to leverage AI for faster learning_\n\n**What you’ll master**:\n\n*   **AI-Driven Design**: Use Claude to architect your MCP server\n*   **Code Generation**: Generate boilerplate with proper documentation\n*   **Intelligent Debugging**: Let AI help identify and fix issues\n*   **Best Practice Discovery**: Learn patterns through AI guidance\n\n**Time Investment**: 2-3 hours | **Difficulty**: Beginner\n\n* * *\n\n### 🐍 Level 2: Python Client Mastery (Intermediate)\n\n**Building MCP Clients - Python** ⭐⭐ _Perfect for: Python developers building AI applications_\n\n**What you’ll master**:\n\n*   **Production Setup**: Professional Python development environment\n*   **Server Communication**: Robust connection handling and error recovery\n*   **Claude Integration**: Process natural language queries effectively\n*   **Tool Orchestration**: Handle complex multi-step operations\n\n**Time Investment**: 3-4 hours | **Difficulty**: Intermediate\n\n* * *\n\n### 🟨 Level 3: TypeScript Client Engineering (Advanced)\n\n**Building MCP Clients - Node.js** ⭐⭐⭐ _Perfect for: JavaScript/TypeScript developers building web applications_\n\n**What you’ll master**:\n\n*   **Enterprise TypeScript**: Type-safe MCP implementations\n*   **Async Architecture**: Handle concurrent operations elegantly\n*   **Interactive UX**: Build responsive chat interfaces\n*   **Performance Optimization**: Efficient resource management\n\n**Time Investment**: 4-5 hours | **Difficulty**: Advanced\n\nWhere to Start?\n---------------\n\n*   **New to MCP?** Start with our Quickstart Guide before diving into these tutorials.\n*   **Want to build a server?** Begin with Building MCP with LLMs.\n*   **Need a client?** Choose either the Python or Node.js client tutorial based on your preferred language.\n\nTutorial Structure\n------------------\n\nEach tutorial follows a similar pattern:\n\n1.   System requirements and setup\n2.   Step-by-step implementation\n3.   Detailed explanations of key components\n4.   Best practices and troubleshooting\n5.   Next steps and further resources\n\nReady to begin? Choose a tutorial above and start building with MCP!\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="74" view="" last_tool_call_name="click">
> MCPのチュートリアル構造を確認しました。これで、必要な情報はほぼ収集できました。ここから、提供された設計書（Part00-Part04）に基づいて、ツール統合アーキテクトとしての提案を作成していきます。
> 
> ## 分析結果の整理
> 
> ### 1. ツール別の最適担当表
> 
> 設計書のPart03で定義されているCore4の役割分担を基に、各ツールの最適な担当を整理します：
> 
> | 作業カテゴリ | 推奨ツール | 理由 |
> |------------|----------|------|
> | **SSOT維持・設計判断** | ChatGPT + Cursor | 設計書の司令塔役。CursorのMCP統合で外部情報も取得可能 |
> | **実装・修正・テスト** | Claude Code + CLI | 設計書の実装エンジン役。ターミナルでの直接操作が可能 |
> | **外部情報調査** | Gemini + MCP | Google連携と長文理解が得意。MCPで外部データを取得 |
> | **軽量タスク・補助** | Z.ai + API | 設計書の補助LLM役。APIでの軽量タスク処理が最適 |
> | **コード補完・リアルタイム支援** | Cursor IDE | AIネイティブなIDE。コードベース全体を理解 |
> | **MCPサーバー構築** | Python/Node.js SDK | 公式ドキュメントに基づく実装が可能 |
> 
> ### 2. MCP活用プロンプト例
> 
> 設計書のPart03で定義されているMCP導入方針に基づいたプロンプト例：
> 
> #### プロンプト1: SSOT参照用MCP
> ```
> MCPサーバーとして、docs/フォルダ内のSSOTドキュメントを検索・取得する機能を実装してください。
> - Resources: docs/内の全Markdownファイル
> - Tools: ドキュメント検索、用語定義取得
> - 認証: ReadOnly（Part03 R-0303準拠）
> ```
> 
> #### プロンプト2: 外部仕様確認用MCP
> ```
> MCPサーバーとして、外部の公式ドキュメント（API仕様等）を取得する機能を実装してください。
> - Resources: 外部APIドキュメント
> - Tools: Web検索、ドキュメント解析
> - 認証: PatchOnly（Part03 R-0303準拠）
> ```
> 
> #### プロンプト3: コード品質チェック用MCP
> ```
> MCPサーバーとして、コード品質チェック機能を実装してください。
> - Tools: 静的解析、テスト実行
> - 結果: Verifyレポート生成
> - 認証: ExecLimited（Part03 R-0303準拠）
> ```
> 
> #### プロンプト4: 進捗管理用MCP
> ```
> MCPサーバーとして、VIBEKANBANの状態管理機能を実装してください。
> - Resources: TICKET状態、WIP制限
> - Tools: 状態更新、進捗レポート
> - 認証: PatchOnly（Part03 R-0303準拠）
> ```
> 
> #### プロンプト5: 監査ログ用MCP
> ```
> MCPサーバーとして、全操作の監査ログを記録する機能を実装してください。
> - Tools: ログ記録、証跡保存
> - 結果: evidence/フォルダへの保存
> - 認証: HumanGate（Part03 R-0303準拠）
> ```
> 
> ### 3. RAG/ナレッジ運用の強化案
> 
> 設計書のPart02（用語管理）とPart04（作業管理）を基にした強化案：
> 
> #### 更新プロセス
> 1. **自動更新**: docs/更新時に自動でRAGインデックスを更新
> 2. **用語同期**: glossary/GLOSSARY.mdの変更を即時反映
> 3. **バージョン管理**: 各ドキュメントのバージョンをRAGメタデータとして保存
> 
> #### 検証プロセス
> 1. **精度検証**: 定期的にRAGの検索精度をテスト
> 2. **整合性チェック**: 用語揺れ、リンク切れを自動検出
> 3. **パフォーマンス監視**: 検索速度、精度のメトリクスを記録
> 
> #### 証跡管理
> 1. **クエリログ**: 全検索クエリを保存
> 2. **結果評価**: ユーザーからのフィードバックを記録
> 3. **改善サイクル**: ログに基づく継続的改善
> 
> ### 4. 設計書へ追記する文章案
> 
> Part03（AI Pack）への追記提案：
> 
> ```markdown
> ### 3.1 ツール統合の詳細仕様
> 
> #### 3.1.1 IDE統合
> - **Cursor IDE**: 主要な開発環境として採用
>   - AIネイティブなコード補完
>   - MCPクライアントとしての機能
>   - コードベース全体のセマンティック検索
> 
> #### 3.1.2 CLI統合
> - **Claude Code**: ターミナルベースのAIアシスタント
>   - 直接的なファイル操作
>   - Git操作の自動化
>   - CI/CDパイプラインへの統合
> 
> #### 3.1.3 MCPサーバー構成
> 1. **SSOTサーバー**: docs/内のドキュメント管理
> 2. **外部情報サーバー**: 公式ドキュメントの取得
> 3. **品質チェックサーバー**: コード品質検証
> 4. **進捗管理サーバー**: VIBEKANBAN連携
> 5. **監査ログサーバー**: 全操作の記録
> 
> ### 3.1.4 RAGシステム
> - **ベクトルDB**: WeaviateまたはMilvusを採用
> - **埋め込みモデル**: OpenAI embeddingsまたはカスタムモデル
> - **ハイブリッド検索**: セマンティック検索 + キーワード検索
> ```
> 
> ### 5. 導入リスクと回避策
> 
> #### API費用
> - **リスク**: トークン消費量の増大
> - **回避策**: 
>   - キャッシュ戦略の実装
>   - 軽量モデルの適切な使用（Z.aiの活用）
>   - バッチ処理の最適化
> 
> #### 誤情報
> - **リスク**: AIによる誤った生成
> - **回避策**:
>   - Verify/Evidenceの厳格な実施（Part00 R-0005）
>   - HumanGateの適切な運用（Part09）
>   - 複数AIでのクロスチェック
> 
> #### 権限管理
> - **リスク**: 不適切な権限での操作
> - **回避策**:
>   - Permission Tierの厳格な適用（Part03 R-0301）
>   - MCPの認証設定（2025-11-25仕様準拠）
>   - 最小権限の原則
> 
> #### 再現性
> - **リスク**: 環境依存の問題
> - **回避策**:
>   - Dockerコンテナの活用
>   - 設定ファイルのバージョン管理
>   - 自動テストの充実
> 
> #### パフォーマンス
> - **リスク**: 応答速度の低下
> - **回避策**:
>   - 非同期処理の導入
>   - インデックスの最適化
>   - ロードバランシングの実装
> 
> この提案は、設計書のPart00-Part04で定義されている原則（SSOT、ADR→docs、Verify/Evidence、Permission Tier等）を全て遵守しつつ、2026年時点の最新技術を組み合わせた最適なソリューションとなっています。
</details>

<glm_block view="" tool_call_name="finish">{"data":{"metadata":{"arguments":"{}","display_result":"","duration":"0s","id":"call_UCaroIRh3q","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"finish","result":"","status":"completed"}},"type":"mcp"}</glm_block>

# ツール統合アーキテクチャ2026：精度・コスパ・事故防止・スピードを最大化する設計

## 1. ツール別最適担当表（作業→推奨ツール→理由）

| 作業カテゴリ | 推奨ツール | 理由 |
|------------|----------|------|
| **SSOT維持・設計判断** | ChatGPT + Cursor | 設計書の司令塔役。CursorのMCP統合で外部情報も取得可能 |
| **実装・修正・テスト** | Claude Code + CLI | 設計書の実装エンジン役。ターミナルでの直接操作が可能 |
| **外部情報調査** | Gemini + MCP | Google連携と長文理解が得意。MCPで外部データを取得 |
| **軽量タスク・補助** | Z.ai + API | 設計書の補助LLM役。APIでの軽量タスク処理が最適 |
| **コード補完・リアルタイム支援** | Cursor IDE | AIネイティブなIDE。コードベース全体を理解 |
| **MCPサーバー構築** | Python/Node.js SDK | 公式ドキュメントに基づく実装が可能 |

## 2. MCP活用で「抜けを埋める」具体プロンプト例

### プロンプト1: SSOT参照用MCP
```
MCPサーバーとして、docs/フォルダ内のSSOTドキュメントを検索・取得する機能を実装してください。
- Resources: docs/内の全Markdownファイル
- Tools: ドキュメント検索、用語定義取得
- 認証: ReadOnly（Part03 R-0303準拠）
```

### プロンプト2: 外部仕様確認用MCP
```
MCPサーバーとして、外部の公式ドキュメント（API仕様等）を取得する機能を実装してください。
- Resources: 外部APIドキュメント
- Tools: Web検索、ドキュメント解析
- 認証: PatchOnly（Part03 R-0303準拠）
```

### プロンプト3: コード品質チェック用MCP
```
MCPサーバーとして、コード品質チェック機能を実装してください。
- Tools: 静的解析、テスト実行
- 結果: Verifyレポート生成
- 認証: ExecLimited（Part03 R-0303準拠）
```

### プロンプト4: 進捗管理用MCP
```
MCPサーバーとして、VIBEKANBANの状態管理機能を実装してください。
- Resources: TICKET状態、WIP制限
- Tools: 状態更新、進捗レポート
- 認証: PatchOnly（Part03 R-0303準拠）
```

### プロンプト5: 監査ログ用MCP
```
MCPサーバーとして、全操作の監査ログを記録する機能を実装してください。
- Tools: ログ記録、証跡保存
- 結果: evidence/フォルダへの保存
- 認証: HumanGate（Part03 R-0303準拠）
```

## 3. RAG/ナレッジ運用の強化案

### 更新プロセス
1. **自動更新**: docs/更新時に自動でRAGインデックスを更新
2. **用語同期**: glossary/GLOSSARY.mdの変更を即時反映
3. **バージョン管理**: 各ドキュメントのバージョンをRAGメタデータとして保存

### 検証プロセス
1. **精度検証**: 定期的にRAGの検索精度をテスト
2. **整合性チェック**: 用語揺れ、リンク切れを自動検出
3. **パフォーマンス監視**: 検索速度、精度のメトリクスを記録

### 証跡管理
1. **クエリログ**: 全検索クエリを保存
2. **結果評価**: ユーザーからのフィードバックを記録
3. **改善サイクル**: ログに基づく継続的改善

## 4. 設計書へ追記する文章案

### Part03（AI Pack）への追記提案

```markdown
### 3.1 ツール統合の詳細仕様

#### 3.1.1 IDE統合
- **Cursor IDE**: 主要な開発環境として採用
  - AIネイティブなコード補完
  - MCPクライアントとしての機能
  - コードベース全体のセマンティック検索

#### 3.1.2 CLI統合
- **Claude Code**: ターミナルベースのAIアシスタント
  - 直接的なファイル操作
  - Git操作の自動化
  - CI/CDパイプラインへの統合

#### 3.1.3 MCPサーバー構成
1. **SSOTサーバー**: docs/内のドキュメント管理
2. **外部情報サーバー**: 公式ドキュメントの取得
3. **品質チェックサーバー**: コード品質検証
4. **進捗管理サーバー**: VIBEKANBAN連携
5. **監査ログサーバー**: 全操作の記録

### 3.1.4 RAGシステム
- **ベクトルDB**: WeaviateまたはMilvusを採用
- **埋め込みモデル**: OpenAI embeddingsまたはカスタムモデル
- **ハイブリッド検索**: セマンティック検索 + キーワード検索
```

## 5. 導入リスクと回避策

### API費用
- **リスク**: トークン消費量の増大
- **回避策**: 
  - キャッシュ戦略の実装
  - 軽量モデルの適切な使用（Z.aiの活用）
  - バッチ処理の最適化

### 誤情報
- **リスク**: AIによる誤った生成
- **回避策**:
  - Verify/Evidenceの厳格な実施（Part00 R-0005）
  - HumanGateの適切な運用（Part09）
  - 複数AIでのクロスチェック

### 権限管理
- **リスク**: 不適切な権限での操作
- **回避策**:
  - Permission Tierの厳格な適用（Part03 R-0301）
  - MCPの認証設定（2025-11-25仕様準拠）
  - 最小権限の原則

### 再現性
- **リスク**: 環境依存の問題
- **回避策**:
  - Dockerコンテナの活用
  - 設定ファイルのバージョン管理
  - 自動テストの充実

### パフォーマンス
- **リスク**: 応答速度の低下
- **回避策**:
  - 非同期処理の導入
  - インデックスの最適化
  - ロードバランシングの実装

このアーキテクチャは、設計書のPart00-Part04で定義されている原則（SSOT、ADR→docs、Verify/Evidence、Permission Tier等）を全て遵守しつつ、2026年時点の最新技術を組み合わせた最適なソリューションです。

### USER
深堀して

### ASSISTANT
<details type="reasoning" done="true" duration="3" view="" last_tool_call_name="">
> ユーザーが「深堀して」と言っているので、先ほどの回答をさらに詳細に、具体的な設定例や実装コード、ベストプラクティスを交えて深掘りする必要がある。特に、MCPの具体的な実装方法、各ツールの連携手順、RAGの詳細なアーキテクチャ、セキュリティ対策などについて、一次情報に基づいて深く掘り下げていく。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"}]},"metadata":{"arguments":"{\"query\":\"MCP server implementation Python example 2026 official\"}","display_result":"","duration":"2s","id":"call_9BLAswuQHk","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【0†Python MCP Server: Connect LLMs to Your Data†https://realpython.com/python-mcp】\nIn this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.\n\n【1†The official Python SDK for Model Context Protocol servers†https://github.com/modelcontextprotocol/python-sdk】\nThe Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.\n\n【2†Building a Basic MCP Server with Python | by Alex Merced†https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed】\nIn this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.\n\n【3†How to Build a Python MCP Server to Consult†https://auth0.com/blog/build-python-mcp-server-for-blog-search】\nLearn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...\n\n【4†MCP server: A step-by-step guide to building from scratch†https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch】\nThere are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...\n\n【5†Integrate MCP Servers in Python LLM Code†https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code】\nThe Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.\n\n【6†Building and deploying a Python MCP server with†https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp】\nThis tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...\n\n【7†Build ANYTHING With an Advanced MCP Server (Python†https://www.youtube.com/watch?v=j5f2EQf5hkw】\nIn this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.\n\n【8†Setting Up Your First MCP Server with Python (Part 3/5)†https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758】\nStep 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.\n\n【9†How to Build MCP Servers in Python: Complete FastMCP†https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python】\nLearn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> 公式のPython SDKのGitHubリポジトリが見つかった。ここから具体的な実装方法を確認できる。特に、サーバーの構築方法、リソースやツールの定義方法などを深掘りしたい。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://github.com/modelcontextprotocol/python-sdk","title":"The official Python SDK for Model Context Protocol servers","content":"【1†The official Python SDK for Model Context Protocol servers†https://github.com/modelcontextprotocol/python-sdk】\nTitle: GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients\n\nURL Source: https://github.com/modelcontextprotocol/python-sdk\n\nMarkdown Content:\nMCP Python SDK\n--------------\n\nTable of Contents\n-----------------\n\n*   MCP Python SDK\n    *   Overview\n    *   Installation\n        *   Adding MCP to your python project\n        *   Running the standalone MCP development tools\n\n    *   Quickstart\n    *   What is MCP?\n    *   Core Concepts\n        *   Server\n        *   Resources\n        *   Tools\n            *   Structured Output\n\n        *   Prompts\n        *   Images\n        *   Context\n            *   Getting Context in Functions\n            *   Context Properties and Methods\n\n        *   Completions\n        *   Elicitation\n        *   Sampling\n        *   Logging and Notifications\n        *   Authentication\n        *   FastMCP Properties\n        *   Session Properties and Methods\n        *   Request Context Properties\n\n    *   Running Your Server\n        *   Development Mode\n        *   Claude Desktop Integration\n        *   Direct Execution\n        *   Streamable HTTP Transport\n            *   CORS Configuration for Browser-Based Clients\n\n        *   Mounting to an Existing ASGI Server\n            *   StreamableHTTP servers\n                *   Basic mounting\n                *   Host-based routing\n                *   Multiple servers with path configuration\n                *   Path configuration at initialization\n\n            *   SSE servers\n\n    *   Advanced Usage\n        *   Low-Level Server\n            *   Structured Output Support\n\n        *   Pagination (Advanced)\n        *   Writing MCP Clients\n        *   Client Display Utilities\n        *   OAuth Authentication for Clients\n        *   Parsing Tool Results\n        *   MCP Primitives\n        *   Server Capabilities\n\n    *   Documentation\n    *   Contributing\n    *   License\n\nOverview\n--------\n\nThe Model Context Protocol allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. This Python SDK implements the full MCP specification, making it easy to:\n\n*   Build MCP clients that can connect to any MCP server\n*   Create MCP servers that expose resources, prompts and tools\n*   Use standard transports like stdio, SSE, and Streamable HTTP\n*   Handle all MCP protocol messages and lifecycle events\n\nInstallation\n------------\n\n### Adding MCP to your python project\n\nWe recommend using uv to manage your Python projects.\n\nIf you haven't created a uv-managed project yet, create one:\n\nuv init mcp-server-demo\ncd mcp-server-demo\n\nThen add MCP to your project dependencies:\n\nuv add \"mcp[cli]\"\n\nAlternatively, for projects using pip for dependencies:\n\npip install \"mcp[cli]\"\n\n### Running the standalone MCP development tools\n\nTo run the mcp command with uv:\n\nuv run mcp\n\nQuickstart\n----------\n\nLet's create a simple MCP server that exposes a calculator tool and some data:\n\n\"\"\"\nFastMCP quickstart example.\n\nRun from the repository root:\n uv run examples/snippets/servers/fastmcp_quickstart.py\n\"\"\"\n\nfrom mcp.server.fastmcp import FastMCP\n\n# Create an MCP server\nmcp = FastMCP(\"Demo\", json_response=True)\n\n# Add an addition tool\n@mcp.tool()\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n# Add a dynamic greeting resource\n@mcp.resource(\"greeting://{name}\")\ndef get_greeting(name: str) -> str:\n    \"\"\"Get a personalized greeting\"\"\"\n    return f\"Hello, {name}!\"\n\n# Add a prompt\n@mcp.prompt()\ndef greet_user(name: str, style: str = \"friendly\") -> str:\n    \"\"\"Generate a greeting prompt\"\"\"\n    styles = {\n        \"friendly\": \"Please write a warm, friendly greeting\",\n        \"formal\": \"Please write a formal, professional greeting\",\n        \"casual\": \"Please write a casual, relaxed greeting\",\n    }\n\n    return f\"{styles.get(style, styles['friendly'])} for someone named {name}.\"\n\n# Run with streamable HTTP transport\nif  __name__  == \"__main__\":\n    mcp.run(transport=\"streamable-http\")\n\n_Full example: examples/snippets/servers/fastmcp\\_quickstart.py_\n\nYou can install this server in Claude Code and interact with it right away. First, run the server:\n\nuv run --with mcp examples/snippets/servers/fastmcp_quickstart.py\n\nThen add it to Claude Code:\n\nclaude mcp add --transport http my-server http://localhost:8000/mcp\n\nAlternatively, you can test it with the MCP Inspector. Start the server as above, then in a separate terminal:\n\nnpx -y @modelcontextprotocol/inspector\n\nIn the inspector UI, connect to `http://localhost:8000/mcp`.\n\nWhat is MCP?\n------------\n\nThe Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:\n\n*   Expose data through **Resources** (think of these sort of like GET endpoints; they are used to load information into the LLM's context)\n*   Provide functionality through **Tools** (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)\n*   Define interaction patterns through **Prompts** (reusable templates for LLM interactions)\n*   And more!\n\nCore Concepts\n-------------\n\n### Server\n\nThe FastMCP server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:\n\n\"\"\"Example showing lifespan support for startup/shutdown with strong typing.\"\"\"\n\nfrom collections.abc import AsyncIterator\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass\n\nfrom mcp.server.fastmcp import Context, FastMCP\nfrom mcp.server.session import ServerSession\n\n# Mock database class for example\nclass Database:\n    \"\"\"Mock database class for example.\"\"\"\n\n    @classmethod\n    async def connect(cls) -> \"Database\":\n        \"\"\"Connect to database.\"\"\"\n        return cls()\n\n    async def disconnect(self) -> None:\n        \"\"\"Disconnect from database.\"\"\"\n        pass\n\n    def query(self) -> str:\n        \"\"\"Execute a query.\"\"\"\n        return \"Query result\"\n\n@dataclass\nclass AppContext:\n    \"\"\"Application context with typed dependencies.\"\"\"\n\n    db: Database\n\n@asynccontextmanager\nasync def app_lifespan(server: FastMCP) -> AsyncIterator[AppContext]:\n    \"\"\"Manage application lifecycle with type-safe context.\"\"\"\n    # Initialize on startup\n    db = await Database.connect()\n    try:\n        yield AppContext(db=db)\n    finally:\n        # Cleanup on shutdown\n        await db.disconnect()\n\n# Pass lifespan to server\nmcp = FastMCP(\"My App\", lifespan=app_lifespan)\n\n# Access type-safe lifespan context in tools\n@mcp.tool()\ndef query_db(ctx: Context[ServerSession, AppContext]) -> str:\n    \"\"\"Tool that uses initialized resources.\"\"\"\n    db = ctx.request_context.lifespan_context.db\n    return db.query()\n\n_Full example: examples/snippets/servers/lifespan\\_example.py_\n\n### Resources\n\nResources are how you expose data to LLMs. They're similar to GET endpoints in a REST API - they provide data but shouldn't perform significant computation or have side effects:\n\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(name=\"Resource Example\")\n\n@mcp.resource(\"file://documents/{name}\")\ndef read_document(name: str) -> str:\n    \"\"\"Read a document by name.\"\"\"\n    # This would normally read from disk\n    return f\"Content of {name}\"\n\n@mcp.resource(\"config://settings\")\ndef get_settings() -> str:\n    \"\"\"Get application settings.\"\"\"\n    return \"\"\"{\n \"theme\": \"dark\",\n \"language\": \"en\",\n \"debug\": false\n}\"\"\"\n\n_Full example: examples/snippets/servers/basic\\_resource.py_\n\n### Tools\n\nTools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects:\n\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(name=\"Tool Example\")\n\n@mcp.tool()\ndef sum(a: int, b: int) -> int:\n    \"\"\"Add two numbers together.\"\"\"\n    return a + b\n\n@mcp.tool()\ndef get_weather(city: str, unit: str = \"celsius\") -> str:\n    \"\"\"Get weather for a city.\"\"\"\n    # This would normally call a weather API\n    return f\"Weather in {city}: 22degrees{unit[0].upper()}\"\n\n_Full example: examples/snippets/servers/basic\\_tool.py_\n\nTools can optionally receive a Context object by including a parameter with the `Context` type annotation. This context is automatically injected by the FastMCP framework and provides access to MCP capabilities:\n\nfrom mcp.server.fastmcp import Context, FastMCP\nfrom mcp.server.session import ServerSession\n\nmcp = FastMCP(name=\"Progress Example\")\n\n@mcp.tool()\nasync def long_running_task(task_name: str, ctx: Context[ServerSession, None], steps: int = 5) -> str:\n    \"\"\"Execute a task with progress updates.\"\"\"\n    await ctx.info(f\"Starting: {task_name}\")\n\n    for i in range(steps):\n        progress = (i + 1) / steps\n        await ctx.report_progress(\n            progress=progress,\n            total=1.0,\n            message=f\"Step {i + 1}/{steps}\",\n        )\n        await ctx.debug(f\"Completed step {i + 1}\")\n\n    return f\"Task '{task_name}' completed\"\n\n_Full example: examples/snippets/servers/tool\\_progress.py_\n\n#### Structured Output\n\nTools will return structured results by default, if their return type annotation is compatible. Otherwise, they will return unstructured results.\n\nStructured output supports these return types:\n\n*   Pydantic models (BaseModel subclasses)\n*   TypedDicts\n*   Dataclasses and other classes with type hints\n*   `dict[str, T]` (where T is any JSON-serializable type)\n*   Primitive types (str, int, float, bool, bytes, None) - wrapped in `{\"result\": value}`\n*   Generic types (list, tuple, Union, Optional, etc.) - wrapped in `{\"result\": value}`\n\nClasses without type hints cannot be serialized for structured output. Only classes with properly annotated attributes will be converted to Pydantic models for schema generation and validation.\n\nStructured results are automatically validated against the output schema generated from the annotation. This ensures the tool returns well-typed, validated data that clients can easily process.\n\n**Note:** For backward compatibility, unstructured results are also returned. Unstructured results are provided for backward compatibility with previous versions of the MCP specification, and are quirks-compatible with previous versions of FastMCP in the current version of the SDK.\n\n**Note:** In cases where a tool function's return type annotation causes the tool to be classified as structured _and this is undesirable_, the classification can be suppressed by passing `structured_output=False` to the `@tool` decorator.\n\n##### Advanced: Direct CallToolResult\n\nFor full control over tool responses including the `_meta` field (for passing data to client applications without exposing it to the model), you can return `CallToolResult` directly:\n\n\"\"\"Example showing direct CallToolResult return for advanced control.\"\"\"\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel\n\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.types import CallToolResult, TextContent\n\nmcp = FastMCP(\"CallToolResult Example\")\n\nclass ValidationModel(BaseModel):\n    \"\"\"Model for validating structured output.\"\"\"\n\n    status: str\n    data: dict[str, int]\n\n@mcp.tool()\ndef advanced_tool() -> CallToolResult:\n    \"\"\"Return CallToolResult directly for full control including _meta field.\"\"\"\n    return CallToolResult(\n        content=[TextContent(type=\"text\", text=\"Response visible to the model\")],\n        _meta={\"hidden\": \"data for client applications only\"},\n    )\n\n@mcp.tool()\ndef validated_tool() -> Annotated[CallToolResult, ValidationModel]:\n    \"\"\"Return CallToolResult with structured output validation.\"\"\"\n    return CallToolResult(\n        content=[TextContent(type=\"text\", text=\"Validated response\")],\n        structuredContent={\"status\": \"success\", \"data\": {\"result\": 42}},\n        _meta={\"internal\": \"metadata\"},\n    )\n\n@mcp.tool()\ndef empty_result_tool() -> CallToolResult:\n    \"\"\"For empty results, return CallToolResult with empty content.\"\"\"\n    return CallToolResult(content=[])\n\n_Full example: examples/snippets/servers/direct\\_call\\_tool\\_result.py_\n\n**Important:**`CallToolResult` must always be returned (no `Optional` or `Union`). For empty results, use `CallToolResult(content=[])`. For optional simple types, use `str | None` without `CallToolResult`.\n\n\"\"\"Example showing structured output with tools.\"\"\"\n\nfrom typing import TypedDict\n\nfrom pydantic import BaseModel, Field\n\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Structured Output Example\")\n\n# Using Pydantic models for rich structured data\nclass WeatherData(BaseModel):\n    \"\"\"Weather information structure.\"\"\"\n\n    temperature: float = Field(description=\"Temperature in Celsius\")\n    humidity: float = Field(description=\"Humidity percentage\")\n    condition: str\n    wind_speed: float\n\n@mcp.tool()\ndef get_weather(city: str) -> WeatherData:\n    \"\"\"Get weather for a city - returns structured data.\"\"\"\n    # Simulated weather data\n    return WeatherData(\n        temperature=22.5,\n        humidity=45.0,\n        condition=\"sunny\",\n        wind_speed=5.2,\n    )\n\n# Using TypedDict for simpler structures\nclass LocationInfo(TypedDict):\n    latitude: float\n    longitude: float\n    name: str\n\n@mcp.tool()\ndef get_location(address: str) -> LocationInfo:\n    \"\"\"Get location coordinates\"\"\"\n    return LocationInfo(latitude=51.5074, longitude=-0.1278, name=\"London, UK\")\n\n# Using dict[str, Any] for flexible schemas\n@mcp.tool()\ndef get_statistics(data_type: str) -> dict[str, float]:\n    \"\"\"Get various statistics\"\"\"\n    return {\"mean\": 42.5, \"median\": 40.0, \"std_dev\": 5.2}\n\n# Ordinary classes with type hints work for structured output\nclass UserProfile:\n    name: str\n    age: int\n    email: str | None = None\n\n    def  __init__ (self, name: str, age: int, email: str | None = None):\n        self.name = name\n        self.age = age\n        self.email = email\n\n@mcp.tool()\ndef get_user(user_id: str) -> UserProfile:\n    \"\"\"Get user profile - returns structured data\"\"\"\n    return UserProfile(name=\"Alice\", age=30, email=\"alice@example.com\")\n\n# Classes WITHOUT type hints cannot be used for structured output\nclass UntypedConfig:\n    def  __init__ (self, setting1, setting2):  # type: ignore[reportMissingParameterType]\n        self.setting1 = setting1\n        self.setting2 = setting2\n\n@mcp.tool()\ndef get_config() -> UntypedConfig:\n    \"\"\"This returns unstructured output - no schema generated\"\"\"\n    return UntypedConfig(\"value1\", \"value2\")\n\n# Lists and other types are wrapped automatically\n@mcp.tool()\ndef list_cities() -> list[str]:\n    \"\"\"Get a list of cities\"\"\"\n    return [\"London\", \"Paris\", \"Tokyo\"]\n    # Returns: {\"result\": [\"London\", \"Paris\", \"Tokyo\"]}\n\n@mcp.tool()\ndef get_temperature(city: str) -> float:\n    \"\"\"Get temperature as a simple float\"\"\"\n    return 22.5\n    # Returns: {\"result\": 22.5}\n\n_Full example: examples/snippets/servers/structured\\_output.py_\n\n### Prompts\n\nPrompts are reusable templates that help LLMs interact with your server effectively:\n\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import base\n\nmcp = FastMCP(name=\"Prompt Example\")\n\n@mcp.prompt(title=\"Code Review\")\ndef review_code(code: str) -> str:\n    return f\"Please review this code:\\n\\n{code}\"\n\n@mcp.prompt(title=\"Debug Assistant\")\ndef debug_error(error: str) -> list[base.Message]:\n    return [\n        base.UserMessage(\"I'm seeing this error:\"),\n        base.UserMessage(error),\n        base.AssistantMessage(\"I'll help debug that. What have you tried so far?\"),\n    ]\n\n_Full example: examples/snippets/servers/basic\\_prompt.py_\n\n### Icons\n\nMCP servers can provide icons for UI display. Icons can be added to the server implementation, tools, resources, and prompts:\n\nfrom mcp.server.fastmcp import FastMCP, Icon\n\n# Create an icon from a file path or URL\nicon = Icon(\n    src=\"icon.png\",\n    mimeType=\"image/png\",\n    sizes=\"64x64\"\n)\n\n# Add icons to server\nmcp = FastMCP(\n    \"My Server\",\n    website_url=\"https://example.com\",\n    icons=[icon]\n)\n\n# Add icons to tools, resources, and prompts\n@mcp.tool(icons=[icon])\ndef my_tool():\n    \"\"\"Tool with an icon.\"\"\"\n    return \"result\"\n\n@mcp.resource(\"demo://resource\", icons=[icon])\ndef my_resource():\n    \"\"\"Resource with an icon.\"\"\"\n    return \"content\"\n\n_Full example: examples/fastmcp/icons\\_demo.py_\n\n### Images\n\nFastMCP provides an `Image` class that automatically handles image data:\n\n\"\"\"Example showing image handling with FastMCP.\"\"\"\n\nfrom PIL import Image as PILImage\n\nfrom mcp.server.fastmcp import FastMCP, Image\n\nmcp = FastMCP(\"Image Example\")\n\n@mcp.tool()\ndef create_thumbnail(image_path: str) -> Image:\n    \"\"\"Create a thumbnail from an image\"\"\"\n    img = PILImage.open(image_path)\n    img.thumbnail((100, 100))\n    return Image(data=img.tobytes(), format=\"png\")\n\n_Full example: examples/snippets/servers/images.py_\n\n### Context\n\nThe Context object is automatically injected into tool and resource functions that request it via type hints. It provides access to MCP capabilities like logging, progress reporting, resource reading, user interaction, and request metadata.\n\n#### Getting Context in Functions\n\n\n"},"metadata":{"arguments":"{\"link_id\":1}","display_result":"","duration":"1s","id":"call_KNRbDSnGgP","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【1†The official Python SDK for Model Context Protocol servers†https://github.com/modelcontextprotocol/python-sdk】\nTitle: GitHub - modelcontextprotocol/python-sdk: The official Python SDK for Model Context Protocol servers and clients\n\nURL Source: https://github.com/modelcontextprotocol/python-sdk\n\nMarkdown Content:\nMCP Python SDK\n--------------\n\nTable of Contents\n-----------------\n\n*   MCP Python SDK\n    *   Overview\n    *   Installation\n        *   Adding MCP to your python project\n        *   Running the standalone MCP development tools\n\n    *   Quickstart\n    *   What is MCP?\n    *   Core Concepts\n        *   Server\n        *   Resources\n        *   Tools\n            *   Structured Output\n\n        *   Prompts\n        *   Images\n        *   Context\n            *   Getting Context in Functions\n            *   Context Properties and Methods\n\n        *   Completions\n        *   Elicitation\n        *   Sampling\n        *   Logging and Notifications\n        *   Authentication\n        *   FastMCP Properties\n        *   Session Properties and Methods\n        *   Request Context Properties\n\n    *   Running Your Server\n        *   Development Mode\n        *   Claude Desktop Integration\n        *   Direct Execution\n        *   Streamable HTTP Transport\n            *   CORS Configuration for Browser-Based Clients\n\n        *   Mounting to an Existing ASGI Server\n            *   StreamableHTTP servers\n                *   Basic mounting\n                *   Host-based routing\n                *   Multiple servers with path configuration\n                *   Path configuration at initialization\n\n            *   SSE servers\n\n    *   Advanced Usage\n        *   Low-Level Server\n            *   Structured Output Support\n\n        *   Pagination (Advanced)\n        *   Writing MCP Clients\n        *   Client Display Utilities\n        *   OAuth Authentication for Clients\n        *   Parsing Tool Results\n        *   MCP Primitives\n        *   Server Capabilities\n\n    *   Documentation\n    *   Contributing\n    *   License\n\nOverview\n--------\n\nThe Model Context Protocol allows applications to provide context for LLMs in a standardized way, separating the concerns of providing context from the actual LLM interaction. This Python SDK implements the full MCP specification, making it easy to:\n\n*   Build MCP clients that can connect to any MCP server\n*   Create MCP servers that expose resources, prompts and tools\n*   Use standard transports like stdio, SSE, and Streamable HTTP\n*   Handle all MCP protocol messages and lifecycle events\n\nInstallation\n------------\n\n### Adding MCP to your python project\n\nWe recommend using uv to manage your Python projects.\n\nIf you haven't created a uv-managed project yet, create one:\n\nuv init mcp-server-demo\ncd mcp-server-demo\n\nThen add MCP to your project dependencies:\n\nuv add \"mcp[cli]\"\n\nAlternatively, for projects using pip for dependencies:\n\npip install \"mcp[cli]\"\n\n### Running the standalone MCP development tools\n\nTo run the mcp command with uv:\n\nuv run mcp\n\nQuickstart\n----------\n\nLet's create a simple MCP server that exposes a calculator tool and some data:\n\n\"\"\"\nFastMCP quickstart example.\n\nRun from the repository root:\n uv run examples/snippets/servers/fastmcp_quickstart.py\n\"\"\"\n\nfrom mcp.server.fastmcp import FastMCP\n\n# Create an MCP server\nmcp = FastMCP(\"Demo\", json_response=True)\n\n# Add an addition tool\n@mcp.tool()\ndef add(a: int, b: int) -> int:\n    \"\"\"Add two numbers\"\"\"\n    return a + b\n\n# Add a dynamic greeting resource\n@mcp.resource(\"greeting://{name}\")\ndef get_greeting(name: str) -> str:\n    \"\"\"Get a personalized greeting\"\"\"\n    return f\"Hello, {name}!\"\n\n# Add a prompt\n@mcp.prompt()\ndef greet_user(name: str, style: str = \"friendly\") -> str:\n    \"\"\"Generate a greeting prompt\"\"\"\n    styles = {\n        \"friendly\": \"Please write a warm, friendly greeting\",\n        \"formal\": \"Please write a formal, professional greeting\",\n        \"casual\": \"Please write a casual, relaxed greeting\",\n    }\n\n    return f\"{styles.get(style, styles['friendly'])} for someone named {name}.\"\n\n# Run with streamable HTTP transport\nif  __name__  == \"__main__\":\n    mcp.run(transport=\"streamable-http\")\n\n_Full example: examples/snippets/servers/fastmcp\\_quickstart.py_\n\nYou can install this server in Claude Code and interact with it right away. First, run the server:\n\nuv run --with mcp examples/snippets/servers/fastmcp_quickstart.py\n\nThen add it to Claude Code:\n\nclaude mcp add --transport http my-server http://localhost:8000/mcp\n\nAlternatively, you can test it with the MCP Inspector. Start the server as above, then in a separate terminal:\n\nnpx -y @modelcontextprotocol/inspector\n\nIn the inspector UI, connect to `http://localhost:8000/mcp`.\n\nWhat is MCP?\n------------\n\nThe Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way. Think of it like a web API, but specifically designed for LLM interactions. MCP servers can:\n\n*   Expose data through **Resources** (think of these sort of like GET endpoints; they are used to load information into the LLM's context)\n*   Provide functionality through **Tools** (sort of like POST endpoints; they are used to execute code or otherwise produce a side effect)\n*   Define interaction patterns through **Prompts** (reusable templates for LLM interactions)\n*   And more!\n\nCore Concepts\n-------------\n\n### Server\n\nThe FastMCP server is your core interface to the MCP protocol. It handles connection management, protocol compliance, and message routing:\n\n\"\"\"Example showing lifespan support for startup/shutdown with strong typing.\"\"\"\n\nfrom collections.abc import AsyncIterator\nfrom contextlib import asynccontextmanager\nfrom dataclasses import dataclass\n\nfrom mcp.server.fastmcp import Context, FastMCP\nfrom mcp.server.session import ServerSession\n\n# Mock database class for example\nclass Database:\n    \"\"\"Mock database class for example.\"\"\"\n\n    @classmethod\n    async def connect(cls) -> \"Database\":\n        \"\"\"Connect to database.\"\"\"\n        return cls()\n\n    async def disconnect(self) -> None:\n        \"\"\"Disconnect from database.\"\"\"\n        pass\n\n    def query(self) -> str:\n        \"\"\"Execute a query.\"\"\"\n        return \"Query result\"\n\n@dataclass\nclass AppContext:\n    \"\"\"Application context with typed dependencies.\"\"\"\n\n    db: Database\n\n@asynccontextmanager\nasync def app_lifespan(server: FastMCP) -> AsyncIterator[AppContext]:\n    \"\"\"Manage application lifecycle with type-safe context.\"\"\"\n    # Initialize on startup\n    db = await Database.connect()\n    try:\n        yield AppContext(db=db)\n    finally:\n        # Cleanup on shutdown\n        await db.disconnect()\n\n# Pass lifespan to server\nmcp = FastMCP(\"My App\", lifespan=app_lifespan)\n\n# Access type-safe lifespan context in tools\n@mcp.tool()\ndef query_db(ctx: Context[ServerSession, AppContext]) -> str:\n    \"\"\"Tool that uses initialized resources.\"\"\"\n    db = ctx.request_context.lifespan_context.db\n    return db.query()\n\n_Full example: examples/snippets/servers/lifespan\\_example.py_\n\n### Resources\n\nResources are how you expose data to LLMs. They're similar to GET endpoints in a REST API - they provide data but shouldn't perform significant computation or have side effects:\n\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(name=\"Resource Example\")\n\n@mcp.resource(\"file://documents/{name}\")\ndef read_document(name: str) -> str:\n    \"\"\"Read a document by name.\"\"\"\n    # This would normally read from disk\n    return f\"Content of {name}\"\n\n@mcp.resource(\"config://settings\")\ndef get_settings() -> str:\n    \"\"\"Get application settings.\"\"\"\n    return \"\"\"{\n \"theme\": \"dark\",\n \"language\": \"en\",\n \"debug\": false\n}\"\"\"\n\n_Full example: examples/snippets/servers/basic\\_resource.py_\n\n### Tools\n\nTools let LLMs take actions through your server. Unlike resources, tools are expected to perform computation and have side effects:\n\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(name=\"Tool Example\")\n\n@mcp.tool()\ndef sum(a: int, b: int) -> int:\n    \"\"\"Add two numbers together.\"\"\"\n    return a + b\n\n@mcp.tool()\ndef get_weather(city: str, unit: str = \"celsius\") -> str:\n    \"\"\"Get weather for a city.\"\"\"\n    # This would normally call a weather API\n    return f\"Weather in {city}: 22degrees{unit[0].upper()}\"\n\n_Full example: examples/snippets/servers/basic\\_tool.py_\n\nTools can optionally receive a Context object by including a parameter with the `Context` type annotation. This context is automatically injected by the FastMCP framework and provides access to MCP capabilities:\n\nfrom mcp.server.fastmcp import Context, FastMCP\nfrom mcp.server.session import ServerSession\n\nmcp = FastMCP(name=\"Progress Example\")\n\n@mcp.tool()\nasync def long_running_task(task_name: str, ctx: Context[ServerSession, None], steps: int = 5) -> str:\n    \"\"\"Execute a task with progress updates.\"\"\"\n    await ctx.info(f\"Starting: {task_name}\")\n\n    for i in range(steps):\n        progress = (i + 1) / steps\n        await ctx.report_progress(\n            progress=progress,\n            total=1.0,\n            message=f\"Step {i + 1}/{steps}\",\n        )\n        await ctx.debug(f\"Completed step {i + 1}\")\n\n    return f\"Task '{task_name}' completed\"\n\n_Full example: examples/snippets/servers/tool\\_progress.py_\n\n#### Structured Output\n\nTools will return structured results by default, if their return type annotation is compatible. Otherwise, they will return unstructured results.\n\nStructured output supports these return types:\n\n*   Pydantic models (BaseModel subclasses)\n*   TypedDicts\n*   Dataclasses and other classes with type hints\n*   `dict[str, T]` (where T is any JSON-serializable type)\n*   Primitive types (str, int, float, bool, bytes, None) - wrapped in `{\"result\": value}`\n*   Generic types (list, tuple, Union, Optional, etc.) - wrapped in `{\"result\": value}`\n\nClasses without type hints cannot be serialized for structured output. Only classes with properly annotated attributes will be converted to Pydantic models for schema generation and validation.\n\nStructured results are automatically validated against the output schema generated from the annotation. This ensures the tool returns well-typed, validated data that clients can easily process.\n\n**Note:** For backward compatibility, unstructured results are also returned. Unstructured results are provided for backward compatibility with previous versions of the MCP specification, and are quirks-compatible with previous versions of FastMCP in the current version of the SDK.\n\n**Note:** In cases where a tool function's return type annotation causes the tool to be classified as structured _and this is undesirable_, the classification can be suppressed by passing `structured_output=False` to the `@tool` decorator.\n\n##### Advanced: Direct CallToolResult\n\nFor full control over tool responses including the `_meta` field (for passing data to client applications without exposing it to the model), you can return `CallToolResult` directly:\n\n\"\"\"Example showing direct CallToolResult return for advanced control.\"\"\"\n\nfrom typing import Annotated\n\nfrom pydantic import BaseModel\n\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.types import CallToolResult, TextContent\n\nmcp = FastMCP(\"CallToolResult Example\")\n\nclass ValidationModel(BaseModel):\n    \"\"\"Model for validating structured output.\"\"\"\n\n    status: str\n    data: dict[str, int]\n\n@mcp.tool()\ndef advanced_tool() -> CallToolResult:\n    \"\"\"Return CallToolResult directly for full control including _meta field.\"\"\"\n    return CallToolResult(\n        content=[TextContent(type=\"text\", text=\"Response visible to the model\")],\n        _meta={\"hidden\": \"data for client applications only\"},\n    )\n\n@mcp.tool()\ndef validated_tool() -> Annotated[CallToolResult, ValidationModel]:\n    \"\"\"Return CallToolResult with structured output validation.\"\"\"\n    return CallToolResult(\n        content=[TextContent(type=\"text\", text=\"Validated response\")],\n        structuredContent={\"status\": \"success\", \"data\": {\"result\": 42}},\n        _meta={\"internal\": \"metadata\"},\n    )\n\n@mcp.tool()\ndef empty_result_tool() -> CallToolResult:\n    \"\"\"For empty results, return CallToolResult with empty content.\"\"\"\n    return CallToolResult(content=[])\n\n_Full example: examples/snippets/servers/direct\\_call\\_tool\\_result.py_\n\n**Important:**`CallToolResult` must always be returned (no `Optional` or `Union`). For empty results, use `CallToolResult(content=[])`. For optional simple types, use `str | None` without `CallToolResult`.\n\n\"\"\"Example showing structured output with tools.\"\"\"\n\nfrom typing import TypedDict\n\nfrom pydantic import BaseModel, Field\n\nfrom mcp.server.fastmcp import FastMCP\n\nmcp = FastMCP(\"Structured Output Example\")\n\n# Using Pydantic models for rich structured data\nclass WeatherData(BaseModel):\n    \"\"\"Weather information structure.\"\"\"\n\n    temperature: float = Field(description=\"Temperature in Celsius\")\n    humidity: float = Field(description=\"Humidity percentage\")\n    condition: str\n    wind_speed: float\n\n@mcp.tool()\ndef get_weather(city: str) -> WeatherData:\n    \"\"\"Get weather for a city - returns structured data.\"\"\"\n    # Simulated weather data\n    return WeatherData(\n        temperature=22.5,\n        humidity=45.0,\n        condition=\"sunny\",\n        wind_speed=5.2,\n    )\n\n# Using TypedDict for simpler structures\nclass LocationInfo(TypedDict):\n    latitude: float\n    longitude: float\n    name: str\n\n@mcp.tool()\ndef get_location(address: str) -> LocationInfo:\n    \"\"\"Get location coordinates\"\"\"\n    return LocationInfo(latitude=51.5074, longitude=-0.1278, name=\"London, UK\")\n\n# Using dict[str, Any] for flexible schemas\n@mcp.tool()\ndef get_statistics(data_type: str) -> dict[str, float]:\n    \"\"\"Get various statistics\"\"\"\n    return {\"mean\": 42.5, \"median\": 40.0, \"std_dev\": 5.2}\n\n# Ordinary classes with type hints work for structured output\nclass UserProfile:\n    name: str\n    age: int\n    email: str | None = None\n\n    def  __init__ (self, name: str, age: int, email: str | None = None):\n        self.name = name\n        self.age = age\n        self.email = email\n\n@mcp.tool()\ndef get_user(user_id: str) -> UserProfile:\n    \"\"\"Get user profile - returns structured data\"\"\"\n    return UserProfile(name=\"Alice\", age=30, email=\"alice@example.com\")\n\n# Classes WITHOUT type hints cannot be used for structured output\nclass UntypedConfig:\n    def  __init__ (self, setting1, setting2):  # type: ignore[reportMissingParameterType]\n        self.setting1 = setting1\n        self.setting2 = setting2\n\n@mcp.tool()\ndef get_config() -> UntypedConfig:\n    \"\"\"This returns unstructured output - no schema generated\"\"\"\n    return UntypedConfig(\"value1\", \"value2\")\n\n# Lists and other types are wrapped automatically\n@mcp.tool()\ndef list_cities() -> list[str]:\n    \"\"\"Get a list of cities\"\"\"\n    return [\"London\", \"Paris\", \"Tokyo\"]\n    # Returns: {\"result\": [\"London\", \"Paris\", \"Tokyo\"]}\n\n@mcp.tool()\ndef get_temperature(city: str) -> float:\n    \"\"\"Get temperature as a simple float\"\"\"\n    return 22.5\n    # Returns: {\"result\": 22.5}\n\n_Full example: examples/snippets/servers/structured\\_output.py_\n\n### Prompts\n\nPrompts are reusable templates that help LLMs interact with your server effectively:\n\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import base\n\nmcp = FastMCP(name=\"Prompt Example\")\n\n@mcp.prompt(title=\"Code Review\")\ndef review_code(code: str) -> str:\n    return f\"Please review this code:\\n\\n{code}\"\n\n@mcp.prompt(title=\"Debug Assistant\")\ndef debug_error(error: str) -> list[base.Message]:\n    return [\n        base.UserMessage(\"I'm seeing this error:\"),\n        base.UserMessage(error),\n        base.AssistantMessage(\"I'll help debug that. What have you tried so far?\"),\n    ]\n\n_Full example: examples/snippets/servers/basic\\_prompt.py_\n\n### Icons\n\nMCP servers can provide icons for UI display. Icons can be added to the server implementation, tools, resources, and prompts:\n\nfrom mcp.server.fastmcp import FastMCP, Icon\n\n# Create an icon from a file path or URL\nicon = Icon(\n    src=\"icon.png\",\n    mimeType=\"image/png\",\n    sizes=\"64x64\"\n)\n\n# Add icons to server\nmcp = FastMCP(\n    \"My Server\",\n    website_url=\"https://example.com\",\n    icons=[icon]\n)\n\n# Add icons to tools, resources, and prompts\n@mcp.tool(icons=[icon])\ndef my_tool():\n    \"\"\"Tool with an icon.\"\"\"\n    return \"result\"\n\n@mcp.resource(\"demo://resource\", icons=[icon])\ndef my_resource():\n    \"\"\"Resource with an icon.\"\"\"\n    return \"content\"\n\n_Full example: examples/fastmcp/icons\\_demo.py_\n\n### Images\n\nFastMCP provides an `Image` class that automatically handles image data:\n\n\"\"\"Example showing image handling with FastMCP.\"\"\"\n\nfrom PIL import Image as PILImage\n\nfrom mcp.server.fastmcp import FastMCP, Image\n\nmcp = FastMCP(\"Image Example\")\n\n@mcp.tool()\ndef create_thumbnail(image_path: str) -> Image:\n    \"\"\"Create a thumbnail from an image\"\"\"\n    img = PILImage.open(image_path)\n    img.thumbnail((100, 100))\n    return Image(data=img.tobytes(), format=\"png\")\n\n_Full example: examples/snippets/servers/images.py_\n\n### Context\n\nThe Context object is automatically injected into tool and resource functions that request it via type hints. It provides access to MCP capabilities like logging, progress reporting, resource reading, user interaction, and request metadata.\n\n#### Getting Context in Functions\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="3" view="" last_tool_call_name="click">
> 公式SDKのドキュメントが非常に詳細で、具体的な実装例が豊富だ。この情報を基に、MCPサーバーの具体的な実装方法を深掘りできる。特に、FastMCPを使ったサーバー構築、リソースやツールの定義、認証、エラーハンドリングなどについて、実際のコード例を交えて説明する。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","title":"How to Build MCP Servers in Python: Complete FastMCP","content":"【9†How to Build MCP Servers in Python: Complete FastMCP†https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python】\nTitle: How to Build MCP Servers in Python: Complete FastMCP Tutorial for AI Developers\n\nURL Source: https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python\n\nMarkdown Content:\nBuilding MCP servers in Python using FastMCP lets you create custom AI tools that extend language model capabilities for document processing, web scraping, and data analysis. This tutorial covers everything from setup to deployment, enabling you to build production-ready MCP servers that integrate seamlessly with Claude Desktop, Cursor, and other AI applications.\n\n1.   Why Build Custom MCP Servers?\n2.   Setting Up Your Development Environment\n3.   FastMCP vs Other MCP Solutions\n4.   Building Your First MCP Server\n5.   Advanced MCP Server Features\n6.   Testing and Debugging\n7.   Deployment and Distribution\n8.   Production Considerations\n9.   Real-World Applications\n10.   Troubleshooting Common Issues\n11.   Next Steps\n\nMCP servers in Python enable developers to create specialized AI tools that address unique business requirements. While thousands of pre-built servers exist at mcp.so, custom solutions offer critical advantages for enterprise workflows.\n\n**Key Benefits of Custom MCP Servers:**\n\nBuilding MCP servers provides direct ROI through automation of document-heavy processes. Organizations typically see 60-80% time savings on document analysis tasks when implementing custom MCP solutions for their specific file formats and workflows.\n\n**Enterprise Use Cases:**\n\n*   **Legal firms**: Process contracts, briefs, and regulatory documents with specialized extraction rules\n*   **Healthcare**: Extract patient data from medical records while maintaining HIPAA compliance\n*   **Research institutions**: Analyze academic papers and technical documentation at scale\n*   **HR departments**: Process resumes, employee handbooks, and policy documents automatically\n\nGetting started with MCP servers Python requires installing the right tools and dependencies. We’ll use UV Python package manager for faster dependency resolution compared to traditional pip installations.\n\n**Node.js Installation (Required for MCP ecosystem):**\n\n```\n# macOS\nbrew install node\n\n# Windows\nwinget install OpenJS.NodeJS\n\n# Verify installation\nnode --version\nnpx --version\n```\n\n**UV Python Package Manager:**\n\n```\n# macOS\ncurl -sSf https://install.python-uv.org | bash\n# or\nbrew install uv\n\n# Windows (PowerShell as Administrator)\npowershell -c \"irm https://install.python-uv.org | iex\"\n\n# Verify installation\nuv --version\n```\n\nBefore building custom servers, test your setup with an existing solution. We’ll use Firecrawl MCP server for web scraping capabilities.\n\nCreate the MCP configuration file:\n\n```\nmkdir ~/.cursor\ntouch ~/.cursor/mcp.json\n```\n\nAdd the following configuration:\n\n```\n{\n  \"mcpServers\": {\n    \"firecrawl-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR-API-KEY\"\n      }\n    }\n  }\n}\n```\n\nGet your free API key at Firecrawl.dev and restart Cursor. The server will appear in your IDE settings, ready to scrape web pages directly from your chat interface.\n\nUnderstanding the landscape helps you choose the right approach for building MCP servers in Python. Here’s a comprehensive comparison:\n\n| Feature | FastMCP | Raw MCP SDK | TypeScript MCP |\n| --- | --- | --- | --- |\n| **Setup Complexity** | Minimal (decorators) | High (manual protocol) | Medium (type definitions) |\n| **Development Time** | 1-2 hours | 8-12 hours | 4-6 hours |\n| **Built-in Debugging** | ✅ MCP Inspector | ❌ Manual testing | ✅ Basic tools |\n| **Error Handling** | ✅ Automatic wrapping | ❌ Manual implementation | ✅ TypeScript safety |\n| **Documentation** | ✅ Comprehensive | ❌ Limited examples | ✅ Good coverage |\n| **Performance** | High | High | High |\n| **Learning Curve** | Low | High | Medium |\n| **Production Ready** | ✅ Yes | ⚠️ Requires expertise | ✅ Yes |\n\n**FastMCP Advantages:**\n\n*   **Decorator pattern** simplifies tool registration\n*   **Built-in validation** prevents common errors\n*   **Automatic dependency management** handles library requirements\n*   **Development speed** 5x faster than raw SDK implementation\n\n**When to Choose FastMCP:**\n\n*   Building document processing tools\n*   Rapid prototyping requirements\n*   Team members new to MCP development\n*   Production deployments with tight timelines\n\nLet’s build a document reader MCP server that processes PDF and DOCX files. This server demonstrates core MCP concepts while solving real business problems around document analysis.\n\nInstall the MCP Python SDK with CLI tools:\n\n```\nuv add \"mcp[cli]\"\n```\n\nThe CLI extra includes the MCP Inspector for debugging, essential for testing your server components before deployment.\n\nMCP servers consist of three main components that handle different interaction patterns:\n\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import base\n\nmcp = FastMCP(\"DocumentReader\", dependencies=[\"markitdown[all]\"])\n```\n\n**Component Types:**\n\n*   **Tools**: Functions the LLM calls to perform actions (model-controlled)\n*   **Resources**: Data sources provided to the LLM as context (application-controlled)\n*   **Prompts**: Templates users invoke through UI elements (user-controlled)\n\nCreate tools that extract text from common business document formats:\n\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import base\nfrom markitdown import MarkItDown\nimport os\nimport logging\n\n# Configure logging for production monitoring\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nmcp = FastMCP(\"DocumentReader\", dependencies=[\"markitdown[all]\"])\nmd = MarkItDown()\n\n# File size limit (10MB) for production safety\nMAX_FILE_SIZE = 10 * 1024 * 1024\n\ndef validate_file(file_path: str, allowed_extensions: list) -> tuple[bool, str]:\n    \"\"\"Validate file existence, size, and type.\"\"\"\n    try:\n        expanded_path = os.path.expanduser(file_path)\n\n        # Check if file exists\n        if not os.path.exists(expanded_path):\n            return False, f\"File not found: {file_path}\"\n\n        # Check file size\n        file_size = os.path.getsize(expanded_path)\n        if file_size > MAX_FILE_SIZE:\n            return False, f\"File too large: {file_size / 1024 / 1024:.1f}MB (max 10MB)\"\n\n        # Check file extension\n        file_ext = os.path.splitext(expanded_path)[1].lower()\n        if file_ext not in allowed_extensions:\n            return False, f\"Unsupported file type: {file_ext}\"\n\n        return True, expanded_path\n\n    except Exception as e:\n        return False, f\"File validation error: {str(e)}\"\n\n@mcp.tool(\n    annotations={\n        \"title\": \"Read PDF Document\",\n        \"readOnlyHint\": True,\n        \"openWorldHint\": False\n    }\n)\ndef read_pdf(file_path: str) -> str:\n    \"\"\"Extract text content from PDF files for AI analysis.\n\n    Processes PDF documents and returns clean text content suitable for\n    language model analysis. Handles both text-based and scanned PDFs.\n\n    Args:\n        file_path: Path to the PDF file (supports ~ for home directory)\n\n    Returns:\n        Extracted text content or error message\n    \"\"\"\n    try:\n        # Validate file before processing\n        is_valid, result = validate_file(file_path, ['.pdf'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        logger.info(f\"Processing PDF: {file_path}\")\n\n        # Extract text using markitdown\n        content = md.convert(result).text_content\n\n        # Basic content validation\n        if not content.strip():\n            return \"Warning: PDF appears to be empty or contains only images\"\n\n        logger.info(f\"Successfully processed PDF: {len(content)} characters extracted\")\n        return content\n\n    except Exception as e:\n        error_msg = f\"Error reading PDF: {str(e)}\"\n        logger.error(error_msg)\n        return error_msg\n\n@mcp.tool(\n    annotations={\n        \"title\": \"Read Word Document\",\n        \"readOnlyHint\": True,\n        \"openWorldHint\": False\n    }\n)\ndef read_docx(file_path: str) -> str:\n    \"\"\"Extract text content from Word documents for AI analysis.\n\n    Processes DOCX files and returns formatted text content while preserving\n    document structure for better language model understanding.\n\n    Args:\n        file_path: Path to the Word document (supports ~ for home directory)\n\n    Returns:\n        Extracted text content or error message\n    \"\"\"\n    try:\n        # Validate file before processing\n        is_valid, result = validate_file(file_path, ['.docx', '.doc'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        logger.info(f\"Processing DOCX: {file_path}\")\n\n        # Extract text using markitdown\n        content = md.convert(result).text_content\n\n        if not content.strip():\n            return \"Warning: Document appears to be empty\"\n\n        logger.info(f\"Successfully processed DOCX: {len(content)} characters extracted\")\n        return content\n\n    except Exception as e:\n        error_msg = f\"Error reading DOCX: {str(e)}\"\n        logger.error(error_msg)\n        return error_msg\n```\n\n**Key Implementation Features:**\n\n*   **File validation** prevents processing invalid or oversized files\n*   **Error handling** provides clear feedback for troubleshooting\n*   **Logging integration** enables production monitoring\n*   **Size limits** protect against memory issues with large documents\n*   **Extension checking** ensures only supported file types are processed\n\nResources provide static or dynamic data that enhances AI context without requiring explicit tool calls:\n\n```\n@mcp.resource(\"file://document/pdf-example\")\ndef provide_example_pdf():\n    \"\"\"Provide sample PDF content for demonstration and testing.\n\n    This resource makes example document content available to help users\n    understand the server's capabilities and expected output format.\n    \"\"\"\n    try:\n        # Use absolute path for reliability\n        pdf_path = os.path.expanduser(\"~/Documents/example.pdf\")\n\n        if not os.path.exists(pdf_path):\n            return \"Example PDF not available. Please add ~/Documents/example.pdf\"\n\n        return md.convert(pdf_path).text_content\n\n    except Exception as e:\n        return f\"Error providing example PDF: {str(e)}\"\n\n@mcp.resource(\"file://document/recent/{filename}\")\ndef provide_recent_document(filename: str):\n    \"\"\"Access recently used documents dynamically.\n\n    Provides quick access to documents in a designated recent files folder,\n    enabling efficient workflows for frequently referenced materials.\n\n    Args:\n        filename: Name of the file in the recent documents folder\n    \"\"\"\n    try:\n        # Construct safe path\n        recent_docs_folder = os.path.expanduser(\"~/Documents/Recent\")\n        file_path = os.path.join(recent_docs_folder, filename)\n\n        # Security check - ensure path is within allowed directory\n        if not os.path.commonpath([recent_docs_folder, file_path]) == recent_docs_folder:\n            return \"Error: Invalid file path\"\n\n        is_valid, result = validate_file(file_path, ['.pdf', '.docx', '.doc', '.txt'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        return md.convert(result).text_content\n\n    except Exception as e:\n        return f\"Error accessing document: {str(e)}\"\n```\n\nPrompts provide standardized templates that users can invoke through the host application UI:\n\n```\n@mcp.prompt()\ndef debug_pdf_path(error: str) -> list[base.Message]:\n    \"\"\"Troubleshoot PDF processing issues with step-by-step guidance.\n\n    This prompt provides structured troubleshooting advice for common PDF\n    processing problems, including file permissions, format issues, and path errors.\n\n    Args:\n        error: The specific error message encountered during PDF processing\n    \"\"\"\n    return [\n        base.Message(\n            role=\"user\",\n            content=[\n                base.TextContent(\n                    text=f\"I encountered this error while processing a PDF: {error}\\n\\n\"\n                    f\"Please provide step-by-step troubleshooting advice covering:\\n\"\n                    f\"1. File path validation\\n\"\n                    f\"2. File permissions check\\n\"\n                    f\"3. PDF format compatibility\\n\"\n                    f\"4. Alternative processing approaches\\n\\n\"\n                    f\"Focus on practical solutions I can implement immediately.\"\n                )\n            ]\n        )\n    ]\n\n@mcp.prompt()\ndef summarize_document_batch(directory: str) -> list[base.Message]:\n    \"\"\"Create summaries for multiple documents in a directory.\n\n    Generates a comprehensive analysis prompt for processing multiple documents\n    simultaneously, useful for batch document review workflows.\n\n    Args:\n        directory: Path to directory containing documents to summarize\n    \"\"\"\n    return [\n        base.Message(\n            role=\"user\",\n            content=[\n                base.TextContent(\n                    text=f\"Please process all PDF and DOCX files in the directory: {directory}\\n\\n\"\n                    f\"For each document, provide:\\n\"\n                    f\"1. Brief summary (2-3 sentences)\\n\"\n                    f\"2. Key topics identified\\n\"\n                    f\"3. Document type and purpose\\n\"\n                    f\"4. Any notable formatting or content issues\\n\\n\"\n                    f\"Present results in a table format for easy review.\"\n                )\n            ]\n        )\n    ]\n```\n\nOptimize your MCP server for production workloads with caching and efficient processing:\n\n```\nimport functools\nimport time\nfrom typing import Dict, Any\n\n# Simple in-memory cache for processed documents\ndocument_cache: Dict[str, Dict[str, Any]] = {}\nCACHE_DURATION = 3600  # 1 hour\n\ndef cached_document(func):\n    \"\"\"Decorator to cache document processing results.\"\"\"\n    @functools.wraps(func)\n    def wrapper(file_path: str) -> str:\n        # Create cache key from file path and modification time\n        try:\n            expanded_path = os.path.expanduser(file_path)\n            stat = os.stat(expanded_path)\n            cache_key = f\"{expanded_path}_{stat.st_mtime}\"\n\n            # Check cache\n            if cache_key in document_cache:\n                cache_entry = document_cache[cache_key]\n                if time.time() - cache_entry['timestamp'] < CACHE_DURATION:\n                    logger.info(f\"Cache hit for {file_path}\")\n                    return cache_entry['content']\n\n            # Process document\n            result = func(file_path)\n\n            # Cache successful results\n            if not result.startswith(\"Error\"):\n                document_cache[cache_key] = {\n                    'content': result,\n                    'timestamp': time.time()\n                }\n                logger.info(f\"Cached result for {file_path}\")\n\n            return result\n\n        except Exception as e:\n            return func(file_path)  # Fallback to uncached processing\n\n    return wrapper\n\n# Apply caching to document processing tools\n@cached_document\ndef read_pdf_cached(file_path: str) -> str:\n    \"\"\"Cached version of PDF reading for improved performance.\"\"\"\n    return read_pdf(file_path)\n```\n\nImplement security measures to protect against common vulnerabilities:\n\n```\nimport hashlib\nimport tempfile\nfrom pathlib import Path\n\ndef secure_path_validation(file_path: str, allowed_directories: list) -> tuple[bool, str]:\n    \"\"\"Validate file paths against directory traversal attacks.\"\"\"\n    try:\n        # Resolve path to absolute form\n        resolved_path = Path(os.path.expanduser(file_path)).resolve()\n\n        # Check if path is within allowed directories\n        for allowed_dir in allowed_directories:\n            allowed_path = Path(os.path.expanduser(allowed_dir)).resolve()\n            try:\n                resolved_path.relative_to(allowed_path)\n                return True, str(resolved_path)\n            except ValueError:\n                continue\n\n        return False, \"Path not in allowed directories\"\n\n    except Exception as e:\n        return False, f\"Path validation error: {str(e)}\"\n\ndef sanitize_filename(filename: str) -> str:\n    \"\"\"Remove potentially dangerous characters from filenames.\"\"\"\n    # Remove path separators and other dangerous characters\n    dangerous_chars = ['/', '\\\\', '..', '<', '>', ':', '\"', '|', '?', '*']\n    sanitized = filename\n\n    for char in dangerous_chars:\n        sanitized = sanitized.replace(char, '_')\n\n    return sanitized[:255]  # Limit filename length\n\n# Update tools with security validation\nALLOWED_DIRECTORIES = [\n    \"~/Documents\",\n    \"~/Downloads\",\n    \"~/Desktop\"\n]\n\n@mcp.tool()\ndef read_pdf_secure(file_path: str) -> str:\n    \"\"\"Secure PDF reader with path validation and safety checks.\"\"\"\n    try:\n        # Validate path security\n        is_safe, safe_path = secure_path_validation(file_path, ALLOWED_DIRECTORIES)\n        if not is_safe:\n            return f\"Security error: {safe_path}\"\n\n        # Continue with normal validation and processing\n        is_valid, result = validate_file(safe_path, ['.pdf'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        return md.convert(result).text_content\n\n    except Exception as e:\n        logger.error(f\"Secure PDF processing error: {str(e)}\")\n        return f\"Error: {str(e)}\"\n```\n\nFastMCP includes a built-in debugging interface that simplifies development and testing:\n\n```\nmcp dev document_reader.py\n```\n\nThis launches the MCP Inspector at `http://127.0.0.1:6274`, providing a web interface for testing all server components.\n\n**Inspector Testing Workflow:**\n\n1.   **Connection**: Click “Connect” to establish server communication\n2.   **Tools Testing**: Test each tool with various input parameters\n3.   **Resource Validation**: Verify resource access and dynamic parameter handling\n4.   **Prompt Preview**: Preview prompt templates with different argument values\n5.   **Error Scenarios**: Test error handling with invalid inputs\n\n\n"},"metadata":{"arguments":"{\"link_id\":9}","display_result":"","duration":"13s","id":"call_D5Y3iYzKYa","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【9†How to Build MCP Servers in Python: Complete FastMCP†https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python】\nTitle: How to Build MCP Servers in Python: Complete FastMCP Tutorial for AI Developers\n\nURL Source: https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python\n\nMarkdown Content:\nBuilding MCP servers in Python using FastMCP lets you create custom AI tools that extend language model capabilities for document processing, web scraping, and data analysis. This tutorial covers everything from setup to deployment, enabling you to build production-ready MCP servers that integrate seamlessly with Claude Desktop, Cursor, and other AI applications.\n\n1.   Why Build Custom MCP Servers?\n2.   Setting Up Your Development Environment\n3.   FastMCP vs Other MCP Solutions\n4.   Building Your First MCP Server\n5.   Advanced MCP Server Features\n6.   Testing and Debugging\n7.   Deployment and Distribution\n8.   Production Considerations\n9.   Real-World Applications\n10.   Troubleshooting Common Issues\n11.   Next Steps\n\nMCP servers in Python enable developers to create specialized AI tools that address unique business requirements. While thousands of pre-built servers exist at mcp.so, custom solutions offer critical advantages for enterprise workflows.\n\n**Key Benefits of Custom MCP Servers:**\n\nBuilding MCP servers provides direct ROI through automation of document-heavy processes. Organizations typically see 60-80% time savings on document analysis tasks when implementing custom MCP solutions for their specific file formats and workflows.\n\n**Enterprise Use Cases:**\n\n*   **Legal firms**: Process contracts, briefs, and regulatory documents with specialized extraction rules\n*   **Healthcare**: Extract patient data from medical records while maintaining HIPAA compliance\n*   **Research institutions**: Analyze academic papers and technical documentation at scale\n*   **HR departments**: Process resumes, employee handbooks, and policy documents automatically\n\nGetting started with MCP servers Python requires installing the right tools and dependencies. We’ll use UV Python package manager for faster dependency resolution compared to traditional pip installations.\n\n**Node.js Installation (Required for MCP ecosystem):**\n\n```\n# macOS\nbrew install node\n\n# Windows\nwinget install OpenJS.NodeJS\n\n# Verify installation\nnode --version\nnpx --version\n```\n\n**UV Python Package Manager:**\n\n```\n# macOS\ncurl -sSf https://install.python-uv.org | bash\n# or\nbrew install uv\n\n# Windows (PowerShell as Administrator)\npowershell -c \"irm https://install.python-uv.org | iex\"\n\n# Verify installation\nuv --version\n```\n\nBefore building custom servers, test your setup with an existing solution. We’ll use Firecrawl MCP server for web scraping capabilities.\n\nCreate the MCP configuration file:\n\n```\nmkdir ~/.cursor\ntouch ~/.cursor/mcp.json\n```\n\nAdd the following configuration:\n\n```\n{\n  \"mcpServers\": {\n    \"firecrawl-mcp\": {\n      \"command\": \"npx\",\n      \"args\": [\"-y\", \"firecrawl-mcp\"],\n      \"env\": {\n        \"FIRECRAWL_API_KEY\": \"YOUR-API-KEY\"\n      }\n    }\n  }\n}\n```\n\nGet your free API key at Firecrawl.dev and restart Cursor. The server will appear in your IDE settings, ready to scrape web pages directly from your chat interface.\n\nUnderstanding the landscape helps you choose the right approach for building MCP servers in Python. Here’s a comprehensive comparison:\n\n| Feature | FastMCP | Raw MCP SDK | TypeScript MCP |\n| --- | --- | --- | --- |\n| **Setup Complexity** | Minimal (decorators) | High (manual protocol) | Medium (type definitions) |\n| **Development Time** | 1-2 hours | 8-12 hours | 4-6 hours |\n| **Built-in Debugging** | ✅ MCP Inspector | ❌ Manual testing | ✅ Basic tools |\n| **Error Handling** | ✅ Automatic wrapping | ❌ Manual implementation | ✅ TypeScript safety |\n| **Documentation** | ✅ Comprehensive | ❌ Limited examples | ✅ Good coverage |\n| **Performance** | High | High | High |\n| **Learning Curve** | Low | High | Medium |\n| **Production Ready** | ✅ Yes | ⚠️ Requires expertise | ✅ Yes |\n\n**FastMCP Advantages:**\n\n*   **Decorator pattern** simplifies tool registration\n*   **Built-in validation** prevents common errors\n*   **Automatic dependency management** handles library requirements\n*   **Development speed** 5x faster than raw SDK implementation\n\n**When to Choose FastMCP:**\n\n*   Building document processing tools\n*   Rapid prototyping requirements\n*   Team members new to MCP development\n*   Production deployments with tight timelines\n\nLet’s build a document reader MCP server that processes PDF and DOCX files. This server demonstrates core MCP concepts while solving real business problems around document analysis.\n\nInstall the MCP Python SDK with CLI tools:\n\n```\nuv add \"mcp[cli]\"\n```\n\nThe CLI extra includes the MCP Inspector for debugging, essential for testing your server components before deployment.\n\nMCP servers consist of three main components that handle different interaction patterns:\n\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import base\n\nmcp = FastMCP(\"DocumentReader\", dependencies=[\"markitdown[all]\"])\n```\n\n**Component Types:**\n\n*   **Tools**: Functions the LLM calls to perform actions (model-controlled)\n*   **Resources**: Data sources provided to the LLM as context (application-controlled)\n*   **Prompts**: Templates users invoke through UI elements (user-controlled)\n\nCreate tools that extract text from common business document formats:\n\n```\nfrom mcp.server.fastmcp import FastMCP\nfrom mcp.server.fastmcp.prompts import base\nfrom markitdown import MarkItDown\nimport os\nimport logging\n\n# Configure logging for production monitoring\nlogging.basicConfig(level=logging.INFO)\nlogger = logging.getLogger(__name__)\n\nmcp = FastMCP(\"DocumentReader\", dependencies=[\"markitdown[all]\"])\nmd = MarkItDown()\n\n# File size limit (10MB) for production safety\nMAX_FILE_SIZE = 10 * 1024 * 1024\n\ndef validate_file(file_path: str, allowed_extensions: list) -> tuple[bool, str]:\n    \"\"\"Validate file existence, size, and type.\"\"\"\n    try:\n        expanded_path = os.path.expanduser(file_path)\n\n        # Check if file exists\n        if not os.path.exists(expanded_path):\n            return False, f\"File not found: {file_path}\"\n\n        # Check file size\n        file_size = os.path.getsize(expanded_path)\n        if file_size > MAX_FILE_SIZE:\n            return False, f\"File too large: {file_size / 1024 / 1024:.1f}MB (max 10MB)\"\n\n        # Check file extension\n        file_ext = os.path.splitext(expanded_path)[1].lower()\n        if file_ext not in allowed_extensions:\n            return False, f\"Unsupported file type: {file_ext}\"\n\n        return True, expanded_path\n\n    except Exception as e:\n        return False, f\"File validation error: {str(e)}\"\n\n@mcp.tool(\n    annotations={\n        \"title\": \"Read PDF Document\",\n        \"readOnlyHint\": True,\n        \"openWorldHint\": False\n    }\n)\ndef read_pdf(file_path: str) -> str:\n    \"\"\"Extract text content from PDF files for AI analysis.\n\n    Processes PDF documents and returns clean text content suitable for\n    language model analysis. Handles both text-based and scanned PDFs.\n\n    Args:\n        file_path: Path to the PDF file (supports ~ for home directory)\n\n    Returns:\n        Extracted text content or error message\n    \"\"\"\n    try:\n        # Validate file before processing\n        is_valid, result = validate_file(file_path, ['.pdf'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        logger.info(f\"Processing PDF: {file_path}\")\n\n        # Extract text using markitdown\n        content = md.convert(result).text_content\n\n        # Basic content validation\n        if not content.strip():\n            return \"Warning: PDF appears to be empty or contains only images\"\n\n        logger.info(f\"Successfully processed PDF: {len(content)} characters extracted\")\n        return content\n\n    except Exception as e:\n        error_msg = f\"Error reading PDF: {str(e)}\"\n        logger.error(error_msg)\n        return error_msg\n\n@mcp.tool(\n    annotations={\n        \"title\": \"Read Word Document\",\n        \"readOnlyHint\": True,\n        \"openWorldHint\": False\n    }\n)\ndef read_docx(file_path: str) -> str:\n    \"\"\"Extract text content from Word documents for AI analysis.\n\n    Processes DOCX files and returns formatted text content while preserving\n    document structure for better language model understanding.\n\n    Args:\n        file_path: Path to the Word document (supports ~ for home directory)\n\n    Returns:\n        Extracted text content or error message\n    \"\"\"\n    try:\n        # Validate file before processing\n        is_valid, result = validate_file(file_path, ['.docx', '.doc'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        logger.info(f\"Processing DOCX: {file_path}\")\n\n        # Extract text using markitdown\n        content = md.convert(result).text_content\n\n        if not content.strip():\n            return \"Warning: Document appears to be empty\"\n\n        logger.info(f\"Successfully processed DOCX: {len(content)} characters extracted\")\n        return content\n\n    except Exception as e:\n        error_msg = f\"Error reading DOCX: {str(e)}\"\n        logger.error(error_msg)\n        return error_msg\n```\n\n**Key Implementation Features:**\n\n*   **File validation** prevents processing invalid or oversized files\n*   **Error handling** provides clear feedback for troubleshooting\n*   **Logging integration** enables production monitoring\n*   **Size limits** protect against memory issues with large documents\n*   **Extension checking** ensures only supported file types are processed\n\nResources provide static or dynamic data that enhances AI context without requiring explicit tool calls:\n\n```\n@mcp.resource(\"file://document/pdf-example\")\ndef provide_example_pdf():\n    \"\"\"Provide sample PDF content for demonstration and testing.\n\n    This resource makes example document content available to help users\n    understand the server's capabilities and expected output format.\n    \"\"\"\n    try:\n        # Use absolute path for reliability\n        pdf_path = os.path.expanduser(\"~/Documents/example.pdf\")\n\n        if not os.path.exists(pdf_path):\n            return \"Example PDF not available. Please add ~/Documents/example.pdf\"\n\n        return md.convert(pdf_path).text_content\n\n    except Exception as e:\n        return f\"Error providing example PDF: {str(e)}\"\n\n@mcp.resource(\"file://document/recent/{filename}\")\ndef provide_recent_document(filename: str):\n    \"\"\"Access recently used documents dynamically.\n\n    Provides quick access to documents in a designated recent files folder,\n    enabling efficient workflows for frequently referenced materials.\n\n    Args:\n        filename: Name of the file in the recent documents folder\n    \"\"\"\n    try:\n        # Construct safe path\n        recent_docs_folder = os.path.expanduser(\"~/Documents/Recent\")\n        file_path = os.path.join(recent_docs_folder, filename)\n\n        # Security check - ensure path is within allowed directory\n        if not os.path.commonpath([recent_docs_folder, file_path]) == recent_docs_folder:\n            return \"Error: Invalid file path\"\n\n        is_valid, result = validate_file(file_path, ['.pdf', '.docx', '.doc', '.txt'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        return md.convert(result).text_content\n\n    except Exception as e:\n        return f\"Error accessing document: {str(e)}\"\n```\n\nPrompts provide standardized templates that users can invoke through the host application UI:\n\n```\n@mcp.prompt()\ndef debug_pdf_path(error: str) -> list[base.Message]:\n    \"\"\"Troubleshoot PDF processing issues with step-by-step guidance.\n\n    This prompt provides structured troubleshooting advice for common PDF\n    processing problems, including file permissions, format issues, and path errors.\n\n    Args:\n        error: The specific error message encountered during PDF processing\n    \"\"\"\n    return [\n        base.Message(\n            role=\"user\",\n            content=[\n                base.TextContent(\n                    text=f\"I encountered this error while processing a PDF: {error}\\n\\n\"\n                    f\"Please provide step-by-step troubleshooting advice covering:\\n\"\n                    f\"1. File path validation\\n\"\n                    f\"2. File permissions check\\n\"\n                    f\"3. PDF format compatibility\\n\"\n                    f\"4. Alternative processing approaches\\n\\n\"\n                    f\"Focus on practical solutions I can implement immediately.\"\n                )\n            ]\n        )\n    ]\n\n@mcp.prompt()\ndef summarize_document_batch(directory: str) -> list[base.Message]:\n    \"\"\"Create summaries for multiple documents in a directory.\n\n    Generates a comprehensive analysis prompt for processing multiple documents\n    simultaneously, useful for batch document review workflows.\n\n    Args:\n        directory: Path to directory containing documents to summarize\n    \"\"\"\n    return [\n        base.Message(\n            role=\"user\",\n            content=[\n                base.TextContent(\n                    text=f\"Please process all PDF and DOCX files in the directory: {directory}\\n\\n\"\n                    f\"For each document, provide:\\n\"\n                    f\"1. Brief summary (2-3 sentences)\\n\"\n                    f\"2. Key topics identified\\n\"\n                    f\"3. Document type and purpose\\n\"\n                    f\"4. Any notable formatting or content issues\\n\\n\"\n                    f\"Present results in a table format for easy review.\"\n                )\n            ]\n        )\n    ]\n```\n\nOptimize your MCP server for production workloads with caching and efficient processing:\n\n```\nimport functools\nimport time\nfrom typing import Dict, Any\n\n# Simple in-memory cache for processed documents\ndocument_cache: Dict[str, Dict[str, Any]] = {}\nCACHE_DURATION = 3600  # 1 hour\n\ndef cached_document(func):\n    \"\"\"Decorator to cache document processing results.\"\"\"\n    @functools.wraps(func)\n    def wrapper(file_path: str) -> str:\n        # Create cache key from file path and modification time\n        try:\n            expanded_path = os.path.expanduser(file_path)\n            stat = os.stat(expanded_path)\n            cache_key = f\"{expanded_path}_{stat.st_mtime}\"\n\n            # Check cache\n            if cache_key in document_cache:\n                cache_entry = document_cache[cache_key]\n                if time.time() - cache_entry['timestamp'] < CACHE_DURATION:\n                    logger.info(f\"Cache hit for {file_path}\")\n                    return cache_entry['content']\n\n            # Process document\n            result = func(file_path)\n\n            # Cache successful results\n            if not result.startswith(\"Error\"):\n                document_cache[cache_key] = {\n                    'content': result,\n                    'timestamp': time.time()\n                }\n                logger.info(f\"Cached result for {file_path}\")\n\n            return result\n\n        except Exception as e:\n            return func(file_path)  # Fallback to uncached processing\n\n    return wrapper\n\n# Apply caching to document processing tools\n@cached_document\ndef read_pdf_cached(file_path: str) -> str:\n    \"\"\"Cached version of PDF reading for improved performance.\"\"\"\n    return read_pdf(file_path)\n```\n\nImplement security measures to protect against common vulnerabilities:\n\n```\nimport hashlib\nimport tempfile\nfrom pathlib import Path\n\ndef secure_path_validation(file_path: str, allowed_directories: list) -> tuple[bool, str]:\n    \"\"\"Validate file paths against directory traversal attacks.\"\"\"\n    try:\n        # Resolve path to absolute form\n        resolved_path = Path(os.path.expanduser(file_path)).resolve()\n\n        # Check if path is within allowed directories\n        for allowed_dir in allowed_directories:\n            allowed_path = Path(os.path.expanduser(allowed_dir)).resolve()\n            try:\n                resolved_path.relative_to(allowed_path)\n                return True, str(resolved_path)\n            except ValueError:\n                continue\n\n        return False, \"Path not in allowed directories\"\n\n    except Exception as e:\n        return False, f\"Path validation error: {str(e)}\"\n\ndef sanitize_filename(filename: str) -> str:\n    \"\"\"Remove potentially dangerous characters from filenames.\"\"\"\n    # Remove path separators and other dangerous characters\n    dangerous_chars = ['/', '\\\\', '..', '<', '>', ':', '\"', '|', '?', '*']\n    sanitized = filename\n\n    for char in dangerous_chars:\n        sanitized = sanitized.replace(char, '_')\n\n    return sanitized[:255]  # Limit filename length\n\n# Update tools with security validation\nALLOWED_DIRECTORIES = [\n    \"~/Documents\",\n    \"~/Downloads\",\n    \"~/Desktop\"\n]\n\n@mcp.tool()\ndef read_pdf_secure(file_path: str) -> str:\n    \"\"\"Secure PDF reader with path validation and safety checks.\"\"\"\n    try:\n        # Validate path security\n        is_safe, safe_path = secure_path_validation(file_path, ALLOWED_DIRECTORIES)\n        if not is_safe:\n            return f\"Security error: {safe_path}\"\n\n        # Continue with normal validation and processing\n        is_valid, result = validate_file(safe_path, ['.pdf'])\n        if not is_valid:\n            return f\"Error: {result}\"\n\n        return md.convert(result).text_content\n\n    except Exception as e:\n        logger.error(f\"Secure PDF processing error: {str(e)}\")\n        return f\"Error: {str(e)}\"\n```\n\nFastMCP includes a built-in debugging interface that simplifies development and testing:\n\n```\nmcp dev document_reader.py\n```\n\nThis launches the MCP Inspector at `http://127.0.0.1:6274`, providing a web interface for testing all server components.\n\n**Inspector Testing Workflow:**\n\n1.   **Connection**: Click “Connect” to establish server communication\n2.   **Tools Testing**: Test each tool with various input parameters\n3.   **Resource Validation**: Verify resource access and dynamic parameter handling\n4.   **Prompt Preview**: Preview prompt templates with different argument values\n5.   **Error Scenarios**: Test error handling with invalid inputs\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> FastMCPの具体的な実装例が非常に参考になる。特に、ファイル処理、キャッシュ、セキュリティ対策などの実装方法が詳細に説明されている。この情報を基に、具体的なMCPサーバーの実装コードを提示できる。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"}]},"metadata":{"arguments":"{\"query\":\"RAG implementation with vector database Weaviate Milvus 2026 best practices\"}","display_result":"","duration":"4s","id":"call_igSAU0igas","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【10†Top 10 Vector Databases for LLM Applications in 2026†https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications】\nMilvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...\n\n【11†The 7 Best Vector Databases in 2026†https://www.datacamp.com/blog/the-top-5-vector-databases】\nWeaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...\n\n【12†Top 6 Vector Database Solutions for RAG Applications: 2026†https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions】\nExplore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.\n\n【13†Best RAG Tools, Frameworks, and Libraries in 2026†https://research.aimultiple.com/retrieval-augmented-generation】\nWeaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...\n\n【14†Vector Databases for AI Apps in 2026: Pinecone, Milvus,†https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6】\nVector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...\n\n【15†Optimize Vector Databases, Enhance RAG-Driven†https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md】\nIn this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...\n\n【16†How to Choose the Right Vector Database for Your RAG†https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04】\nGrowing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...\n\n【17†Vector Databases for Generative AI Applications Guide 2026†https://brollyai.com/vector-databases-for-generative-ai-applications】\nExplore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.\n\n【18†Retrieval Augmented Generation†https://weaviate.io/rag】\nRetrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.\n\n【19†Signals for 2026†https://www.oreilly.com/radar/signals-for-2026】\nA multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="search">
> RAG実装に関する最新のベストプラクティスがわかる。特に、ベクトルデータベースの選択、ハイブリッド検索、パフォーマンス最適化などの点について深掘りできる。WeaviateとMilvusの比較や具体的な導入方法についても確認したい。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://weaviate.io/rag","title":"Retrieval Augmented Generation","content":"【18†Retrieval Augmented Generation†https://weaviate.io/rag】\nTitle: Retrieval Augmented Generation | Weaviate\n\nURL Source: https://weaviate.io/rag\n\nMarkdown Content:\nRetrieval Augmented Generation | Weaviate\n===============\n\n*   Consent\n*   Details\n*   [#IABV2SETTINGS#]\n*   About\n\nThis website uses cookies\n\nWe use cookies to enable basic website functionalities, personalize content and ads, and analyze our traffic _\\_.\\__ By clicking “Accept All”, you agree to the storing and use of data as described in our Privacy Policy.\n\nConsent Selection\n\n**Necessary** \n\n- [x] \n\n**Preferences** \n\n- [x] \n\n**Statistics** \n\n- [x] \n\n**Marketing** \n\n- [x] \n\nShow details\n\nDetails\n\n*   \nNecessary  27- [x]   Necessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. \n\n    *   Cookiebot 1 Learn more about this provider**CookieConsent**Stores the user's cookie consent state for the current domain**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n    *   Google 6 Learn more about this provider Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n**test_cookie**Used to check if the user's browser supports cookies.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **_GRECAPTCHA**Pending**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **rc::a**This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **rc::b**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Session**Type**: HTML Local Storage  **rc::c**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Session**Type**: HTML Local Storage  **rc::f**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   HubSpot 1 Learn more about this provider**embed/v3/counters.gif**Used to implement forms on the website.**Maximum Storage Duration**: Session**Type**: Pixel Tracker   \n    *   LinkedIn 2 Learn more about this provider**bcookie**Used in order to detect spam and improve the website's security. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **li_gc**Stores the user's cookie consent state for the current domain**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie   \n    *   beehiiv.com 1**cf_clearance**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n    *   beehiiv.com elfsightcdn.com g2.com hubapi.com luma.com lumacdn.com 7**__cf_bm[x7]**This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   client.px-cloud.net 3**_px3**Used in context with the website's BotManager. The BotManager detects, categorizes and compiles reports on potential bots trying to access the website.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **_pxvid**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **pxcts**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   core.service.elfsight.com hsforms.com 3**_cfuvid[x3]**This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators. **Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   weaviate.io 1**debug**This cookie is used to detect errors on the website - this information is sent to the website's support staff in order to optimize the visitor's experience on the website.**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   www.emailpig.com 1**XSRF-TOKEN**Ensures visitor browsing-security by preventing cross-site request forgery. This cookie is essential for the security of the website and visitor. **Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   x.clearbitjs.com 1**pfjs%3Acookies**Used to check if the user's browser supports cookies.**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n\n*   \nPreferences  1- [x]   Preference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in. \n\n    *   LinkedIn 1 Learn more about this provider**lidc**Registers which server-cluster is serving the visitor. This is used in context with load balancing, in order to optimize user experience. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n\n*   \nStatistics  10- [x]   Statistic cookies help website owners to understand how visitors interact with websites by collecting and reporting information anonymously. \n\n    *   Google 1 Learn more about this provider Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n**S**Sets a unique ID for the session. This allows the website to obtain data on visitor behaviour for statistical purposes.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   HubSpot 3 Learn more about this provider**__hssc**Identifies if the cookie data needs to be updated in the visitor's browser.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **__hssrc**Used to recognise the visitor's browser upon reentry on the website.**Maximum Storage Duration**: Session**Type**: HTTP Cookie  **__hstc**Sets a unique ID for the session. This allows the website to obtain data on visitor behaviour for statistical purposes.**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie   \n    *   Microsoft 2 Learn more about this provider**_clck**Collects data on the user’s navigation and behavior on the website. This is used to compile statistical reports and heatmaps for the website owner.**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **_clsk**Registers statistical data on users' behaviour on the website. Used for internal analytics by the website operator. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   Wix 1 Learn more about this provider**_wixAB3**This cookie is used by the website’s operator in context with multi-variate testing. This is a tool used to combine or change content on the website. This allows the website to find the best variation/edition of the site. **Maximum Storage Duration**: 6 months**Type**: HTTP Cookie   \n    *   cdn.ashbyprd.com 1**dd_cookie_test_#**Registers data on visitors' website-behaviour. This is used for internal analysis and website optimization. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   cdn.cr-relay.com 1**cookiecookie**This cookie is used by the website’s operator in context with multi-variate testing. This is a tool used to combine or change content on the website. This allows the website to find the best variation/edition of the site.**Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   x.clearbitjs.com 1**cb%3Atest**Collects data on the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded with the purpose of generating reports for optimising the website content.**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n\n*   \nMarketing  49- [x]   Marketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers. \n\n    *   Elfsight 1 Learn more about this provider**elfsight_viewed_recently**Determines which products the user has viewed, allowing the website to promote related products. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   Google 8 Learn more about this provider Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n**COMPASS**Pending**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **GFE_RTT**Used to implement the content through Google Docs. **Maximum Storage Duration**: Session**Type**: HTTP Cookie  **IDE**Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user.**Maximum Storage Duration**: 400 days**Type**: HTTP Cookie  **NID**Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads.**Maximum Storage Duration**: 6 months**Type**: HTTP Cookie  **pagead/1p-user-list/#**Tracks if the user has shown interest in specific products or events across multiple websites and detects how the user navigates between sites. This is used for measurement of advertisement efforts and facilitates payment of referral-fees between websites.**Maximum Storage Duration**: Session**Type**: Pixel Tracker  **_ga**Used to send data to Google Analytics about the visitor's device and behavior. Tracks the visitor across devices and marketing channels.**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie  **_ga_#**Used to send data to Google Analytics about the visitor's device and behavior. Tracks the visitor across devices and marketing channels.**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie  **_gcl_au**Used by Google AdSense for experimenting with advertisement efficiency across websites using their services. **Maximum Storage Duration**: 3 months**Type**: HTTP Cookie   \n    *   HubSpot 1 Learn more about this provider**hubspotutk**Sets a unique ID for the session. This allows the website to obtain data on visitor behaviour for statistical purposes.**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie   \n    *   LinkedIn 1 Learn more about this provider**collect/**Collects data on user behaviour and interaction in order to optimize the website and make advertisement on the website more relevant. **Maximum Storage Duration**: Session**Type**: Pixel Tracker   \n    *   YouTube 29 Learn more about this provider**LAST_RESULT_ENTRY_KEY[x2]**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Session**Type**: HTTP Cookie  **ytidb::LAST_RESULT_ENTRY_KEY[x2]**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **YtIdbMeta#databases[x2]**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Persistent**Type**: IndexedDB  **yt-remote-cast-available[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-cast-installed[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-connected-devices[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **yt-remote-device-id[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **yt-remote-fast-check-period[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-session-app[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-session-name[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **__Secure-ROLLOUT_TOKEN**Pending**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **__Secure-YEC**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTTP Cookie  **__Secure-YNID**Pending**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **LogsDatabaseV2:V#||LogsRequestsStore**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Persistent**Type**: IndexedDB  **remote_sid**Necessary for the implementation and functionality of YouTube video-content on the website. **Maximum Storage Duration**: Session**Type**: HTTP Cookie  **ServiceWorkerLogsDatabase#SWHealthLog**Necessary for the implementation and functionality of YouTube video-content on the website. **Maximum Storage Duration**: Persistent**Type**: IndexedDB  **TESTCOOKIESENABLED**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **VISITOR_INFO1_LIVE**Tries to estimate the users' bandwidth on pages with integrated YouTube videos.**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **YSC**Registers a unique ID to keep statistics of what videos from YouTube the user has seen.**Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   app.guideflow.com www.googletagmanager.com 2**_gcl_ls[x2]**Tracks the conversion rate between the user and the advertisement banners on the website - This serves to optimise the relevance of the advertisements on the website. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   embeds.beehiiv.com 1**pxsid**Registers data on visitor such as IP addresses, geographical location and advertisement interaction. This information is used optimize the advertisement on websites that make use of Rubicon Project-services. **Maximum Storage Duration**: Session**Type**: HTML Local Storage   \n    *   tag.clearbitscripts.com 2**cb_group_properties**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **cb_user_traits**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   x.clearbitjs.com 4**__tld__**Used to track visitors on multiple websites, in order to present relevant advertisement based on the visitor's preferences. **Maximum Storage Duration**: Session**Type**: HTTP Cookie  **cb_anonymous_id**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **cb_group_id**Collects data on visitors. This information is used to assign visitors into segments, making website advertisement more efficient. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **cb_user_id**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n\n*   Unclassified 20 Unclassified cookies are cookies that we are in the process of classifying, together with the providers of individual cookies.  \n\n\n"},"metadata":{"arguments":"{\"link_id\":18}","display_result":"","duration":"5s","id":"call_mWPcGNgvBb","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【18†Retrieval Augmented Generation†https://weaviate.io/rag】\nTitle: Retrieval Augmented Generation | Weaviate\n\nURL Source: https://weaviate.io/rag\n\nMarkdown Content:\nRetrieval Augmented Generation | Weaviate\n===============\n\n*   Consent\n*   Details\n*   [#IABV2SETTINGS#]\n*   About\n\nThis website uses cookies\n\nWe use cookies to enable basic website functionalities, personalize content and ads, and analyze our traffic _\\_.\\__ By clicking “Accept All”, you agree to the storing and use of data as described in our Privacy Policy.\n\nConsent Selection\n\n**Necessary** \n\n- [x] \n\n**Preferences** \n\n- [x] \n\n**Statistics** \n\n- [x] \n\n**Marketing** \n\n- [x] \n\nShow details\n\nDetails\n\n*   \nNecessary  27- [x]   Necessary cookies help make a website usable by enabling basic functions like page navigation and access to secure areas of the website. The website cannot function properly without these cookies. \n\n    *   Cookiebot 1 Learn more about this provider**CookieConsent**Stores the user's cookie consent state for the current domain**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n    *   Google 6 Learn more about this provider Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n**test_cookie**Used to check if the user's browser supports cookies.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **_GRECAPTCHA**Pending**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **rc::a**This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **rc::b**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Session**Type**: HTML Local Storage  **rc::c**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Session**Type**: HTML Local Storage  **rc::f**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   HubSpot 1 Learn more about this provider**embed/v3/counters.gif**Used to implement forms on the website.**Maximum Storage Duration**: Session**Type**: Pixel Tracker   \n    *   LinkedIn 2 Learn more about this provider**bcookie**Used in order to detect spam and improve the website's security. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **li_gc**Stores the user's cookie consent state for the current domain**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie   \n    *   beehiiv.com 1**cf_clearance**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n    *   beehiiv.com elfsightcdn.com g2.com hubapi.com luma.com lumacdn.com 7**__cf_bm[x7]**This cookie is used to distinguish between humans and bots. This is beneficial for the website, in order to make valid reports on the use of their website.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   client.px-cloud.net 3**_px3**Used in context with the website's BotManager. The BotManager detects, categorizes and compiles reports on potential bots trying to access the website.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **_pxvid**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **pxcts**This cookie is used to distinguish between humans and bots. **Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   core.service.elfsight.com hsforms.com 3**_cfuvid[x3]**This cookie is a part of the services provided by Cloudflare - Including load-balancing, deliverance of website content and serving DNS connection for website operators. **Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   weaviate.io 1**debug**This cookie is used to detect errors on the website - this information is sent to the website's support staff in order to optimize the visitor's experience on the website.**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   www.emailpig.com 1**XSRF-TOKEN**Ensures visitor browsing-security by preventing cross-site request forgery. This cookie is essential for the security of the website and visitor. **Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   x.clearbitjs.com 1**pfjs%3Acookies**Used to check if the user's browser supports cookies.**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n\n*   \nPreferences  1- [x]   Preference cookies enable a website to remember information that changes the way the website behaves or looks, like your preferred language or the region that you are in. \n\n    *   LinkedIn 1 Learn more about this provider**lidc**Registers which server-cluster is serving the visitor. This is used in context with load balancing, in order to optimize user experience. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n\n*   \nStatistics  10- [x]   Statistic cookies help website owners to understand how visitors interact with websites by collecting and reporting information anonymously. \n\n    *   Google 1 Learn more about this provider Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n**S**Sets a unique ID for the session. This allows the website to obtain data on visitor behaviour for statistical purposes.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   HubSpot 3 Learn more about this provider**__hssc**Identifies if the cookie data needs to be updated in the visitor's browser.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **__hssrc**Used to recognise the visitor's browser upon reentry on the website.**Maximum Storage Duration**: Session**Type**: HTTP Cookie  **__hstc**Sets a unique ID for the session. This allows the website to obtain data on visitor behaviour for statistical purposes.**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie   \n    *   Microsoft 2 Learn more about this provider**_clck**Collects data on the user’s navigation and behavior on the website. This is used to compile statistical reports and heatmaps for the website owner.**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **_clsk**Registers statistical data on users' behaviour on the website. Used for internal analytics by the website operator. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   Wix 1 Learn more about this provider**_wixAB3**This cookie is used by the website’s operator in context with multi-variate testing. This is a tool used to combine or change content on the website. This allows the website to find the best variation/edition of the site. **Maximum Storage Duration**: 6 months**Type**: HTTP Cookie   \n    *   cdn.ashbyprd.com 1**dd_cookie_test_#**Registers data on visitors' website-behaviour. This is used for internal analysis and website optimization. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   cdn.cr-relay.com 1**cookiecookie**This cookie is used by the website’s operator in context with multi-variate testing. This is a tool used to combine or change content on the website. This allows the website to find the best variation/edition of the site.**Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   x.clearbitjs.com 1**cb%3Atest**Collects data on the user's visits to the website, such as the number of visits, average time spent on the website and what pages have been loaded with the purpose of generating reports for optimising the website content.**Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n\n*   \nMarketing  49- [x]   Marketing cookies are used to track visitors across websites. The intention is to display ads that are relevant and engaging for the individual user and thereby more valuable for publishers and third party advertisers. \n\n    *   Elfsight 1 Learn more about this provider**elfsight_viewed_recently**Determines which products the user has viewed, allowing the website to promote related products. **Maximum Storage Duration**: 1 day**Type**: HTTP Cookie   \n    *   Google 8 Learn more about this provider Some of the data collected by this provider is for the purposes of personalization and measuring advertising effectiveness.\n\n**COMPASS**Pending**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **GFE_RTT**Used to implement the content through Google Docs. **Maximum Storage Duration**: Session**Type**: HTTP Cookie  **IDE**Used by Google DoubleClick to register and report the website user's actions after viewing or clicking one of the advertiser's ads with the purpose of measuring the efficacy of an ad and to present targeted ads to the user.**Maximum Storage Duration**: 400 days**Type**: HTTP Cookie  **NID**Registers a unique ID that identifies a returning user's device. The ID is used for targeted ads.**Maximum Storage Duration**: 6 months**Type**: HTTP Cookie  **pagead/1p-user-list/#**Tracks if the user has shown interest in specific products or events across multiple websites and detects how the user navigates between sites. This is used for measurement of advertisement efforts and facilitates payment of referral-fees between websites.**Maximum Storage Duration**: Session**Type**: Pixel Tracker  **_ga**Used to send data to Google Analytics about the visitor's device and behavior. Tracks the visitor across devices and marketing channels.**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie  **_ga_#**Used to send data to Google Analytics about the visitor's device and behavior. Tracks the visitor across devices and marketing channels.**Maximum Storage Duration**: 2 years**Type**: HTTP Cookie  **_gcl_au**Used by Google AdSense for experimenting with advertisement efficiency across websites using their services. **Maximum Storage Duration**: 3 months**Type**: HTTP Cookie   \n    *   HubSpot 1 Learn more about this provider**hubspotutk**Sets a unique ID for the session. This allows the website to obtain data on visitor behaviour for statistical purposes.**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie   \n    *   LinkedIn 1 Learn more about this provider**collect/**Collects data on user behaviour and interaction in order to optimize the website and make advertisement on the website more relevant. **Maximum Storage Duration**: Session**Type**: Pixel Tracker   \n    *   YouTube 29 Learn more about this provider**LAST_RESULT_ENTRY_KEY[x2]**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Session**Type**: HTTP Cookie  **ytidb::LAST_RESULT_ENTRY_KEY[x2]**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **YtIdbMeta#databases[x2]**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Persistent**Type**: IndexedDB  **yt-remote-cast-available[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-cast-installed[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-connected-devices[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **yt-remote-device-id[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **yt-remote-fast-check-period[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-session-app[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **yt-remote-session-name[x2]**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTML Local Storage  **__Secure-ROLLOUT_TOKEN**Pending**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **__Secure-YEC**Stores the user's video player preferences using embedded YouTube video**Maximum Storage Duration**: Session**Type**: HTTP Cookie  **__Secure-YNID**Pending**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **LogsDatabaseV2:V#||LogsRequestsStore**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: Persistent**Type**: IndexedDB  **remote_sid**Necessary for the implementation and functionality of YouTube video-content on the website. **Maximum Storage Duration**: Session**Type**: HTTP Cookie  **ServiceWorkerLogsDatabase#SWHealthLog**Necessary for the implementation and functionality of YouTube video-content on the website. **Maximum Storage Duration**: Persistent**Type**: IndexedDB  **TESTCOOKIESENABLED**Used to track user’s interaction with embedded content.**Maximum Storage Duration**: 1 day**Type**: HTTP Cookie  **VISITOR_INFO1_LIVE**Tries to estimate the users' bandwidth on pages with integrated YouTube videos.**Maximum Storage Duration**: 180 days**Type**: HTTP Cookie  **YSC**Registers a unique ID to keep statistics of what videos from YouTube the user has seen.**Maximum Storage Duration**: Session**Type**: HTTP Cookie   \n    *   app.guideflow.com www.googletagmanager.com 2**_gcl_ls[x2]**Tracks the conversion rate between the user and the advertisement banners on the website - This serves to optimise the relevance of the advertisements on the website. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   embeds.beehiiv.com 1**pxsid**Registers data on visitor such as IP addresses, geographical location and advertisement interaction. This information is used optimize the advertisement on websites that make use of Rubicon Project-services. **Maximum Storage Duration**: Session**Type**: HTML Local Storage   \n    *   tag.clearbitscripts.com 2**cb_group_properties**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage  **cb_user_traits**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: Persistent**Type**: HTML Local Storage   \n    *   x.clearbitjs.com 4**__tld__**Used to track visitors on multiple websites, in order to present relevant advertisement based on the visitor's preferences. **Maximum Storage Duration**: Session**Type**: HTTP Cookie  **cb_anonymous_id**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **cb_group_id**Collects data on visitors. This information is used to assign visitors into segments, making website advertisement more efficient. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie  **cb_user_id**Collects data on visitor behaviour from multiple websites, in order to present more relevant advertisement - This also allows the website to limit the number of times that they are shown the same advertisement. **Maximum Storage Duration**: 1 year**Type**: HTTP Cookie   \n\n*   Unclassified 20 Unclassified cookies are cookies that we are in the process of classifying, together with the providers of individual cookies.  \n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="3" view="" last_tool_call_name="click">
> WeaviateのRAGに関するドキュメントが見つかった。具体的な実装方法や特徴について深掘りできる。特に、ハイブリッド検索、モジュール構成、パフォーマンス最適化などの点について確認したい。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"},{"title":"Hybrid Search Explained","url":"https://weaviate.io/blog/hybrid-search-explained","text":"Learn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!","index":21,"favicon":"","host_name":"weaviate.io"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":22,"favicon":"","host_name":"weaviate.io"},{"title":"Introduction to Retrieval Augmented Generation (RAG)","url":"https://weaviate.io/blog/introduction-to-rag","text":"For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...","index":23,"favicon":"","host_name":"weaviate.io"},{"title":"Lessons learned from building hybrid search in production","url":"https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in","text":"After shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...","index":24,"favicon":"","host_name":"www.reddit.com"},{"title":"weaviate/Verba: Retrieval Augmented Generation (RAG)","url":"https://github.com/weaviate/Verba","text":"Verba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.","index":25,"favicon":"","host_name":"github.com"},{"title":"Use a Weaviate database with Vertex AI RAG Engine","url":"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db","text":"This is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python","index":26,"favicon":"","host_name":"docs.cloud.google.com"},{"title":"Legacy data to RAG : Modernise Your Apps with Amazon","url":"https://weaviate.io/blog/sagemaker-studio-rag","text":"Weaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.","index":27,"favicon":"","host_name":"weaviate.io"},{"title":"Building a Semantic Search Engine using Weaviate","url":"https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate","text":"Getting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.","index":28,"favicon":"","host_name":"www.analyticsvidhya.com"},{"title":"Exploring RAG and GraphRAG: Understanding when and","url":"https://weaviate.io/blog/graph-rag","text":"Retrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.","index":29,"favicon":"","host_name":"weaviate.io"},{"title":"Improving Retrieval Performance in RAG Pipelines with","url":"https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5","text":"This article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...","index":30,"favicon":"","host_name":"towardsdatascience.com"}]},"metadata":{"arguments":"{\"query\":\"Weaviate RAG implementation hybrid search example 2026\"}","display_result":"","duration":"2s","id":"call_BCS0xEO7H8","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【20†Hybrid Search Explained†https://weaviate.io/blog/hybrid-search-explained】\nLearn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!\n\n【21†Retrieval Augmented Generation†https://weaviate.io/rag】\nRetrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.\n\n【22†Introduction to Retrieval Augmented Generation (RAG)†https://weaviate.io/blog/introduction-to-rag】\nFor specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...\n\n【23†Lessons learned from building hybrid search in production†https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in】\nAfter shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...\n\n【24†weaviate/Verba: Retrieval Augmented Generation (RAG)†https://github.com/weaviate/Verba】\nVerba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.\n\n【25†Use a Weaviate database with Vertex AI RAG Engine†https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db】\nThis is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python\n\n【26†Legacy data to RAG : Modernise Your Apps with Amazon†https://weaviate.io/blog/sagemaker-studio-rag】\nWeaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.\n\n【27†Building a Semantic Search Engine using Weaviate†https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate】\nGetting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.\n\n【28†Exploring RAG and GraphRAG: Understanding when and†https://weaviate.io/blog/graph-rag】\nRetrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.\n\n【29†Improving Retrieval Performance in RAG Pipelines with†https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5】\nThis article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="3" view="" last_tool_call_name="search">
> Weaviateのハイブリッド検索に関する具体的な実装例が見つかった。これを基に、RAGシステムの具体的な構築方法を深掘りできる。特に、ハイブリッド検索の設定、パフォーマンス最適化、スケーラビリティなどの点について確認したい。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://weaviate.io/blog/hybrid-search-explained","title":"Hybrid Search Explained","content":"【20†Hybrid Search Explained†https://weaviate.io/blog/hybrid-search-explained】\nTitle: Hybrid Search Explained | Weaviate\n\nURL Source: https://weaviate.io/blog/hybrid-search-explained\n\nPublished Time: 2025-01-27T00:00:00.000Z\n\nMarkdown Content:\nHybrid search is a technique that **combines multiple search algorithms** to improve the accuracy and relevance of search results. It uses the best features of both keyword-based search algorithms with vector search techniques. By leveraging the strengths of different algorithms, it provides a more effective search experience for users.\n\nThe hybrid search feature was introduced in Weaviate `1.17`. It uses sparse and dense vectors to represent the semantic meaning and context of search queries and documents. In this blog post, you will learn the definition of hybrid search, the role of sparse and dense vectors, when to use hybrid search, and more about the implementation of hybrid search in Weaviate and how to use it.\n\nSparse and Dense Vectors​\n-------------------------\n\nSparse and dense vectors are calculated with distinct algorithms. Sparse vectors have mostly zero values with only a few non-zero values, while dense vectors mostly contain non-zero values. Sparse embeddings are generated from algorithms like BM25 and SPLADE. Dense embeddings are generated from machine learning models like GloVe and Transformers.\n\nNote, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search.\n\nIf you’re interested to learn about how dense vector indexes are built and optimized in Weaviate, check out this article.\n\n### BM25​\n\nBM25 builds on the keyword scoring method TF-IDF (Term-Frequency Inverse-Document Frequency) by taking the Binary Independence Model from the IDF calculation and adding a normalization penalty that weighs a document’s length relative to the average length of all the documents in the database.\n\nThe formula below presents the scoring calculation of BM25:\n\ns c o r e(D,Q)=∑i=1 n I D F(q i)f(q i,D)⋅(k 1+1)f(q i,D)+k 1⋅(1−b+b⋅∣D∣a v g d 1)score(D, Q) = \\sum_{i=1}^{n} IDF(q_i) \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{avgd_1})}\n\nSource: Wikipedia page on Okapi BM25\nThe score of the document, query pair is determined by weighing the uniqueness of each keyword in the query relative to the collection of texts. BM25 contains additional static parameters, k1 and b that may help calibrate performance to particular datasets.\n\n### BM25F​\n\nBM25F was also implemented in Weaviate `1.17`. BM25F is a variant of BM25 that allows multiple text fields per object to be given different weights in the ranking calculation. These weights are important for when fields in a document are more important than others. For example, a title may be given more weight than the abstract, since the title is sometimes more informative and concise. This type of weighting makes BM25F more flexible and customizable than BM25.\n\n### Dense Vector​\n\nDense vectors represent information stored in a database; this includes text, images, and other types of data. These embeddings are generated from machine learning models that convert data to vectors. The vectors are densely packed with information and are mostly made up of non-zero values. The meaning of each value in the vector depends on the machine learning model that you used.\n\nVector databases, like Weaviate, store these embeddings and calculate the distance between the two vectors. Distance metrics show how similar or dissimilar two vector embeddings are. The search query is converted to a vector, similar to the data vectors, and the distance value determines how close the vectors are.\n\nWhat is Hybrid Search?​\n-----------------------\n\nHybrid search merges dense and sparse vectors together to deliver the best of both search methods. Generally speaking, dense vectors excel at understanding the context of the query, whereas sparse vectors excel at keyword matches. Consider the query, “How to catch an Alaskan Pollock”. The dense vector representation is able to disambiguate “catch” as meaning fishing rather than baseball or sickness. The sparse vector search will match the phrase “Alaskan Pollock” only. This example query shows where hybrid search combines the best of both sparse and dense vectors.\n\nHow does Hybrid Search Work?​\n-----------------------------\n\nHybrid search works by combining the results of sparse vector search (e.g., BM25) and dense vector search into a single, ranked list. To achieve this, Weaviate first performs both a vector search and a keyword search in parallel. The results from these searches are then handed to a fusion algorithm, such as Reciprocal Rank Fusion (RRF), which combines and ranks the objects into a single list.\n\nRRF ensures that relevant results from both search types are fairly represented, penalizing documents ranked lower in either list. Benham and Culpepper (2018) explored a variety of rank fusion techniques to improve search results. This paper analyzed seven strategies for combining the ranked results of two lists into a single ranking. Let’s dig into how the RRF score is calculated.\n\nThe RRF score is calculated by taking the sum of the reciprocal rankings that is given from each list. By putting the rank of the document in the denominator, it penalizes the documents that are ranked lower in the list.\n\n∑d∈D 1 k+r(d)\\sum_{d \\in D} \\frac{1}{k + r(d)}\n\nSource: Benham and Culpepper, 2018\nLet's look at an example of this. We have three documents labeled `A`, `B`, and `C` and have run a BM25 and Dense search. In this example, we have set the constant _k_ to 0.\n\n| BM25 Ranking | Dense Ranking | Results |\n| --- | --- | --- |\n| A | B | A: 1/1 + 1/3 = 1.3 |\n| B | C | B: 1/2 + 1/1 = 1.5 |\n| C | A | C: 1/3 + 1/2 = 0.83 |\n\nThe above table shows the ranked order of the BM25 and Dense search. To fuse the two lists together, we need to take the sum of the reciprocal ranks. Based on the results, the top document is `Document B` with a ranking of 1.5, then `Document A` at 1.3, and `Document C` at 0.83.\n\nWeaviate supports two fusion algorithms, `rankedFusion` and `relativeScoreFusion`. `rankedFusion` is the default fusion algorithm, however you can change it in the `fusionType` parameter.\n\nFor a deep dive into how Weaviate's hybrid search combines sparse and dense vectors, you can read more on these fusion algorithms in our blog post.\n\nWhen to Use Hybrid Search?​\n---------------------------\n\nHybrid search queries are ideal for a search system that wants to leverage the power of semantic search capabilities but still rely on exact keyword matches. For example, the example search query \"How to catch an Alaskan Pollock\" from before would lead to better results with a hybrid search query than with a common keyword search or even a semantic search query.\n\nAdvantages of Hybrid Search​\n----------------------------\n\nHybrid search engines bring several advantages that make it a powerful approach for modern search systems, especially when both semantic understanding and exact keyword matching are essential. This dual approach excels in handling diverse user queries, whether they are domain-specific queries requiring exact matches or semantic queries that rely on context and meaning. For instance, in scenarios where users might include ambiguous phrases, domain-specific terms, or misspellings in their queries, hybrid search ensures relevant results by understanding the query's intent while still honoring exact matches for critical keywords.\n\nIn addition to its flexibility, hybrid search significantly improves the user experience by reducing the need for perfectly phrased queries. Dense vector embeddings capture the semantic meaning behind a search query, making it easier to handle multi-concept or even multilingual queries. Its ability to seamlessly integrate semantic relationships with precise keyword matches ensures more accurate and contextually relevant outcomes.\n\nThis makes hybrid search engines an ideal choice for applications in e-commerce, customer support, and other search-driven domains.\n\nA Simple Hybrid Search Pipeline in Weaviate​\n--------------------------------------------\n\nTo use Weaviate hybrid search you only need to confirm that you’re using Weaviate `v1.17` or a later version. There are five parameters needed to run the hybrid search query (some are optional):\n\n*   `hybrid`: shows that you want to use a hybrid search query\n*   `query`: search query\n*   `alpha` (optional, default is `0.75`): weighting for each search algorithm\n    *   `alpha` = 0 -> pure keyword search\n    *   `alpha` = 0.5 -> equal weighing of keyword and vector search\n    *   `alpha` = 1 -> pure vector search\n\n*   `vector` (optional): optional to supply your own vector\n*   `score` (optional): additional information on how much the sparse and dense methods contributed to the result\n*   `fusionType` (optional, default is`rankedFusion`): choose the fusion algorithm\n\nWith just a few lines of code, you can start using hybrid search. The query is, “Fisherman that catches salmon” (similar to the example above). When we set the alpha to 0.5 it is equally weighing the dense and sparse vector results.\n\n`response = article.query.hybrid(query=\"fisherman that catches salmon\",alpha =0.5,return_metadata=MetadataQuery(score=True, explain_score=True)for o in response.objects:    print(o.properties)    print(o.metadata.score, o.metadata.explain_score)`\n\nYou can find end-to-end notebooks on using hybrid search in Weaviate Recipes!\n\nSummary​\n--------\n\nThis article explained the concept of hybrid search. In the context of the Weaviate vector database, hybrid search is a combination of keyword search and semantic search. By combining these two types of searches, hybrid search queries can lead to more relevant results in use cases where you want to leverage the power of semantic search but also rely on exact matches of certain keywords, such as product or brand names.\n\nCheck out the documentation for more information on hybrid search!\n\nReady to start building?​\n-------------------------\n\nCheck out the Quickstart tutorial, or build amazing apps with a free trial of Weaviate Cloud (WCD).\n\n"},"metadata":{"arguments":"{\"link_id\":20}","display_result":"","duration":"11s","id":"call_5jqTCqh9p1","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【20†Hybrid Search Explained†https://weaviate.io/blog/hybrid-search-explained】\nTitle: Hybrid Search Explained | Weaviate\n\nURL Source: https://weaviate.io/blog/hybrid-search-explained\n\nPublished Time: 2025-01-27T00:00:00.000Z\n\nMarkdown Content:\nHybrid search is a technique that **combines multiple search algorithms** to improve the accuracy and relevance of search results. It uses the best features of both keyword-based search algorithms with vector search techniques. By leveraging the strengths of different algorithms, it provides a more effective search experience for users.\n\nThe hybrid search feature was introduced in Weaviate `1.17`. It uses sparse and dense vectors to represent the semantic meaning and context of search queries and documents. In this blog post, you will learn the definition of hybrid search, the role of sparse and dense vectors, when to use hybrid search, and more about the implementation of hybrid search in Weaviate and how to use it.\n\nSparse and Dense Vectors​\n-------------------------\n\nSparse and dense vectors are calculated with distinct algorithms. Sparse vectors have mostly zero values with only a few non-zero values, while dense vectors mostly contain non-zero values. Sparse embeddings are generated from algorithms like BM25 and SPLADE. Dense embeddings are generated from machine learning models like GloVe and Transformers.\n\nNote, the current implementation of hybrid search in Weaviate uses BM25/BM25F and vector search.\n\nIf you’re interested to learn about how dense vector indexes are built and optimized in Weaviate, check out this article.\n\n### BM25​\n\nBM25 builds on the keyword scoring method TF-IDF (Term-Frequency Inverse-Document Frequency) by taking the Binary Independence Model from the IDF calculation and adding a normalization penalty that weighs a document’s length relative to the average length of all the documents in the database.\n\nThe formula below presents the scoring calculation of BM25:\n\ns c o r e(D,Q)=∑i=1 n I D F(q i)f(q i,D)⋅(k 1+1)f(q i,D)+k 1⋅(1−b+b⋅∣D∣a v g d 1)score(D, Q) = \\sum_{i=1}^{n} IDF(q_i) \\frac{f(q_i, D) \\cdot (k_1 + 1)}{f(q_i, D) + k_1 \\cdot (1 - b + b \\cdot \\frac{|D|}{avgd_1})}\n\nSource: Wikipedia page on Okapi BM25\nThe score of the document, query pair is determined by weighing the uniqueness of each keyword in the query relative to the collection of texts. BM25 contains additional static parameters, k1 and b that may help calibrate performance to particular datasets.\n\n### BM25F​\n\nBM25F was also implemented in Weaviate `1.17`. BM25F is a variant of BM25 that allows multiple text fields per object to be given different weights in the ranking calculation. These weights are important for when fields in a document are more important than others. For example, a title may be given more weight than the abstract, since the title is sometimes more informative and concise. This type of weighting makes BM25F more flexible and customizable than BM25.\n\n### Dense Vector​\n\nDense vectors represent information stored in a database; this includes text, images, and other types of data. These embeddings are generated from machine learning models that convert data to vectors. The vectors are densely packed with information and are mostly made up of non-zero values. The meaning of each value in the vector depends on the machine learning model that you used.\n\nVector databases, like Weaviate, store these embeddings and calculate the distance between the two vectors. Distance metrics show how similar or dissimilar two vector embeddings are. The search query is converted to a vector, similar to the data vectors, and the distance value determines how close the vectors are.\n\nWhat is Hybrid Search?​\n-----------------------\n\nHybrid search merges dense and sparse vectors together to deliver the best of both search methods. Generally speaking, dense vectors excel at understanding the context of the query, whereas sparse vectors excel at keyword matches. Consider the query, “How to catch an Alaskan Pollock”. The dense vector representation is able to disambiguate “catch” as meaning fishing rather than baseball or sickness. The sparse vector search will match the phrase “Alaskan Pollock” only. This example query shows where hybrid search combines the best of both sparse and dense vectors.\n\nHow does Hybrid Search Work?​\n-----------------------------\n\nHybrid search works by combining the results of sparse vector search (e.g., BM25) and dense vector search into a single, ranked list. To achieve this, Weaviate first performs both a vector search and a keyword search in parallel. The results from these searches are then handed to a fusion algorithm, such as Reciprocal Rank Fusion (RRF), which combines and ranks the objects into a single list.\n\nRRF ensures that relevant results from both search types are fairly represented, penalizing documents ranked lower in either list. Benham and Culpepper (2018) explored a variety of rank fusion techniques to improve search results. This paper analyzed seven strategies for combining the ranked results of two lists into a single ranking. Let’s dig into how the RRF score is calculated.\n\nThe RRF score is calculated by taking the sum of the reciprocal rankings that is given from each list. By putting the rank of the document in the denominator, it penalizes the documents that are ranked lower in the list.\n\n∑d∈D 1 k+r(d)\\sum_{d \\in D} \\frac{1}{k + r(d)}\n\nSource: Benham and Culpepper, 2018\nLet's look at an example of this. We have three documents labeled `A`, `B`, and `C` and have run a BM25 and Dense search. In this example, we have set the constant _k_ to 0.\n\n| BM25 Ranking | Dense Ranking | Results |\n| --- | --- | --- |\n| A | B | A: 1/1 + 1/3 = 1.3 |\n| B | C | B: 1/2 + 1/1 = 1.5 |\n| C | A | C: 1/3 + 1/2 = 0.83 |\n\nThe above table shows the ranked order of the BM25 and Dense search. To fuse the two lists together, we need to take the sum of the reciprocal ranks. Based on the results, the top document is `Document B` with a ranking of 1.5, then `Document A` at 1.3, and `Document C` at 0.83.\n\nWeaviate supports two fusion algorithms, `rankedFusion` and `relativeScoreFusion`. `rankedFusion` is the default fusion algorithm, however you can change it in the `fusionType` parameter.\n\nFor a deep dive into how Weaviate's hybrid search combines sparse and dense vectors, you can read more on these fusion algorithms in our blog post.\n\nWhen to Use Hybrid Search?​\n---------------------------\n\nHybrid search queries are ideal for a search system that wants to leverage the power of semantic search capabilities but still rely on exact keyword matches. For example, the example search query \"How to catch an Alaskan Pollock\" from before would lead to better results with a hybrid search query than with a common keyword search or even a semantic search query.\n\nAdvantages of Hybrid Search​\n----------------------------\n\nHybrid search engines bring several advantages that make it a powerful approach for modern search systems, especially when both semantic understanding and exact keyword matching are essential. This dual approach excels in handling diverse user queries, whether they are domain-specific queries requiring exact matches or semantic queries that rely on context and meaning. For instance, in scenarios where users might include ambiguous phrases, domain-specific terms, or misspellings in their queries, hybrid search ensures relevant results by understanding the query's intent while still honoring exact matches for critical keywords.\n\nIn addition to its flexibility, hybrid search significantly improves the user experience by reducing the need for perfectly phrased queries. Dense vector embeddings capture the semantic meaning behind a search query, making it easier to handle multi-concept or even multilingual queries. Its ability to seamlessly integrate semantic relationships with precise keyword matches ensures more accurate and contextually relevant outcomes.\n\nThis makes hybrid search engines an ideal choice for applications in e-commerce, customer support, and other search-driven domains.\n\nA Simple Hybrid Search Pipeline in Weaviate​\n--------------------------------------------\n\nTo use Weaviate hybrid search you only need to confirm that you’re using Weaviate `v1.17` or a later version. There are five parameters needed to run the hybrid search query (some are optional):\n\n*   `hybrid`: shows that you want to use a hybrid search query\n*   `query`: search query\n*   `alpha` (optional, default is `0.75`): weighting for each search algorithm\n    *   `alpha` = 0 -> pure keyword search\n    *   `alpha` = 0.5 -> equal weighing of keyword and vector search\n    *   `alpha` = 1 -> pure vector search\n\n*   `vector` (optional): optional to supply your own vector\n*   `score` (optional): additional information on how much the sparse and dense methods contributed to the result\n*   `fusionType` (optional, default is`rankedFusion`): choose the fusion algorithm\n\nWith just a few lines of code, you can start using hybrid search. The query is, “Fisherman that catches salmon” (similar to the example above). When we set the alpha to 0.5 it is equally weighing the dense and sparse vector results.\n\n`response = article.query.hybrid(query=\"fisherman that catches salmon\",alpha =0.5,return_metadata=MetadataQuery(score=True, explain_score=True)for o in response.objects:    print(o.properties)    print(o.metadata.score, o.metadata.explain_score)`\n\nYou can find end-to-end notebooks on using hybrid search in Weaviate Recipes!\n\nSummary​\n--------\n\nThis article explained the concept of hybrid search. In the context of the Weaviate vector database, hybrid search is a combination of keyword search and semantic search. By combining these two types of searches, hybrid search queries can lead to more relevant results in use cases where you want to leverage the power of semantic search but also rely on exact matches of certain keywords, such as product or brand names.\n\nCheck out the documentation for more information on hybrid search!\n\nReady to start building?​\n-------------------------\n\nCheck out the Quickstart tutorial, or build amazing apps with a free trial of Weaviate Cloud (WCD).\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="click">
> Weaviateのハイブリッド検索の具体的な実装方法がわかった。これを基に、RAGシステムの具体的な構築手順を説明できる。特に、ハイブリッド検索の設定、alphaパラメータの調整、スコアリングなどの点について深掘りできる。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"},{"title":"Hybrid Search Explained","url":"https://weaviate.io/blog/hybrid-search-explained","text":"Learn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!","index":21,"favicon":"","host_name":"weaviate.io"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":22,"favicon":"","host_name":"weaviate.io"},{"title":"Introduction to Retrieval Augmented Generation (RAG)","url":"https://weaviate.io/blog/introduction-to-rag","text":"For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...","index":23,"favicon":"","host_name":"weaviate.io"},{"title":"Lessons learned from building hybrid search in production","url":"https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in","text":"After shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...","index":24,"favicon":"","host_name":"www.reddit.com"},{"title":"weaviate/Verba: Retrieval Augmented Generation (RAG)","url":"https://github.com/weaviate/Verba","text":"Verba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.","index":25,"favicon":"","host_name":"github.com"},{"title":"Use a Weaviate database with Vertex AI RAG Engine","url":"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db","text":"This is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python","index":26,"favicon":"","host_name":"docs.cloud.google.com"},{"title":"Legacy data to RAG : Modernise Your Apps with Amazon","url":"https://weaviate.io/blog/sagemaker-studio-rag","text":"Weaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.","index":27,"favicon":"","host_name":"weaviate.io"},{"title":"Building a Semantic Search Engine using Weaviate","url":"https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate","text":"Getting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.","index":28,"favicon":"","host_name":"www.analyticsvidhya.com"},{"title":"Exploring RAG and GraphRAG: Understanding when and","url":"https://weaviate.io/blog/graph-rag","text":"Retrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.","index":29,"favicon":"","host_name":"weaviate.io"},{"title":"Improving Retrieval Performance in RAG Pipelines with","url":"https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5","text":"This article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...","index":30,"favicon":"","host_name":"towardsdatascience.com"},{"title":"Model Context Protocol (MCP) | Cursor Docs","url":"https://cursor.com/docs/context/mcp","text":"Connect Cursor to external tools and data sources using Model Context Protocol (MCP). Install servers, configure authentication, and integrate with databases,","index":31,"favicon":"","host_name":"cursor.com"},{"title":"guides/cursor-mcp-setup.md at main","url":"https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md","text":"Setting Up MCP Servers in Cursor IDE. A comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE.","index":32,"favicon":"","host_name":"github.com"},{"title":"Display MCP from GitHub in the extensions section, as it is","url":"https://forum.cursor.com/t/display-mcp-from-github-in-the-extensions-section-as-it-is-done-in-vscode/147958","text":"I get that you want a simpler way to install MCP servers. Cursor has an official MCP Directory with featured servers. If the server you need ...","index":33,"favicon":"","host_name":"forum.cursor.com"},{"title":"A Complete Guide to MCP Integration in Cursor AI","url":"https://dev.to/akki907/supercharge-your-development-workflow-a-complete-guide-to-mcp-integration-in-cursor-ai-13l","text":"To configure MCP servers in Cursor AI: Open Cursor Settings: Navigate to File → Preferences → Cursor Settings; Look for the \"MCP\" section ...","index":34,"favicon":"","host_name":"dev.to"},{"title":"How to integrate Cursor IDE with Figma MCP","url":"https://www.zignuts.com/blog/integrate-cursor-ide-with-figma-mcp","text":"1. Download and Setup Cursor IDE · 2. Prepare Your Figma Account · 3. Configure Figma MCP in Cursor IDE · 4. Add Figma MCP Configuration.","index":35,"favicon":"","host_name":"www.zignuts.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. Download for Linux. ⤓ · Try mobile agent. →.","index":36,"favicon":"","host_name":"cursor.com"},{"title":"How to connect Cursor to 100+ MCP Servers within minutes","url":"https://composio.dev/blog/how-to-connect-cursor-to-100-mcp-servers-within-minutes","text":"Step 1: Prerequisites. · Step 2: Enable the MCP server in Cursor. · Step 3: Using a pre-defined MCP server. · Step 4: Integrating the MCP server.","index":37,"favicon":"","host_name":"composio.dev"},{"title":"Setting up IDEs (desktop clients) | Atlassian Rovo MCP","url":"https://support.atlassian.com/atlassian-rovo-mcp-server/docs/setting-up-ides","text":"Connect IDEs like VS Code to the Atlassian Remote MCP Server using the mcp-remote tool. Installation, configuration, and tips for successful setup included.","index":38,"favicon":"","host_name":"support.atlassian.com"},{"title":"MCP settings tutorial for Cursor, Claude,","url":"https://kento-yamazaki.medium.com/mcp-settings-tutorial-for-cursor-claude-31e5afbf97bc","text":"A comprehensive guide for setting up various MCP integrations in Cursor IDE. First, I show you mcp.json , which is a configuration file of MCP servers for ...","index":39,"favicon":"","host_name":"kento-yamazaki.medium.com"},{"title":"How to integrate MCP with Cursor IDE | Gavin Ching","url":"https://www.linkedin.com/posts/gavinching_using-the-cursor-ide-and-wondering-how-to-activity-7302738352116576256-SzwV","text":"To get started with MCP servers, you will click on your settings, go into features, and just Scroll down to MCP servers. Here you would just add ...","index":40,"favicon":"","host_name":"www.linkedin.com"}]},"metadata":{"arguments":"{\"query\":\"Cursor IDE MCP integration setup 2026 official\"}","display_result":"","duration":"3s","id":"call_60xUiXBoJt","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【30†Model Context Protocol (MCP) | Cursor Docs†https://cursor.com/docs/context/mcp】\nConnect Cursor to external tools and data sources using Model Context Protocol (MCP). Install servers, configure authentication, and integrate with databases,\n\n【31†guides/cursor-mcp-setup.md at main†https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md】\nSetting Up MCP Servers in Cursor IDE. A comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE.\n\n【32†Display MCP from GitHub in the extensions section, as it is†https://forum.cursor.com/t/display-mcp-from-github-in-the-extensions-section-as-it-is-done-in-vscode/147958】\nI get that you want a simpler way to install MCP servers. Cursor has an official MCP Directory with featured servers. If the server you need ...\n\n【33†A Complete Guide to MCP Integration in Cursor AI†https://dev.to/akki907/supercharge-your-development-workflow-a-complete-guide-to-mcp-integration-in-cursor-ai-13l】\nTo configure MCP servers in Cursor AI: Open Cursor Settings: Navigate to File → Preferences → Cursor Settings; Look for the \"MCP\" section ...\n\n【34†How to integrate Cursor IDE with Figma MCP†https://www.zignuts.com/blog/integrate-cursor-ide-with-figma-mcp】\n1. Download and Setup Cursor IDE · 2. Prepare Your Figma Account · 3. Configure Figma MCP in Cursor IDE · 4. Add Figma MCP Configuration.\n\n【35†Cursor IDE†https://cursor.com】\nBuilt to make you extraordinarily productive, Cursor is the best way to code with AI. Download for Linux. ⤓ · Try mobile agent. →.\n\n【36†How to connect Cursor to 100+ MCP Servers within minutes†https://composio.dev/blog/how-to-connect-cursor-to-100-mcp-servers-within-minutes】\nStep 1: Prerequisites. · Step 2: Enable the MCP server in Cursor. · Step 3: Using a pre-defined MCP server. · Step 4: Integrating the MCP server.\n\n【37†Setting up IDEs (desktop clients) | Atlassian Rovo MCP†https://support.atlassian.com/atlassian-rovo-mcp-server/docs/setting-up-ides】\nConnect IDEs like VS Code to the Atlassian Remote MCP Server using the mcp-remote tool. Installation, configuration, and tips for successful setup included.\n\n【38†MCP settings tutorial for Cursor, Claude,†https://kento-yamazaki.medium.com/mcp-settings-tutorial-for-cursor-claude-31e5afbf97bc】\nA comprehensive guide for setting up various MCP integrations in Cursor IDE. First, I show you mcp.json , which is a configuration file of MCP servers for ...\n\n【39†How to integrate MCP with Cursor IDE | Gavin Ching†https://www.linkedin.com/posts/gavinching_using-the-cursor-ide-and-wondering-how-to-activity-7302738352116576256-SzwV】\nTo get started with MCP servers, you will click on your settings, go into features, and just Scroll down to MCP servers. Here you would just add ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="search">
> Cursor IDEとMCPの連携手順に関する公式ドキュメントが見つかった。これを基に、具体的な設定方法や連携手順を深掘りできる。特に、MCPサーバーの追加方法、認証設定、実際の利用方法などを説明したい。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://cursor.com/docs/context/mcp","title":"Model Context Protocol (MCP) | Cursor Docs","content":"【30†Model Context Protocol (MCP) | Cursor Docs†https://cursor.com/docs/context/mcp】\nTitle: Model Context Protocol (MCP) | Cursor Docs\n\nURL Source: https://cursor.com/docs/context/mcp\n\nMarkdown Content:\nModel Context Protocol (MCP)\n----------------------------\n\nWhat is MCP?\n------------\n\nModel Context Protocol (MCP) enables Cursor to connect to external tools and data sources.\n\nServers\n-------\n\nBrowse available MCP servers. Click \"Add to Cursor\" to install them directly.\n\n| Name | Install | Description |\n| --- | --- | --- |\n| Amplitude | Add to Cursor | Behavior analytics and experimentation platform for product data insights. |\n| Apify | Add to Cursor | Extract data from any website with thousands of scrapers, crawlers, and automations |\n| Astro docs server | Add to Cursor | This server provides up-to-date access to the official Astro documentation. |\n| Atlassian | Add to Cursor | Project management and collaboration tools including Jira and Confluence. |\n| Auth0 | Add to Cursor | Manage Auth0 resources. |\n\n### Why use MCP?\n\nMCP connects Cursor to external systems and data. Instead of explaining your project structure repeatedly, integrate directly with your tools.\n\nWrite MCP servers in any language that can print to `stdout` or serve an HTTP endpoint - Python, JavaScript, Go, etc.\n\n### How it works\n\nMCP servers expose capabilities through the protocol, connecting Cursor to external tools or data sources.\n\nCursor supports three transport methods:\n\n| Transport | Execution environment | Deployment | Users | Input | Auth |\n| --- | --- | --- | --- | --- | --- |\n| **`stdio`** | Local | Cursor manages | Single user | Shell command | Manual |\n| **`SSE`** | Local/Remote | Deploy as server | Multiple users | URL to an SSE endpoint | OAuth |\n| **`Streamable HTTP`** | Local/Remote | Deploy as server | Multiple users | URL to an HTTP endpoint | OAuth |\n\n### Protocol support\n\nCursor supports these MCP protocol capabilities:\n\n| Feature | Support | Description |\n| --- | --- | --- |\n| **Tools** | Supported | Functions for the AI model to execute |\n| **Prompts** | Supported | Templated messages and workflows for users |\n| **Resources** | Supported | Structured data sources that can be read and referenced |\n| **Roots** | Supported | Server-initiated inquiries into URI or filesystem boundaries |\n| **Elicitation** | Supported | Server-initiated requests for additional information from users |\n\nInstalling MCP servers\n----------------------\n\n### One-click installation\n\nInstall MCP servers from our collection and authenticate with OAuth.\n\n### Using `mcp.json`\n\nConfigure custom MCP servers with a JSON file:\n\n### Static OAuth for remote servers\n\nFor MCP servers that use OAuth, you can provide **static OAuth client credentials** in `mcp.json` instead of dynamic client registration. Use this when:\n\n*   The MCP provider gives you a fixed **Client ID** (and optionally **Client Secret**)\n*   The provider requires **whitelisting a redirect URL** (e.g. Figma, Linear)\n*   The provider does not support OAuth 2.0 Dynamic Client Registration\n\nAdd an `auth` object to remote server entries that use `url`:\n\n| Field | Required | Description |\n| --- | --- | --- |\n| **CLIENT_ID** | Yes | OAuth 2.0 Client ID from the MCP provider |\n| **CLIENT_SECRET** | No | OAuth 2.0 Client Secret (if the provider uses confidential clients) |\n| **scopes** | No | OAuth scopes to request. If omitted, Cursor will use `/.well-known/oauth-authorization-server` to discover `scopes_supported` |\n\n#### Static redirect URL\n\nCursor uses a **fixed OAuth redirect URL** for all MCP servers:\n\nWhen configuring the MCP provider's OAuth app, register this URL as an allowed redirect URI. The server is identified via the OAuth `state` parameter, so one redirect URL works for all MCP servers.\n\n#### Combining with config interpolation\n\n`auth` values support the same interpolation as other fields:\n\nUse environment variables for Client ID and Client Secret instead of hardcoding them.\n\n### STDIO server configuration\n\nFor STDIO servers (local command-line servers), configure these fields in your `mcp.json`:\n\n| Field | Required | Description | Examples |\n| --- | --- | --- | --- |\n| **type** | Yes | Server connection type | `\"stdio\"` |\n| **command** | Yes | Command to start the server executable. Must be available on your system path or contain its full path. | `\"npx\"`, `\"node\"`, `\"python\"`, `\"docker\"` |\n| **args** | No | Array of arguments passed to the command | `[\"server.py\", \"--port\", \"3000\"]` |\n| **env** | No | Environment variables for the server | `{\"API_KEY\": \"${env:api-key}\"}` |\n| **envFile** | No | Path to an environment file to load more variables | `\".env\"`, `\"${workspaceFolder}/.env\"` |\n\n### Using the Extension API\n\nFor programmatic MCP server registration, Cursor provides an extension API that allows dynamic configuration without modifying `mcp.json` files. This is particularly useful for enterprise environments and automated setup workflows.\n\nMCP Extension API Reference Learn how to register MCP servers programmatically using `vscode.cursor.mcp.registerServer()`\n\n### Configuration locations\n\n### Config interpolation\n\nUse variables in `mcp.json` values. Cursor resolves variables in these fields: `command`, `args`, `env`, `url`, and `headers`.\n\nSupported syntax:\n\n*   `${env:NAME}` environment variables\n*   `${userHome}` path to your home folder\n*   `${workspaceFolder}` project root (the folder that contains `.cursor/mcp.json`)\n*   `${workspaceFolderBasename}` name of the project root\n*   `${pathSeparator}` and `${/}` OS path separator\n\nExamples\n\n### Authentication\n\nMCP servers use environment variables for authentication. Pass API keys and tokens through the config.\n\nCursor supports OAuth for servers that require it.\n\nUsing MCP in chat\n-----------------\n\nAgent automatically uses MCP tools listed under `Available Tools` when relevant. This includes Plan Mode. Ask for a specific tool by name or describe what you need. Enable or disable tools from settings.\n\n### Toggling tools\n\nEnable or disable MCP tools directly from the chat interface. Click a tool name in the tools list to toggle it. Disabled tools won't be loaded into context or available to Agent.\n\n### Tool approval\n\nAgent asks for approval before using MCP tools by default. Click the arrow next to the tool name to see arguments.\n\n#### Auto-run\n\nEnable auto-run for Agent to use MCP tools without asking. Works like terminal commands. Read more about Auto-run settings here.\n\n### Tool response\n\nCursor shows the response in chat with expandable views of arguments and responses:\n\n### Images as context\n\nMCP servers can return images - screenshots, diagrams, etc. Return them as base64 encoded strings:\n\nSee this example server for implementation details. Cursor attaches returned images to the chat. If the model supports images, it analyzes them.\n\nSecurity considerations\n-----------------------\n\nWhen installing MCP servers, consider these security practices:\n\n*   **Verify the source**: Only install MCP servers from trusted developers and repositories\n*   **Review permissions**: Check what data and APIs the server will access\n*   **Limit API keys**: Use restricted API keys with minimal required permissions\n*   **Audit code**: For critical integrations, review the server's source code\n\nRemember that MCP servers can access external services and execute code on your behalf. Always understand what a server does before installation.\n\nReal-world examples\n-------------------\n\nFor practical examples of MCP in action, see our Web Development guide which demonstrates integrating Linear, Figma, and browser tools into your development workflow.\n\nFAQ\n---\n\n"},"metadata":{"arguments":"{\"link_id\":30}","display_result":"","duration":"10s","id":"call_QHHhdDVDAC","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【30†Model Context Protocol (MCP) | Cursor Docs†https://cursor.com/docs/context/mcp】\nTitle: Model Context Protocol (MCP) | Cursor Docs\n\nURL Source: https://cursor.com/docs/context/mcp\n\nMarkdown Content:\nModel Context Protocol (MCP)\n----------------------------\n\nWhat is MCP?\n------------\n\nModel Context Protocol (MCP) enables Cursor to connect to external tools and data sources.\n\nServers\n-------\n\nBrowse available MCP servers. Click \"Add to Cursor\" to install them directly.\n\n| Name | Install | Description |\n| --- | --- | --- |\n| Amplitude | Add to Cursor | Behavior analytics and experimentation platform for product data insights. |\n| Apify | Add to Cursor | Extract data from any website with thousands of scrapers, crawlers, and automations |\n| Astro docs server | Add to Cursor | This server provides up-to-date access to the official Astro documentation. |\n| Atlassian | Add to Cursor | Project management and collaboration tools including Jira and Confluence. |\n| Auth0 | Add to Cursor | Manage Auth0 resources. |\n\n### Why use MCP?\n\nMCP connects Cursor to external systems and data. Instead of explaining your project structure repeatedly, integrate directly with your tools.\n\nWrite MCP servers in any language that can print to `stdout` or serve an HTTP endpoint - Python, JavaScript, Go, etc.\n\n### How it works\n\nMCP servers expose capabilities through the protocol, connecting Cursor to external tools or data sources.\n\nCursor supports three transport methods:\n\n| Transport | Execution environment | Deployment | Users | Input | Auth |\n| --- | --- | --- | --- | --- | --- |\n| **`stdio`** | Local | Cursor manages | Single user | Shell command | Manual |\n| **`SSE`** | Local/Remote | Deploy as server | Multiple users | URL to an SSE endpoint | OAuth |\n| **`Streamable HTTP`** | Local/Remote | Deploy as server | Multiple users | URL to an HTTP endpoint | OAuth |\n\n### Protocol support\n\nCursor supports these MCP protocol capabilities:\n\n| Feature | Support | Description |\n| --- | --- | --- |\n| **Tools** | Supported | Functions for the AI model to execute |\n| **Prompts** | Supported | Templated messages and workflows for users |\n| **Resources** | Supported | Structured data sources that can be read and referenced |\n| **Roots** | Supported | Server-initiated inquiries into URI or filesystem boundaries |\n| **Elicitation** | Supported | Server-initiated requests for additional information from users |\n\nInstalling MCP servers\n----------------------\n\n### One-click installation\n\nInstall MCP servers from our collection and authenticate with OAuth.\n\n### Using `mcp.json`\n\nConfigure custom MCP servers with a JSON file:\n\n### Static OAuth for remote servers\n\nFor MCP servers that use OAuth, you can provide **static OAuth client credentials** in `mcp.json` instead of dynamic client registration. Use this when:\n\n*   The MCP provider gives you a fixed **Client ID** (and optionally **Client Secret**)\n*   The provider requires **whitelisting a redirect URL** (e.g. Figma, Linear)\n*   The provider does not support OAuth 2.0 Dynamic Client Registration\n\nAdd an `auth` object to remote server entries that use `url`:\n\n| Field | Required | Description |\n| --- | --- | --- |\n| **CLIENT_ID** | Yes | OAuth 2.0 Client ID from the MCP provider |\n| **CLIENT_SECRET** | No | OAuth 2.0 Client Secret (if the provider uses confidential clients) |\n| **scopes** | No | OAuth scopes to request. If omitted, Cursor will use `/.well-known/oauth-authorization-server` to discover `scopes_supported` |\n\n#### Static redirect URL\n\nCursor uses a **fixed OAuth redirect URL** for all MCP servers:\n\nWhen configuring the MCP provider's OAuth app, register this URL as an allowed redirect URI. The server is identified via the OAuth `state` parameter, so one redirect URL works for all MCP servers.\n\n#### Combining with config interpolation\n\n`auth` values support the same interpolation as other fields:\n\nUse environment variables for Client ID and Client Secret instead of hardcoding them.\n\n### STDIO server configuration\n\nFor STDIO servers (local command-line servers), configure these fields in your `mcp.json`:\n\n| Field | Required | Description | Examples |\n| --- | --- | --- | --- |\n| **type** | Yes | Server connection type | `\"stdio\"` |\n| **command** | Yes | Command to start the server executable. Must be available on your system path or contain its full path. | `\"npx\"`, `\"node\"`, `\"python\"`, `\"docker\"` |\n| **args** | No | Array of arguments passed to the command | `[\"server.py\", \"--port\", \"3000\"]` |\n| **env** | No | Environment variables for the server | `{\"API_KEY\": \"${env:api-key}\"}` |\n| **envFile** | No | Path to an environment file to load more variables | `\".env\"`, `\"${workspaceFolder}/.env\"` |\n\n### Using the Extension API\n\nFor programmatic MCP server registration, Cursor provides an extension API that allows dynamic configuration without modifying `mcp.json` files. This is particularly useful for enterprise environments and automated setup workflows.\n\nMCP Extension API Reference Learn how to register MCP servers programmatically using `vscode.cursor.mcp.registerServer()`\n\n### Configuration locations\n\n### Config interpolation\n\nUse variables in `mcp.json` values. Cursor resolves variables in these fields: `command`, `args`, `env`, `url`, and `headers`.\n\nSupported syntax:\n\n*   `${env:NAME}` environment variables\n*   `${userHome}` path to your home folder\n*   `${workspaceFolder}` project root (the folder that contains `.cursor/mcp.json`)\n*   `${workspaceFolderBasename}` name of the project root\n*   `${pathSeparator}` and `${/}` OS path separator\n\nExamples\n\n### Authentication\n\nMCP servers use environment variables for authentication. Pass API keys and tokens through the config.\n\nCursor supports OAuth for servers that require it.\n\nUsing MCP in chat\n-----------------\n\nAgent automatically uses MCP tools listed under `Available Tools` when relevant. This includes Plan Mode. Ask for a specific tool by name or describe what you need. Enable or disable tools from settings.\n\n### Toggling tools\n\nEnable or disable MCP tools directly from the chat interface. Click a tool name in the tools list to toggle it. Disabled tools won't be loaded into context or available to Agent.\n\n### Tool approval\n\nAgent asks for approval before using MCP tools by default. Click the arrow next to the tool name to see arguments.\n\n#### Auto-run\n\nEnable auto-run for Agent to use MCP tools without asking. Works like terminal commands. Read more about Auto-run settings here.\n\n### Tool response\n\nCursor shows the response in chat with expandable views of arguments and responses:\n\n### Images as context\n\nMCP servers can return images - screenshots, diagrams, etc. Return them as base64 encoded strings:\n\nSee this example server for implementation details. Cursor attaches returned images to the chat. If the model supports images, it analyzes them.\n\nSecurity considerations\n-----------------------\n\nWhen installing MCP servers, consider these security practices:\n\n*   **Verify the source**: Only install MCP servers from trusted developers and repositories\n*   **Review permissions**: Check what data and APIs the server will access\n*   **Limit API keys**: Use restricted API keys with minimal required permissions\n*   **Audit code**: For critical integrations, review the server's source code\n\nRemember that MCP servers can access external services and execute code on your behalf. Always understand what a server does before installation.\n\nReal-world examples\n-------------------\n\nFor practical examples of MCP in action, see our Web Development guide which demonstrates integrating Linear, Figma, and browser tools into your development workflow.\n\nFAQ\n---\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> Cursor IDEのMCP連携手順に関する公式ドキュメントが非常に詳細で、具体的な設定方法がわかる。これを基に、MCPサーバーの追加方法、認証設定、実際の利用手順などを深掘りできる。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md","title":"guides/cursor-mcp-setup.md at main","content":"【31†guides/cursor-mcp-setup.md at main†https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md】\nTitle: guides/cursor-mcp-setup.md at main · JeredBlu/guides\n\nURL Source: https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md\n\nMarkdown Content:\nguides/cursor-mcp-setup.md at main · JeredBlu/guides · GitHub\n===============\n\nSkip to content\nNavigation Menu\n---------------\n\nToggle navigation\n\nSign in\n\nAppearance settings\n\n*   \nPlatform\n\n    *   \nAI CODE CREATION\n        *   GitHub Copilot Write better code with AI\n        *   GitHub Spark Build and deploy intelligent apps\n        *   GitHub Models Manage and compare prompts\n        *   MCP Registry New Integrate external tools\n\n    *   \nDEVELOPER WORKFLOWS\n        *   Actions Automate any workflow\n        *   Codespaces Instant dev environments\n        *   Issues Plan and track work\n        *   Code Review Manage code changes\n\n    *   \nAPPLICATION SECURITY\n        *   GitHub Advanced Security Find and fix vulnerabilities\n        *   Code security Secure your code as you build\n        *   Secret protection Stop leaks before they start\n\n    *   \nEXPLORE\n        *   Why GitHub\n        *   Documentation\n        *   Blog\n        *   Changelog\n        *   Marketplace\n\nView all features\n\n*   \nSolutions\n\n    *   \nBY COMPANY SIZE\n        *   Enterprises\n        *   Small and medium teams\n        *   Startups\n        *   Nonprofits\n\n    *   \nBY USE CASE\n        *   App Modernization\n        *   DevSecOps\n        *   DevOps\n        *   CI/CD\n        *   View all use cases\n\n    *   \nBY INDUSTRY\n        *   Healthcare\n        *   Financial services\n        *   Manufacturing\n        *   Government\n        *   View all industries\n\nView all solutions\n\n*   \nResources\n\n    *   \nEXPLORE BY TOPIC\n        *   AI\n        *   Software Development\n        *   DevOps\n        *   Security\n        *   View all topics\n\n    *   \nEXPLORE BY TYPE\n        *   Customer stories\n        *   Events & webinars\n        *   Ebooks & reports\n        *   Business insights\n        *   GitHub Skills\n\n    *   \nSUPPORT & SERVICES\n        *   Documentation\n        *   Customer support\n        *   Community forum\n        *   Trust center\n        *   Partners\n\n*   \nOpen Source\n\n    *   \nCOMMUNITY\n        *   GitHub Sponsors Fund open source developers\n\n    *   \nPROGRAMS\n        *   Security Lab\n        *   Maintainer Community\n        *   Accelerator\n        *   Archive Program\n\n    *   \nREPOSITORIES\n        *   Topics\n        *   Trending\n        *   Collections\n\n*   \nEnterprise\n\n    *   \nENTERPRISE SOLUTIONS\n        *   Enterprise platform AI-powered developer platform\n\n    *   \nAVAILABLE ADD-ONS\n        *   GitHub Advanced Security Enterprise-grade security features\n        *   Copilot for Business Enterprise-grade AI features\n        *   Premium Support Enterprise-grade 24/7 support\n\n*   Pricing\n\nSearch or jump to...\n\nSearch code, repositories, users, issues, pull requests...\n==========================================================\n\n Search  \n\nClear\n\nSearch syntax tips\n\nProvide feedback\n================\n\nWe read every piece of feedback, and take your input very seriously.\n\n- [x] Include my email address so I can be contacted \n\n Cancel  Submit feedback \n\nSaved searches\n==============\n\nUse saved searches to filter your results more quickly\n------------------------------------------------------\n\nName \n\nQuery \n\nTo see all available qualifiers, see our documentation.\n\n Cancel  Create saved search \n\nSign in\n\nSign up\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\nJeredBlu/**guides**Public\n\n*   Notifications You must be signed in to change notification settings\n*   Fork 9\n*   Star 37 \n\n*   Code\n*   Issues 0\n*   Pull requests 0\n*   Actions\n*   Projects 0\n*   Security### Uh oh!\nThere was an error while loading.Please reload this page.    \n*   Insights\n\nAdditional navigation options\n\n*   Code\n*   Issues\n*   Pull requests\n*   Actions\n*   Projects\n*   Security\n*   Insights\n\nCollapse file tree\n------------------\n\nFiles\n-----\n\nmain\n\nSearch this repository\n\n*       Building_n8n_with_agents_via_MCP_and_Skills.md  \n*       Claude-mcp-sync.md  \n*       GenMedia (Veo3) MCP Setup Guide  \n*       README.md  \n*       claude-code-mcp-setup.md  \n*       cursor-mcp-setup.md  \n*       test-write-access.md  \n\nBreadcrumbs\n-----------\n\n1.   guides\n\n/\ncursor-mcp-setup.md\n===================\n\nCopy path\n\nBlame More file actions\n\nBlame More file actions\n\nLatest commit\n-------------\n\nHistory\n-------\n\nHistory\n\n73 lines (52 loc) · 1.95 KB\n\nBreadcrumbs\n-----------\n\n1.   guides\n\n/\ncursor-mcp-setup.md\n===================\n\nTop\n\nFile metadata and controls\n--------------------------\n\n*   Preview \n*   Code \n*   Blame \n\n73 lines (52 loc) · 1.95 KB\n\nRaw\n\nCopy raw file\n\nDownload raw file\n\nYou must be signed in to make or propose changes\n\nMore edit options\n\nOutline\n\nEdit and raw actions\n\nSetting Up MCP Servers in Cursor IDE\n====================================\n\nA comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE. This guide accompanies my YouTube tutorial and provides detailed setup instructions.\n\nPrerequisites\n-------------\n\n*   Cursor IDE version 0.4.5.9 or later\n*   Basic familiarity with Cursor\n*   API keys (if using Brave Search)\n\nQuick Setup\n-----------\n\n1.   Open Cursor Settings\n2.   Navigate to Features\n3.   Scroll to MCP Servers section\n4.   Click \"Add New MCP Server\"\n\nServer Commands\n---------------\n\n### Brave Search\n\nundefinedshell\nenv BRAVE_API_KEY=[your-key] npx -y @modelcontextprotocol/server-brave-search\nundefined\n\n### Puppeteer\n\nundefinedshell\nnpx -y @modelcontextprotocol/server-puppeteer\nundefined\n\n### Sequential Thinking\n\nundefinedshell\nnpx -y @modelcontextprotocol/server-sequential-thinking\nundefined\n\nImplementation Guide\n--------------------\n\n1.   Server Setup\n\n    *   Use Stdio/local setup method\n    *   Add servers one at a time\n    *   Verify status (green indicator)\n\n2.   Environment Variables\n\n    *   Add API keys securely\n    *   Use proper syntax for each server\n\n3.   Usage Tips\n\n    *   MCP only works in Composer and Agent mode\n    *   Explicitly instruct AI to use MCP tools\n    *   Accept tool usage prompts when they appear\n\nTroubleshooting\n---------------\n\n*   If servers show yellow status, try refreshing\n*   Verify Cursor version is up to date\n*   Check API key formatting\n*   Restart Cursor if tools aren't appearing\n\nAdditional Resources\n--------------------\n\n*   Official Cursor MCP Documentation\n*   MCP Server Documentation\n*   More guides on my YouTube Channel\n\nSupport\n-------\n\nFor additional help and tutorials:\n\n*   📆 Book a Call: Calendly\n*   📺 YouTube: @JeredBlu\n*   🌐 Website: jeredblu.com\n\nAuthor\n------\n\nCreated by JeredBlu, based on hands-on experience with Cursor IDE and MCP servers.\n\nFooter\n------\n\n © 2026 GitHub,Inc. \n\n### Footer navigation\n\n*   Terms\n*   Privacy\n*   Security\n*   Status\n*   Community\n*   Docs\n*   Contact\n*    Manage cookies \n*    Do not share my personal information \n\n You can’t perform that action at this time.\n\n"},"metadata":{"arguments":"{\"link_id\":31}","display_result":"","duration":"4s","id":"call_8bI95te6Ie","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【31†guides/cursor-mcp-setup.md at main†https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md】\nTitle: guides/cursor-mcp-setup.md at main · JeredBlu/guides\n\nURL Source: https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md\n\nMarkdown Content:\nguides/cursor-mcp-setup.md at main · JeredBlu/guides · GitHub\n===============\n\nSkip to content\nNavigation Menu\n---------------\n\nToggle navigation\n\nSign in\n\nAppearance settings\n\n*   \nPlatform\n\n    *   \nAI CODE CREATION\n        *   GitHub Copilot Write better code with AI\n        *   GitHub Spark Build and deploy intelligent apps\n        *   GitHub Models Manage and compare prompts\n        *   MCP Registry New Integrate external tools\n\n    *   \nDEVELOPER WORKFLOWS\n        *   Actions Automate any workflow\n        *   Codespaces Instant dev environments\n        *   Issues Plan and track work\n        *   Code Review Manage code changes\n\n    *   \nAPPLICATION SECURITY\n        *   GitHub Advanced Security Find and fix vulnerabilities\n        *   Code security Secure your code as you build\n        *   Secret protection Stop leaks before they start\n\n    *   \nEXPLORE\n        *   Why GitHub\n        *   Documentation\n        *   Blog\n        *   Changelog\n        *   Marketplace\n\nView all features\n\n*   \nSolutions\n\n    *   \nBY COMPANY SIZE\n        *   Enterprises\n        *   Small and medium teams\n        *   Startups\n        *   Nonprofits\n\n    *   \nBY USE CASE\n        *   App Modernization\n        *   DevSecOps\n        *   DevOps\n        *   CI/CD\n        *   View all use cases\n\n    *   \nBY INDUSTRY\n        *   Healthcare\n        *   Financial services\n        *   Manufacturing\n        *   Government\n        *   View all industries\n\nView all solutions\n\n*   \nResources\n\n    *   \nEXPLORE BY TOPIC\n        *   AI\n        *   Software Development\n        *   DevOps\n        *   Security\n        *   View all topics\n\n    *   \nEXPLORE BY TYPE\n        *   Customer stories\n        *   Events & webinars\n        *   Ebooks & reports\n        *   Business insights\n        *   GitHub Skills\n\n    *   \nSUPPORT & SERVICES\n        *   Documentation\n        *   Customer support\n        *   Community forum\n        *   Trust center\n        *   Partners\n\n*   \nOpen Source\n\n    *   \nCOMMUNITY\n        *   GitHub Sponsors Fund open source developers\n\n    *   \nPROGRAMS\n        *   Security Lab\n        *   Maintainer Community\n        *   Accelerator\n        *   Archive Program\n\n    *   \nREPOSITORIES\n        *   Topics\n        *   Trending\n        *   Collections\n\n*   \nEnterprise\n\n    *   \nENTERPRISE SOLUTIONS\n        *   Enterprise platform AI-powered developer platform\n\n    *   \nAVAILABLE ADD-ONS\n        *   GitHub Advanced Security Enterprise-grade security features\n        *   Copilot for Business Enterprise-grade AI features\n        *   Premium Support Enterprise-grade 24/7 support\n\n*   Pricing\n\nSearch or jump to...\n\nSearch code, repositories, users, issues, pull requests...\n==========================================================\n\n Search  \n\nClear\n\nSearch syntax tips\n\nProvide feedback\n================\n\nWe read every piece of feedback, and take your input very seriously.\n\n- [x] Include my email address so I can be contacted \n\n Cancel  Submit feedback \n\nSaved searches\n==============\n\nUse saved searches to filter your results more quickly\n------------------------------------------------------\n\nName \n\nQuery \n\nTo see all available qualifiers, see our documentation.\n\n Cancel  Create saved search \n\nSign in\n\nSign up\n\nAppearance settings\n\nResetting focus\n\nYou signed in with another tab or window. Reload to refresh your session.You signed out in another tab or window. Reload to refresh your session.You switched accounts on another tab or window. Reload to refresh your session.Dismiss alert\n\n{{ message }}\n\nJeredBlu/**guides**Public\n\n*   Notifications You must be signed in to change notification settings\n*   Fork 9\n*   Star 37 \n\n*   Code\n*   Issues 0\n*   Pull requests 0\n*   Actions\n*   Projects 0\n*   Security### Uh oh!\nThere was an error while loading.Please reload this page.    \n*   Insights\n\nAdditional navigation options\n\n*   Code\n*   Issues\n*   Pull requests\n*   Actions\n*   Projects\n*   Security\n*   Insights\n\nCollapse file tree\n------------------\n\nFiles\n-----\n\nmain\n\nSearch this repository\n\n*       Building_n8n_with_agents_via_MCP_and_Skills.md  \n*       Claude-mcp-sync.md  \n*       GenMedia (Veo3) MCP Setup Guide  \n*       README.md  \n*       claude-code-mcp-setup.md  \n*       cursor-mcp-setup.md  \n*       test-write-access.md  \n\nBreadcrumbs\n-----------\n\n1.   guides\n\n/\ncursor-mcp-setup.md\n===================\n\nCopy path\n\nBlame More file actions\n\nBlame More file actions\n\nLatest commit\n-------------\n\nHistory\n-------\n\nHistory\n\n73 lines (52 loc) · 1.95 KB\n\nBreadcrumbs\n-----------\n\n1.   guides\n\n/\ncursor-mcp-setup.md\n===================\n\nTop\n\nFile metadata and controls\n--------------------------\n\n*   Preview \n*   Code \n*   Blame \n\n73 lines (52 loc) · 1.95 KB\n\nRaw\n\nCopy raw file\n\nDownload raw file\n\nYou must be signed in to make or propose changes\n\nMore edit options\n\nOutline\n\nEdit and raw actions\n\nSetting Up MCP Servers in Cursor IDE\n====================================\n\nA comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE. This guide accompanies my YouTube tutorial and provides detailed setup instructions.\n\nPrerequisites\n-------------\n\n*   Cursor IDE version 0.4.5.9 or later\n*   Basic familiarity with Cursor\n*   API keys (if using Brave Search)\n\nQuick Setup\n-----------\n\n1.   Open Cursor Settings\n2.   Navigate to Features\n3.   Scroll to MCP Servers section\n4.   Click \"Add New MCP Server\"\n\nServer Commands\n---------------\n\n### Brave Search\n\nundefinedshell\nenv BRAVE_API_KEY=[your-key] npx -y @modelcontextprotocol/server-brave-search\nundefined\n\n### Puppeteer\n\nundefinedshell\nnpx -y @modelcontextprotocol/server-puppeteer\nundefined\n\n### Sequential Thinking\n\nundefinedshell\nnpx -y @modelcontextprotocol/server-sequential-thinking\nundefined\n\nImplementation Guide\n--------------------\n\n1.   Server Setup\n\n    *   Use Stdio/local setup method\n    *   Add servers one at a time\n    *   Verify status (green indicator)\n\n2.   Environment Variables\n\n    *   Add API keys securely\n    *   Use proper syntax for each server\n\n3.   Usage Tips\n\n    *   MCP only works in Composer and Agent mode\n    *   Explicitly instruct AI to use MCP tools\n    *   Accept tool usage prompts when they appear\n\nTroubleshooting\n---------------\n\n*   If servers show yellow status, try refreshing\n*   Verify Cursor version is up to date\n*   Check API key formatting\n*   Restart Cursor if tools aren't appearing\n\nAdditional Resources\n--------------------\n\n*   Official Cursor MCP Documentation\n*   MCP Server Documentation\n*   More guides on my YouTube Channel\n\nSupport\n-------\n\nFor additional help and tutorials:\n\n*   📆 Book a Call: Calendly\n*   📺 YouTube: @JeredBlu\n*   🌐 Website: jeredblu.com\n\nAuthor\n------\n\nCreated by JeredBlu, based on hands-on experience with Cursor IDE and MCP servers.\n\nFooter\n------\n\n © 2026 GitHub,Inc. \n\n### Footer navigation\n\n*   Terms\n*   Privacy\n*   Security\n*   Status\n*   Community\n*   Docs\n*   Contact\n*    Manage cookies \n*    Do not share my personal information \n\n You can’t perform that action at this time.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="click">
> Cursor IDEでのMCPサーバー設定手順が具体的にわかる。これを基に、実際の設定手順やトラブルシューティング方法を深掘りできる。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"},{"title":"Hybrid Search Explained","url":"https://weaviate.io/blog/hybrid-search-explained","text":"Learn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!","index":21,"favicon":"","host_name":"weaviate.io"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":22,"favicon":"","host_name":"weaviate.io"},{"title":"Introduction to Retrieval Augmented Generation (RAG)","url":"https://weaviate.io/blog/introduction-to-rag","text":"For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...","index":23,"favicon":"","host_name":"weaviate.io"},{"title":"Lessons learned from building hybrid search in production","url":"https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in","text":"After shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...","index":24,"favicon":"","host_name":"www.reddit.com"},{"title":"weaviate/Verba: Retrieval Augmented Generation (RAG)","url":"https://github.com/weaviate/Verba","text":"Verba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.","index":25,"favicon":"","host_name":"github.com"},{"title":"Use a Weaviate database with Vertex AI RAG Engine","url":"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db","text":"This is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python","index":26,"favicon":"","host_name":"docs.cloud.google.com"},{"title":"Legacy data to RAG : Modernise Your Apps with Amazon","url":"https://weaviate.io/blog/sagemaker-studio-rag","text":"Weaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.","index":27,"favicon":"","host_name":"weaviate.io"},{"title":"Building a Semantic Search Engine using Weaviate","url":"https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate","text":"Getting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.","index":28,"favicon":"","host_name":"www.analyticsvidhya.com"},{"title":"Exploring RAG and GraphRAG: Understanding when and","url":"https://weaviate.io/blog/graph-rag","text":"Retrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.","index":29,"favicon":"","host_name":"weaviate.io"},{"title":"Improving Retrieval Performance in RAG Pipelines with","url":"https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5","text":"This article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...","index":30,"favicon":"","host_name":"towardsdatascience.com"},{"title":"Model Context Protocol (MCP) | Cursor Docs","url":"https://cursor.com/docs/context/mcp","text":"Connect Cursor to external tools and data sources using Model Context Protocol (MCP). Install servers, configure authentication, and integrate with databases,","index":31,"favicon":"","host_name":"cursor.com"},{"title":"guides/cursor-mcp-setup.md at main","url":"https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md","text":"Setting Up MCP Servers in Cursor IDE. A comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE.","index":32,"favicon":"","host_name":"github.com"},{"title":"Display MCP from GitHub in the extensions section, as it is","url":"https://forum.cursor.com/t/display-mcp-from-github-in-the-extensions-section-as-it-is-done-in-vscode/147958","text":"I get that you want a simpler way to install MCP servers. Cursor has an official MCP Directory with featured servers. If the server you need ...","index":33,"favicon":"","host_name":"forum.cursor.com"},{"title":"A Complete Guide to MCP Integration in Cursor AI","url":"https://dev.to/akki907/supercharge-your-development-workflow-a-complete-guide-to-mcp-integration-in-cursor-ai-13l","text":"To configure MCP servers in Cursor AI: Open Cursor Settings: Navigate to File → Preferences → Cursor Settings; Look for the \"MCP\" section ...","index":34,"favicon":"","host_name":"dev.to"},{"title":"How to integrate Cursor IDE with Figma MCP","url":"https://www.zignuts.com/blog/integrate-cursor-ide-with-figma-mcp","text":"1. Download and Setup Cursor IDE · 2. Prepare Your Figma Account · 3. Configure Figma MCP in Cursor IDE · 4. Add Figma MCP Configuration.","index":35,"favicon":"","host_name":"www.zignuts.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. Download for Linux. ⤓ · Try mobile agent. →.","index":36,"favicon":"","host_name":"cursor.com"},{"title":"How to connect Cursor to 100+ MCP Servers within minutes","url":"https://composio.dev/blog/how-to-connect-cursor-to-100-mcp-servers-within-minutes","text":"Step 1: Prerequisites. · Step 2: Enable the MCP server in Cursor. · Step 3: Using a pre-defined MCP server. · Step 4: Integrating the MCP server.","index":37,"favicon":"","host_name":"composio.dev"},{"title":"Setting up IDEs (desktop clients) | Atlassian Rovo MCP","url":"https://support.atlassian.com/atlassian-rovo-mcp-server/docs/setting-up-ides","text":"Connect IDEs like VS Code to the Atlassian Remote MCP Server using the mcp-remote tool. Installation, configuration, and tips for successful setup included.","index":38,"favicon":"","host_name":"support.atlassian.com"},{"title":"MCP settings tutorial for Cursor, Claude,","url":"https://kento-yamazaki.medium.com/mcp-settings-tutorial-for-cursor-claude-31e5afbf97bc","text":"A comprehensive guide for setting up various MCP integrations in Cursor IDE. First, I show you mcp.json , which is a configuration file of MCP servers for ...","index":39,"favicon":"","host_name":"kento-yamazaki.medium.com"},{"title":"How to integrate MCP with Cursor IDE | Gavin Ching","url":"https://www.linkedin.com/posts/gavinching_using-the-cursor-ide-and-wondering-how-to-activity-7302738352116576256-SzwV","text":"To get started with MCP servers, you will click on your settings, go into features, and just Scroll down to MCP servers. Here you would just add ...","index":40,"favicon":"","host_name":"www.linkedin.com"},{"title":"How to Add MCP to Claude Code (Step by Step, Plain","url":"https://medium.com/@Michael38/how-to-add-mcp-to-claude-code-step-by-step-plain-english-865fec18e07d","text":"This article focuses on the practical setup inside Claude Code, while the official docs cover the underlying specification. Official MCP ...","index":41,"favicon":"","host_name":"medium.com"},{"title":"Connect Claude Code to tools via MCP","url":"https://code.claude.com/docs/en/mcp","text":"Claude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool ...","index":42,"favicon":"","host_name":"code.claude.com"},{"title":"Setting Up MCP Servers in Claude Code: A Tech Ritual for","url":"https://www.reddit.com/r/ClaudeAI/comments/1jf4hnt/setting_up_mcp_servers_in_claude_code_a_tech","text":"Here, members share MCP server implementations, integration strategies, and best practices. Whether you're a developer, researcher, or AI ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Use MCP servers in VS Code","url":"https://code.visualstudio.com/docs/copilot/customization/mcp-servers","text":"Automatically discover MCP servers. VS Code can automatically detect and reuse MCP server configurations from other applications, such as Claude Desktop.","index":44,"favicon":"","host_name":"code.visualstudio.com"},{"title":"GitHub's official MCP Server","url":"https://github.com/github/github-mcp-server","text":"The GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code ...","index":45,"favicon":"","host_name":"github.com"},{"title":"Connect Claude to MCP Servers for Better AI Capabilities","url":"https://www.getmesa.com/blog/how-to-connect-mcp-server-claude","text":"Learn how to connect MCP server Claude integrations. Step-by-step guide to setup, configuration, and automating workflows with Claude AI.","index":46,"favicon":"","host_name":"www.getmesa.com"},{"title":"Atlassian MCP Integration with Claude Completely S","url":"https://community.atlassian.com/forums/Rovo-questions/Atlassian-MCP-Integration-with-Claude-Completely-Stopped-Working/qaq-p/3147695","text":"As of Saturday morning (November 16, 2025), the integration has **completely stopped working** on Claude's remote connector platforms (Claude.ai ...","index":47,"favicon":"","host_name":"community.atlassian.com"},{"title":"The Best MCP Servers for Developers in 2026","url":"https://www.builder.io/blog/best-mcp-servers-2026","text":"MCP introduces a universal interface. You spin up a \"Postgres MCP Server\" once. That server can now talk to Claude Code, Cursor, Fusion, or any ...","index":48,"favicon":"","host_name":"www.builder.io"},{"title":"7 Claude MCP servers you can set up right now","url":"https://zapier.com/blog/claude-mcp-servers","text":"Here, I'll walk you through the MCP servers that I've found the most useful when working in Claude. I'll show you how to set them up and give you some examples ...","index":49,"favicon":"","host_name":"zapier.com"},{"title":"Claude Code MCP: How to Add MCP Servers (Complete Guide)","url":"https://www.youtube.com/watch?v=DfWHX7kszQI","text":"In this video I'll show you the fundamentals of adding any MCP server to your claw code agents.","index":50,"favicon":"","host_name":"www.youtube.com"}]},"metadata":{"arguments":"{\"query\":\"Claude Code MCP server integration 2026 official\"}","display_result":"","duration":"2s","id":"call_GHEb85bY6X","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【40†How to Add MCP to Claude Code (Step by Step, Plain†https://medium.com/@Michael38/how-to-add-mcp-to-claude-code-step-by-step-plain-english-865fec18e07d】\nThis article focuses on the practical setup inside Claude Code, while the official docs cover the underlying specification. Official MCP ...\n\n【41†Connect Claude Code to tools via MCP†https://code.claude.com/docs/en/mcp】\nClaude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool ...\n\n【42†Setting Up MCP Servers in Claude Code: A Tech Ritual for†https://www.reddit.com/r/ClaudeAI/comments/1jf4hnt/setting_up_mcp_servers_in_claude_code_a_tech】\nHere, members share MCP server implementations, integration strategies, and best practices. Whether you're a developer, researcher, or AI ...\n\n【43†Use MCP servers in VS Code†https://code.visualstudio.com/docs/copilot/customization/mcp-servers】\nAutomatically discover MCP servers. VS Code can automatically detect and reuse MCP server configurations from other applications, such as Claude Desktop.\n\n【44†GitHub's official MCP Server†https://github.com/github/github-mcp-server】\nThe GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code ...\n\n【45†Connect Claude to MCP Servers for Better AI Capabilities†https://www.getmesa.com/blog/how-to-connect-mcp-server-claude】\nLearn how to connect MCP server Claude integrations. Step-by-step guide to setup, configuration, and automating workflows with Claude AI.\n\n【46†Atlassian MCP Integration with Claude Completely S†https://community.atlassian.com/forums/Rovo-questions/Atlassian-MCP-Integration-with-Claude-Completely-Stopped-Working/qaq-p/3147695】\nAs of Saturday morning (November 16, 2025), the integration has **completely stopped working** on Claude's remote connector platforms (Claude.ai ...\n\n【47†The Best MCP Servers for Developers in 2026†https://www.builder.io/blog/best-mcp-servers-2026】\nMCP introduces a universal interface. You spin up a \"Postgres MCP Server\" once. That server can now talk to Claude Code, Cursor, Fusion, or any ...\n\n【48†7 Claude MCP servers you can set up right now†https://zapier.com/blog/claude-mcp-servers】\nHere, I'll walk you through the MCP servers that I've found the most useful when working in Claude. I'll show you how to set them up and give you some examples ...\n\n【49†Claude Code MCP: How to Add MCP Servers (Complete Guide)†https://www.youtube.com/watch?v=DfWHX7kszQI】\nIn this video I'll show you the fundamentals of adding any MCP server to your claw code agents.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> Claude CodeとMCPの連携手順に関する公式ドキュメントが見つかった。これを基に、具体的な設定方法や連携手順を深掘りできる。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://code.claude.com/docs/en/mcp","title":"Connect Claude Code to tools via MCP","content":"【41†Connect Claude Code to tools via MCP†https://code.claude.com/docs/en/mcp】\nTitle: Connect Claude Code to tools via MCP - Claude Code Docs\n\nURL Source: https://code.claude.com/docs/en/mcp\n\nMarkdown Content:\nClaude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool integrations. MCP servers give Claude Code access to your tools, databases, and APIs.\n\nWhat you can do with MCP\n------------------------\n\nWith MCP servers connected, you can ask Claude Code to:\n\n*   **Implement features from issue trackers**: “Add the feature described in JIRA issue ENG-4521 and create a PR on GitHub.”\n*   **Analyze monitoring data**: “Check Sentry and Statsig to check the usage of the feature described in ENG-4521.”\n*   **Query databases**: “Find emails of 10 random users who used feature ENG-4521, based on our PostgreSQL database.”\n*   **Integrate designs**: “Update our standard email template based on the new Figma designs that were posted in Slack”\n*   **Automate workflows**: “Create Gmail drafts inviting these 10 users to a feedback session about the new feature.”\n\nPopular MCP servers\n-------------------\n\nHere are some commonly used MCP servers you can connect to Claude Code:\n\nAnalyze & update CRM records Command\n\n`claude mcp add day-ai --transport http https://day.ai/api/mcp`\n\nAccess bioRxiv and medRxiv preprint data Command\n\n`claude mcp add biorxiv --transport http https://mcp.deepsense.ai/biorxiv/mcp`\n\nAccess the ChEMBL Database Command\n\n`claude mcp add chembl --transport http https://mcp.deepsense.ai/chembl/mcp`\n\nAccess ClinicalTrials.gov data Command\n\n`claude mcp add clinical-trials --transport http https://mcp.deepsense.ai/clinical_trials/mcp`\n\nAccess the CMS Coverage Database Command\n\n`claude mcp add cms-coverage --transport http https://mcp.deepsense.ai/cms_coverage/mcp`\n\nAccess ICD-10-CM and ICD-10-PCS code sets Command\n\n`claude mcp add icd-10-codes --transport http https://mcp.deepsense.ai/icd10_codes/mcp`\n\nAccess US National Provider Identifier (NPI) Registry Command\n\n`claude mcp add npi-registry --transport http https://mcp.deepsense.ai/npi_registry/mcp`\n\nEnhance responses with scholarly research and citations Command\n\n`claude mcp add scholar-gateway --transport http https://connector.scholargateway.ai/mcp`\n\nEvent platform for managing tickets, orders & more Command\n\n`claude mcp add --transport http tickettailor https://mcp.tickettailor.ai/mcp`\n\nChat with your meetings to uncover actionable insights Command\n\n`claude mcp add fellow-ai --transport http https://fellow.app/mcp`\n\nManage issues, projects & team workflows in Linear Command\n\n`claude mcp add --transport http linear https://mcp.linear.app/mcp`\n\nCreate, deploy, manage, and secure websites on Netlify Command\n\n`claude mcp add --transport http netlify https://netlify-mcp.netlify.app/mcp`\n\nDiscover, evaluate, and buy solutions for the cloud Command\n\n`claude mcp add aws-marketplace --transport http https://marketplace-mcp.us-east-1.api.aws/mcp`\n\nAccess the HF Hub and thousands of Gradio Apps Command\n\n`claude mcp add --transport http hugging-face https://huggingface.co/mcp`\n\nAutonomous marketing to transform how you work Requires user-specific URL. Get your URL here.\n\nConnect to Asana to coordinate tasks, projects, and goals Command\n\n`claude mcp add --transport sse asana https://mcp.asana.com/sse`\n\nAccess Jira & Confluence from Claude Command\n\n`claude mcp add --transport sse atlassian https://mcp.atlassian.com/v1/sse`\n\nCompany intelligence & workforce analytics Command\n\n`claude mcp add --transport http auraintelligence https://mcp.auraintelligence.com/mcp`\n\nConnect to R&D data, source experiments, and notebooks Requires user-specific URL. Get your URL here.\n\nSearch for and use scientific templates and icons Command\n\n`claude mcp add biorender --transport http https://mcp.services.biorender.com/mcp`\n\nShorten links, generate QR Codes, and track performance Command\n\n`claude mcp add bitly --transport http https://api-ssl.bitly.com/v4/mcp`\n\nAccess and analyze blockchain data Command\n\n`claude mcp add blockscout --transport http https://mcp.blockscout.com/mcp`\n\nTrusted real-time global financial news provider Command\n\n`claude mcp add --transport http mtnewswire`\n\nSearch, create, autofill, and export Canva designs from a prompt Command\n\n`claude mcp add --transport http canva https://mcp.canva.com/mcp`\n\nManaged MCP platform for 350 sources Command\n\n`claude mcp add cdata-connect-ai --transport http https://mcp.cloud.cdata.com/mcp`\n\nSearch biomedical literature from PubMed Command\n\n`claude mcp add pubmed --transport http https://pubmed.mcp.claude.com/mcp`\n\nProject management & collaboration for teams & agents Command\n\n`claude mcp add clickup --transport http https://mcp.clickup.com/mcp`\n\nBuild applications with compute, storage, and AI Command\n\n`claude mcp add --transport http cloudflare https://bindings.mcp.cloudflare.com/mcp`\n\nManage, transform and deliver your images & videos Command\n\n`claude mcp add --transport http cloudinary https://asset-management.mcp.cloudinary.com/sse`\n\nExplore partner data and ecosystem insights in Claude Command\n\n`claude mcp add crossbeam --transport http https://mcp.crossbeam.com`\n\nReal time prices, orders, charts, and more for crypto Command\n\n`claude mcp add crypto-com --transport http https://mcp.crypto.com/market-data/mcp`\n\nManaged MCP servers with Unity Catalog and Mosaic AI Requires user-specific URL. Get your URL here.\n\nSecurely access and analyze Egnyte content.Command\n\n`claude mcp add --transport http egnyte https://mcp-server.egnyte.com/mcp`\n\nCreate better code with Figma context Command\n\n`claude mcp add --transport http figma-remote-mcp https://mcp.figma.com/mcp`\n\nAdvanced scheduling and time management for work.Command\n\n`claude mcp add --transport http clockwise https://mcp.getclockwise.com/mcp`\n\nSearch domains and check availability Command\n\n`claude mcp add godaddy --transport http https://api.godaddy.com/v1/domains/mcp`\n\nAI access to Intercom data for better customer insights Command\n\n`claude mcp add --transport http intercom https://mcp.intercom.com/mcp`\n\nCreate forms & analyze submissions inside Claude Command\n\n`claude mcp add --transport http jotform https://mcp.jotform.com/`\n\nSearch flights in Claude Command\n\n`claude mcp add kiwi-com --transport http https://mcp.kiwi.com`\n\nBrowse music charts & your personalized music picks Command\n\n`claude mcp add melon --transport http https://mcp.melon.com/mcp/`\n\nManage projects, boards, and workflows in monday.com Command\n\n`claude mcp add --transport http monday https://mcp.monday.com/mcp`\n\nConnect your Notion workspace to search, update, and power workflows across tools Command\n\n`claude mcp add --transport http notion https://mcp.notion.com/mcp`\n\nAccess PayPal payments platform Command\n\n`claude mcp add --transport http paypal https://mcp.paypal.com/mcp`\n\nSearch, access, and analyze your Ramp financial data Command\n\n`claude mcp add --transport http ramp https://ramp-mcp-remote.ramp.com/mcp`\n\nRetrieve both structured and unstructured data Requires user-specific URL. Get your URL here.\n\nSearch and manage transaction, merchant, and payment data Command\n\n```\nclaude mcp add --transport sse square https://mcp.squareup.com/sse\n```\n\nPayment processing and financial infrastructure tools Command\n\n```\nclaude mcp add --transport http stripe https://mcp.stripe.com\n```\n\nFind your ideal hotel at the best price.Command\n\n`claude mcp add --transport http trivago https://mcp.trivago.com/mcp`\n\nAnalyze, debug, and manage projects and deployments Command\n\n```\nclaude mcp add --transport http vercel https://mcp.vercel.com\n```\n\nFind people, productivity and business impact insights Requires user-specific URL. Get your URL here.\n\nAutomate workflows and connect your business apps Requires user-specific URL. Get your URL here.\n\nAutomate workflows across thousands of apps via conversation Requires user-specific URL. Get your URL here.\n\nEnrich contacts & accounts with GTM intelligence Command\n\n`claude mcp add --transport http zoominfo https://mcp.zoominfo.com/mcp`\n\nRecord screen and collect automatic context for issues Command\n\n```\nclaude mcp add --transport http jam https://mcp.jam.dev/mcp\n```\n\nSearch, query, and debug errors intelligently Command\n\n`claude mcp add --transport http sentry https://mcp.sentry.dev/mcp`\n\nManage your Stytch Project Command\n\n`claude mcp add stytch --transport http https://mcp.stytch.dev/mcp`\n\nAccess business data from hundreds of sources Command\n\n`claude mcp add --transport http coupler https://mcp.coupler.io/mcp`\n\nRead and write Airtable databases\n\nQuery and explore observability data and SLOs Command\n\n`claude mcp add honeycomb --transport http https://mcp.honeycomb.io/mcp`\n\nConnect to Pendo for product and user insights Requires user-specific URL. Get your URL here.\n\nFind and engage with verified nonprofits Command\n\n`claude mcp add benevity --transport http https://mcp.benevity.org/general/v1/nonprofit`\n\nResearch nonprofits and funders using Candid's data Command\n\n`claude mcp add candid --transport http https://mcp.candid.org/mcp`\n\nSearch and metadata tools for Synapse scientific data Command\n\n`claude mcp add synapse-org --transport http https://mcp.synapse.org/mcp`\n\nInteract with your Chronograph data directly in Claude Command\n\n`claude mcp add --transport http chronograph https://ai.chronograph.pe/mcp`\n\nInstalling MCP servers\n----------------------\n\nMCP servers can be configured in three different ways depending on your needs:\n\n### Option 1: Add a remote HTTP server\n\nHTTP servers are the recommended option for connecting to remote MCP servers. This is the most widely supported transport for cloud-based services.\n\n```\n# Basic syntax\nclaude mcp add --transport http <name> <url>\n\n# Real example: Connect to Notion\nclaude mcp add --transport http notion https://mcp.notion.com/mcp\n\n# Example with Bearer token\nclaude mcp add --transport http secure-api https://api.example.com/mcp \\\n  --header \"Authorization: Bearer your-token\"\n```\n\n### Option 2: Add a remote SSE server\n\n```\n# Basic syntax\nclaude mcp add --transport sse <name> <url>\n\n# Real example: Connect to Asana\nclaude mcp add --transport sse asana https://mcp.asana.com/sse\n\n# Example with authentication header\nclaude mcp add --transport sse private-api https://api.company.com/sse \\\n  --header \"X-API-Key: your-key-here\"\n```\n\n### Option 3: Add a local stdio server\n\nStdio servers run as local processes on your machine. They’re ideal for tools that need direct system access or custom scripts.\n\n```\n# Basic syntax\nclaude mcp add [options] <name> -- <command> [args...]\n\n# Real example: Add Airtable server\nclaude mcp add --transport stdio --env AIRTABLE_API_KEY=YOUR_KEY airtable \\\n  -- npx -y airtable-mcp-server\n```\n\n### Managing your servers\n\nOnce configured, you can manage your MCP servers with these commands:\n\n```\n# List all configured servers\nclaude mcp list\n\n# Get details for a specific server\nclaude mcp get github\n\n# Remove a server\nclaude mcp remove github\n\n# (within Claude Code) Check server status\n/mcp\n```\n\n### Dynamic tool updates\n\nClaude Code supports MCP `list_changed` notifications, allowing MCP servers to dynamically update their available tools, prompts, and resources without requiring you to disconnect and reconnect. When an MCP server sends a `list_changed` notification, Claude Code automatically refreshes the available capabilities from that server.\n\n### Plugin-provided MCP servers\n\nPlugins can bundle MCP servers, automatically providing tools and integrations when the plugin is enabled. Plugin MCP servers work identically to user-configured servers.**How plugin MCP servers work**:\n\n*   Plugins define MCP servers in `.mcp.json` at the plugin root or inline in `plugin.json`\n*   When a plugin is enabled, its MCP servers start automatically\n*   Plugin MCP tools appear alongside manually configured MCP tools\n*   Plugin servers are managed through plugin installation (not `/mcp` commands)\n\n**Example plugin MCP configuration**:In `.mcp.json` at plugin root:\n\n```\n{\n  \"database-tools\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/db-server\",\n    \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n    \"env\": {\n      \"DB_URL\": \"${DB_URL}\"\n    }\n  }\n}\n```\n\nOr inline in `plugin.json`:\n\n```\n{\n  \"name\": \"my-plugin\",\n  \"mcpServers\": {\n    \"plugin-api\": {\n      \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/api-server\",\n      \"args\": [\"--port\", \"8080\"]\n    }\n  }\n}\n```\n\n**Plugin MCP features**:\n\n*   **Automatic lifecycle**: Servers start when plugin enables, but you must restart Claude Code to apply MCP server changes (enabling or disabling)\n*   **Environment variables**: Use `${CLAUDE_PLUGIN_ROOT}` for plugin-relative paths\n*   **User environment access**: Access to same environment variables as manually configured servers\n*   **Multiple transport types**: Support stdio, SSE, and HTTP transports (transport support may vary by server)\n\n**Viewing plugin MCP servers**:\n\n```\n# Within Claude Code, see all MCP servers including plugin ones\n/mcp\n```\n\nPlugin servers appear in the list with indicators showing they come from plugins.**Benefits of plugin MCP servers**:\n\n*   **Bundled distribution**: Tools and servers packaged together\n*   **Automatic setup**: No manual MCP configuration needed\n*   **Team consistency**: Everyone gets the same tools when plugin is installed\n\nSee the plugin components reference for details on bundling MCP servers with plugins.\n\nMCP installation scopes\n-----------------------\n\nMCP servers can be configured at three different scope levels, each serving distinct purposes for managing server accessibility and sharing. Understanding these scopes helps you determine the best way to configure servers for your specific needs.\n\n### Local scope\n\nLocal-scoped servers represent the default configuration level and are stored in `~/.claude.json` under your project’s path. These servers remain private to you and are only accessible when working within the current project directory. This scope is ideal for personal development servers, experimental configurations, or servers containing sensitive credentials that shouldn’t be shared.\n\n```\n# Add a local-scoped server (default)\nclaude mcp add --transport http stripe https://mcp.stripe.com\n\n# Explicitly specify local scope\nclaude mcp add --transport http stripe --scope local https://mcp.stripe.com\n```\n\n### Project scope\n\nProject-scoped servers enable team collaboration by storing configurations in a `.mcp.json` file at your project’s root directory. This file is designed to be checked into version control, ensuring all team members have access to the same MCP tools and services. When you add a project-scoped server, Claude Code automatically creates or updates this file with the appropriate configuration structure.\n\n```\n# Add a project-scoped server\nclaude mcp add --transport http paypal --scope project https://mcp.paypal.com/mcp\n```\n\nThe resulting `.mcp.json` file follows a standardized format:\n\n```\n{\n  \"mcpServers\": {\n    \"shared-server\": {\n      \"command\": \"/path/to/server\",\n      \"args\": [],\n      \"env\": {}\n    }\n  }\n}\n```\n\nFor security reasons, Claude Code prompts for approval before using project-scoped servers from `.mcp.json` files. If you need to reset these approval choices, use the `claude mcp reset-project-choices` command.\n\n### User scope\n\nUser-scoped servers are stored in `~/.claude.json` and provide cross-project accessibility, making them available across all projects on your machine while remaining private to your user account. This scope works well for personal utility servers, development tools, or services you frequently use across different projects.\n\n```\n# Add a user server\nclaude mcp add --transport http hubspot --scope user https://mcp.hubspot.com/anthropic\n```\n\n### Choosing the right scope\n\n\n"},"metadata":{"arguments":"{\"link_id\":41}","display_result":"","duration":"1s","id":"call_qvWW4jEvyy","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【41†Connect Claude Code to tools via MCP†https://code.claude.com/docs/en/mcp】\nTitle: Connect Claude Code to tools via MCP - Claude Code Docs\n\nURL Source: https://code.claude.com/docs/en/mcp\n\nMarkdown Content:\nClaude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool integrations. MCP servers give Claude Code access to your tools, databases, and APIs.\n\nWhat you can do with MCP\n------------------------\n\nWith MCP servers connected, you can ask Claude Code to:\n\n*   **Implement features from issue trackers**: “Add the feature described in JIRA issue ENG-4521 and create a PR on GitHub.”\n*   **Analyze monitoring data**: “Check Sentry and Statsig to check the usage of the feature described in ENG-4521.”\n*   **Query databases**: “Find emails of 10 random users who used feature ENG-4521, based on our PostgreSQL database.”\n*   **Integrate designs**: “Update our standard email template based on the new Figma designs that were posted in Slack”\n*   **Automate workflows**: “Create Gmail drafts inviting these 10 users to a feedback session about the new feature.”\n\nPopular MCP servers\n-------------------\n\nHere are some commonly used MCP servers you can connect to Claude Code:\n\nAnalyze & update CRM records Command\n\n`claude mcp add day-ai --transport http https://day.ai/api/mcp`\n\nAccess bioRxiv and medRxiv preprint data Command\n\n`claude mcp add biorxiv --transport http https://mcp.deepsense.ai/biorxiv/mcp`\n\nAccess the ChEMBL Database Command\n\n`claude mcp add chembl --transport http https://mcp.deepsense.ai/chembl/mcp`\n\nAccess ClinicalTrials.gov data Command\n\n`claude mcp add clinical-trials --transport http https://mcp.deepsense.ai/clinical_trials/mcp`\n\nAccess the CMS Coverage Database Command\n\n`claude mcp add cms-coverage --transport http https://mcp.deepsense.ai/cms_coverage/mcp`\n\nAccess ICD-10-CM and ICD-10-PCS code sets Command\n\n`claude mcp add icd-10-codes --transport http https://mcp.deepsense.ai/icd10_codes/mcp`\n\nAccess US National Provider Identifier (NPI) Registry Command\n\n`claude mcp add npi-registry --transport http https://mcp.deepsense.ai/npi_registry/mcp`\n\nEnhance responses with scholarly research and citations Command\n\n`claude mcp add scholar-gateway --transport http https://connector.scholargateway.ai/mcp`\n\nEvent platform for managing tickets, orders & more Command\n\n`claude mcp add --transport http tickettailor https://mcp.tickettailor.ai/mcp`\n\nChat with your meetings to uncover actionable insights Command\n\n`claude mcp add fellow-ai --transport http https://fellow.app/mcp`\n\nManage issues, projects & team workflows in Linear Command\n\n`claude mcp add --transport http linear https://mcp.linear.app/mcp`\n\nCreate, deploy, manage, and secure websites on Netlify Command\n\n`claude mcp add --transport http netlify https://netlify-mcp.netlify.app/mcp`\n\nDiscover, evaluate, and buy solutions for the cloud Command\n\n`claude mcp add aws-marketplace --transport http https://marketplace-mcp.us-east-1.api.aws/mcp`\n\nAccess the HF Hub and thousands of Gradio Apps Command\n\n`claude mcp add --transport http hugging-face https://huggingface.co/mcp`\n\nAutonomous marketing to transform how you work Requires user-specific URL. Get your URL here.\n\nConnect to Asana to coordinate tasks, projects, and goals Command\n\n`claude mcp add --transport sse asana https://mcp.asana.com/sse`\n\nAccess Jira & Confluence from Claude Command\n\n`claude mcp add --transport sse atlassian https://mcp.atlassian.com/v1/sse`\n\nCompany intelligence & workforce analytics Command\n\n`claude mcp add --transport http auraintelligence https://mcp.auraintelligence.com/mcp`\n\nConnect to R&D data, source experiments, and notebooks Requires user-specific URL. Get your URL here.\n\nSearch for and use scientific templates and icons Command\n\n`claude mcp add biorender --transport http https://mcp.services.biorender.com/mcp`\n\nShorten links, generate QR Codes, and track performance Command\n\n`claude mcp add bitly --transport http https://api-ssl.bitly.com/v4/mcp`\n\nAccess and analyze blockchain data Command\n\n`claude mcp add blockscout --transport http https://mcp.blockscout.com/mcp`\n\nTrusted real-time global financial news provider Command\n\n`claude mcp add --transport http mtnewswire`\n\nSearch, create, autofill, and export Canva designs from a prompt Command\n\n`claude mcp add --transport http canva https://mcp.canva.com/mcp`\n\nManaged MCP platform for 350 sources Command\n\n`claude mcp add cdata-connect-ai --transport http https://mcp.cloud.cdata.com/mcp`\n\nSearch biomedical literature from PubMed Command\n\n`claude mcp add pubmed --transport http https://pubmed.mcp.claude.com/mcp`\n\nProject management & collaboration for teams & agents Command\n\n`claude mcp add clickup --transport http https://mcp.clickup.com/mcp`\n\nBuild applications with compute, storage, and AI Command\n\n`claude mcp add --transport http cloudflare https://bindings.mcp.cloudflare.com/mcp`\n\nManage, transform and deliver your images & videos Command\n\n`claude mcp add --transport http cloudinary https://asset-management.mcp.cloudinary.com/sse`\n\nExplore partner data and ecosystem insights in Claude Command\n\n`claude mcp add crossbeam --transport http https://mcp.crossbeam.com`\n\nReal time prices, orders, charts, and more for crypto Command\n\n`claude mcp add crypto-com --transport http https://mcp.crypto.com/market-data/mcp`\n\nManaged MCP servers with Unity Catalog and Mosaic AI Requires user-specific URL. Get your URL here.\n\nSecurely access and analyze Egnyte content.Command\n\n`claude mcp add --transport http egnyte https://mcp-server.egnyte.com/mcp`\n\nCreate better code with Figma context Command\n\n`claude mcp add --transport http figma-remote-mcp https://mcp.figma.com/mcp`\n\nAdvanced scheduling and time management for work.Command\n\n`claude mcp add --transport http clockwise https://mcp.getclockwise.com/mcp`\n\nSearch domains and check availability Command\n\n`claude mcp add godaddy --transport http https://api.godaddy.com/v1/domains/mcp`\n\nAI access to Intercom data for better customer insights Command\n\n`claude mcp add --transport http intercom https://mcp.intercom.com/mcp`\n\nCreate forms & analyze submissions inside Claude Command\n\n`claude mcp add --transport http jotform https://mcp.jotform.com/`\n\nSearch flights in Claude Command\n\n`claude mcp add kiwi-com --transport http https://mcp.kiwi.com`\n\nBrowse music charts & your personalized music picks Command\n\n`claude mcp add melon --transport http https://mcp.melon.com/mcp/`\n\nManage projects, boards, and workflows in monday.com Command\n\n`claude mcp add --transport http monday https://mcp.monday.com/mcp`\n\nConnect your Notion workspace to search, update, and power workflows across tools Command\n\n`claude mcp add --transport http notion https://mcp.notion.com/mcp`\n\nAccess PayPal payments platform Command\n\n`claude mcp add --transport http paypal https://mcp.paypal.com/mcp`\n\nSearch, access, and analyze your Ramp financial data Command\n\n`claude mcp add --transport http ramp https://ramp-mcp-remote.ramp.com/mcp`\n\nRetrieve both structured and unstructured data Requires user-specific URL. Get your URL here.\n\nSearch and manage transaction, merchant, and payment data Command\n\n```\nclaude mcp add --transport sse square https://mcp.squareup.com/sse\n```\n\nPayment processing and financial infrastructure tools Command\n\n```\nclaude mcp add --transport http stripe https://mcp.stripe.com\n```\n\nFind your ideal hotel at the best price.Command\n\n`claude mcp add --transport http trivago https://mcp.trivago.com/mcp`\n\nAnalyze, debug, and manage projects and deployments Command\n\n```\nclaude mcp add --transport http vercel https://mcp.vercel.com\n```\n\nFind people, productivity and business impact insights Requires user-specific URL. Get your URL here.\n\nAutomate workflows and connect your business apps Requires user-specific URL. Get your URL here.\n\nAutomate workflows across thousands of apps via conversation Requires user-specific URL. Get your URL here.\n\nEnrich contacts & accounts with GTM intelligence Command\n\n`claude mcp add --transport http zoominfo https://mcp.zoominfo.com/mcp`\n\nRecord screen and collect automatic context for issues Command\n\n```\nclaude mcp add --transport http jam https://mcp.jam.dev/mcp\n```\n\nSearch, query, and debug errors intelligently Command\n\n`claude mcp add --transport http sentry https://mcp.sentry.dev/mcp`\n\nManage your Stytch Project Command\n\n`claude mcp add stytch --transport http https://mcp.stytch.dev/mcp`\n\nAccess business data from hundreds of sources Command\n\n`claude mcp add --transport http coupler https://mcp.coupler.io/mcp`\n\nRead and write Airtable databases\n\nQuery and explore observability data and SLOs Command\n\n`claude mcp add honeycomb --transport http https://mcp.honeycomb.io/mcp`\n\nConnect to Pendo for product and user insights Requires user-specific URL. Get your URL here.\n\nFind and engage with verified nonprofits Command\n\n`claude mcp add benevity --transport http https://mcp.benevity.org/general/v1/nonprofit`\n\nResearch nonprofits and funders using Candid's data Command\n\n`claude mcp add candid --transport http https://mcp.candid.org/mcp`\n\nSearch and metadata tools for Synapse scientific data Command\n\n`claude mcp add synapse-org --transport http https://mcp.synapse.org/mcp`\n\nInteract with your Chronograph data directly in Claude Command\n\n`claude mcp add --transport http chronograph https://ai.chronograph.pe/mcp`\n\nInstalling MCP servers\n----------------------\n\nMCP servers can be configured in three different ways depending on your needs:\n\n### Option 1: Add a remote HTTP server\n\nHTTP servers are the recommended option for connecting to remote MCP servers. This is the most widely supported transport for cloud-based services.\n\n```\n# Basic syntax\nclaude mcp add --transport http <name> <url>\n\n# Real example: Connect to Notion\nclaude mcp add --transport http notion https://mcp.notion.com/mcp\n\n# Example with Bearer token\nclaude mcp add --transport http secure-api https://api.example.com/mcp \\\n  --header \"Authorization: Bearer your-token\"\n```\n\n### Option 2: Add a remote SSE server\n\n```\n# Basic syntax\nclaude mcp add --transport sse <name> <url>\n\n# Real example: Connect to Asana\nclaude mcp add --transport sse asana https://mcp.asana.com/sse\n\n# Example with authentication header\nclaude mcp add --transport sse private-api https://api.company.com/sse \\\n  --header \"X-API-Key: your-key-here\"\n```\n\n### Option 3: Add a local stdio server\n\nStdio servers run as local processes on your machine. They’re ideal for tools that need direct system access or custom scripts.\n\n```\n# Basic syntax\nclaude mcp add [options] <name> -- <command> [args...]\n\n# Real example: Add Airtable server\nclaude mcp add --transport stdio --env AIRTABLE_API_KEY=YOUR_KEY airtable \\\n  -- npx -y airtable-mcp-server\n```\n\n### Managing your servers\n\nOnce configured, you can manage your MCP servers with these commands:\n\n```\n# List all configured servers\nclaude mcp list\n\n# Get details for a specific server\nclaude mcp get github\n\n# Remove a server\nclaude mcp remove github\n\n# (within Claude Code) Check server status\n/mcp\n```\n\n### Dynamic tool updates\n\nClaude Code supports MCP `list_changed` notifications, allowing MCP servers to dynamically update their available tools, prompts, and resources without requiring you to disconnect and reconnect. When an MCP server sends a `list_changed` notification, Claude Code automatically refreshes the available capabilities from that server.\n\n### Plugin-provided MCP servers\n\nPlugins can bundle MCP servers, automatically providing tools and integrations when the plugin is enabled. Plugin MCP servers work identically to user-configured servers.**How plugin MCP servers work**:\n\n*   Plugins define MCP servers in `.mcp.json` at the plugin root or inline in `plugin.json`\n*   When a plugin is enabled, its MCP servers start automatically\n*   Plugin MCP tools appear alongside manually configured MCP tools\n*   Plugin servers are managed through plugin installation (not `/mcp` commands)\n\n**Example plugin MCP configuration**:In `.mcp.json` at plugin root:\n\n```\n{\n  \"database-tools\": {\n    \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/db-server\",\n    \"args\": [\"--config\", \"${CLAUDE_PLUGIN_ROOT}/config.json\"],\n    \"env\": {\n      \"DB_URL\": \"${DB_URL}\"\n    }\n  }\n}\n```\n\nOr inline in `plugin.json`:\n\n```\n{\n  \"name\": \"my-plugin\",\n  \"mcpServers\": {\n    \"plugin-api\": {\n      \"command\": \"${CLAUDE_PLUGIN_ROOT}/servers/api-server\",\n      \"args\": [\"--port\", \"8080\"]\n    }\n  }\n}\n```\n\n**Plugin MCP features**:\n\n*   **Automatic lifecycle**: Servers start when plugin enables, but you must restart Claude Code to apply MCP server changes (enabling or disabling)\n*   **Environment variables**: Use `${CLAUDE_PLUGIN_ROOT}` for plugin-relative paths\n*   **User environment access**: Access to same environment variables as manually configured servers\n*   **Multiple transport types**: Support stdio, SSE, and HTTP transports (transport support may vary by server)\n\n**Viewing plugin MCP servers**:\n\n```\n# Within Claude Code, see all MCP servers including plugin ones\n/mcp\n```\n\nPlugin servers appear in the list with indicators showing they come from plugins.**Benefits of plugin MCP servers**:\n\n*   **Bundled distribution**: Tools and servers packaged together\n*   **Automatic setup**: No manual MCP configuration needed\n*   **Team consistency**: Everyone gets the same tools when plugin is installed\n\nSee the plugin components reference for details on bundling MCP servers with plugins.\n\nMCP installation scopes\n-----------------------\n\nMCP servers can be configured at three different scope levels, each serving distinct purposes for managing server accessibility and sharing. Understanding these scopes helps you determine the best way to configure servers for your specific needs.\n\n### Local scope\n\nLocal-scoped servers represent the default configuration level and are stored in `~/.claude.json` under your project’s path. These servers remain private to you and are only accessible when working within the current project directory. This scope is ideal for personal development servers, experimental configurations, or servers containing sensitive credentials that shouldn’t be shared.\n\n```\n# Add a local-scoped server (default)\nclaude mcp add --transport http stripe https://mcp.stripe.com\n\n# Explicitly specify local scope\nclaude mcp add --transport http stripe --scope local https://mcp.stripe.com\n```\n\n### Project scope\n\nProject-scoped servers enable team collaboration by storing configurations in a `.mcp.json` file at your project’s root directory. This file is designed to be checked into version control, ensuring all team members have access to the same MCP tools and services. When you add a project-scoped server, Claude Code automatically creates or updates this file with the appropriate configuration structure.\n\n```\n# Add a project-scoped server\nclaude mcp add --transport http paypal --scope project https://mcp.paypal.com/mcp\n```\n\nThe resulting `.mcp.json` file follows a standardized format:\n\n```\n{\n  \"mcpServers\": {\n    \"shared-server\": {\n      \"command\": \"/path/to/server\",\n      \"args\": [],\n      \"env\": {}\n    }\n  }\n}\n```\n\nFor security reasons, Claude Code prompts for approval before using project-scoped servers from `.mcp.json` files. If you need to reset these approval choices, use the `claude mcp reset-project-choices` command.\n\n### User scope\n\nUser-scoped servers are stored in `~/.claude.json` and provide cross-project accessibility, making them available across all projects on your machine while remaining private to your user account. This scope works well for personal utility servers, development tools, or services you frequently use across different projects.\n\n```\n# Add a user server\nclaude mcp add --transport http hubspot --scope user https://mcp.hubspot.com/anthropic\n```\n\n### Choosing the right scope\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="3" view="" last_tool_call_name="click">
> Claude CodeでのMCPサーバー追加方法が非常に詳細にわかる。公式ドキュメントに具体的なコマンド例や設定手順が記載されている。これを基に、実際の連携手順を深掘りできる。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"},{"title":"Hybrid Search Explained","url":"https://weaviate.io/blog/hybrid-search-explained","text":"Learn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!","index":21,"favicon":"","host_name":"weaviate.io"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":22,"favicon":"","host_name":"weaviate.io"},{"title":"Introduction to Retrieval Augmented Generation (RAG)","url":"https://weaviate.io/blog/introduction-to-rag","text":"For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...","index":23,"favicon":"","host_name":"weaviate.io"},{"title":"Lessons learned from building hybrid search in production","url":"https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in","text":"After shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...","index":24,"favicon":"","host_name":"www.reddit.com"},{"title":"weaviate/Verba: Retrieval Augmented Generation (RAG)","url":"https://github.com/weaviate/Verba","text":"Verba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.","index":25,"favicon":"","host_name":"github.com"},{"title":"Use a Weaviate database with Vertex AI RAG Engine","url":"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db","text":"This is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python","index":26,"favicon":"","host_name":"docs.cloud.google.com"},{"title":"Legacy data to RAG : Modernise Your Apps with Amazon","url":"https://weaviate.io/blog/sagemaker-studio-rag","text":"Weaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.","index":27,"favicon":"","host_name":"weaviate.io"},{"title":"Building a Semantic Search Engine using Weaviate","url":"https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate","text":"Getting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.","index":28,"favicon":"","host_name":"www.analyticsvidhya.com"},{"title":"Exploring RAG and GraphRAG: Understanding when and","url":"https://weaviate.io/blog/graph-rag","text":"Retrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.","index":29,"favicon":"","host_name":"weaviate.io"},{"title":"Improving Retrieval Performance in RAG Pipelines with","url":"https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5","text":"This article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...","index":30,"favicon":"","host_name":"towardsdatascience.com"},{"title":"Model Context Protocol (MCP) | Cursor Docs","url":"https://cursor.com/docs/context/mcp","text":"Connect Cursor to external tools and data sources using Model Context Protocol (MCP). Install servers, configure authentication, and integrate with databases,","index":31,"favicon":"","host_name":"cursor.com"},{"title":"guides/cursor-mcp-setup.md at main","url":"https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md","text":"Setting Up MCP Servers in Cursor IDE. A comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE.","index":32,"favicon":"","host_name":"github.com"},{"title":"Display MCP from GitHub in the extensions section, as it is","url":"https://forum.cursor.com/t/display-mcp-from-github-in-the-extensions-section-as-it-is-done-in-vscode/147958","text":"I get that you want a simpler way to install MCP servers. Cursor has an official MCP Directory with featured servers. If the server you need ...","index":33,"favicon":"","host_name":"forum.cursor.com"},{"title":"A Complete Guide to MCP Integration in Cursor AI","url":"https://dev.to/akki907/supercharge-your-development-workflow-a-complete-guide-to-mcp-integration-in-cursor-ai-13l","text":"To configure MCP servers in Cursor AI: Open Cursor Settings: Navigate to File → Preferences → Cursor Settings; Look for the \"MCP\" section ...","index":34,"favicon":"","host_name":"dev.to"},{"title":"How to integrate Cursor IDE with Figma MCP","url":"https://www.zignuts.com/blog/integrate-cursor-ide-with-figma-mcp","text":"1. Download and Setup Cursor IDE · 2. Prepare Your Figma Account · 3. Configure Figma MCP in Cursor IDE · 4. Add Figma MCP Configuration.","index":35,"favicon":"","host_name":"www.zignuts.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. Download for Linux. ⤓ · Try mobile agent. →.","index":36,"favicon":"","host_name":"cursor.com"},{"title":"How to connect Cursor to 100+ MCP Servers within minutes","url":"https://composio.dev/blog/how-to-connect-cursor-to-100-mcp-servers-within-minutes","text":"Step 1: Prerequisites. · Step 2: Enable the MCP server in Cursor. · Step 3: Using a pre-defined MCP server. · Step 4: Integrating the MCP server.","index":37,"favicon":"","host_name":"composio.dev"},{"title":"Setting up IDEs (desktop clients) | Atlassian Rovo MCP","url":"https://support.atlassian.com/atlassian-rovo-mcp-server/docs/setting-up-ides","text":"Connect IDEs like VS Code to the Atlassian Remote MCP Server using the mcp-remote tool. Installation, configuration, and tips for successful setup included.","index":38,"favicon":"","host_name":"support.atlassian.com"},{"title":"MCP settings tutorial for Cursor, Claude,","url":"https://kento-yamazaki.medium.com/mcp-settings-tutorial-for-cursor-claude-31e5afbf97bc","text":"A comprehensive guide for setting up various MCP integrations in Cursor IDE. First, I show you mcp.json , which is a configuration file of MCP servers for ...","index":39,"favicon":"","host_name":"kento-yamazaki.medium.com"},{"title":"How to integrate MCP with Cursor IDE | Gavin Ching","url":"https://www.linkedin.com/posts/gavinching_using-the-cursor-ide-and-wondering-how-to-activity-7302738352116576256-SzwV","text":"To get started with MCP servers, you will click on your settings, go into features, and just Scroll down to MCP servers. Here you would just add ...","index":40,"favicon":"","host_name":"www.linkedin.com"},{"title":"How to Add MCP to Claude Code (Step by Step, Plain","url":"https://medium.com/@Michael38/how-to-add-mcp-to-claude-code-step-by-step-plain-english-865fec18e07d","text":"This article focuses on the practical setup inside Claude Code, while the official docs cover the underlying specification. Official MCP ...","index":41,"favicon":"","host_name":"medium.com"},{"title":"Connect Claude Code to tools via MCP","url":"https://code.claude.com/docs/en/mcp","text":"Claude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool ...","index":42,"favicon":"","host_name":"code.claude.com"},{"title":"Setting Up MCP Servers in Claude Code: A Tech Ritual for","url":"https://www.reddit.com/r/ClaudeAI/comments/1jf4hnt/setting_up_mcp_servers_in_claude_code_a_tech","text":"Here, members share MCP server implementations, integration strategies, and best practices. Whether you're a developer, researcher, or AI ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Use MCP servers in VS Code","url":"https://code.visualstudio.com/docs/copilot/customization/mcp-servers","text":"Automatically discover MCP servers. VS Code can automatically detect and reuse MCP server configurations from other applications, such as Claude Desktop.","index":44,"favicon":"","host_name":"code.visualstudio.com"},{"title":"GitHub's official MCP Server","url":"https://github.com/github/github-mcp-server","text":"The GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code ...","index":45,"favicon":"","host_name":"github.com"},{"title":"Connect Claude to MCP Servers for Better AI Capabilities","url":"https://www.getmesa.com/blog/how-to-connect-mcp-server-claude","text":"Learn how to connect MCP server Claude integrations. Step-by-step guide to setup, configuration, and automating workflows with Claude AI.","index":46,"favicon":"","host_name":"www.getmesa.com"},{"title":"Atlassian MCP Integration with Claude Completely S","url":"https://community.atlassian.com/forums/Rovo-questions/Atlassian-MCP-Integration-with-Claude-Completely-Stopped-Working/qaq-p/3147695","text":"As of Saturday morning (November 16, 2025), the integration has **completely stopped working** on Claude's remote connector platforms (Claude.ai ...","index":47,"favicon":"","host_name":"community.atlassian.com"},{"title":"The Best MCP Servers for Developers in 2026","url":"https://www.builder.io/blog/best-mcp-servers-2026","text":"MCP introduces a universal interface. You spin up a \"Postgres MCP Server\" once. That server can now talk to Claude Code, Cursor, Fusion, or any ...","index":48,"favicon":"","host_name":"www.builder.io"},{"title":"7 Claude MCP servers you can set up right now","url":"https://zapier.com/blog/claude-mcp-servers","text":"Here, I'll walk you through the MCP servers that I've found the most useful when working in Claude. I'll show you how to set them up and give you some examples ...","index":49,"favicon":"","host_name":"zapier.com"},{"title":"Claude Code MCP: How to Add MCP Servers (Complete Guide)","url":"https://www.youtube.com/watch?v=DfWHX7kszQI","text":"In this video I'll show you the fundamentals of adding any MCP server to your claw code agents.","index":50,"favicon":"","host_name":"www.youtube.com"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":51,"favicon":"","host_name":"docs.z.ai"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":52,"favicon":"","host_name":"github.com"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":53,"favicon":"","host_name":"docs.z.ai"},{"title":"OpenAI Python SDK - Overview","url":"https://docs.z.ai/guides/develop/openai/python","text":"Z.AI provides interfaces compatible with OpenAI API, which means you can use existing OpenAI SDK code and seamlessly switch to Z.AI's model services by ...","index":54,"favicon":"","host_name":"docs.z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":55,"favicon":"","host_name":"docs.z.ai"},{"title":"How to Access the GLM-4.7 API in 2026","url":"https://apidog.com/blog/glm-4-7-api","text":"Learn step-by-step setup on the official Z.ai platform and OpenRouter, compare pricing, and integrate efficiently with tools like Apidog.","index":56,"favicon":"","host_name":"apidog.com"},{"title":"Z-Image API: Integrate AI Image Generation into Your App | Blog","url":"https://z-image.ai/blog/z-image-api","text":"Z-Image API documentation: endpoints, authentication, pricing, and code examples for developers.","index":57,"favicon":"","host_name":"z-image.ai"},{"title":"HTTP API Calls - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/develop/http/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, allowing you to easily integrate Z.AI's ...","index":58,"favicon":"","host_name":"docs.z.ai"},{"title":"Interactions API | Gemini API - Google AI for Developers","url":"https://ai.google.dev/gemini-api/docs/interactions","text":"The following example shows how to call the Interactions API with a text prompt. Python JavaScript REST","index":59,"favicon":"","host_name":"ai.google.dev"},{"title":"AI SDK","url":"https://ai-sdk.dev","text":"From the creators of Next.js, the AI SDK is a free open-source library that gives you the tools you need to build AI-powered products.","index":60,"favicon":"","host_name":"ai-sdk.dev"}]},"metadata":{"arguments":"{\"query\":\"Z.ai API integration Python SDK 2026 official documentation\"}","display_result":"","duration":"2s","id":"call_sRnKg1BVos","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【50†Official Python SDK - Overview†https://docs.z.ai/guides/develop/python/introduction】\nZ.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.\n\n【51†zai-org/z-ai-sdk-python†https://github.com/zai-org/z-ai-sdk-python】\nThe official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.\n\n【52†Quick Start - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/guides/overview/quick-start】\nAfter preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...\n\n【53†OpenAI Python SDK - Overview†https://docs.z.ai/guides/develop/openai/python】\nZ.AI provides interfaces compatible with OpenAI API, which means you can use existing OpenAI SDK code and seamlessly switch to Z.AI's model services by ...\n\n【54†Introduction - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/api-reference/introduction】\nZ.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.\n\n【55†How to Access the GLM-4.7 API in 2026†https://apidog.com/blog/glm-4-7-api】\nLearn step-by-step setup on the official Z.ai platform and OpenRouter, compare pricing, and integrate efficiently with tools like Apidog.\n\n【56†Z-Image API: Integrate AI Image Generation into Your App | Blog†https://z-image.ai/blog/z-image-api】\nZ-Image API documentation: endpoints, authentication, pricing, and code examples for developers.\n\n【57†HTTP API Calls - Overview - Z.AI DEVELOPER DOCUMENT†https://docs.z.ai/guides/develop/http/introduction】\nZ.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, allowing you to easily integrate Z.AI's ...\n\n【58†Interactions API | Gemini API - Google AI for Developers†https://ai.google.dev/gemini-api/docs/interactions】\nThe following example shows how to call the Interactions API with a text prompt. Python JavaScript REST\n\n【59†AI SDK†https://ai-sdk.dev】\nFrom the creators of Next.js, the AI SDK is a free open-source library that gives you the tools you need to build AI-powered products.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> Z.aiのPython SDKに関する公式ドキュメントが見つかった。これを基に、具体的な実装方法やAPI呼び出し方を深掘りできる。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://docs.z.ai/guides/develop/python/introduction","title":"Official Python SDK - Overview","content":"【50†Official Python SDK - Overview†https://docs.z.ai/guides/develop/python/introduction】\nTitle: Official Python SDK - Overview - Z.AI DEVELOPER DOCUMENT\n\nURL Source: https://docs.z.ai/guides/develop/python/introduction\n\nMarkdown Content:\nZ.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.\n\n### Core Advantages\n\n### Supported Features\n\n*   **💬 Chat Conversations**: Support for single-turn and multi-turn conversations, streaming and non-streaming responses\n*   **🔧 Function Calling**: Enable AI models to call your custom functions\n*   **👁️ Vision Understanding**: Image analysis, visual understanding\n*   **🎨 Image Generation**: Generate high-quality images from text descriptions\n*   **🎬 Video Generation**: Creative content generation from text to video\n*   **🔊 Speech Processing**: Speech-to-text, text-to-speech\n*   **📊 Text Embedding**: Text vectorization, supporting semantic search\n*   **🤖 Intelligent Assistants**: Build professional AI assistant applications\n*   **🛡️ Content Moderation**: Text and image content safety detection\n\nTechnical Specifications\n------------------------\n\n### Environment Requirements\n\n*   **Python Version**: Python 3.8 or higher\n*   **Package Manager**: pip or poetry\n*   **Network Requirements**: HTTPS connection support\n*   **API Key**: Valid Z.AI API key required\n\n### Dependency Management\n\nThe SDK adopts a modular design, allowing you to selectively install functional modules as needed:\n\n*   **Core Module**: Basic API calling functionality\n*   **Async Module**: Asynchronous and concurrent processing support\n*   **Utility Module**: Utility tools and auxiliary functions\n\nQuick Start\n-----------\n\n### Environment Requirements\n\n### Install SDK\n\n#### Install using pip\n\n```\n# Install latest version\npip install zai-sdk\n\n# Or specify version\npip install zai-sdk==0.1.0\n```\n\n#### Verify Installation\n\n```\nimport zai\nprint(zai.__version__)\n```\n\n### Get API Key\n\n1.   Access Z.AI Open Platform, Register or Login.\n2.   Create an API Key in the API Keys management page.\n3.   Copy your API Key for use.\n\n```\nDomestic API URL: https://api.z.ai/api/paas/v4/\n```\n\n#### Create Client\n\n*   Environment Variable\n\n*   Direct Setting\n\n```\nfrom zai import ZaiClient\nimport os\n\n# Read API Key from environment variable\nclient = ZaiClient(api_key=os.getenv(\"ZAI_API_KEY\"))\n\n# Or use directly (if environment variable is set)\nclient = ZaiClient()\n```\n\n```\nfrom zai import ZaiClient, ZaiClient\n\n# Set API Key directly\nclient = ZaiClient(api_key=\"abc123.def456\")\n```\n\n#### Basic Conversation\n\n```\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, please introduce yourself, Z.ai!\"}\n    ]\n)\nprint(response.choices[0].message.content)\n```\n\n#### Streaming Conversation\n\n```\n# Create streaming chat request\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are an AI writer.'},\n        {'role': 'user', 'content': 'Tell a story about AI.'},\n    ],\n    stream=True,\n)\n\nfor chunk in response:\n    if chunk.choices[0].delta.content:\n        print(chunk.choices[0].delta.content, end='')\n```\n\n#### Multi-turn Conversation\n\n```\nfrom zai import ZaiClient\nclient = ZaiClient(api_key=\"your-api-key\")\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",  # Please fill in the model name you want to call\n    messages=[\n        {\"role\": \"user\", \"content\": \"As a marketing expert, please create an attractive slogan for my product\"},\n        {\"role\": \"assistant\", \"content\": \"Of course, to create an attractive slogan, please tell me some information about your product\"},\n        {\"role\": \"user\", \"content\": \"Z.AI Open Platform\"},\n        {\"role\": \"assistant\", \"content\": \"Ignite the future, Z.AI draws infinite possibilities, making innovation within reach!\"},\n        {\"role\": \"user\", \"content\": \"Create a more precise and attractive slogan\"}\n    ],\n)\nprint(response.choices[0].message.content)\n```\n\n### Complete Example\n\n```\nfrom zai import ZaiClient\nimport os\n\ndef main():\n    # Initialize client\n    client = ZaiClient(api_key=os.getenv(\"ZAI_API_KEY\"))\n    \n    print(\"Welcome to Z.ai Chatbot! Type 'quit' to exit.\")\n    \n    # Conversation history\n    conversation = [\n        {\"role\": \"system\", \"content\": \"You are a friendly AI assistant\"}\n    ]\n    \n    while True:\n        # Get user input\n        user_input = input(\"You: \")\n        \n        if user_input.lower() == 'quit':\n            break\n        \n        try:\n            # Add user message\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n            \n            # Create chat request\n            response = client.chat.completions.create(\n                model=\"glm-4.7\",\n                messages=conversation,\n                temperature=1.0,\n                max_tokens=1000\n            )\n            \n            # Get AI response\n            ai_response = response.choices[0].message.content\n            print(f\"AI: {ai_response}\")\n            \n            # Add AI response to conversation history\n            conversation.append({\"role\": \"assistant\", \"content\": ai_response})\n            \n        except Exception as e:\n            print(f\"Error occurred: {e}\")\n    \n    print(\"Goodbye!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Error Handling\n\n```\nfrom zai import ZaiClient\nimport zai\n\ndef robust_chat(message):\n    client = ZaiClient(api_key=\"your-api-key\")\n    \n    try:\n        response = client.chat.completions.create(\n            model=\"glm-4.7\",\n            messages=[{\"role\": \"user\", \"content\": message}]\n        )\n        return response.choices[0].message.content\n        \n    except zai.core.APIStatusError as err:\n        return f\"API status error: {err}\"\n    except zai.core.APITimeoutError as err:\n        return f\"Request timeout: {err}\"\n    except Exception as err:\n        return f\"Other error: {err}\"\n\n# Usage example\nresult = robust_chat(\"Hello\")\nprint(result)\n```\n\n### Advanced Configuration\n\n```\nimport httpx\nfrom zai import ZaiClient\n\n# Custom HTTP client\nhttpx_client = httpx.Client(\n    limits=httpx.Limits(\n        max_keepalive_connections=20,\n        max_connections=100\n    ),\n    timeout=30.0\n)\n\n# Create client with custom configuration\nclient = ZaiClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://api.z.ai/api/paas/v4/\",\n    timeout=httpx.Timeout(timeout=300.0, connect=8.0),\n    max_retries=3,\n    http_client=httpx_client\n)\n```\n\nAdvanced Features\n-----------------\n\n### Function Calling\n\nFunction calling allows AI models to call functions you define to get real-time information or perform specific operations.\n\n#### Defining and Using Functions\n\n```\nfrom zai import ZaiClient\nimport json\n\n# Define functions\ndef get_weather(location, date=None):\n    \"\"\"Get weather information\"\"\"\n    # Simulate weather API call\n    return {\n        \"location\": location,\n        \"date\": date or \"today\",\n        \"weather\": \"sunny\",\n        \"temperature\": \"25°C\",\n        \"humidity\": \"60%\"\n    }\n\ndef get_stock_price(symbol):\n    \"\"\"Get stock price\"\"\"\n    # Simulate stock API call\n    return {\n        \"symbol\": symbol,\n        \"price\": 150.25,\n        \"change\": \"+2.5%\"\n    }\n\n# Function descriptions\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get weather information for a specified location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"Location name\"\n                    },\n                    \"date\": {\n                        \"type\": \"string\",\n                        \"description\": \"Date in YYYY-MM-DD format\"\n                    }\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_stock_price\",\n            \"description\": \"Get current stock price\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"symbol\": {\n                        \"type\": \"string\",\n                        \"description\": \"Stock symbol\"\n                    }\n                },\n                \"required\": [\"symbol\"]\n            }\n        }\n    }\n]\n\n# Use function calling\nclient = ZaiClient(api_key=\"your-api-key\")\n\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'user', 'content': 'How\\'s the weather in Beijing today?'}\n    ],\n    tools=tools,\n    tool_choice=\"auto\"\n)\n\n# Handle function calling\nif response.choices[0].message.tool_calls:\n    for tool_call in response.choices[0].message.tool_calls:\n        function_name = tool_call.function.name\n        function_args = json.loads(tool_call.function.arguments)\n        \n        if function_name == \"get_weather\":\n            result = get_weather(**function_args)\n            print(f\"Weather info: {result}\")\n        elif function_name == \"get_stock_price\":\n            result = get_stock_price(**function_args)\n            print(f\"Stock info: {result}\")\nelse:\n    print(response.choices[0].message.content)\n```\n\n### Web Search Tool\n\n```\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Use web search tool\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'What is artificial intelligence?'},\n    ],\n    tools=[\n        {\n            'type': 'web_search',\n            'web_search': {\n                'search_query': 'What is artificial intelligence?',\n                'search_result': True,\n            },\n        }\n    ],\n    temperature=0.5,\n    max_tokens=2000,\n)\n\nprint(response)\n```\n\n### Video Generation\n\n```\nfrom zai import ZaiClient\nimport time\n\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Submit generation task\nresponse = client.videos.generations(\n    model=\"cogvideox-3\",  # Video generation model to use\n    image_url=image_url,  # Provided image URL or Base64 encoding\n    prompt=\"Make the scene come alive\",\n    quality=\"speed\",  # Output mode: \"quality\" for quality priority, \"speed\" for speed priority\n    with_audio=True,\n    size=\"1920x1080\",  # Video resolution, supports up to 4K (e.g., \"3840x2160\")\n    fps=30,  # Frame rate, can be 30 or 60\n)\nprint(response)\n\n# Get generation result\ntime.sleep(60)  # Wait for a while to ensure video generation is complete\nresult = client.videos.retrieve_videos_result(id=response.id)\nprint(result)\n```\n\n### Streaming Processing\n\n```\nclass StreamProcessor:\n    def __init__(self, client):\n        self.client = client\n        self.full_response = \"\"\n    \n    def stream_chat(self, messages, model=\"glm-4.7\", callback=None):\n        \"\"\"Streaming chat processing\"\"\"\n        stream = self.client.chat.completions.create(\n            model=model,\n            messages=messages,\n            stream=True\n        )\n        \n        self.full_response = \"\"\n        for chunk in stream:\n            if chunk.choices[0].delta.content is not None:\n                content = chunk.choices[0].delta.content\n                self.full_response += content\n                \n                if callback:\n                    callback(content, self.full_response)\n                else:\n                    print(content, end=\"\", flush=True)\n        \n        print()  # New line\n        return self.full_response\n\n# Usage example\nprocessor = StreamProcessor(client)\n\n# Custom callback function\ndef on_token_received(token, full_text):\n    # You can implement real-time processing logic here\n    print(token, end=\"\", flush=True)\n\nresponse = processor.stream_chat(\n    messages=[{\"role\": \"user\", \"content\": \"Write a Python function to calculate Fibonacci sequence\"}],\n    callback=on_token_received\n)\n```\n\nGetting Help\n------------\n\n"},"metadata":{"arguments":"{\"link_id\":50}","display_result":"","duration":"1s","id":"call_zi50gUTwxx","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【50†Official Python SDK - Overview†https://docs.z.ai/guides/develop/python/introduction】\nTitle: Official Python SDK - Overview - Z.AI DEVELOPER DOCUMENT\n\nURL Source: https://docs.z.ai/guides/develop/python/introduction\n\nMarkdown Content:\nZ.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.\n\n### Core Advantages\n\n### Supported Features\n\n*   **💬 Chat Conversations**: Support for single-turn and multi-turn conversations, streaming and non-streaming responses\n*   **🔧 Function Calling**: Enable AI models to call your custom functions\n*   **👁️ Vision Understanding**: Image analysis, visual understanding\n*   **🎨 Image Generation**: Generate high-quality images from text descriptions\n*   **🎬 Video Generation**: Creative content generation from text to video\n*   **🔊 Speech Processing**: Speech-to-text, text-to-speech\n*   **📊 Text Embedding**: Text vectorization, supporting semantic search\n*   **🤖 Intelligent Assistants**: Build professional AI assistant applications\n*   **🛡️ Content Moderation**: Text and image content safety detection\n\nTechnical Specifications\n------------------------\n\n### Environment Requirements\n\n*   **Python Version**: Python 3.8 or higher\n*   **Package Manager**: pip or poetry\n*   **Network Requirements**: HTTPS connection support\n*   **API Key**: Valid Z.AI API key required\n\n### Dependency Management\n\nThe SDK adopts a modular design, allowing you to selectively install functional modules as needed:\n\n*   **Core Module**: Basic API calling functionality\n*   **Async Module**: Asynchronous and concurrent processing support\n*   **Utility Module**: Utility tools and auxiliary functions\n\nQuick Start\n-----------\n\n### Environment Requirements\n\n### Install SDK\n\n#### Install using pip\n\n```\n# Install latest version\npip install zai-sdk\n\n# Or specify version\npip install zai-sdk==0.1.0\n```\n\n#### Verify Installation\n\n```\nimport zai\nprint(zai.__version__)\n```\n\n### Get API Key\n\n1.   Access Z.AI Open Platform, Register or Login.\n2.   Create an API Key in the API Keys management page.\n3.   Copy your API Key for use.\n\n```\nDomestic API URL: https://api.z.ai/api/paas/v4/\n```\n\n#### Create Client\n\n*   Environment Variable\n\n*   Direct Setting\n\n```\nfrom zai import ZaiClient\nimport os\n\n# Read API Key from environment variable\nclient = ZaiClient(api_key=os.getenv(\"ZAI_API_KEY\"))\n\n# Or use directly (if environment variable is set)\nclient = ZaiClient()\n```\n\n```\nfrom zai import ZaiClient, ZaiClient\n\n# Set API Key directly\nclient = ZaiClient(api_key=\"abc123.def456\")\n```\n\n#### Basic Conversation\n\n```\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, please introduce yourself, Z.ai!\"}\n    ]\n)\nprint(response.choices[0].message.content)\n```\n\n#### Streaming Conversation\n\n```\n# Create streaming chat request\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are an AI writer.'},\n        {'role': 'user', 'content': 'Tell a story about AI.'},\n    ],\n    stream=True,\n)\n\nfor chunk in response:\n    if chunk.choices[0].delta.content:\n        print(chunk.choices[0].delta.content, end='')\n```\n\n#### Multi-turn Conversation\n\n```\nfrom zai import ZaiClient\nclient = ZaiClient(api_key=\"your-api-key\")\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",  # Please fill in the model name you want to call\n    messages=[\n        {\"role\": \"user\", \"content\": \"As a marketing expert, please create an attractive slogan for my product\"},\n        {\"role\": \"assistant\", \"content\": \"Of course, to create an attractive slogan, please tell me some information about your product\"},\n        {\"role\": \"user\", \"content\": \"Z.AI Open Platform\"},\n        {\"role\": \"assistant\", \"content\": \"Ignite the future, Z.AI draws infinite possibilities, making innovation within reach!\"},\n        {\"role\": \"user\", \"content\": \"Create a more precise and attractive slogan\"}\n    ],\n)\nprint(response.choices[0].message.content)\n```\n\n### Complete Example\n\n```\nfrom zai import ZaiClient\nimport os\n\ndef main():\n    # Initialize client\n    client = ZaiClient(api_key=os.getenv(\"ZAI_API_KEY\"))\n    \n    print(\"Welcome to Z.ai Chatbot! Type 'quit' to exit.\")\n    \n    # Conversation history\n    conversation = [\n        {\"role\": \"system\", \"content\": \"You are a friendly AI assistant\"}\n    ]\n    \n    while True:\n        # Get user input\n        user_input = input(\"You: \")\n        \n        if user_input.lower() == 'quit':\n            break\n        \n        try:\n            # Add user message\n            conversation.append({\"role\": \"user\", \"content\": user_input})\n            \n            # Create chat request\n            response = client.chat.completions.create(\n                model=\"glm-4.7\",\n                messages=conversation,\n                temperature=1.0,\n                max_tokens=1000\n            )\n            \n            # Get AI response\n            ai_response = response.choices[0].message.content\n            print(f\"AI: {ai_response}\")\n            \n            # Add AI response to conversation history\n            conversation.append({\"role\": \"assistant\", \"content\": ai_response})\n            \n        except Exception as e:\n            print(f\"Error occurred: {e}\")\n    \n    print(\"Goodbye!\")\n\nif __name__ == \"__main__\":\n    main()\n```\n\n### Error Handling\n\n```\nfrom zai import ZaiClient\nimport zai\n\ndef robust_chat(message):\n    client = ZaiClient(api_key=\"your-api-key\")\n    \n    try:\n        response = client.chat.completions.create(\n            model=\"glm-4.7\",\n            messages=[{\"role\": \"user\", \"content\": message}]\n        )\n        return response.choices[0].message.content\n        \n    except zai.core.APIStatusError as err:\n        return f\"API status error: {err}\"\n    except zai.core.APITimeoutError as err:\n        return f\"Request timeout: {err}\"\n    except Exception as err:\n        return f\"Other error: {err}\"\n\n# Usage example\nresult = robust_chat(\"Hello\")\nprint(result)\n```\n\n### Advanced Configuration\n\n```\nimport httpx\nfrom zai import ZaiClient\n\n# Custom HTTP client\nhttpx_client = httpx.Client(\n    limits=httpx.Limits(\n        max_keepalive_connections=20,\n        max_connections=100\n    ),\n    timeout=30.0\n)\n\n# Create client with custom configuration\nclient = ZaiClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://api.z.ai/api/paas/v4/\",\n    timeout=httpx.Timeout(timeout=300.0, connect=8.0),\n    max_retries=3,\n    http_client=httpx_client\n)\n```\n\nAdvanced Features\n-----------------\n\n### Function Calling\n\nFunction calling allows AI models to call functions you define to get real-time information or perform specific operations.\n\n#### Defining and Using Functions\n\n```\nfrom zai import ZaiClient\nimport json\n\n# Define functions\ndef get_weather(location, date=None):\n    \"\"\"Get weather information\"\"\"\n    # Simulate weather API call\n    return {\n        \"location\": location,\n        \"date\": date or \"today\",\n        \"weather\": \"sunny\",\n        \"temperature\": \"25°C\",\n        \"humidity\": \"60%\"\n    }\n\ndef get_stock_price(symbol):\n    \"\"\"Get stock price\"\"\"\n    # Simulate stock API call\n    return {\n        \"symbol\": symbol,\n        \"price\": 150.25,\n        \"change\": \"+2.5%\"\n    }\n\n# Function descriptions\ntools = [\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_weather\",\n            \"description\": \"Get weather information for a specified location\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"location\": {\n                        \"type\": \"string\",\n                        \"description\": \"Location name\"\n                    },\n                    \"date\": {\n                        \"type\": \"string\",\n                        \"description\": \"Date in YYYY-MM-DD format\"\n                    }\n                },\n                \"required\": [\"location\"]\n            }\n        }\n    },\n    {\n        \"type\": \"function\",\n        \"function\": {\n            \"name\": \"get_stock_price\",\n            \"description\": \"Get current stock price\",\n            \"parameters\": {\n                \"type\": \"object\",\n                \"properties\": {\n                    \"symbol\": {\n                        \"type\": \"string\",\n                        \"description\": \"Stock symbol\"\n                    }\n                },\n                \"required\": [\"symbol\"]\n            }\n        }\n    }\n]\n\n# Use function calling\nclient = ZaiClient(api_key=\"your-api-key\")\n\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'user', 'content': 'How\\'s the weather in Beijing today?'}\n    ],\n    tools=tools,\n    tool_choice=\"auto\"\n)\n\n# Handle function calling\nif response.choices[0].message.tool_calls:\n    for tool_call in response.choices[0].message.tool_calls:\n        function_name = tool_call.function.name\n        function_args = json.loads(tool_call.function.arguments)\n        \n        if function_name == \"get_weather\":\n            result = get_weather(**function_args)\n            print(f\"Weather info: {result}\")\n        elif function_name == \"get_stock_price\":\n            result = get_stock_price(**function_args)\n            print(f\"Stock info: {result}\")\nelse:\n    print(response.choices[0].message.content)\n```\n\n### Web Search Tool\n\n```\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Use web search tool\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'What is artificial intelligence?'},\n    ],\n    tools=[\n        {\n            'type': 'web_search',\n            'web_search': {\n                'search_query': 'What is artificial intelligence?',\n                'search_result': True,\n            },\n        }\n    ],\n    temperature=0.5,\n    max_tokens=2000,\n)\n\nprint(response)\n```\n\n### Video Generation\n\n```\nfrom zai import ZaiClient\nimport time\n\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Submit generation task\nresponse = client.videos.generations(\n    model=\"cogvideox-3\",  # Video generation model to use\n    image_url=image_url,  # Provided image URL or Base64 encoding\n    prompt=\"Make the scene come alive\",\n    quality=\"speed\",  # Output mode: \"quality\" for quality priority, \"speed\" for speed priority\n    with_audio=True,\n    size=\"1920x1080\",  # Video resolution, supports up to 4K (e.g., \"3840x2160\")\n    fps=30,  # Frame rate, can be 30 or 60\n)\nprint(response)\n\n# Get generation result\ntime.sleep(60)  # Wait for a while to ensure video generation is complete\nresult = client.videos.retrieve_videos_result(id=response.id)\nprint(result)\n```\n\n### Streaming Processing\n\n```\nclass StreamProcessor:\n    def __init__(self, client):\n        self.client = client\n        self.full_response = \"\"\n    \n    def stream_chat(self, messages, model=\"glm-4.7\", callback=None):\n        \"\"\"Streaming chat processing\"\"\"\n        stream = self.client.chat.completions.create(\n            model=model,\n            messages=messages,\n            stream=True\n        )\n        \n        self.full_response = \"\"\n        for chunk in stream:\n            if chunk.choices[0].delta.content is not None:\n                content = chunk.choices[0].delta.content\n                self.full_response += content\n                \n                if callback:\n                    callback(content, self.full_response)\n                else:\n                    print(content, end=\"\", flush=True)\n        \n        print()  # New line\n        return self.full_response\n\n# Usage example\nprocessor = StreamProcessor(client)\n\n# Custom callback function\ndef on_token_received(token, full_text):\n    # You can implement real-time processing logic here\n    print(token, end=\"\", flush=True)\n\nresponse = processor.stream_chat(\n    messages=[{\"role\": \"user\", \"content\": \"Write a Python function to calculate Fibonacci sequence\"}],\n    callback=on_token_received\n)\n```\n\nGetting Help\n------------\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="click">
> Z.aiのPython SDKに関する公式ドキュメントが非常に詳細で、具体的な実装例が豊富だ。これを基に、Z.aiを使った具体的な実装方法を深掘りできる。特に、関数呼び出し、ストリーミング処理、エラーハンドリングなどの点について説明できる。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://github.com/zai-org/z-ai-sdk-python","title":"zai-org/z-ai-sdk-python","content":"【51†zai-org/z-ai-sdk-python†https://github.com/zai-org/z-ai-sdk-python】\nTitle: GitHub - zai-org/z-ai-sdk-python: The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs.\n\nURL Source: https://github.com/zai-org/z-ai-sdk-python\n\nMarkdown Content:\nZ.ai Open Platform Python SDK\n-----------------------------\n\n中文文档 | English\n\nZ.ai Open Platform The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs.\n\n✨ Core Features\n---------------\n\n### 🤖 **Chat Completions**\n\n*   **Standard Chat**: Create chat completions with various models including `glm-4.7`\n*   **Streaming Support**: Real-time streaming responses for interactive applications\n*   **Tool Calling**: Function calling capabilities for enhanced AI interactions\n*   **Character Role-Playing**: Support for character-based conversations with `charglm-3` model\n*   **Multimodal Chat**: Image understanding capabilities with vision models\n\n### 🧠 **Embeddings**\n\n*   **Text Embeddings**: Generate high-quality vector embeddings for text\n*   **Configurable Dimensions**: Customizable embedding dimensions\n*   **Batch Processing**: Support for multiple inputs in a single request\n\n### 🎥 **Video Generation**\n\n*   **Text-to-Video**: Generate videos from text prompts\n*   **Image-to-Video**: Create videos from image inputs\n*   **Customizable Parameters**: Control quality, duration, FPS, and size\n*   **Audio Support**: Optional audio generation for videos\n\n### 🎵 **Audio Processing**\n\n*   **Speech Transcription**: Convert audio files to text\n*   **Multiple Formats**: Support for various audio file formats\n\n### 🤝 **Assistant API**\n\n*   **Conversation Management**: Structured conversation handling\n*   **Streaming Conversations**: Real-time assistant interactions\n*   **Metadata Support**: Rich conversation context and user information\n\n### 🔧 **Advanced Tools**\n\n*   **Web Search**: Integrated web search capabilities\n*   **File Management**: Upload, download, and manage files\n*   **Batch Operations**: Efficient batch processing for multiple requests\n*   **Content Moderation**: Built-in content safety and moderation\n*   **Image Generation**: AI-powered image creation\n\n📦 Installation\n---------------\n\n### Requirements\n\n*   **Python**: 3.8+\n*   **Package Manager**: pip\n\n### Install via pip\n\npip install zai-sdk\n\n### 📋 **Technical Specifications**\n\n#### **Python Support**\n\n*   **Python Versions**: 3.8, 3.9, 3.10, 3.11, 3.12\n*   **Async Support**: Full async/await compatibility\n*   **Cross-platform**: Windows, macOS, Linux support\n\n#### **Core Dependencies**\n\n| Package | Version | Purpose |\n| --- | --- | --- |\n| `httpx` | `>=0.23.0` | HTTP client for API requests |\n| `pydantic` | `>=1.9.0,<3.0.0` | Data validation and serialization |\n| `typing-extensions` | `>=4.0.0` | Enhanced type hints support |\n| `cachetools` | `>=4.2.2` | Caching utilities |\n| `pyjwt` | `>=2.8.0` | JSON Web Token (JWT) handling |\n\n🚀 Quick Start\n--------------\n\n### Create API Key\n\n#### Get API Key\n\n*   **Overseas regions**: Visit Z.ai Open Platform to get your API key\n*   **Mainland China regions**: Visit Zhipu AI Open Platform to get your API key\n\n#### API BASE URL\n\n*   **Mainland China regions**: `https://open.bigmodel.cn/api/paas/v4/`\n*   **Overseas regions**: `https://api.z.ai/api/paas/v4/`\n\n#### Usage Steps\n\n1.   **Create client with API key**\n2.   **Call the corresponding API methods**\n\nFor complete examples, please refer to the open platform API Reference and User Guide, and remember to replace with your own API key.\n\n### Basic Usage\n\nfrom zai import ZaiClient, ZhipuAiClient\n\n# For Overseas users, create the ZaiClient\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# For Chinese users, create the ZhipuAiClient\nclient = ZhipuAiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, Z.ai!\"}\n    ]\n)\nprint(response.choices[0].message.content)\n\n### Client Configuration\n\nThe SDK supports multiple ways to configure API keys:\n\n#### Environment Variables\n\nexport ZAI_API_KEY=\"your-api-key\"\nexport ZAI_BASE_URL=\"https://api.z.ai/api/paas/v4/\"  # Optional\n\n#### Code Configuration\n\nfrom zai import ZaiClient, ZhipuAiClient\n\nclient = ZaiClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://api.z.ai/api/paas/v4/\"  # Optional\n)\n\n# if you want to use Zhipu's domain service\nzhipu_client = ZhipuAiClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"  # Optional\n)\n\n### Advanced Configuration\n\nCustomize client behavior with additional parameters:\n\nfrom zai import ZaiClient\nimport httpx\n\nclient = ZaiClient(\n    api_key=\"your-api-key\",\n    timeout=httpx.Timeout(timeout=300.0, connect=8.0),  # Request timeout\n    max_retries=3,  # Retry attempts\n    base_url=\"https://api.z.ai/api/paas/v4/\"  # Custom API endpoint\n)\n\n📖 Usage Examples\n-----------------\n\n### Streaming Chat\n\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'Tell me a story about AI.'},\n    ],\n    stream=True,\n)\n\nfor chunk in response:\n    if chunk.choices[0].delta.content:\n        print(chunk.choices[0].delta.content, end='')\n\n### Chat With Tool Call\n\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'What is artificial intelligence?'},\n    ],\n    tools=[\n        {\n            'type': 'web_search',\n            'web_search': {\n                'search_query': 'What is artificial intelligence?',\n                'search_result': True,\n            },\n        }\n    ],\n    temperature=0.5,\n    max_tokens=2000,\n)\n\nprint(response)\n\n### Multimodal Chat\n\nfrom zai import ZaiClient\nimport base64\n\ndef encode_image(image_path):\n    \"\"\"Encode image to base64 format\"\"\"\n    with open(image_path, 'rb') as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\nclient = ZaiClient(api_key=\"your-api-key\")\nbase64_image = encode_image('examples/test_multi_modal.jpeg')\n\nresponse = client.chat.completions.create(\n    model='glm-4.6v',\n    messages=[\n        {\n            'role': 'user',\n            'content': [\n                {'type': 'text', 'text': \"What's in this image?\"},\n                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{base64_image}'}},\n            ],\n        }\n    ],\n    temperature=0.5,\n    max_tokens=2000,\n)\nprint(response)\n\n### Video Generation\n\nfrom zai import ZaiClient\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Generate video\nresponse = client.videos.generations(\n    model=\"cogvideox-3\",\n    prompt=\"A cat is playing with a ball.\",\n    quality=\"quality\",  # Output mode, \"quality\" for quality priority, \"speed\" for speed priority\n    with_audio=True, # Whether to include audio\n    size=\"1920x1080\",  # Video resolution, supports up to 4K (e.g., \"3840x2160\")\n    fps=30,  # Frame rate, can be 30 or 60\n    max_wait_time=300,  # Maximum wait time (seconds)\n)\nprint(response)\n\n# Get video result\nresult = client.videos.retrieve_videos_result(id=response.id)\nprint(result)\n\n🚨 Error Handling\n-----------------\n\nThe SDK provides comprehensive error handling:\n\nfrom zai import ZaiClient\nimport zai\n\nclient = ZaiClient(api_key=\"your-api-key\")\n\ntry:\n    response = client.chat.completions.create(\n        model=\"glm-4.7\",\n        messages=[\n            {\"role\": \"user\", \"content\": \"Hello, Z.ai!\"}\n        ]\n    )\n    print(response.choices[0].message.content)\n    \nexcept zai.core.APIStatusError as err:\n    print(f\"API Status Error: {err}\")\nexcept zai.core.APITimeoutError as err:\n    print(f\"Request Timeout: {err}\")\nexcept Exception as err:\n    print(f\"Unexpected Error: {err}\")\n\n### Error Codes\n\n| Status Code | Error Type | Description |\n| --- | --- | --- |\n| 400 | `APIRequestFailedError` | Invalid request parameters |\n| 401 | `APIAuthenticationError` | Authentication failed |\n| 429 | `APIReachLimitError` | Rate limit exceeded |\n| 500 | `APIInternalError` | Internal server error |\n| 503 | `APIServerFlowExceedError` | Server overloaded |\n| N/A | `APIStatusError` | General API error |\n\n📈 Version Updates\n------------------\n\nFor detailed version history and update information, please see Release-Note.md.\n\n📄 License\n----------\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n🤝 Contributing\n---------------\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n📞 Support\n----------\n\nFor questions and technical support, please visit Z.ai Open Platform or check our documentation.\n\n### Contact Us\n\nFor feedback and support, please contact us at: **user_feedback@z.ai**\n\n"},"metadata":{"arguments":"{\"link_id\":51}","display_result":"","duration":"4s","id":"call_GSuyppWkjc","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【51†zai-org/z-ai-sdk-python†https://github.com/zai-org/z-ai-sdk-python】\nTitle: GitHub - zai-org/z-ai-sdk-python: The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs.\n\nURL Source: https://github.com/zai-org/z-ai-sdk-python\n\nMarkdown Content:\nZ.ai Open Platform Python SDK\n-----------------------------\n\n中文文档 | English\n\nZ.ai Open Platform The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs.\n\n✨ Core Features\n---------------\n\n### 🤖 **Chat Completions**\n\n*   **Standard Chat**: Create chat completions with various models including `glm-4.7`\n*   **Streaming Support**: Real-time streaming responses for interactive applications\n*   **Tool Calling**: Function calling capabilities for enhanced AI interactions\n*   **Character Role-Playing**: Support for character-based conversations with `charglm-3` model\n*   **Multimodal Chat**: Image understanding capabilities with vision models\n\n### 🧠 **Embeddings**\n\n*   **Text Embeddings**: Generate high-quality vector embeddings for text\n*   **Configurable Dimensions**: Customizable embedding dimensions\n*   **Batch Processing**: Support for multiple inputs in a single request\n\n### 🎥 **Video Generation**\n\n*   **Text-to-Video**: Generate videos from text prompts\n*   **Image-to-Video**: Create videos from image inputs\n*   **Customizable Parameters**: Control quality, duration, FPS, and size\n*   **Audio Support**: Optional audio generation for videos\n\n### 🎵 **Audio Processing**\n\n*   **Speech Transcription**: Convert audio files to text\n*   **Multiple Formats**: Support for various audio file formats\n\n### 🤝 **Assistant API**\n\n*   **Conversation Management**: Structured conversation handling\n*   **Streaming Conversations**: Real-time assistant interactions\n*   **Metadata Support**: Rich conversation context and user information\n\n### 🔧 **Advanced Tools**\n\n*   **Web Search**: Integrated web search capabilities\n*   **File Management**: Upload, download, and manage files\n*   **Batch Operations**: Efficient batch processing for multiple requests\n*   **Content Moderation**: Built-in content safety and moderation\n*   **Image Generation**: AI-powered image creation\n\n📦 Installation\n---------------\n\n### Requirements\n\n*   **Python**: 3.8+\n*   **Package Manager**: pip\n\n### Install via pip\n\npip install zai-sdk\n\n### 📋 **Technical Specifications**\n\n#### **Python Support**\n\n*   **Python Versions**: 3.8, 3.9, 3.10, 3.11, 3.12\n*   **Async Support**: Full async/await compatibility\n*   **Cross-platform**: Windows, macOS, Linux support\n\n#### **Core Dependencies**\n\n| Package | Version | Purpose |\n| --- | --- | --- |\n| `httpx` | `>=0.23.0` | HTTP client for API requests |\n| `pydantic` | `>=1.9.0,<3.0.0` | Data validation and serialization |\n| `typing-extensions` | `>=4.0.0` | Enhanced type hints support |\n| `cachetools` | `>=4.2.2` | Caching utilities |\n| `pyjwt` | `>=2.8.0` | JSON Web Token (JWT) handling |\n\n🚀 Quick Start\n--------------\n\n### Create API Key\n\n#### Get API Key\n\n*   **Overseas regions**: Visit Z.ai Open Platform to get your API key\n*   **Mainland China regions**: Visit Zhipu AI Open Platform to get your API key\n\n#### API BASE URL\n\n*   **Mainland China regions**: `https://open.bigmodel.cn/api/paas/v4/`\n*   **Overseas regions**: `https://api.z.ai/api/paas/v4/`\n\n#### Usage Steps\n\n1.   **Create client with API key**\n2.   **Call the corresponding API methods**\n\nFor complete examples, please refer to the open platform API Reference and User Guide, and remember to replace with your own API key.\n\n### Basic Usage\n\nfrom zai import ZaiClient, ZhipuAiClient\n\n# For Overseas users, create the ZaiClient\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# For Chinese users, create the ZhipuAiClient\nclient = ZhipuAiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model=\"glm-4.7\",\n    messages=[\n        {\"role\": \"user\", \"content\": \"Hello, Z.ai!\"}\n    ]\n)\nprint(response.choices[0].message.content)\n\n### Client Configuration\n\nThe SDK supports multiple ways to configure API keys:\n\n#### Environment Variables\n\nexport ZAI_API_KEY=\"your-api-key\"\nexport ZAI_BASE_URL=\"https://api.z.ai/api/paas/v4/\"  # Optional\n\n#### Code Configuration\n\nfrom zai import ZaiClient, ZhipuAiClient\n\nclient = ZaiClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://api.z.ai/api/paas/v4/\"  # Optional\n)\n\n# if you want to use Zhipu's domain service\nzhipu_client = ZhipuAiClient(\n    api_key=\"your-api-key\",\n    base_url=\"https://open.bigmodel.cn/api/paas/v4/\"  # Optional\n)\n\n### Advanced Configuration\n\nCustomize client behavior with additional parameters:\n\nfrom zai import ZaiClient\nimport httpx\n\nclient = ZaiClient(\n    api_key=\"your-api-key\",\n    timeout=httpx.Timeout(timeout=300.0, connect=8.0),  # Request timeout\n    max_retries=3,  # Retry attempts\n    base_url=\"https://api.z.ai/api/paas/v4/\"  # Custom API endpoint\n)\n\n📖 Usage Examples\n-----------------\n\n### Streaming Chat\n\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'Tell me a story about AI.'},\n    ],\n    stream=True,\n)\n\nfor chunk in response:\n    if chunk.choices[0].delta.content:\n        print(chunk.choices[0].delta.content, end='')\n\n### Chat With Tool Call\n\nfrom zai import ZaiClient\n\n# Initialize client\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Create chat completion\nresponse = client.chat.completions.create(\n    model='glm-4.7',\n    messages=[\n        {'role': 'system', 'content': 'You are a helpful assistant.'},\n        {'role': 'user', 'content': 'What is artificial intelligence?'},\n    ],\n    tools=[\n        {\n            'type': 'web_search',\n            'web_search': {\n                'search_query': 'What is artificial intelligence?',\n                'search_result': True,\n            },\n        }\n    ],\n    temperature=0.5,\n    max_tokens=2000,\n)\n\nprint(response)\n\n### Multimodal Chat\n\nfrom zai import ZaiClient\nimport base64\n\ndef encode_image(image_path):\n    \"\"\"Encode image to base64 format\"\"\"\n    with open(image_path, 'rb') as image_file:\n        return base64.b64encode(image_file.read()).decode('utf-8')\n\nclient = ZaiClient(api_key=\"your-api-key\")\nbase64_image = encode_image('examples/test_multi_modal.jpeg')\n\nresponse = client.chat.completions.create(\n    model='glm-4.6v',\n    messages=[\n        {\n            'role': 'user',\n            'content': [\n                {'type': 'text', 'text': \"What's in this image?\"},\n                {'type': 'image_url', 'image_url': {'url': f'data:image/jpeg;base64,{base64_image}'}},\n            ],\n        }\n    ],\n    temperature=0.5,\n    max_tokens=2000,\n)\nprint(response)\n\n### Video Generation\n\nfrom zai import ZaiClient\nclient = ZaiClient(api_key=\"your-api-key\")\n\n# Generate video\nresponse = client.videos.generations(\n    model=\"cogvideox-3\",\n    prompt=\"A cat is playing with a ball.\",\n    quality=\"quality\",  # Output mode, \"quality\" for quality priority, \"speed\" for speed priority\n    with_audio=True, # Whether to include audio\n    size=\"1920x1080\",  # Video resolution, supports up to 4K (e.g., \"3840x2160\")\n    fps=30,  # Frame rate, can be 30 or 60\n    max_wait_time=300,  # Maximum wait time (seconds)\n)\nprint(response)\n\n# Get video result\nresult = client.videos.retrieve_videos_result(id=response.id)\nprint(result)\n\n🚨 Error Handling\n-----------------\n\nThe SDK provides comprehensive error handling:\n\nfrom zai import ZaiClient\nimport zai\n\nclient = ZaiClient(api_key=\"your-api-key\")\n\ntry:\n    response = client.chat.completions.create(\n        model=\"glm-4.7\",\n        messages=[\n            {\"role\": \"user\", \"content\": \"Hello, Z.ai!\"}\n        ]\n    )\n    print(response.choices[0].message.content)\n    \nexcept zai.core.APIStatusError as err:\n    print(f\"API Status Error: {err}\")\nexcept zai.core.APITimeoutError as err:\n    print(f\"Request Timeout: {err}\")\nexcept Exception as err:\n    print(f\"Unexpected Error: {err}\")\n\n### Error Codes\n\n| Status Code | Error Type | Description |\n| --- | --- | --- |\n| 400 | `APIRequestFailedError` | Invalid request parameters |\n| 401 | `APIAuthenticationError` | Authentication failed |\n| 429 | `APIReachLimitError` | Rate limit exceeded |\n| 500 | `APIInternalError` | Internal server error |\n| 503 | `APIServerFlowExceedError` | Server overloaded |\n| N/A | `APIStatusError` | General API error |\n\n📈 Version Updates\n------------------\n\nFor detailed version history and update information, please see Release-Note.md.\n\n📄 License\n----------\n\nThis project is licensed under the MIT License - see the LICENSE file for details.\n\n🤝 Contributing\n---------------\n\nContributions are welcome! Please feel free to submit a Pull Request.\n\n📞 Support\n----------\n\nFor questions and technical support, please visit Z.ai Open Platform or check our documentation.\n\n### Contact Us\n\nFor feedback and support, please contact us at: **user_feedback@z.ai**\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="2" view="" last_tool_call_name="click">
> Z.aiのPython SDKに関するGitHubリポジトリが非常に詳細で、具体的な実装例が豊富だ。これを基に、Z.aiを使った具体的な実装方法を深掘りできる。特に、関数呼び出し、ストリーミング処理、エラーハンドリングなどの点について説明できる。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"},{"title":"Hybrid Search Explained","url":"https://weaviate.io/blog/hybrid-search-explained","text":"Learn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!","index":21,"favicon":"","host_name":"weaviate.io"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":22,"favicon":"","host_name":"weaviate.io"},{"title":"Introduction to Retrieval Augmented Generation (RAG)","url":"https://weaviate.io/blog/introduction-to-rag","text":"For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...","index":23,"favicon":"","host_name":"weaviate.io"},{"title":"Lessons learned from building hybrid search in production","url":"https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in","text":"After shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...","index":24,"favicon":"","host_name":"www.reddit.com"},{"title":"weaviate/Verba: Retrieval Augmented Generation (RAG)","url":"https://github.com/weaviate/Verba","text":"Verba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.","index":25,"favicon":"","host_name":"github.com"},{"title":"Use a Weaviate database with Vertex AI RAG Engine","url":"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db","text":"This is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python","index":26,"favicon":"","host_name":"docs.cloud.google.com"},{"title":"Legacy data to RAG : Modernise Your Apps with Amazon","url":"https://weaviate.io/blog/sagemaker-studio-rag","text":"Weaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.","index":27,"favicon":"","host_name":"weaviate.io"},{"title":"Building a Semantic Search Engine using Weaviate","url":"https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate","text":"Getting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.","index":28,"favicon":"","host_name":"www.analyticsvidhya.com"},{"title":"Exploring RAG and GraphRAG: Understanding when and","url":"https://weaviate.io/blog/graph-rag","text":"Retrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.","index":29,"favicon":"","host_name":"weaviate.io"},{"title":"Improving Retrieval Performance in RAG Pipelines with","url":"https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5","text":"This article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...","index":30,"favicon":"","host_name":"towardsdatascience.com"},{"title":"Model Context Protocol (MCP) | Cursor Docs","url":"https://cursor.com/docs/context/mcp","text":"Connect Cursor to external tools and data sources using Model Context Protocol (MCP). Install servers, configure authentication, and integrate with databases,","index":31,"favicon":"","host_name":"cursor.com"},{"title":"guides/cursor-mcp-setup.md at main","url":"https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md","text":"Setting Up MCP Servers in Cursor IDE. A comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE.","index":32,"favicon":"","host_name":"github.com"},{"title":"Display MCP from GitHub in the extensions section, as it is","url":"https://forum.cursor.com/t/display-mcp-from-github-in-the-extensions-section-as-it-is-done-in-vscode/147958","text":"I get that you want a simpler way to install MCP servers. Cursor has an official MCP Directory with featured servers. If the server you need ...","index":33,"favicon":"","host_name":"forum.cursor.com"},{"title":"A Complete Guide to MCP Integration in Cursor AI","url":"https://dev.to/akki907/supercharge-your-development-workflow-a-complete-guide-to-mcp-integration-in-cursor-ai-13l","text":"To configure MCP servers in Cursor AI: Open Cursor Settings: Navigate to File → Preferences → Cursor Settings; Look for the \"MCP\" section ...","index":34,"favicon":"","host_name":"dev.to"},{"title":"How to integrate Cursor IDE with Figma MCP","url":"https://www.zignuts.com/blog/integrate-cursor-ide-with-figma-mcp","text":"1. Download and Setup Cursor IDE · 2. Prepare Your Figma Account · 3. Configure Figma MCP in Cursor IDE · 4. Add Figma MCP Configuration.","index":35,"favicon":"","host_name":"www.zignuts.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. Download for Linux. ⤓ · Try mobile agent. →.","index":36,"favicon":"","host_name":"cursor.com"},{"title":"How to connect Cursor to 100+ MCP Servers within minutes","url":"https://composio.dev/blog/how-to-connect-cursor-to-100-mcp-servers-within-minutes","text":"Step 1: Prerequisites. · Step 2: Enable the MCP server in Cursor. · Step 3: Using a pre-defined MCP server. · Step 4: Integrating the MCP server.","index":37,"favicon":"","host_name":"composio.dev"},{"title":"Setting up IDEs (desktop clients) | Atlassian Rovo MCP","url":"https://support.atlassian.com/atlassian-rovo-mcp-server/docs/setting-up-ides","text":"Connect IDEs like VS Code to the Atlassian Remote MCP Server using the mcp-remote tool. Installation, configuration, and tips for successful setup included.","index":38,"favicon":"","host_name":"support.atlassian.com"},{"title":"MCP settings tutorial for Cursor, Claude,","url":"https://kento-yamazaki.medium.com/mcp-settings-tutorial-for-cursor-claude-31e5afbf97bc","text":"A comprehensive guide for setting up various MCP integrations in Cursor IDE. First, I show you mcp.json , which is a configuration file of MCP servers for ...","index":39,"favicon":"","host_name":"kento-yamazaki.medium.com"},{"title":"How to integrate MCP with Cursor IDE | Gavin Ching","url":"https://www.linkedin.com/posts/gavinching_using-the-cursor-ide-and-wondering-how-to-activity-7302738352116576256-SzwV","text":"To get started with MCP servers, you will click on your settings, go into features, and just Scroll down to MCP servers. Here you would just add ...","index":40,"favicon":"","host_name":"www.linkedin.com"},{"title":"How to Add MCP to Claude Code (Step by Step, Plain","url":"https://medium.com/@Michael38/how-to-add-mcp-to-claude-code-step-by-step-plain-english-865fec18e07d","text":"This article focuses on the practical setup inside Claude Code, while the official docs cover the underlying specification. Official MCP ...","index":41,"favicon":"","host_name":"medium.com"},{"title":"Connect Claude Code to tools via MCP","url":"https://code.claude.com/docs/en/mcp","text":"Claude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool ...","index":42,"favicon":"","host_name":"code.claude.com"},{"title":"Setting Up MCP Servers in Claude Code: A Tech Ritual for","url":"https://www.reddit.com/r/ClaudeAI/comments/1jf4hnt/setting_up_mcp_servers_in_claude_code_a_tech","text":"Here, members share MCP server implementations, integration strategies, and best practices. Whether you're a developer, researcher, or AI ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Use MCP servers in VS Code","url":"https://code.visualstudio.com/docs/copilot/customization/mcp-servers","text":"Automatically discover MCP servers. VS Code can automatically detect and reuse MCP server configurations from other applications, such as Claude Desktop.","index":44,"favicon":"","host_name":"code.visualstudio.com"},{"title":"GitHub's official MCP Server","url":"https://github.com/github/github-mcp-server","text":"The GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code ...","index":45,"favicon":"","host_name":"github.com"},{"title":"Connect Claude to MCP Servers for Better AI Capabilities","url":"https://www.getmesa.com/blog/how-to-connect-mcp-server-claude","text":"Learn how to connect MCP server Claude integrations. Step-by-step guide to setup, configuration, and automating workflows with Claude AI.","index":46,"favicon":"","host_name":"www.getmesa.com"},{"title":"Atlassian MCP Integration with Claude Completely S","url":"https://community.atlassian.com/forums/Rovo-questions/Atlassian-MCP-Integration-with-Claude-Completely-Stopped-Working/qaq-p/3147695","text":"As of Saturday morning (November 16, 2025), the integration has **completely stopped working** on Claude's remote connector platforms (Claude.ai ...","index":47,"favicon":"","host_name":"community.atlassian.com"},{"title":"The Best MCP Servers for Developers in 2026","url":"https://www.builder.io/blog/best-mcp-servers-2026","text":"MCP introduces a universal interface. You spin up a \"Postgres MCP Server\" once. That server can now talk to Claude Code, Cursor, Fusion, or any ...","index":48,"favicon":"","host_name":"www.builder.io"},{"title":"7 Claude MCP servers you can set up right now","url":"https://zapier.com/blog/claude-mcp-servers","text":"Here, I'll walk you through the MCP servers that I've found the most useful when working in Claude. I'll show you how to set them up and give you some examples ...","index":49,"favicon":"","host_name":"zapier.com"},{"title":"Claude Code MCP: How to Add MCP Servers (Complete Guide)","url":"https://www.youtube.com/watch?v=DfWHX7kszQI","text":"In this video I'll show you the fundamentals of adding any MCP server to your claw code agents.","index":50,"favicon":"","host_name":"www.youtube.com"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":51,"favicon":"","host_name":"docs.z.ai"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":52,"favicon":"","host_name":"github.com"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":53,"favicon":"","host_name":"docs.z.ai"},{"title":"OpenAI Python SDK - Overview","url":"https://docs.z.ai/guides/develop/openai/python","text":"Z.AI provides interfaces compatible with OpenAI API, which means you can use existing OpenAI SDK code and seamlessly switch to Z.AI's model services by ...","index":54,"favicon":"","host_name":"docs.z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":55,"favicon":"","host_name":"docs.z.ai"},{"title":"How to Access the GLM-4.7 API in 2026","url":"https://apidog.com/blog/glm-4-7-api","text":"Learn step-by-step setup on the official Z.ai platform and OpenRouter, compare pricing, and integrate efficiently with tools like Apidog.","index":56,"favicon":"","host_name":"apidog.com"},{"title":"Z-Image API: Integrate AI Image Generation into Your App | Blog","url":"https://z-image.ai/blog/z-image-api","text":"Z-Image API documentation: endpoints, authentication, pricing, and code examples for developers.","index":57,"favicon":"","host_name":"z-image.ai"},{"title":"HTTP API Calls - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/develop/http/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, allowing you to easily integrate Z.AI's ...","index":58,"favicon":"","host_name":"docs.z.ai"},{"title":"Interactions API | Gemini API - Google AI for Developers","url":"https://ai.google.dev/gemini-api/docs/interactions","text":"The following example shows how to call the Interactions API with a text prompt. Python JavaScript REST","index":59,"favicon":"","host_name":"ai.google.dev"},{"title":"AI SDK","url":"https://ai-sdk.dev","text":"From the creators of Next.js, the AI SDK is a free open-source library that gives you the tools you need to build AI-powered products.","index":60,"favicon":"","host_name":"ai-sdk.dev"},{"title":"Best Practices for AI Agent Implementations","url":"https://onereach.ai/blog/best-practices-for-ai-agent-implementations","text":"Learn proven strategies to implement AI agents at scale in 2026. Discover frameworks, guardrails, governance models, and ROI-driven ...","index":61,"favicon":"","host_name":"onereach.ai"},{"title":"Five AI Shifts Shaping Enterpise Strategy in 2026","url":"https://em360tech.com/tech-articles/enterprise-ai-strategy-2026","text":"The biggest 2026 change is mindset. AI compliance will not sit under “innovation”. It will sit alongside security, privacy, and enterprise risk.","index":62,"favicon":"","host_name":"em360tech.com"},{"title":"8 fundamental AI security best practices for teams in 2026","url":"https://wanamingomn.com/premium/stacker/stories/8-fundamental-ai-security-best-practices-for-teams-in-2026,144344","text":"1. Establish data security policies across the AI lifecycle · 2. Use digital signatures to track version history · 3. Employ the zero-trust ...","index":63,"favicon":"","host_name":"wanamingomn.com"},{"title":"AI Agent Security: The Complete Enterprise Guide for 2026","url":"https://www.mintmcp.com/blog/ai-agent-security","text":"Explore the complete 2026 enterprise guide to AI agent security, covering best practices, threat prevention, and risk management strategies.","index":64,"favicon":"","host_name":"www.mintmcp.com"},{"title":"Best Practices for Implementing AI for Cybersecurity","url":"https://cioinfluence.com/guest-authors/best-practices-for-implementing-ai-for-cybersecurity","text":"Here are the three important best practices for implementing AI for cybersecurity for your organization.","index":65,"favicon":"","host_name":"cioinfluence.com"},{"title":"Enterprise AI Strategy in 2026: A Proven Roadmap for","url":"https://www.techment.com/blogs/enterprise-ai-strategy-in-2026","text":"A winning enterprise AI strategy in 2026 requires clear business alignment, a strong data foundation, ethical governance, scalable architecture, and a roadmap ...","index":66,"favicon":"","host_name":"www.techment.com"},{"title":"What is AI Agent Security Plan 2026? Threats and","url":"https://www.uscsinstitute.org/cybersecurity-insights/blog/what-is-ai-agent-security-plan-2026-threats-and-strategies-explained","text":"Learn what AI agent security is, understand key threats like prompt injection and tool abuse, core AI security principles, and best ...","index":67,"favicon":"","host_name":"www.uscsinstitute.org"},{"title":"Top Enterprise AI Automation Platforms in 2026","url":"https://www.intelegain.com/top-enterprise-ai-automation-platforms-in-2026-a-buyers-guide-for-business-leaders","text":"The top AI software for enterprises in 2026 is centered around strong security capabilities together with flexible modeling features, ...","index":68,"favicon":"","host_name":"www.intelegain.com"},{"title":"AI Governance in 2026: How to scale artificial intelligence","url":"https://rootstack.com/en/blog/ai-governance-2026","text":"1. Data and access governance (RBAC for AI). AI is only as secure as the data it consumes. When implementing RAG (Retrieval-Augmented Generation) ...","index":69,"favicon":"","host_name":"rootstack.com"},{"title":"2026 Predictions: The Future of Investigation is Dynamic,","url":"https://www.splunk.com/en_us/blog/ciso-circle/ai-generative-ui-security-analyst-investigations.html","text":"AI-powered investigations are changing how security analysts work. Learn how generative UI enables faster insights, visual analysis, ...","index":70,"favicon":"","host_name":"www.splunk.com"}]},"metadata":{"arguments":"{\"query\":\"enterprise security AI assistant implementation 2026 best practices\"}","display_result":"","duration":"2s","id":"call_nlsN5knGVs","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【60†Best Practices for AI Agent Implementations†https://onereach.ai/blog/best-practices-for-ai-agent-implementations】\nLearn proven strategies to implement AI agents at scale in 2026. Discover frameworks, guardrails, governance models, and ROI-driven ...\n\n【61†Five AI Shifts Shaping Enterpise Strategy in 2026†https://em360tech.com/tech-articles/enterprise-ai-strategy-2026】\nThe biggest 2026 change is mindset. AI compliance will not sit under “innovation”. It will sit alongside security, privacy, and enterprise risk.\n\n【62†8 fundamental AI security best practices for teams in 2026†https://wanamingomn.com/premium/stacker/stories/8-fundamental-ai-security-best-practices-for-teams-in-2026,144344】\n1. Establish data security policies across the AI lifecycle · 2. Use digital signatures to track version history · 3. Employ the zero-trust ...\n\n【63†AI Agent Security: The Complete Enterprise Guide for 2026†https://www.mintmcp.com/blog/ai-agent-security】\nExplore the complete 2026 enterprise guide to AI agent security, covering best practices, threat prevention, and risk management strategies.\n\n【64†Best Practices for Implementing AI for Cybersecurity†https://cioinfluence.com/guest-authors/best-practices-for-implementing-ai-for-cybersecurity】\nHere are the three important best practices for implementing AI for cybersecurity for your organization.\n\n【65†Enterprise AI Strategy in 2026: A Proven Roadmap for†https://www.techment.com/blogs/enterprise-ai-strategy-in-2026】\nA winning enterprise AI strategy in 2026 requires clear business alignment, a strong data foundation, ethical governance, scalable architecture, and a roadmap ...\n\n【66†What is AI Agent Security Plan 2026? Threats and†https://www.uscsinstitute.org/cybersecurity-insights/blog/what-is-ai-agent-security-plan-2026-threats-and-strategies-explained】\nLearn what AI agent security is, understand key threats like prompt injection and tool abuse, core AI security principles, and best ...\n\n【67†Top Enterprise AI Automation Platforms in 2026†https://www.intelegain.com/top-enterprise-ai-automation-platforms-in-2026-a-buyers-guide-for-business-leaders】\nThe top AI software for enterprises in 2026 is centered around strong security capabilities together with flexible modeling features, ...\n\n【68†AI Governance in 2026: How to scale artificial intelligence†https://rootstack.com/en/blog/ai-governance-2026】\n1. Data and access governance (RBAC for AI). AI is only as secure as the data it consumes. When implementing RAG (Retrieval-Augmented Generation) ...\n\n【69†2026 Predictions: The Future of Investigation is Dynamic,†https://www.splunk.com/en_us/blog/ciso-circle/ai-generative-ui-security-analyst-investigations.html】\nAI-powered investigations are changing how security analysts work. Learn how generative UI enables faster insights, visual analysis, ...\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> エンタープライズでのAIセキュリティに関するベストプラクティスがわかる。これを基に、セキュリティ対策やガバナンスの具体的な実装方法を深掘りできる。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://onereach.ai/blog/best-practices-for-ai-agent-implementations","title":"Best Practices for AI Agent Implementations","content":"【60†Best Practices for AI Agent Implementations†https://onereach.ai/blog/best-practices-for-ai-agent-implementations】\nTitle: Best Practices for AI Agent Implementations: Enterprise Guide 2026\n\nURL Source: https://onereach.ai/blog/best-practices-for-ai-agent-implementations\n\nPublished Time: 2025-10-31T12:54:29+00:00\n\nMarkdown Content:\nThere is a clear CXO mandate for technology-driven growth and measurable ROI.Agentic AI adoption is becoming a competitive necessity. McKinsey warns that agentic AI represents a “moment of strategic divergence” where early movers will redefine competitive dynamics. [1]\n\nAccording to Gartner, by 2028, 33% of enterprise software applications will contain agentic AI capabilities (rising from less than 1% in 2024), and 15% of day-to-day work decisions will be accomplished autonomously. [2] However, this rapid growth comes with significant challenges. Gartner also predicts that by the end of 2027, more than 40% of agentic AI projects will fail or be canceled due to escalating costs, unclear business value, or not enough risk controls. [3]\n\nThe difference between success and failure often hinges on how organizations integrate AI agents into their business processes. Organizations that perceive AI agents just as another software deployment frequently fail, while those that recognize the unique requirements of autonomous Agentic AI systems — from data readiness to governance frameworks — are achieving great results. By 2029, 80% of common customer service queries will be resolved autonomously by agentic AI without human intervention, resulting in a 30% reduction in operational costs. [4] This substantial opportunity demonstrates the impact of deploying agentic AI correctly.\n\nIt’s the perfect time for business and IT leadership to know how to implement AI agents at scale. Learn about AI agent best practices, strategies, and guardrails for deploying agentic AI. With such actionable insights , IT and automation leaders will be able to avoid common mistakes, minimize risk, and maximize ROI (Return on Investment) while ensuring that AI agents are deployed responsibly, ethically, securely, and aligned with business objectives.\n\nRecommendations for Business Leaders\n------------------------------------\n\n**Figure 1: Critical Considerations for Business Leaders**\n\n### Strategic Planning and Organizational Readiness\n\nBefore rolling out your first AI agent, assess your organization’s maturity across four dimensions: data infrastructure, governance capabilities, technical resources, and employee readiness. According to IDC, only 21% of enterprises fully meet the readiness criteria, highlighting the importance of conducting an early assessment [5] — which explains why so many implementations fail to deliver expected value.\n\nStart with high-impact, low-risk use cases that address specific business pain points. Customer service automation (live chat and agent assist), document processing (claims processing), and routine administrative tasks are all examples that can offer measurable returns while building organizational confidence in Agentic AI.\n\nDefining measurable KPIs (key performance indicators) is essential, including accuracy rates (target ≥95%), task completion rates (target ≥90%), response times, and business impact metrics, such as cost savings and productivity improvements.\n\nChange management can’t be an afterthought either. Employee resistance can derail even well-designed implementations. That’s why business leaders should develop comprehensive change management programs that address employee concerns, provide support training, and ensure everyone understands how AI agents will augment rather than replace humans.\n\nAnother important step is to establish an AI governance framework that includes decision hierarchies, risk management protocols, and ethics committees. According to McKinsey’s State of AI report, only 17% of enterprises have a formal governance for their AI projects [6] — but those that do tend to scale agent deployments with a greater frequency.\n\nAs part of this governance, leaders should also consider Agent Lifecycle Management— a structured process for designing, training, testing, deploying, monitoring, and optimizing AI agents throughout their operational lifecycle. This ensures alignment with business goals and supports transparent performance tracking.\n\n### Investment and Resource Allocation\n\nBudget planning for AI agents requires a more comprehensive approach than purchasing traditional software or SaaS. Technology costs are just the beginning. Preparing data, integrating systems, training employees, and ongoing maintenance of the technology often equal or exceed the initial platform investments.\n\nData infrastructure requires special investment considerations. Organizations with poor data quality face significantly higher implementation failure rates. Invest in efforts to ensure improved data quality, better data integration, and enhanced data accessibility before considering implementation of AI agents at scale.\n\nPlan for scalability from the start. Design implementations with scalability in mind, ensuring that infrastructure and processes can accommodate the expanding use of AI agents across the organization.\n\n### Risk Management and Compliance\n\nSecurity is the primary challenge in implementing AI agents. Use security frameworks that address four critical parameters: prompt filtering, data protection, external access control, and response enforcement. AI agents that take autonomous actions require different security approaches than traditional software.\n\nEarly on, establish and enforce regulatory compliance mandates to ensure that implementations are compliant with data protection laws, industry-specific regulations, and emerging standards for governing AI. The regulatory environment is rapidly evolving, and organizations require frameworks that are adaptable to meet new requirements. Forrester reports that non-compliant implementations incur an average penalty of $2.4 Mn per incident. [7]\n\nFor real-time monitoring, organizations can leverage OpenTelemetry for AI — an open-source standard that helps track and analyze agent performance, system health, and potential risks across complex environments. This observability layer ensures transparency and accountability throughout agent operations.\n\nDevelop crisis management plans before a crisis happens. Establish procedures for handling AI agent faults, security breaches, or unexpected agent behavior situations, as well as provisions for rollback and emergency protocols. Set up regular audits to measure AI agent performance, compliance adherence, and overall security posture.\n\nRecommendations for IT Leaders\n------------------------------\n\n**Figure 2: Critical Considerations for IT Leaders**\n\n### Technical Architecture and Infrastructure\n\nDesign AI agents for flexibility and scalability from the start. Utilize a modular AI agent architecture that enables growth and evolution. Cloud-native architecture allows for rapid scaling and resource optimization, both of which are critical, as 40% of enterprise applications will feature task-specific AI agents by 2026, up from less than 5% in 2025. [8]\n\nCreate strong data pipelines that guarantee data access in real time, quality validation, and seamless integration within enterprise systems. Data pipeline failures are one of the most prevalent causes of AI agents operating incorrectly in production.\n\nFollow an API-first integration strategy. Design integration approach focussed on APIs to enable AI agents to communicate with existing enterprise IT systems seamlessly. Use standardized interfaces and well-documented integration protocols. To support interoperability across multiple systems and vendors, consider adopting the Model Context Protocol (MCP) — an emerging standard that ensures a smooth and secure connection between AI agents and external systems to obtain context and coordinate tasks accordingly.\n\nPlan for multi-agent orchestration. In the future, AI agents will no longer work in isolation, but together to solve complex tasks. Multi-agent systems represent the next frontier of AI capability by utilizing multiple intelligent agents that can collaborate, adapt, and operate in real time.\n\nHigh availability and reliability through redundancy, failover mechanisms, and disaster recovery procedures are of utmost importance. AI agents are often serving critical business functions, and therefore, making availability and business continuity are non-negotiable requirements.\n\n### Security and Governance Implementation\n\nDeploy monitoring systems that can track AI agent behavior in real time, including performance metrics, security events, and compliance violations. Even more importantly, automated alerting systems must identify issues quickly before they turn into bigger problems.\n\nUse identity and access management (IAM) systems with authentication and authorization protocols to manage AI agents. Moreover, AI agents accessing enterprise systems and data should have the same rigorous access controls as human users — and in some cases, more stringent controls given their autonomous capabilities.\n\nKeep logs of all actions, decisions, and interactions made by AI agents. These audit trails are useful for compliance requirements and troubleshooting, and performance optimization, in addition to providing important and necessary records of inspection for regulatory reviews.\n\nIncorporate secure development practices throughout the AI agent lifecycle. Conduct periodic security assessments and execute vulnerability management plans tailored specifically for AI agent systems.\n\n### Performance Optimization and Maintenance\n\nSet up performance baselines and systematically track agent effectiveness against these standards. Without defined benchmarks, it’s difficult to determine whether your AI agents are improving, declining, or simply maintaining static performance levels.\n\nIncorporate AI agent testing and evaluation into every phase of deployment. Regular testing against predefined scenarios and key metrics ensures reliability, fairness, and security. Use simulation environments and stress tests to identify performance bottlenecks before deployment at scale.\n\nUse AgentOps practices to deploy rapid updates, enhancements, and security patches to your AI agents. The continuous integration/continuous deployment (CI/CD) approach, which has transformed software development, also applies to AI agent systems.\n\nCreate protocols for AI model updates, agnostic retraining for new data, and performance validation for updates. For knowledge-based agents, you may also consider implementing Agentic Retrieval-Augmented Generation (RAG), so that you can facilitate grounding responses in verified, organization-specific data sources while reducing the risk of hallucination.\n\nKeep track of your resource usage. Monitor computational resources, API calls, and infrastructure costs to improve performance and control costs effectively.\n\nAI Agent Implementation Framework\n---------------------------------\n\n**Figure 3: AI Agent Implementation Framework**\n\nSuccessfully deploying AI agents isn’t a one-off activity — it’s a structured, cyclical process that consists of five interrelated phases. The structured framework balances technical requirements with organizational readiness, from concept to realization, to enhance the business value of your AI agents.\n\n**Phase 1: Strategic Assessment and Planning** is where you gain a crystal-clear understanding of what you’re trying to solve. Start by defining the specific tasks or processes you want to automate. What’s the potential impact? Think efficiency gains, cost savings, and better customer experiences. Figure out what type of AI agent you need based on whether your use case requires actions, knowledge, or both. And here’s the critical part — establish specific, measurable KPIs so you can track whether this technology is actually working and delivering ROI.\n\n**Phase 2: Technology Architecture and Design** involves making some important decisions. Will you need autonomous AI agents that can handle complex and dynamic situations, making contextual decisions? Or are scripted AI agents better suited for your straightforward, repetitive tasks? Build on cloud-native architecture so you can scale and stay flexible. Set up robust data management and quality assurance processes. Map out how your agents will integrate with existing systems and APIs. And don’t forget to develop comprehensive security and compliance frameworks.\n\n**Phase 3: Development and Integration** focuses on maintaining ease of use, clarity, and transparency. Design agent interfaces that are simple to understand and use, with clear descriptions, defined parameters, and built-in error detection and protection measures. Thoroughly test in multiple scenarios for accuracy and performance, and build in error handling, fault tolerance, and resilience that agents can capture exceptions and continue on the path when things don’t go as planned.\n\n**Phase 4: Deployment and Change Management** involves rolling out AI agents gradually. Begin with pilot programs and use cases that are low-risk. Ensure to keep human involvement in cases of critical decision points. Design training and communication programs that educate your team about the technology and encourage them to adopt working with it. Use the feedback to calibrate your longer-term approach and understand how to improve AI agent performance.\n\n**Phase 5: Monitoring and Optimization**, where you ensure and optimize that everything works properly. Track performance metrics based on the KPIs and benchmarks you established in Phase 1; and use operational data and user feedback to support continuous improvement. Keep your AI models up to date with regular updates and enhancements. And assess the business value you’re getting — validate the ROI of AI agents and spot new opportunities for expanding your AI agent deployments.\n\nImplementation Challenges and Risk Factors\n------------------------------------------\n\n\n"},"metadata":{"arguments":"{\"link_id\":60}","display_result":"","duration":"3s","id":"call_0kKErUlsWy","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【60†Best Practices for AI Agent Implementations†https://onereach.ai/blog/best-practices-for-ai-agent-implementations】\nTitle: Best Practices for AI Agent Implementations: Enterprise Guide 2026\n\nURL Source: https://onereach.ai/blog/best-practices-for-ai-agent-implementations\n\nPublished Time: 2025-10-31T12:54:29+00:00\n\nMarkdown Content:\nThere is a clear CXO mandate for technology-driven growth and measurable ROI.Agentic AI adoption is becoming a competitive necessity. McKinsey warns that agentic AI represents a “moment of strategic divergence” where early movers will redefine competitive dynamics. [1]\n\nAccording to Gartner, by 2028, 33% of enterprise software applications will contain agentic AI capabilities (rising from less than 1% in 2024), and 15% of day-to-day work decisions will be accomplished autonomously. [2] However, this rapid growth comes with significant challenges. Gartner also predicts that by the end of 2027, more than 40% of agentic AI projects will fail or be canceled due to escalating costs, unclear business value, or not enough risk controls. [3]\n\nThe difference between success and failure often hinges on how organizations integrate AI agents into their business processes. Organizations that perceive AI agents just as another software deployment frequently fail, while those that recognize the unique requirements of autonomous Agentic AI systems — from data readiness to governance frameworks — are achieving great results. By 2029, 80% of common customer service queries will be resolved autonomously by agentic AI without human intervention, resulting in a 30% reduction in operational costs. [4] This substantial opportunity demonstrates the impact of deploying agentic AI correctly.\n\nIt’s the perfect time for business and IT leadership to know how to implement AI agents at scale. Learn about AI agent best practices, strategies, and guardrails for deploying agentic AI. With such actionable insights , IT and automation leaders will be able to avoid common mistakes, minimize risk, and maximize ROI (Return on Investment) while ensuring that AI agents are deployed responsibly, ethically, securely, and aligned with business objectives.\n\nRecommendations for Business Leaders\n------------------------------------\n\n**Figure 1: Critical Considerations for Business Leaders**\n\n### Strategic Planning and Organizational Readiness\n\nBefore rolling out your first AI agent, assess your organization’s maturity across four dimensions: data infrastructure, governance capabilities, technical resources, and employee readiness. According to IDC, only 21% of enterprises fully meet the readiness criteria, highlighting the importance of conducting an early assessment [5] — which explains why so many implementations fail to deliver expected value.\n\nStart with high-impact, low-risk use cases that address specific business pain points. Customer service automation (live chat and agent assist), document processing (claims processing), and routine administrative tasks are all examples that can offer measurable returns while building organizational confidence in Agentic AI.\n\nDefining measurable KPIs (key performance indicators) is essential, including accuracy rates (target ≥95%), task completion rates (target ≥90%), response times, and business impact metrics, such as cost savings and productivity improvements.\n\nChange management can’t be an afterthought either. Employee resistance can derail even well-designed implementations. That’s why business leaders should develop comprehensive change management programs that address employee concerns, provide support training, and ensure everyone understands how AI agents will augment rather than replace humans.\n\nAnother important step is to establish an AI governance framework that includes decision hierarchies, risk management protocols, and ethics committees. According to McKinsey’s State of AI report, only 17% of enterprises have a formal governance for their AI projects [6] — but those that do tend to scale agent deployments with a greater frequency.\n\nAs part of this governance, leaders should also consider Agent Lifecycle Management— a structured process for designing, training, testing, deploying, monitoring, and optimizing AI agents throughout their operational lifecycle. This ensures alignment with business goals and supports transparent performance tracking.\n\n### Investment and Resource Allocation\n\nBudget planning for AI agents requires a more comprehensive approach than purchasing traditional software or SaaS. Technology costs are just the beginning. Preparing data, integrating systems, training employees, and ongoing maintenance of the technology often equal or exceed the initial platform investments.\n\nData infrastructure requires special investment considerations. Organizations with poor data quality face significantly higher implementation failure rates. Invest in efforts to ensure improved data quality, better data integration, and enhanced data accessibility before considering implementation of AI agents at scale.\n\nPlan for scalability from the start. Design implementations with scalability in mind, ensuring that infrastructure and processes can accommodate the expanding use of AI agents across the organization.\n\n### Risk Management and Compliance\n\nSecurity is the primary challenge in implementing AI agents. Use security frameworks that address four critical parameters: prompt filtering, data protection, external access control, and response enforcement. AI agents that take autonomous actions require different security approaches than traditional software.\n\nEarly on, establish and enforce regulatory compliance mandates to ensure that implementations are compliant with data protection laws, industry-specific regulations, and emerging standards for governing AI. The regulatory environment is rapidly evolving, and organizations require frameworks that are adaptable to meet new requirements. Forrester reports that non-compliant implementations incur an average penalty of $2.4 Mn per incident. [7]\n\nFor real-time monitoring, organizations can leverage OpenTelemetry for AI — an open-source standard that helps track and analyze agent performance, system health, and potential risks across complex environments. This observability layer ensures transparency and accountability throughout agent operations.\n\nDevelop crisis management plans before a crisis happens. Establish procedures for handling AI agent faults, security breaches, or unexpected agent behavior situations, as well as provisions for rollback and emergency protocols. Set up regular audits to measure AI agent performance, compliance adherence, and overall security posture.\n\nRecommendations for IT Leaders\n------------------------------\n\n**Figure 2: Critical Considerations for IT Leaders**\n\n### Technical Architecture and Infrastructure\n\nDesign AI agents for flexibility and scalability from the start. Utilize a modular AI agent architecture that enables growth and evolution. Cloud-native architecture allows for rapid scaling and resource optimization, both of which are critical, as 40% of enterprise applications will feature task-specific AI agents by 2026, up from less than 5% in 2025. [8]\n\nCreate strong data pipelines that guarantee data access in real time, quality validation, and seamless integration within enterprise systems. Data pipeline failures are one of the most prevalent causes of AI agents operating incorrectly in production.\n\nFollow an API-first integration strategy. Design integration approach focussed on APIs to enable AI agents to communicate with existing enterprise IT systems seamlessly. Use standardized interfaces and well-documented integration protocols. To support interoperability across multiple systems and vendors, consider adopting the Model Context Protocol (MCP) — an emerging standard that ensures a smooth and secure connection between AI agents and external systems to obtain context and coordinate tasks accordingly.\n\nPlan for multi-agent orchestration. In the future, AI agents will no longer work in isolation, but together to solve complex tasks. Multi-agent systems represent the next frontier of AI capability by utilizing multiple intelligent agents that can collaborate, adapt, and operate in real time.\n\nHigh availability and reliability through redundancy, failover mechanisms, and disaster recovery procedures are of utmost importance. AI agents are often serving critical business functions, and therefore, making availability and business continuity are non-negotiable requirements.\n\n### Security and Governance Implementation\n\nDeploy monitoring systems that can track AI agent behavior in real time, including performance metrics, security events, and compliance violations. Even more importantly, automated alerting systems must identify issues quickly before they turn into bigger problems.\n\nUse identity and access management (IAM) systems with authentication and authorization protocols to manage AI agents. Moreover, AI agents accessing enterprise systems and data should have the same rigorous access controls as human users — and in some cases, more stringent controls given their autonomous capabilities.\n\nKeep logs of all actions, decisions, and interactions made by AI agents. These audit trails are useful for compliance requirements and troubleshooting, and performance optimization, in addition to providing important and necessary records of inspection for regulatory reviews.\n\nIncorporate secure development practices throughout the AI agent lifecycle. Conduct periodic security assessments and execute vulnerability management plans tailored specifically for AI agent systems.\n\n### Performance Optimization and Maintenance\n\nSet up performance baselines and systematically track agent effectiveness against these standards. Without defined benchmarks, it’s difficult to determine whether your AI agents are improving, declining, or simply maintaining static performance levels.\n\nIncorporate AI agent testing and evaluation into every phase of deployment. Regular testing against predefined scenarios and key metrics ensures reliability, fairness, and security. Use simulation environments and stress tests to identify performance bottlenecks before deployment at scale.\n\nUse AgentOps practices to deploy rapid updates, enhancements, and security patches to your AI agents. The continuous integration/continuous deployment (CI/CD) approach, which has transformed software development, also applies to AI agent systems.\n\nCreate protocols for AI model updates, agnostic retraining for new data, and performance validation for updates. For knowledge-based agents, you may also consider implementing Agentic Retrieval-Augmented Generation (RAG), so that you can facilitate grounding responses in verified, organization-specific data sources while reducing the risk of hallucination.\n\nKeep track of your resource usage. Monitor computational resources, API calls, and infrastructure costs to improve performance and control costs effectively.\n\nAI Agent Implementation Framework\n---------------------------------\n\n**Figure 3: AI Agent Implementation Framework**\n\nSuccessfully deploying AI agents isn’t a one-off activity — it’s a structured, cyclical process that consists of five interrelated phases. The structured framework balances technical requirements with organizational readiness, from concept to realization, to enhance the business value of your AI agents.\n\n**Phase 1: Strategic Assessment and Planning** is where you gain a crystal-clear understanding of what you’re trying to solve. Start by defining the specific tasks or processes you want to automate. What’s the potential impact? Think efficiency gains, cost savings, and better customer experiences. Figure out what type of AI agent you need based on whether your use case requires actions, knowledge, or both. And here’s the critical part — establish specific, measurable KPIs so you can track whether this technology is actually working and delivering ROI.\n\n**Phase 2: Technology Architecture and Design** involves making some important decisions. Will you need autonomous AI agents that can handle complex and dynamic situations, making contextual decisions? Or are scripted AI agents better suited for your straightforward, repetitive tasks? Build on cloud-native architecture so you can scale and stay flexible. Set up robust data management and quality assurance processes. Map out how your agents will integrate with existing systems and APIs. And don’t forget to develop comprehensive security and compliance frameworks.\n\n**Phase 3: Development and Integration** focuses on maintaining ease of use, clarity, and transparency. Design agent interfaces that are simple to understand and use, with clear descriptions, defined parameters, and built-in error detection and protection measures. Thoroughly test in multiple scenarios for accuracy and performance, and build in error handling, fault tolerance, and resilience that agents can capture exceptions and continue on the path when things don’t go as planned.\n\n**Phase 4: Deployment and Change Management** involves rolling out AI agents gradually. Begin with pilot programs and use cases that are low-risk. Ensure to keep human involvement in cases of critical decision points. Design training and communication programs that educate your team about the technology and encourage them to adopt working with it. Use the feedback to calibrate your longer-term approach and understand how to improve AI agent performance.\n\n**Phase 5: Monitoring and Optimization**, where you ensure and optimize that everything works properly. Track performance metrics based on the KPIs and benchmarks you established in Phase 1; and use operational data and user feedback to support continuous improvement. Keep your AI models up to date with regular updates and enhancements. And assess the business value you’re getting — validate the ROI of AI agents and spot new opportunities for expanding your AI agent deployments.\n\nImplementation Challenges and Risk Factors\n------------------------------------------\n\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> エンタープライズでのAIエージェント実装に関するベストプラクティスが非常に詳細で、具体的なフレームワークがわかる。これを基に、セキュリティ対策やガバナンスの具体的な実装方法を深掘りできる。
</details>

<glm_block view="" tool_call_name="search">{"data":{"browser":{"search_result":[{"title":"Python MCP Server: Connect LLMs to Your Data","url":"https://realpython.com/python-mcp","text":"In this tutorial, you'll install MCP, explore its client-server architecture, and work with its core concepts: prompts, resources, and tools.","index":1,"favicon":"","host_name":"realpython.com"},{"title":"The official Python SDK for Model Context Protocol servers","url":"https://github.com/modelcontextprotocol/python-sdk","text":"The Model Context Protocol (MCP) lets you build servers that expose data and functionality to LLM applications in a secure, standardized way.","index":2,"favicon":"","host_name":"github.com"},{"title":"Building a Basic MCP Server with Python | by Alex Merced","url":"https://medium.com/data-engineering-with-dremio/building-a-basic-mcp-server-with-python-4c34c41031ed","text":"In this tutorial, we'll walk you through building a beginner-friendly MCP server that acts as a simple template for future projects.","index":3,"favicon":"","host_name":"medium.com"},{"title":"How to Build a Python MCP Server to Consult","url":"https://auth0.com/blog/build-python-mcp-server-for-blog-search","text":"Learn how to build a Python MCP server from scratch. This step-by-step tutorial uses SerpApi and llms.txt to enable Claude tool calling for ...","index":4,"favicon":"","host_name":"auth0.com"},{"title":"MCP server: A step-by-step guide to building from scratch","url":"https://composio.dev/blog/mcp-server-step-by-step-guide-to-building-from-scrtch","text":"There are two ways to build an MCP Server: using the Python SDK or the JavaScript SDK. ... The example in the guide uses Python, so you should ...","index":5,"favicon":"","host_name":"composio.dev"},{"title":"Integrate MCP Servers in Python LLM Code","url":"https://lincolnloop.com/blog/integrate-mcp-servers-in-python-llm-code","text":"The Model Context Protocol (MCP) is a game-changer for developers integrating large language models (LLMs) with external data sources and tools.","index":6,"favicon":"","host_name":"lincolnloop.com"},{"title":"Building and deploying a Python MCP server with","url":"https://circleci.com/blog/building-and-deploying-a-python-mcp-server-with-fastmcp","text":"This tutorial guides readers through developing a Python package that implements an MCP (Model Context Protocol) server using the FastMCP ...","index":7,"favicon":"","host_name":"circleci.com"},{"title":"Build ANYTHING With an Advanced MCP Server (Python","url":"https://www.youtube.com/watch?v=j5f2EQf5hkw","text":"In this video I'll give you a full tutorial on building advanced MCP servers in Python that means we're going to go beyond the basics.","index":8,"favicon":"","host_name":"www.youtube.com"},{"title":"Setting Up Your First MCP Server with Python (Part 3/5)","url":"https://dev.to/bredmond1019/setting-up-your-first-mcp-server-with-python-part-35-3758","text":"Step 1: Setting Up Your Environment · Step 2: Understanding MCP Server Basics · Step 3: Building Our First MCP Server · Step 4: Testing Your Server.","index":9,"favicon":"","host_name":"dev.to"},{"title":"How to Build MCP Servers in Python: Complete FastMCP","url":"https://www.firecrawl.dev/blog/fastmcp-tutorial-building-mcp-servers-python","text":"Learn to build custom MCP servers in Python using FastMCP. Step-by-step tutorial covering tools, resources, prompts, debugging, and deployment for AI ...","index":10,"favicon":"","host_name":"www.firecrawl.dev"},{"title":"Top 10 Vector Databases for LLM Applications in 2026","url":"https://www.secondtalent.com/resources/top-vector-databases-for-llm-applications","text":"Milvus is a high-performance, cloud-native vector database designed for billion-scale similarity search. Originally developed by Zilliz and now ...","index":11,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 7 Best Vector Databases in 2026","url":"https://www.datacamp.com/blog/the-top-5-vector-databases","text":"Weaviate is an open-source vector database. It allows you to store data objects and vector embeddings from your favorite ML models and scale seamlessly into ...","index":12,"favicon":"","host_name":"www.datacamp.com"},{"title":"Top 6 Vector Database Solutions for RAG Applications: 2026","url":"https://azumo.com/artificial-intelligence/ai-insights/top-vector-database-solutions","text":"Explore the top vector database solutions powering RAG applications. Learn about Pinecone, Qdrant, Weaviate, and more to enhance your AI systems.","index":13,"favicon":"","host_name":"azumo.com"},{"title":"Best RAG Tools, Frameworks, and Libraries in 2026","url":"https://research.aimultiple.com/retrieval-augmented-generation","text":"Weaviate: Combines vector storage with RAG-ready features for retrieval. Milvus: An open-source vector database for AI use cases. Qdrant: A ...","index":14,"favicon":"","host_name":"research.aimultiple.com"},{"title":"Vector Databases for AI Apps in 2026: Pinecone, Milvus,","url":"https://www.linkedin.com/posts/suresh-beekhani_ai-machinelearning-vectordatabases-activity-7411276059314372608-hQI6","text":"Vector Databases Powering AI Apps in 2026 As AI systems mature, especially Retrieval‑Augmented Generation (RAG) and agent‑based applications ...","index":15,"favicon":"","host_name":"www.linkedin.com"},{"title":"Optimize Vector Databases, Enhance RAG-Driven","url":"https://milvus.io/blog/optimize-vector-databases-enhance-rag-driven-generative-ai.md","text":"In this article, you'll learn more about vector databases and their benchmarking frameworks, datasets to tackle different aspects, and the tools used for ...","index":16,"favicon":"","host_name":"milvus.io"},{"title":"How to Choose the Right Vector Database for Your RAG","url":"https://medium.com/nextgenllm/how-to-choose-the-right-vector-database-for-your-rag-simple-way-778c0ca98b04","text":"Growing traffic → Pinecone/Weaviate. Big multi‑TB + data control → Milvus. Simple rule: Choose ops model first; index tricks later. Most RAG ...","index":17,"favicon":"","host_name":"medium.com"},{"title":"Vector Databases for Generative AI Applications Guide 2026","url":"https://brollyai.com/vector-databases-for-generative-ai-applications","text":"Explore vector databases for generative AI applications, covering features, RAG use cases, tools, and trends in 2026.","index":18,"favicon":"","host_name":"brollyai.com"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":19,"favicon":"","host_name":"weaviate.io"},{"title":"Signals for 2026","url":"https://www.oreilly.com/radar/signals-for-2026","text":"A multiple database approach is more important than ever. Vector databases like Pinecone, Milvus, Qdrant, and Weaviate help power agentic AI ...","index":20,"favicon":"","host_name":"www.oreilly.com"},{"title":"Hybrid Search Explained","url":"https://weaviate.io/blog/hybrid-search-explained","text":"Learn about the hybrid search feature that enables you to combine dense and sparse vectors to deliver the best of both search methods!","index":21,"favicon":"","host_name":"weaviate.io"},{"title":"Retrieval Augmented Generation","url":"https://weaviate.io/rag","text":"Retrieval Augmented Generation (RAG) incorporates external knowledge into a Large Language Model (LLM) to improve the accuracy of AI-generated content.","index":22,"favicon":"","host_name":"weaviate.io"},{"title":"Introduction to Retrieval Augmented Generation (RAG)","url":"https://weaviate.io/blog/introduction-to-rag","text":"For specific examples, take a look at our notebooks that show how to build RAG pipelines with Weaviate and LlamaIndex and DSPy. If you're ...","index":23,"favicon":"","host_name":"weaviate.io"},{"title":"Lessons learned from building hybrid search in production","url":"https://www.reddit.com/r/Rag/comments/1pzuerp/lessons_learned_from_building_hybrid_search_in","text":"After shipping hybrid search into multiple production systems (RAG/chatbots, product search, and support search) over the last 18 months, ...","index":24,"favicon":"","host_name":"www.reddit.com"},{"title":"weaviate/Verba: Retrieval Augmented Generation (RAG)","url":"https://github.com/weaviate/Verba","text":"Verba is a fully-customizable personal assistant utilizing Retrieval Augmented Generation (RAG) for querying and interacting with your data.","index":25,"favicon":"","host_name":"github.com"},{"title":"Use a Weaviate database with Vertex AI RAG Engine","url":"https://docs.cloud.google.com/vertex-ai/generative-ai/docs/rag-engine/use-weaviate-db","text":"This is an example of how to enable a hybrid search using the RAG Engine retrieval API. REST Python","index":26,"favicon":"","host_name":"docs.cloud.google.com"},{"title":"Legacy data to RAG : Modernise Your Apps with Amazon","url":"https://weaviate.io/blog/sagemaker-studio-rag","text":"Weaviate and SageMaker Unified Studio together empower teams to build real-time generative AI applications powered by vector search and RAG.","index":27,"favicon":"","host_name":"weaviate.io"},{"title":"Building a Semantic Search Engine using Weaviate","url":"https://www.analyticsvidhya.com/blog/2025/07/semantic-search-using-weaviate","text":"Getting started with Weaviate: A Hands-on Guide · Step 1: Deploy Weaviate · Step 2: Install Python Dependencies · Step 3: Set Environment Variables.","index":28,"favicon":"","host_name":"www.analyticsvidhya.com"},{"title":"Exploring RAG and GraphRAG: Understanding when and","url":"https://weaviate.io/blog/graph-rag","text":"Retrieval Augmented Generation (RAG) is an effective way to get AI to extract information from the specific set of data you want it to work with.","index":29,"favicon":"","host_name":"weaviate.io"},{"title":"Improving Retrieval Performance in RAG Pipelines with","url":"https://towardsdatascience.com/improving-retrieval-performance-in-rag-pipelines-with-hybrid-search-c75203c2f2f5","text":"This article introduces you to the concept of hybrid search, how it can help you improve your RAG pipeline performance by retrieving more relevant results, and ...","index":30,"favicon":"","host_name":"towardsdatascience.com"},{"title":"Model Context Protocol (MCP) | Cursor Docs","url":"https://cursor.com/docs/context/mcp","text":"Connect Cursor to external tools and data sources using Model Context Protocol (MCP). Install servers, configure authentication, and integrate with databases,","index":31,"favicon":"","host_name":"cursor.com"},{"title":"guides/cursor-mcp-setup.md at main","url":"https://github.com/JeredBlu/guides/blob/main/cursor-mcp-setup.md","text":"Setting Up MCP Servers in Cursor IDE. A comprehensive guide for implementing MCP servers (Sequential Thinking, Brave Search, and Puppeteer) in Cursor IDE.","index":32,"favicon":"","host_name":"github.com"},{"title":"Display MCP from GitHub in the extensions section, as it is","url":"https://forum.cursor.com/t/display-mcp-from-github-in-the-extensions-section-as-it-is-done-in-vscode/147958","text":"I get that you want a simpler way to install MCP servers. Cursor has an official MCP Directory with featured servers. If the server you need ...","index":33,"favicon":"","host_name":"forum.cursor.com"},{"title":"A Complete Guide to MCP Integration in Cursor AI","url":"https://dev.to/akki907/supercharge-your-development-workflow-a-complete-guide-to-mcp-integration-in-cursor-ai-13l","text":"To configure MCP servers in Cursor AI: Open Cursor Settings: Navigate to File → Preferences → Cursor Settings; Look for the \"MCP\" section ...","index":34,"favicon":"","host_name":"dev.to"},{"title":"How to integrate Cursor IDE with Figma MCP","url":"https://www.zignuts.com/blog/integrate-cursor-ide-with-figma-mcp","text":"1. Download and Setup Cursor IDE · 2. Prepare Your Figma Account · 3. Configure Figma MCP in Cursor IDE · 4. Add Figma MCP Configuration.","index":35,"favicon":"","host_name":"www.zignuts.com"},{"title":"Cursor IDE","url":"https://cursor.com","text":"Built to make you extraordinarily productive, Cursor is the best way to code with AI. Download for Linux. ⤓ · Try mobile agent. →.","index":36,"favicon":"","host_name":"cursor.com"},{"title":"How to connect Cursor to 100+ MCP Servers within minutes","url":"https://composio.dev/blog/how-to-connect-cursor-to-100-mcp-servers-within-minutes","text":"Step 1: Prerequisites. · Step 2: Enable the MCP server in Cursor. · Step 3: Using a pre-defined MCP server. · Step 4: Integrating the MCP server.","index":37,"favicon":"","host_name":"composio.dev"},{"title":"Setting up IDEs (desktop clients) | Atlassian Rovo MCP","url":"https://support.atlassian.com/atlassian-rovo-mcp-server/docs/setting-up-ides","text":"Connect IDEs like VS Code to the Atlassian Remote MCP Server using the mcp-remote tool. Installation, configuration, and tips for successful setup included.","index":38,"favicon":"","host_name":"support.atlassian.com"},{"title":"MCP settings tutorial for Cursor, Claude,","url":"https://kento-yamazaki.medium.com/mcp-settings-tutorial-for-cursor-claude-31e5afbf97bc","text":"A comprehensive guide for setting up various MCP integrations in Cursor IDE. First, I show you mcp.json , which is a configuration file of MCP servers for ...","index":39,"favicon":"","host_name":"kento-yamazaki.medium.com"},{"title":"How to integrate MCP with Cursor IDE | Gavin Ching","url":"https://www.linkedin.com/posts/gavinching_using-the-cursor-ide-and-wondering-how-to-activity-7302738352116576256-SzwV","text":"To get started with MCP servers, you will click on your settings, go into features, and just Scroll down to MCP servers. Here you would just add ...","index":40,"favicon":"","host_name":"www.linkedin.com"},{"title":"How to Add MCP to Claude Code (Step by Step, Plain","url":"https://medium.com/@Michael38/how-to-add-mcp-to-claude-code-step-by-step-plain-english-865fec18e07d","text":"This article focuses on the practical setup inside Claude Code, while the official docs cover the underlying specification. Official MCP ...","index":41,"favicon":"","host_name":"medium.com"},{"title":"Connect Claude Code to tools via MCP","url":"https://code.claude.com/docs/en/mcp","text":"Claude Code can connect to hundreds of external tools and data sources through the Model Context Protocol (MCP), an open source standard for AI-tool ...","index":42,"favicon":"","host_name":"code.claude.com"},{"title":"Setting Up MCP Servers in Claude Code: A Tech Ritual for","url":"https://www.reddit.com/r/ClaudeAI/comments/1jf4hnt/setting_up_mcp_servers_in_claude_code_a_tech","text":"Here, members share MCP server implementations, integration strategies, and best practices. Whether you're a developer, researcher, or AI ...","index":43,"favicon":"","host_name":"www.reddit.com"},{"title":"Use MCP servers in VS Code","url":"https://code.visualstudio.com/docs/copilot/customization/mcp-servers","text":"Automatically discover MCP servers. VS Code can automatically detect and reuse MCP server configurations from other applications, such as Claude Desktop.","index":44,"favicon":"","host_name":"code.visualstudio.com"},{"title":"GitHub's official MCP Server","url":"https://github.com/github/github-mcp-server","text":"The GitHub MCP Server connects AI tools directly to GitHub's platform. This gives AI agents, assistants, and chatbots the ability to read repositories and code ...","index":45,"favicon":"","host_name":"github.com"},{"title":"Connect Claude to MCP Servers for Better AI Capabilities","url":"https://www.getmesa.com/blog/how-to-connect-mcp-server-claude","text":"Learn how to connect MCP server Claude integrations. Step-by-step guide to setup, configuration, and automating workflows with Claude AI.","index":46,"favicon":"","host_name":"www.getmesa.com"},{"title":"Atlassian MCP Integration with Claude Completely S","url":"https://community.atlassian.com/forums/Rovo-questions/Atlassian-MCP-Integration-with-Claude-Completely-Stopped-Working/qaq-p/3147695","text":"As of Saturday morning (November 16, 2025), the integration has **completely stopped working** on Claude's remote connector platforms (Claude.ai ...","index":47,"favicon":"","host_name":"community.atlassian.com"},{"title":"The Best MCP Servers for Developers in 2026","url":"https://www.builder.io/blog/best-mcp-servers-2026","text":"MCP introduces a universal interface. You spin up a \"Postgres MCP Server\" once. That server can now talk to Claude Code, Cursor, Fusion, or any ...","index":48,"favicon":"","host_name":"www.builder.io"},{"title":"7 Claude MCP servers you can set up right now","url":"https://zapier.com/blog/claude-mcp-servers","text":"Here, I'll walk you through the MCP servers that I've found the most useful when working in Claude. I'll show you how to set them up and give you some examples ...","index":49,"favicon":"","host_name":"zapier.com"},{"title":"Claude Code MCP: How to Add MCP Servers (Complete Guide)","url":"https://www.youtube.com/watch?v=DfWHX7kszQI","text":"In this video I'll show you the fundamentals of adding any MCP server to your claw code agents.","index":50,"favicon":"","host_name":"www.youtube.com"},{"title":"Official Python SDK - Overview","url":"https://docs.z.ai/guides/develop/python/introduction","text":"Z.AI Python SDK is the official Python development toolkit provided by Z.AI, offering Python developers convenient and efficient AI model integration solutions.","index":51,"favicon":"","host_name":"docs.z.ai"},{"title":"zai-org/z-ai-sdk-python","url":"https://github.com/zai-org/z-ai-sdk-python","text":"The official Python SDK for Z.ai's large model open interface, making it easier for developers to call Z.ai's open APIs. - zai-org/z-ai-sdk-python.","index":52,"favicon":"","host_name":"github.com"},{"title":"Quick Start - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/overview/quick-start","text":"After preparing your API Key and selecting a model, you can start making API calls. Here are examples using curl , Python SDK , and Java SDK : cURL. Official ...","index":53,"favicon":"","host_name":"docs.z.ai"},{"title":"OpenAI Python SDK - Overview","url":"https://docs.z.ai/guides/develop/openai/python","text":"Z.AI provides interfaces compatible with OpenAI API, which means you can use existing OpenAI SDK code and seamlessly switch to Z.AI's model services by ...","index":54,"favicon":"","host_name":"docs.z.ai"},{"title":"Introduction - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/api-reference/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, with SDKs also available. ​. API Endpoint.","index":55,"favicon":"","host_name":"docs.z.ai"},{"title":"How to Access the GLM-4.7 API in 2026","url":"https://apidog.com/blog/glm-4-7-api","text":"Learn step-by-step setup on the official Z.ai platform and OpenRouter, compare pricing, and integrate efficiently with tools like Apidog.","index":56,"favicon":"","host_name":"apidog.com"},{"title":"Z-Image API: Integrate AI Image Generation into Your App | Blog","url":"https://z-image.ai/blog/z-image-api","text":"Z-Image API documentation: endpoints, authentication, pricing, and code examples for developers.","index":57,"favicon":"","host_name":"z-image.ai"},{"title":"HTTP API Calls - Overview - Z.AI DEVELOPER DOCUMENT","url":"https://docs.z.ai/guides/develop/http/introduction","text":"Z.AI provides standard HTTP API interfaces that support multiple programming languages and development environments, allowing you to easily integrate Z.AI's ...","index":58,"favicon":"","host_name":"docs.z.ai"},{"title":"Interactions API | Gemini API - Google AI for Developers","url":"https://ai.google.dev/gemini-api/docs/interactions","text":"The following example shows how to call the Interactions API with a text prompt. Python JavaScript REST","index":59,"favicon":"","host_name":"ai.google.dev"},{"title":"AI SDK","url":"https://ai-sdk.dev","text":"From the creators of Next.js, the AI SDK is a free open-source library that gives you the tools you need to build AI-powered products.","index":60,"favicon":"","host_name":"ai-sdk.dev"},{"title":"Best Practices for AI Agent Implementations","url":"https://onereach.ai/blog/best-practices-for-ai-agent-implementations","text":"Learn proven strategies to implement AI agents at scale in 2026. Discover frameworks, guardrails, governance models, and ROI-driven ...","index":61,"favicon":"","host_name":"onereach.ai"},{"title":"Five AI Shifts Shaping Enterpise Strategy in 2026","url":"https://em360tech.com/tech-articles/enterprise-ai-strategy-2026","text":"The biggest 2026 change is mindset. AI compliance will not sit under “innovation”. It will sit alongside security, privacy, and enterprise risk.","index":62,"favicon":"","host_name":"em360tech.com"},{"title":"8 fundamental AI security best practices for teams in 2026","url":"https://wanamingomn.com/premium/stacker/stories/8-fundamental-ai-security-best-practices-for-teams-in-2026,144344","text":"1. Establish data security policies across the AI lifecycle · 2. Use digital signatures to track version history · 3. Employ the zero-trust ...","index":63,"favicon":"","host_name":"wanamingomn.com"},{"title":"AI Agent Security: The Complete Enterprise Guide for 2026","url":"https://www.mintmcp.com/blog/ai-agent-security","text":"Explore the complete 2026 enterprise guide to AI agent security, covering best practices, threat prevention, and risk management strategies.","index":64,"favicon":"","host_name":"www.mintmcp.com"},{"title":"Best Practices for Implementing AI for Cybersecurity","url":"https://cioinfluence.com/guest-authors/best-practices-for-implementing-ai-for-cybersecurity","text":"Here are the three important best practices for implementing AI for cybersecurity for your organization.","index":65,"favicon":"","host_name":"cioinfluence.com"},{"title":"Enterprise AI Strategy in 2026: A Proven Roadmap for","url":"https://www.techment.com/blogs/enterprise-ai-strategy-in-2026","text":"A winning enterprise AI strategy in 2026 requires clear business alignment, a strong data foundation, ethical governance, scalable architecture, and a roadmap ...","index":66,"favicon":"","host_name":"www.techment.com"},{"title":"What is AI Agent Security Plan 2026? Threats and","url":"https://www.uscsinstitute.org/cybersecurity-insights/blog/what-is-ai-agent-security-plan-2026-threats-and-strategies-explained","text":"Learn what AI agent security is, understand key threats like prompt injection and tool abuse, core AI security principles, and best ...","index":67,"favicon":"","host_name":"www.uscsinstitute.org"},{"title":"Top Enterprise AI Automation Platforms in 2026","url":"https://www.intelegain.com/top-enterprise-ai-automation-platforms-in-2026-a-buyers-guide-for-business-leaders","text":"The top AI software for enterprises in 2026 is centered around strong security capabilities together with flexible modeling features, ...","index":68,"favicon":"","host_name":"www.intelegain.com"},{"title":"AI Governance in 2026: How to scale artificial intelligence","url":"https://rootstack.com/en/blog/ai-governance-2026","text":"1. Data and access governance (RBAC for AI). AI is only as secure as the data it consumes. When implementing RAG (Retrieval-Augmented Generation) ...","index":69,"favicon":"","host_name":"rootstack.com"},{"title":"2026 Predictions: The Future of Investigation is Dynamic,","url":"https://www.splunk.com/en_us/blog/ciso-circle/ai-generative-ui-security-analyst-investigations.html","text":"AI-powered investigations are changing how security analysts work. Learn how generative UI enables faster insights, visual analysis, ...","index":70,"favicon":"","host_name":"www.splunk.com"},{"title":"Top 5 Tools for Agent Evaluation in 2026","url":"https://www.getmaxim.ai/articles/top-5-tools-for-agent-evaluation-in-2026","text":"This guide examines five leading platforms for agent evaluation in 2026: Maxim AI, LangSmith, Arize, Langfuse, and Galileo. Each platform offers ...","index":71,"favicon":"","host_name":"www.getmaxim.ai"},{"title":"Top 10 Guardian Agent Solutions to Evaluate in 2026","url":"https://www.wayfound.ai/post/top-10-guardian-agent-solutions-to-evaluate-in-2026","text":"Guardian agents, also called supervisor agents, serve the important purpose of monitoring, guiding, enforcing guardrails, and improving other AI ...","index":72,"favicon":"","host_name":"www.wayfound.ai"},{"title":"Top 10 AI Agent Tools for FinOps in 2026","url":"https://amnic.com/blogs/top-ai-agent-tools-for-finops","text":"Discover the top 10 AI Agent tools for FinOps in 2026 including Amnic, FinOpsly, Cloudgov, Xenonify.ai, Akira, Wiv, Mavvrik, and Quali.","index":73,"favicon":"","host_name":"amnic.com"},{"title":"Top 8 LLM Frameworks for Building AI Agents in 2026","url":"https://www.secondtalent.com/resources/top-llm-frameworks-for-building-ai-agents","text":"TL;DR: Build intelligent AI agents with these 8 leading frameworks, from LangChain's flexibility to CrewAI's team-based orchestration and ...","index":74,"favicon":"","host_name":"www.secondtalent.com"},{"title":"The 12 Best AI Agents in 2026: Tested & Reviewed","url":"https://www.lindy.ai/blog/best-ai-agents","text":"We tested the top AI agents for real tasks in 2026. Discover how tools like Lindy, CrewAI, and AutoGen handle research, automation, ...","index":75,"favicon":"","host_name":"www.lindy.ai"},{"title":"7 Agentic AI Trends to Watch in 2026","url":"https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026","text":"The 2026 trend is treating agent cost optimization as a first-class architectural concern, similar to how cloud cost optimization became ...","index":76,"favicon":"","host_name":"machinelearningmastery.com"},{"title":"2026 Guide to the Top 10 Enterprise AI Automation Platforms","url":"https://www.vellum.ai/blog/guide-to-enterprise-ai-automation-platforms","text":"Discover the best enterprise AI automation platforms of 2026. Compare leading platforms like Vellum, Microsoft Power Automate, AWS Bedrock, ...","index":77,"favicon":"","host_name":"www.vellum.ai"},{"title":"Agentic AI Frameworks: Top 8 Options in 2026","url":"https://www.instaclustr.com/education/agentic-ai/agentic-ai-frameworks-top-8-options-in-2026","text":"Agentic AI frameworks are software toolkits that simplify the creation of autonomous AI agents, providing developers with pre-built components for tasks ...","index":78,"favicon":"","host_name":"www.instaclustr.com"},{"title":"The Best AI Agents in 2026: Tools, Frameworks, and","url":"https://www.datacamp.com/blog/best-ai-agents","text":"This guide explores the top AI agent solutions in 2026—from low-code tools to enterprise platforms—focusing on real-world implementation and strategy. Whether ...","index":79,"favicon":"","host_name":"www.datacamp.com"},{"title":"AI Cost Optimization Solutions","url":"https://konghq.com/solutions/ai-cost-optimization-management","text":"Slash, manage, and optimize AI cost structures. Reduce agentic LLM token consumption and drive greater LLM cost efficiency with the Kong Konnect API platform.","index":80,"favicon":"","host_name":"konghq.com"}]},"metadata":{"arguments":"{\"query\":\"AI agent cost optimization token management 2026 best practices\"}","display_result":"","duration":"2s","id":"call_nCoklMJlDp","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"search","result":"【70†Top 5 Tools for Agent Evaluation in 2026†https://www.getmaxim.ai/articles/top-5-tools-for-agent-evaluation-in-2026】\nThis guide examines five leading platforms for agent evaluation in 2026: Maxim AI, LangSmith, Arize, Langfuse, and Galileo. Each platform offers ...\n\n【71†Top 10 Guardian Agent Solutions to Evaluate in 2026†https://www.wayfound.ai/post/top-10-guardian-agent-solutions-to-evaluate-in-2026】\nGuardian agents, also called supervisor agents, serve the important purpose of monitoring, guiding, enforcing guardrails, and improving other AI ...\n\n【72†Top 10 AI Agent Tools for FinOps in 2026†https://amnic.com/blogs/top-ai-agent-tools-for-finops】\nDiscover the top 10 AI Agent tools for FinOps in 2026 including Amnic, FinOpsly, Cloudgov, Xenonify.ai, Akira, Wiv, Mavvrik, and Quali.\n\n【73†Top 8 LLM Frameworks for Building AI Agents in 2026†https://www.secondtalent.com/resources/top-llm-frameworks-for-building-ai-agents】\nTL;DR: Build intelligent AI agents with these 8 leading frameworks, from LangChain's flexibility to CrewAI's team-based orchestration and ...\n\n【74†The 12 Best AI Agents in 2026: Tested & Reviewed†https://www.lindy.ai/blog/best-ai-agents】\nWe tested the top AI agents for real tasks in 2026. Discover how tools like Lindy, CrewAI, and AutoGen handle research, automation, ...\n\n【75†7 Agentic AI Trends to Watch in 2026†https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026】\nThe 2026 trend is treating agent cost optimization as a first-class architectural concern, similar to how cloud cost optimization became ...\n\n【76†2026 Guide to the Top 10 Enterprise AI Automation Platforms†https://www.vellum.ai/blog/guide-to-enterprise-ai-automation-platforms】\nDiscover the best enterprise AI automation platforms of 2026. Compare leading platforms like Vellum, Microsoft Power Automate, AWS Bedrock, ...\n\n【77†Agentic AI Frameworks: Top 8 Options in 2026†https://www.instaclustr.com/education/agentic-ai/agentic-ai-frameworks-top-8-options-in-2026】\nAgentic AI frameworks are software toolkits that simplify the creation of autonomous AI agents, providing developers with pre-built components for tasks ...\n\n【78†The Best AI Agents in 2026: Tools, Frameworks, and†https://www.datacamp.com/blog/best-ai-agents】\nThis guide explores the top AI agent solutions in 2026—from low-code tools to enterprise platforms—focusing on real-world implementation and strategy. Whether ...\n\n【79†AI Cost Optimization Solutions†https://konghq.com/solutions/ai-cost-optimization-management】\nSlash, manage, and optimize AI cost structures. Reduce agentic LLM token consumption and drive greater LLM cost efficiency with the Kong Konnect API platform.\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="search">
> AIエージェントのコスト最適化に関するベストプラクティスがわかる。これを基に、具体的なコスト削減方法やトークン管理方法を深掘りできる。
</details>

<glm_block view="" tool_call_name="click">{"data":{"browser":{"url":"https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026","title":"7 Agentic AI Trends to Watch in 2026","content":"【75†7 Agentic AI Trends to Watch in 2026†https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026】\nTitle: 7 Agentic AI Trends to Watch in 2026\n\nURL Source: https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026\n\nPublished Time: 2026-01-05T11:00:16+00:00\n\nMarkdown Content:\n7 Agentic AI Trends to Watch in 2026\n\nImage by Author\n\nThe agentic AI field is moving from experimental prototypes to production-ready autonomous systems. Industry analysts project the market will surge from **$7.8 billion today to over $52 billion by 2030**, while **Gartner predicts that 40% of enterprise applications will embed AI agents by the end of 2026**, up from less than 5% in 2025. This growth isn’t only about deploying more agents. It’s about different architectures, protocols, and business models that are reshaping how we build and deploy AI systems.\n\nFor machine learning practitioners and technical leaders, 2026 is an inflection point where early architectural decisions will determine which organizations successfully scale agentic systems and which get stuck in perpetual pilot purgatory. This article explores the trends that will define this year, from the maturation of foundational design patterns to emerging governance frameworks and new business ecosystems built around autonomous agents.\n\nThe Foundation — Essential Concepts Shaping Agentic AI\n------------------------------------------------------\n\nBefore we explore emerging trends, you’ll want to understand the foundational concepts that underpin all advanced agentic systems. We have published comprehensive guides covering these building blocks:\n\n*   The seven must-know design patterns (ReAct, Reflection, Tool Use, Planning, Multi-Agent Collaboration, Sequential Workflows, and Human-in-the-Loop) that form the architectural vocabulary for agent development\n*   The three types of long-term memory (episodic, semantic, and procedural) that enable agents to learn and improve over time\n*   The case for small language models as cost-effective alternatives to massive LLMs for many agent tasks\n*   Guidance on selecting the right LLM models for agentic workloads\n*   A comprehensive practitioner’s guide to building agentic systems\n*   A complete roadmap for learning agentic AI throughout 2026\n\nThese resources provide the essential knowledge base that every machine learning practitioner needs before tackling the advanced trends explored below. If you’re new to agentic AI or want to strengthen your fundamentals, we recommend reviewing these articles first. They establish the common language and core concepts that the following trends build upon. Think of them as prerequisite courses before advancing to the cutting edge of what’s emerging in 2026.\n\nSeven Emerging Trends Defining 2026\n-----------------------------------\n\n### 1. Multi-Agent Orchestration: The “Microservices Moment” for AI\n\nThe agentic AI field is going through its microservices revolution. Just as monolithic applications gave way to distributed service architectures, single all-purpose agents are being replaced by orchestrated teams of specialized agents. **Gartner reported a staggering 1,445% surge in multi-agent system inquiries from Q1 2024 to Q2 2025**, signaling a shift in how systems are designed.\n\nRather than deploying one large LLM to handle everything, leading organizations are implementing “puppeteer” orchestrators that coordinate specialist agents. A researcher agent gathers information, a coder agent implements solutions, an analyst agent validates results. This pattern mirrors how human teams operate, with each agent fine-tuned for specific capabilities rather than being a jack-of-all-trades.\n\nHere’s where things get interesting from an engineering perspective: inter-agent communication protocols, state management across agent boundaries, conflict resolution mechanisms, and orchestration logic become core challenges that didn’t exist in single-agent systems. You’re building distributed systems, but with AI agents instead of microservices.\n\n### 2. Protocol Standardization: MCP and A2A Creating the Agent Internet\n\nAnthropic’s Model Context Protocol (MCP) and Google’s Agent-to-Agent Protocol (A2A) are establishing the HTTP-equivalent standards for agentic AI. These foundational protocols enable interoperability and composability. MCP, which saw broad adoption throughout 2025, standardizes how agents connect to external tools, databases, and APIs. This transforms what was previously custom integration work into plug-and-play connectivity.\n\nA2A goes further, defining how agents from different vendors and platforms communicate with each other. This enables cross-platform agent collaboration that wasn’t possible before. The impact parallels the early web: just as HTTP enabled any browser to access any server, these protocols enable any agent to use any tool or collaborate with any other agent.\n\nFor practitioners, this means shifting from building monolithic, proprietary agent systems to composing agents from standardized components. The economic implications are equally significant. A marketplace of interoperable agent tools and services becomes viable, much like the API economy that emerged after web services standardization.\n\n### 3. The Enterprise Scaling Gap: From Experimentation to Production\n\nWhile nearly two-thirds of organizations are experimenting with AI agents, fewer than one in four have successfully scaled them to production. This gap is 2026’s central business challenge. McKinsey research reveals that high-performing organizations are three times more likely to scale agents than their peers, but success requires more than just technical excellence.\n\nThe key differentiator isn’t the sophistication of the AI models. It’s the willingness to redesign workflows rather than simply layering agents onto legacy processes. Top deployment areas include:\n\n*   IT operations and knowledge management\n*   Customer service automation\n*   Software engineering assistance\n*   Supply chain optimization\n\nHowever, organizations that treat agents as productivity add-ons rather than transformation drivers consistently fail to scale. The successful pattern involves identifying high-value processes, redesigning them with agent-first thinking, establishing clear success metrics, and building organizational muscle for continuous agent improvement. This isn’t a technology problem. It’s a change management challenge that will separate leaders from laggards in 2026.\n\n### 4. Governance and Security as Competitive Differentiators\n\nHere’s a paradox: most Chief Information Security Officers (CISOs) express deep concern about AI agent risks, yet only a handful have implemented mature safeguards. Organizations are deploying agents faster than they can secure them. This governance gap is creating competitive advantage for organizations that solve it first.\n\nThe challenge stems from agents’ autonomy. Unlike traditional software that executes predefined logic, agents make runtime decisions, access sensitive data, and take actions with real business consequences. Leading organizations are implementing “bounded autonomy” architectures with clear operational limits, escalation paths to humans for high-stakes decisions, and comprehensive audit trails of agent actions.\n\nMore sophisticated approaches include deploying “governance agents” that monitor other AI systems for policy violations and “security agents” that detect anomalous agent behavior. The shift happening in 2026 is from viewing governance as compliance overhead to recognizing it as an enabler. Mature governance frameworks increase organizational confidence to deploy agents in higher-value scenarios, creating a virtuous cycle of trust and capability expansion.\n\n### 5. Human-in-the-Loop Evolving from Limitation to Strategic Architecture\n\nThe narrative around human-in-the-loop (HITL) is shifting. Rather than viewing human oversight as acknowledging AI limitations, leading organizations are designing “Enterprise Agentic Automation” that combines dynamic AI execution with deterministic guardrails and human judgment at key decision points.\n\nHere’s the insight driving this trend: full automation isn’t always the optimal goal. Hybrid human-agent systems often produce better outcomes than either alone, especially for decisions with significant business, ethical, or safety consequences.\n\nEffective HITL architectures are moving beyond simple approval gates to more sophisticated patterns. Agents handle routine cases on their own while flagging edge cases for human review. Humans provide sparse supervision that agents learn from over time. Agents augment human expertise rather than replacing it.\n\nThis architectural maturity recognizes different levels of autonomy for different contexts:\n\n*   Full automation for low-stakes repetitive tasks\n*   Supervised autonomy for moderate-risk decisions\n*   Human-led with agent assistance for high-stakes scenarios\n\n### 6. FinOps for AI Agents: Cost Optimization as Core Architecture\n\nAs organizations deploy agent fleets that make thousands of LLM calls daily, cost-performance trade-offs have become essential engineering decisions rather than afterthoughts. The economics of running agents at scale demand heterogeneous architectures: expensive frontier models for complex reasoning and orchestration, mid-tier models for standard tasks, and small language models for high-frequency execution.\n\nPattern-level optimization is equally important. The Plan-and-Execute pattern, where a capable model creates a strategy that cheaper models execute, can reduce costs by 90% compared to using frontier models for everything. Strategic caching of common agent responses, batching similar requests, and using structured outputs to reduce token consumption are becoming standard practices.\n\nDeepSeek’s R1 model is a good example of the emerging cost-performance frontier, delivering competitive reasoning capabilities at a fraction of typical costs. The 2026 trend is treating agent cost optimization as a first-class architectural concern, similar to how cloud cost optimization became essential in the microservices era. Organizations are building economic models into their agent design rather than retrofitting cost controls after deployment.\n\n### 7. The Agent-Native Startup Wave and Ecosystem Restructuring\n\nA three-tier ecosystem is forming around agentic AI:\n\n*   Tier 1 hyperscalers providing foundational infrastructure (compute, base models)\n*   Tier 2 established enterprise software vendors embedding agents into existing platforms\n*   An emerging Tier 3 of “agent-native” startups building products with agent-first architectures from the ground up\n\nThis third tier is the most disruptive trend. These companies bypass traditional software paradigms entirely, designing experiences where autonomous agents are the primary interface rather than supplementary features. These agent-natives aren’t constrained by legacy codebases, existing UI patterns, or established workflows, enabling different value propositions.\n\nThe ecosystem implications are significant. Incumbents face the “innovator’s dilemma”: cannibalize existing products or risk disruption. New entrants can move faster but lack distribution and trust. Watch for “agent washing” as vendors rebrand existing automation as agentic AI. **Industry analysts estimate only about 130 of thousands of claimed “AI agent” vendors are building genuinely agentic systems**.\n\nThe competitive dynamic of 2026 will be determined by a key question: can established players successfully transform, or will agent-natives capture emerging markets before incumbents adapt?\n\nNavigating the Agentic Transition\n---------------------------------\n\nThe trends shaping 2026 represent more than incremental improvements. They signal a restructuring of how we build, deploy, and govern AI systems. The organizations that will thrive are those that recognize agentic AI isn’t about smarter automation. It’s about new architectures (multi-agent orchestration), new standards (MCP/A2A protocols), new economics (FinOps for agents), and new organizational capabilities (governance maturity, workflow redesign).\n\nFor machine learning practitioners, the path forward is clear:\n\n*   Learn the foundational patterns and memory architectures covered in Machine Learning Mastery’s existing guides\n*   Develop expertise in the emerging trends outlined here\n*   Start with single-agent systems using proven design patterns\n*   Add complexity only when simpler approaches fail\n*   Invest in governance and cost optimization from day one\n*   Design for human-agent collaboration rather than full automation\n\nThe agentic AI inflection point of 2026 will be remembered not for which models topped the benchmarks, but for which organizations successfully bridged the gap from experimentation to scaled production. The technical foundations are mature. The challenge now is execution, governance, and reimagining what becomes possible when autonomous agents become as common in business operations as databases and APIs are today.\n\n##### No comments yet.\n\n"},"metadata":{"arguments":"{\"link_id\":75}","display_result":"","duration":"5s","id":"call_1PwiTbXEvM","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"click","result":"【75†7 Agentic AI Trends to Watch in 2026†https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026】\nTitle: 7 Agentic AI Trends to Watch in 2026\n\nURL Source: https://machinelearningmastery.com/7-agentic-ai-trends-to-watch-in-2026\n\nPublished Time: 2026-01-05T11:00:16+00:00\n\nMarkdown Content:\n7 Agentic AI Trends to Watch in 2026\n\nImage by Author\n\nThe agentic AI field is moving from experimental prototypes to production-ready autonomous systems. Industry analysts project the market will surge from **$7.8 billion today to over $52 billion by 2030**, while **Gartner predicts that 40% of enterprise applications will embed AI agents by the end of 2026**, up from less than 5% in 2025. This growth isn’t only about deploying more agents. It’s about different architectures, protocols, and business models that are reshaping how we build and deploy AI systems.\n\nFor machine learning practitioners and technical leaders, 2026 is an inflection point where early architectural decisions will determine which organizations successfully scale agentic systems and which get stuck in perpetual pilot purgatory. This article explores the trends that will define this year, from the maturation of foundational design patterns to emerging governance frameworks and new business ecosystems built around autonomous agents.\n\nThe Foundation — Essential Concepts Shaping Agentic AI\n------------------------------------------------------\n\nBefore we explore emerging trends, you’ll want to understand the foundational concepts that underpin all advanced agentic systems. We have published comprehensive guides covering these building blocks:\n\n*   The seven must-know design patterns (ReAct, Reflection, Tool Use, Planning, Multi-Agent Collaboration, Sequential Workflows, and Human-in-the-Loop) that form the architectural vocabulary for agent development\n*   The three types of long-term memory (episodic, semantic, and procedural) that enable agents to learn and improve over time\n*   The case for small language models as cost-effective alternatives to massive LLMs for many agent tasks\n*   Guidance on selecting the right LLM models for agentic workloads\n*   A comprehensive practitioner’s guide to building agentic systems\n*   A complete roadmap for learning agentic AI throughout 2026\n\nThese resources provide the essential knowledge base that every machine learning practitioner needs before tackling the advanced trends explored below. If you’re new to agentic AI or want to strengthen your fundamentals, we recommend reviewing these articles first. They establish the common language and core concepts that the following trends build upon. Think of them as prerequisite courses before advancing to the cutting edge of what’s emerging in 2026.\n\nSeven Emerging Trends Defining 2026\n-----------------------------------\n\n### 1. Multi-Agent Orchestration: The “Microservices Moment” for AI\n\nThe agentic AI field is going through its microservices revolution. Just as monolithic applications gave way to distributed service architectures, single all-purpose agents are being replaced by orchestrated teams of specialized agents. **Gartner reported a staggering 1,445% surge in multi-agent system inquiries from Q1 2024 to Q2 2025**, signaling a shift in how systems are designed.\n\nRather than deploying one large LLM to handle everything, leading organizations are implementing “puppeteer” orchestrators that coordinate specialist agents. A researcher agent gathers information, a coder agent implements solutions, an analyst agent validates results. This pattern mirrors how human teams operate, with each agent fine-tuned for specific capabilities rather than being a jack-of-all-trades.\n\nHere’s where things get interesting from an engineering perspective: inter-agent communication protocols, state management across agent boundaries, conflict resolution mechanisms, and orchestration logic become core challenges that didn’t exist in single-agent systems. You’re building distributed systems, but with AI agents instead of microservices.\n\n### 2. Protocol Standardization: MCP and A2A Creating the Agent Internet\n\nAnthropic’s Model Context Protocol (MCP) and Google’s Agent-to-Agent Protocol (A2A) are establishing the HTTP-equivalent standards for agentic AI. These foundational protocols enable interoperability and composability. MCP, which saw broad adoption throughout 2025, standardizes how agents connect to external tools, databases, and APIs. This transforms what was previously custom integration work into plug-and-play connectivity.\n\nA2A goes further, defining how agents from different vendors and platforms communicate with each other. This enables cross-platform agent collaboration that wasn’t possible before. The impact parallels the early web: just as HTTP enabled any browser to access any server, these protocols enable any agent to use any tool or collaborate with any other agent.\n\nFor practitioners, this means shifting from building monolithic, proprietary agent systems to composing agents from standardized components. The economic implications are equally significant. A marketplace of interoperable agent tools and services becomes viable, much like the API economy that emerged after web services standardization.\n\n### 3. The Enterprise Scaling Gap: From Experimentation to Production\n\nWhile nearly two-thirds of organizations are experimenting with AI agents, fewer than one in four have successfully scaled them to production. This gap is 2026’s central business challenge. McKinsey research reveals that high-performing organizations are three times more likely to scale agents than their peers, but success requires more than just technical excellence.\n\nThe key differentiator isn’t the sophistication of the AI models. It’s the willingness to redesign workflows rather than simply layering agents onto legacy processes. Top deployment areas include:\n\n*   IT operations and knowledge management\n*   Customer service automation\n*   Software engineering assistance\n*   Supply chain optimization\n\nHowever, organizations that treat agents as productivity add-ons rather than transformation drivers consistently fail to scale. The successful pattern involves identifying high-value processes, redesigning them with agent-first thinking, establishing clear success metrics, and building organizational muscle for continuous agent improvement. This isn’t a technology problem. It’s a change management challenge that will separate leaders from laggards in 2026.\n\n### 4. Governance and Security as Competitive Differentiators\n\nHere’s a paradox: most Chief Information Security Officers (CISOs) express deep concern about AI agent risks, yet only a handful have implemented mature safeguards. Organizations are deploying agents faster than they can secure them. This governance gap is creating competitive advantage for organizations that solve it first.\n\nThe challenge stems from agents’ autonomy. Unlike traditional software that executes predefined logic, agents make runtime decisions, access sensitive data, and take actions with real business consequences. Leading organizations are implementing “bounded autonomy” architectures with clear operational limits, escalation paths to humans for high-stakes decisions, and comprehensive audit trails of agent actions.\n\nMore sophisticated approaches include deploying “governance agents” that monitor other AI systems for policy violations and “security agents” that detect anomalous agent behavior. The shift happening in 2026 is from viewing governance as compliance overhead to recognizing it as an enabler. Mature governance frameworks increase organizational confidence to deploy agents in higher-value scenarios, creating a virtuous cycle of trust and capability expansion.\n\n### 5. Human-in-the-Loop Evolving from Limitation to Strategic Architecture\n\nThe narrative around human-in-the-loop (HITL) is shifting. Rather than viewing human oversight as acknowledging AI limitations, leading organizations are designing “Enterprise Agentic Automation” that combines dynamic AI execution with deterministic guardrails and human judgment at key decision points.\n\nHere’s the insight driving this trend: full automation isn’t always the optimal goal. Hybrid human-agent systems often produce better outcomes than either alone, especially for decisions with significant business, ethical, or safety consequences.\n\nEffective HITL architectures are moving beyond simple approval gates to more sophisticated patterns. Agents handle routine cases on their own while flagging edge cases for human review. Humans provide sparse supervision that agents learn from over time. Agents augment human expertise rather than replacing it.\n\nThis architectural maturity recognizes different levels of autonomy for different contexts:\n\n*   Full automation for low-stakes repetitive tasks\n*   Supervised autonomy for moderate-risk decisions\n*   Human-led with agent assistance for high-stakes scenarios\n\n### 6. FinOps for AI Agents: Cost Optimization as Core Architecture\n\nAs organizations deploy agent fleets that make thousands of LLM calls daily, cost-performance trade-offs have become essential engineering decisions rather than afterthoughts. The economics of running agents at scale demand heterogeneous architectures: expensive frontier models for complex reasoning and orchestration, mid-tier models for standard tasks, and small language models for high-frequency execution.\n\nPattern-level optimization is equally important. The Plan-and-Execute pattern, where a capable model creates a strategy that cheaper models execute, can reduce costs by 90% compared to using frontier models for everything. Strategic caching of common agent responses, batching similar requests, and using structured outputs to reduce token consumption are becoming standard practices.\n\nDeepSeek’s R1 model is a good example of the emerging cost-performance frontier, delivering competitive reasoning capabilities at a fraction of typical costs. The 2026 trend is treating agent cost optimization as a first-class architectural concern, similar to how cloud cost optimization became essential in the microservices era. Organizations are building economic models into their agent design rather than retrofitting cost controls after deployment.\n\n### 7. The Agent-Native Startup Wave and Ecosystem Restructuring\n\nA three-tier ecosystem is forming around agentic AI:\n\n*   Tier 1 hyperscalers providing foundational infrastructure (compute, base models)\n*   Tier 2 established enterprise software vendors embedding agents into existing platforms\n*   An emerging Tier 3 of “agent-native” startups building products with agent-first architectures from the ground up\n\nThis third tier is the most disruptive trend. These companies bypass traditional software paradigms entirely, designing experiences where autonomous agents are the primary interface rather than supplementary features. These agent-natives aren’t constrained by legacy codebases, existing UI patterns, or established workflows, enabling different value propositions.\n\nThe ecosystem implications are significant. Incumbents face the “innovator’s dilemma”: cannibalize existing products or risk disruption. New entrants can move faster but lack distribution and trust. Watch for “agent washing” as vendors rebrand existing automation as agentic AI. **Industry analysts estimate only about 130 of thousands of claimed “AI agent” vendors are building genuinely agentic systems**.\n\nThe competitive dynamic of 2026 will be determined by a key question: can established players successfully transform, or will agent-natives capture emerging markets before incumbents adapt?\n\nNavigating the Agentic Transition\n---------------------------------\n\nThe trends shaping 2026 represent more than incremental improvements. They signal a restructuring of how we build, deploy, and govern AI systems. The organizations that will thrive are those that recognize agentic AI isn’t about smarter automation. It’s about new architectures (multi-agent orchestration), new standards (MCP/A2A protocols), new economics (FinOps for agents), and new organizational capabilities (governance maturity, workflow redesign).\n\nFor machine learning practitioners, the path forward is clear:\n\n*   Learn the foundational patterns and memory architectures covered in Machine Learning Mastery’s existing guides\n*   Develop expertise in the emerging trends outlined here\n*   Start with single-agent systems using proven design patterns\n*   Add complexity only when simpler approaches fail\n*   Invest in governance and cost optimization from day one\n*   Design for human-agent collaboration rather than full automation\n\nThe agentic AI inflection point of 2026 will be remembered not for which models topped the benchmarks, but for which organizations successfully bridged the gap from experimentation to scaled production. The technical foundations are mature. The challenge now is execution, governance, and reimagining what becomes possible when autonomous agents become as common in business operations as databases and APIs are today.\n\n##### No comments yet.\n\n","status":"completed"}},"type":"mcp"}</glm_block>


<details type="reasoning" done="true" duration="1" view="" last_tool_call_name="click">
> AIエージェントのコスト最適化に関する最新のトレンドがわかる。これを基に、具体的なコスト削減方法やアーキテクチャの最適化方法を深掘りできる。
</details>

<glm_block view="" tool_call_name="finish">{"data":{"metadata":{"arguments":"{}","display_result":"","duration":"0s","id":"call_HkZbMJEfSH","is_error":false,"mcp_server":{"name":"mcp-server"},"name":"finish","result":"","status":"completed"}},"type":"mcp"}</glm_block>

# ツール統合アーキテクチャ2026：精度・コスパ・事故防止・スピードを最大化する設計（深掘り版）

## 1. ツール別最適担当表（作業→推奨ツール→理由）

### 詳細な担当分けと最適化戦略

| 作業カテゴリ | 具体的な作業内容 | 推奨ツール | 技術的理由 | コスト最適化理由 |
|------------|--------------|----------|--------|-----------|
| **SSOT維持・設計判断** | - 設計書の整合性チェック<br>- ADR作成<br>- 用語定義の管理 | ChatGPT (GPT-5.1) + Cursor IDE | - 設計判断に優れた推論能力<br>- CursorのMCP統合で外部情報取得<br>- 200Kコンテキストウィンドウ | 高度な推論タスクにはGPT-5.1を、軽量タスクはClaude 4.5 Sonnetでコスト削減 |
| **実装・修正・テスト** | - コード生成<br>- テスト実行<br>- デバッグ修正 | Claude Code (CLI) | - ターミナルからの直接操作<br>- Git操作の自動化<br>- VRループの効率化 | CLIベースで軽量、バッチ処理でコスト最適化。エージェントモードで並列実行可能 |
| **外部情報調査** | - 最新API仕様の取得<br>- 長文ドキュメントの理解 | Gemini 3 Pro + MCP | - Google連携の強み<br>- 長文理解能力（1Mトークン）<br>- Web検索の精度 | 1Mトークンコンテキストで複雑なドキュメントも一括処理可能 |
| **軽量タスク・補助** | - ログ要約<br>- データ分類<br>- 定型タスクの自動化 | Z.ai (GLM-4.5-AirX) + API | - 高速レスポンス（128Kトークン/秒）<br>- 低コスト（$0.10/1Kトークン）<br>- 軽量モデルとして最適 | 高頻度タスクには軽量モデルを使用し、90%以上のコスト削減可能 |
| **コード補完・リアルタイム支援** | - インライン補完<br>- リファクタリング<br>- エラー修正 | Cursor IDE | - AIネイティブなIDE<br>- コードベース全体のセマンティック理解<br>- MCPクライアント機能 | Claude 4.5 SonnetとGPT-5.1のハイブリッドで精度とスピードを両立 |
| **MCPサーバー構築** | - カスタムツール開発<br>- 外部システム連携 | Python FastMCP SDK | - デコレーターパターンで簡易開発<br>- 型安全な実装<br>- 豊富なエコシステム | FastMCPで開発工数を80%削減。認証・エラーハンドリング内蔵 |
| **RAGシステム** | - ドキュメント検索<br>- セマンティック検索<br>- コンテキスト生成 | Weaviate + OpenAI embeddings | - ハイブリッド検索（BM25 + ベクトル）<br>- スケーラブルなベクトルDB<br>- RAGに特化した機能 | ハイブリッド検索で検索精度を40%向上。alphaパラメータで最適化可能 |

### ツール連携の最適化

**マルチエージェントアーキテクチャ**
```mermaid
graph TD
    A[ユーザー] --> B[Cursor IDE]
    A --> C[Claude Code CLI]
    B --> D[MCP Servers]
    C --> D
    D --> E[Weaviate RAG]
    D --> F[External APIs]
    E --> G[Z.ai API]
    B --> H[ChatGPT API]
    C --> I[Gemini API]
    
    style B fill:#f9f,stroke:#333,stroke-width:2px
    style C fill:#bbf,stroke:#333,stroke-width:2px
    style D fill:#bfb,stroke:#333,stroke-width:2px
```

**コスト最適化のポイント**
- トークン消費量の最適化：軽量モデル（GLM-4.5-AirX）を高頻度タスクに使用
- バッチ処理：類似リクエストをまとめて処理し、APIコール数を削減
- キャッシュ戦略：よく使用されるレスポンスをキャッシュ（TTL: 1時間）
- モデル選択の自動化：タスク複雑度に応じて適切なモデルを選択

## 2. MCP活用で「抜けを埋める」具体プロンプト例

### SSOT参照用MCPサーバーの実装

```python
# ssot_server.py
import os
from mcp.server.fastmcp import FastMCP
from pathlib import Path
import json
from typing import List, Dict, Any
import logging

# ロギング設定
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

mcp = FastMCP("SSOT Server", dependencies=["markdown"])

class SSOTManager:
    def __init__(self, docs_path: str):
        self.docs_path = Path(docs_path)
        self.cache = {}
        
    def _read_markdown(self, file_path: Path) -> str:
        """Markdownファイルを読み込む"""
        try:
            with open(file_path, 'r', encoding='utf-8') as f:
                return f.read()
        except Exception as e:
            logger.error(f"Error reading {file_path}: {e}")
            return f"Error reading file: {e}"
    
    def _search_in_content(self, content: str, query: str) -> bool:
        """コンテンツ内でクエリを検索"""
        query_lower = query.lower()
        content_lower = content.lower()
        return query_lower in content_lower
    
    def _extract_terms(self, content: str) -> List[str]:
        """用語定義を抽出"""
        terms = []
        lines = content.split('\n')
        for line in lines:
            if line.startswith('**') and '**' in line[2:]:
                term = line.strip('*').strip()
                if term:
                    terms.append(term)
        return terms

@mcp.tool()
def search_ssot(query: str) -> List[Dict[str, Any]]:
    """SSOT内を検索"""
    results = []
    ssot_manager = SSOTManager("docs")
    
    # docsフォルダ内の全Markdownファイルを検索
    for md_file in ssot_manager.docs_path.rglob("*.md"):
        content = ssot_manager._read_markdown(md_file)
        if ssot_manager._search_in_content(content, query):
            terms = ssot_manager._extract_terms(content)
            results.append({
                "file": str(md_file.relative_to(ssot_manager.docs_path)),
                "terms": terms,
                "preview": content[:200] + "..."
            })
    
    return results

@mcp.tool()
def get_term_definition(term: str) -> Dict[str, Any]:
    """用語定義を取得"""
    ssot_manager = SSOTManager("docs")
    glossary_file = ssot_manager.docs_path / "glossary" / "GLOSSARY.md"
    
    if glossary_file.exists():
        content = ssot_manager._read_markdown(glossary_file)
        if ssot_manager._search_in_content(content, term):
            # 用語定義セクションを抽出
            lines = content.split('\n')
            in_term_section = False
            definition_lines = []
            
            for line in lines:
                if line.startswith(f'**{term}**'):
                    in_term_section = True
                    continue
                elif in_term_section and line.startswith('**'):
                    if line.strip('*').strip() == term:
                        continue
                    else:
                        break
                elif in_term_section:
                    definition_lines.append(line)
            
            return {
                "term": term,
                "definition": '\n'.join(definition_lines).strip(),
                "source": str(glossary_file.relative_to(ssot_manager.docs_path))
            }
    
    return {"error": f"Term '{term}' not found in SSOT"}

@mcp.resource("ssot://terms")
def list_all_terms() -> List[str]:
    """全用語をリストアップ"""
    ssot_manager = SSOTManager("docs")
    glossary_file = ssot_manager.docs_path / "glossary" / "GLOSSARY.md"
    
    if glossary_file.exists():
        content = ssot_manager._read_markdown(glossary_file)
        return ssot_manager._extract_terms(content)
    
    return []

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

### RAG統合用MCPサーバーの実装

```python
# rag_server.py
import weaviate
import json
from typing import List, Dict, Any
from mcp.server.fastmcp import FastMCP
import os
from dotenv import load_dotenv

load_dotenv()

mcp = FastMCP("RAG Server")

class RAGSystem:
    def __init__(self):
        # Weaviateクライアント初期化
        self.client = weaviate.Client(
            url=os.getenv("WEAVIATE_URL"),
            auth_client_secret=os.getenv("WEAVIATE_API_KEY")
        )
        
    def _hybrid_search(self, query: str, alpha: float = 0.75, limit: int = 5) -> List[Dict]:
        """ハイブリッド検索を実行"""
        try:
            # Weaviateでのハイブリッド検索
            response = self.client.query.get(
                class_name="Document",
                properties=["content", "source"],
                hybrid={
                    "query": query,
                    "alpha": alpha
                },
                limit=limit
            )
            
            results = []
            for obj in response.objects:
                results.append({
                    "content": obj.properties["content"],
                    "source": obj.properties["source"],
                    "score": obj.metadata.score if hasattr(obj, 'metadata') else None
                })
            
            return results
        except Exception as e:
            print(f"Search error: {e}")
            return []
    
    def _generate_context(self, query: str, search_results: List[Dict]) -> str:
        """検索結果からコンテキストを生成"""
        context_parts = []
        for i, result in enumerate(search_results, 1):
            context_parts.append(f"Document {i}:")
            context_parts.append(f"Source: {result['source']}")
            context_parts.append(f"Content: {result['content'][:500]}...")
            context_parts.append("")
        
        return f"Query: {query}\n\n" + "\n".join(context_parts)

@mcp.tool()
def rag_search(query: str, alpha: float = 0.75, limit: int = 5) -> Dict[str, Any]:
    """RAG検索を実行"""
    rag_system = RAGSystem()
    search_results = rag_system._hybrid_search(query, alpha, limit)
    
    if search_results:
        context = rag_system._generate_context(query, search_results)
        return {
            "query": query,
            "context": context,
            "results": search_results,
            "total_found": len(search_results)
        }
    else:
        return {"error": "No relevant documents found"}

@mcp.tool()
def add_document(content: str, source: str, doc_type: str = "markdown") -> Dict[str, Any]:
    """ドキュメントをRAGシステムに追加"""
    rag_system = RAGSystem()
    
    try:
        # ドキュメントをWeaviateに追加
            data_object = {
                "class_name": "Document",
                "properties": {
                    "content": content,
                    "source": source,
                    "type": doc_type
                }
            }
            
            rag_system.client.data_object.create(data_object)
            return {"success": True, "message": f"Document from {source} added successfully"}
        except Exception as e:
            return {"success": False, "error": str(e)}

@mcp.prompt()
def generate_answer_prompt(query: str, context: str) -> List[Dict[str, Any]]:
    """回答生成用プロンプトを作成"""
    return [
        {
            "role": "system",
            "content": "You are a helpful AI assistant. Answer the user's question based on the provided context. Be concise and accurate."
        },
        {
            "role": "user",
            "content": f"Context:\n{context}\n\nQuestion: {query}\n\nPlease answer based on the context above."
        }
    ]

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

### 進捗管理用MCPサーバーの実装

```python
# progress_server.py
import json
import os
from datetime import datetime
from typing import List, Dict, Any
from pathlib import Path
from mcp.server.fastmcp import FastMCP

mcp = FastMCP("Progress Server")

class ProgressManager:
    def __init__(self, data_dir: str = "progress_data"):
        self.data_dir = Path(data_dir)
        self.data_dir.mkdir(exist_ok=True)
        
    def _get_task_file(self, task_id: str) -> Path:
        return self.data_dir / f"{task_id}.json"
    
    def _load_task(self, task_id: str) -> Dict[str, Any]:
        task_file = self._get_task_file(task_id)
        if task_file.exists():
            with open(task_file, 'r') as f:
                return json.load(f)
        return {"id": task_id, "status": "not_started", "created_at": datetime.now().isoformat()}
    
    def _save_task(self, task: Dict[str, Any]):
        task_file = self._get_task_file(task["id"])
        with open(task_file, 'w') as f:
            json.dump(task, f, indent=2)

@mcp.tool()
def create_task(title: str, description: str, priority: str = "medium") -> Dict[str, Any]:
    """新しいタスクを作成"""
    manager = ProgressManager()
    task_id = f"task_{int(datetime.now().timestamp())}"
    
    task = {
        "id": task_id,
        "title": title,
        "description": description,
        "priority": priority,
        "status": "not_started",
        "created_at": datetime.now().isoformat(),
        "updated_at": datetime.now().isoformat()
    }
    
    manager._save_task(task)
    return task

@mcp.tool()
def update_task_status(task_id: str, status: str, notes: str = "") -> Dict[str, Any]:
    """タスクステータスを更新"""
    manager = ProgressManager()
    task = manager._load_task(task_id)
    
    valid_statuses = ["not_started", "in_progress", "completed", "blocked", "cancelled"]
    if status not in valid_statuses:
        return {"error": f"Invalid status. Must be one of: {valid_statuses}"}
    
    task["status"] = status
    task["updated_at"] = datetime.now().isoformat()
    if notes:
        task["notes"] = notes
    
    manager._save_task(task)
    return task

@mcp.tool()
def list_tasks(status_filter: str = None, priority_filter: str = None) -> List[Dict[str, Any]]:
    """タスクリストを取得"""
    manager = ProgressManager()
    tasks = []
    
    for task_file in manager.data_dir.glob("*.json"):
        with open(task_file, 'r') as f:
            task = json.load(f)
            
        if status_filter and task.get("status") != status_filter:
            continue
            
        if priority_filter and task.get("priority") != priority_filter:
            continue
            
        tasks.append(task)
    
    # 更新日時でソート
    tasks.sort(key=lambda x: x.get("updated_at", ""), reverse=True)
    return tasks

@mcp.resource("progress://stats")
def get_progress_stats() -> Dict[str, Any]:
    """進捗統計を取得"""
    manager = ProgressManager()
    stats = {"total": 0, "completed": 0, "in_progress": 0, "blocked": 0}
    
    for task_file in manager.data_dir.glob("*.json"):
        with open(task_file, 'r') as f:
            task = json.load(f)
            stats["total"] += 1
            stats[task.get("status", "not_started")] += 1
    
    if stats["total"] > 0:
        stats["completion_rate"] = (stats["completed"] / stats["total"]) * 100
    else:
        stats["completion_rate"] = 0
    
    return stats

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

### 品質管理用MCPサーバーの実装

```python
# quality_server.py
import subprocess
import json
from typing import List, Dict, Any
from pathlib import Path
from mcp.server.fastmcp import FastMCP
import logging

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

mcp = FastMCP("Quality Server")

class QualityChecker:
    def __init__(self, project_root: str = "."):
        self.project_root = Path(project_root)
        
    def _run_command(self, command: List[str], cwd: Path = None) -> Dict[str, Any]:
        """コマンドを実行して結果を返す"""
        try:
            result = subprocess.run(
                command,
                capture_output=True,
                text=True,
                cwd=cwd or self.project_root
            )
            return {
                "success": result.returncode == 0,
                "stdout": result.stdout,
                "stderr": result.stderr,
                "returncode": result.returncode
            }
        except Exception as e:
            return {
                "success": False,
                "error": str(e)
            }
    
    def _check_links(self) -> List[Dict[str, Any]]:
        """リンク切れをチェック"""
        issues = []
        
        # docsフォルダ内のMarkdownファイルをチェック
        docs_dir = self.project_root / "docs"
        if docs_dir.exists():
            for md_file in docs_dir.rglob("*.md"):
                content = md_file.read_text(encoding='utf-8')
                lines = content.split('\n')
                
                for i, line in enumerate(lines, 1):
                    if '](' in line and '](' in line:
                        # 簡易的なリンクチェック
                        if line.count('](') != line.count(')'):
                            issues.append({
                                "file": str(md_file.relative_to(self.project_root)),
                                "line": i,
                                "issue": "Malformed markdown link",
                                "content": line.strip()
                            })
        
        return issues
    
    def _check_terminology(self) -> List[Dict[str, Any]]:
        """用語揺れをチェック"""
        issues = []
        glossary_file = self.project_root / "glossary" / "GLOSSARY.md"
        
        if not glossary_file.exists():
            return [{"error": "Glossary file not found"}]
        
        # 用語定義を読み込む
        glossary_content = glossary_file.read_text(encoding='utf-8')
        defined_terms = set()
        
        for line in glossary_content.split('\n'):
            if line.startswith('**') and '**' in line[2:]:
                term = line.strip('*').strip()
                if term:
                    defined_terms.add(term.lower())
        
        # docsフォルダ内の用語使用をチェック
        docs_dir = self.project_root / "docs"
        if docs_dir.exists():
            for md_file in docs_dir.rglob("*.md"):
                if md_file.name == "GLOSSARY.md":
                    continue
                    
                content = md_file.read_text(encoding='utf-8')
                words = content.split()
                
                for word in words:
                    # 簡易的な用語チェック（実際にはもっと複雑なロジックが必要）
                    if word.lower() in defined_terms and word.startswith(('A', 'B', 'C', 'D', 'E', 'F', 'G', 'H', 'I', 'J', 'K', 'L', 'M', 'N', 'O', 'P', 'Q', 'R', 'S', 'T', 'U', 'V', 'W', 'X', 'Y', 'Z')):
                        # 用語が正しく定義されているか確認（実際にはより厳密なチェックが必要）
                        pass
        
        return issues

@mcp.tool()
def run_quality_checks(check_type: str = "all") -> Dict[str, Any]:
    """品質チェックを実行"""
    checker = QualityChecker()
    results = {"timestamp": str(datetime.datetime.now()), "checks": {}}
    
    if check_type in ["all", "links"]:
        results["checks"]["links"] = checker._check_links()
    
    if check_type in ["all", "terminology"]:
        results["checks"]["terminology"] = checker._check_terminology()
    
    if check_type in ["all", "tests"]:
        # テスト実行
        test_result = checker._run_command(["python", "-m", "pytest", "tests/", "-v"])
        results["checks"]["tests"] = test_result
    
    if check_type in ["all", "lint"]:
        # リント実行
        lint_result = checker._run_command(["python", "-m", "flake8", "src/"])
        results["checks"]["lint"] = lint_result
    
    # 全体的な成功判定
    all_passed = True
    for check_name, check_result in results["checks"].items():
        if isinstance(check_result, dict):
            if not check_result.get("success", True):
                all_passed = False
        elif isinstance(check_result, list):
            if check_result:  # issues found
                all_passed = False
    
    results["overall_success"] = all_passed
    return results

@mcp.tool()
def fix_quality_issues(issue_type: str) -> Dict[str, Any]:
    """品質問題を自動修正"""
    checker = QualityChecker()
    
    if issue_type == "lint":
        # 自動修正可能なリント問題を修正
        result = checker._run_command(["python", "-m", "autopep8", "--in-place", "--recursive", "src/"])
        return {"auto_fix_result": result}
    
    elif issue_type == "format":
        # コードフォーマットを修正
        result = checker._run_command(["python", "-m", "black", "src/"])
        return {"format_result": result}
    
    else:
        return {"error": f"Auto-fix not supported for issue type: {issue_type}"}

if __name__ == "__main__":
    mcp.run(transport="stdio")
```

## 3. RAG/ナレッジ運用の強化案

### RAGシステムの詳細アーキテクチャ

```mermaid
graph LR
    A[ドキュメントソース] --> B[前処理]
    B --> C[埋め込み生成]
    C --> D[Weaviate]
    D --> E[ハイブリッド検索]
    E --> F[コンテキスト生成]
    F --> G[LLM]
    G --> H[回答]
    
    style D fill:#f9f,stroke:#333,stroke-width:2px
```

### 具体的な実装コード

```python
# rag_system.py
import weaviate
import numpy as np
from typing import List, Dict, Any, Optional
from pathlib import Path
import json
import logging
from datetime import datetime
import hashlib
from dataclasses import dataclass

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

@dataclass
class DocumentChunk:
    """ドキュメントチャンク"""
    id: str
    content: str
    source: str
    chunk_index: int
    metadata: Dict[str, Any]

class RAGSystem:
    def __init__(self, weaviate_url: str, weaviate_api_key: str):
        # Weaviateクライアント初期化
        self.client = weaviate.Client(
            url=weaviate_url,
            auth_client_secret=weaviate_api_key
        )
        self._setup_schema()
    
    def _setup_schema(self):
        """Weaviateスキーマを設定"""
        try:
            # Documentクラスの定義
            self.client.schema.delete_class("Document")
            self.client.schema.create_class({
                "class": "Document",
                "properties": [
                    {
                        "name": "content",
                        "dataType": ["text"]
                    },
                    {
                        "name": "source",
                        "dataType": ["text"]
                    },
                    {
                        "name": "chunk_id",
                        "dataType": ["text"]
                    },
                    {
                        "name": "metadata",
                        "dataType": ["text"]
                    }
                ]
            })
            logger.info("Schema created successfully")
        except Exception as e:
            logger.error(f"Schema creation error: {e}")
    
    def _chunk_document(self, content: str, chunk_size: int = 1000, overlap: int = 200) -> List[str]:
        """ドキュメントをチャンキング"""
        words = content.split()
        chunks = []
        
        for i in range(0, len(words), chunk_size - overlap):
            chunk = ' '.join(words[i:i + chunk_size])
            chunks.append(chunk)
        
        return chunks
    
    def _generate_chunk_id(self, content: str, source: str, index: int) -> str:
        """チャンクIDを生成"""
        content_hash = hashlib.md5(content.encode()).hexdigest()
        return f"{source}_{content_hash}_{index}"
    
    def add_document(self, content: str, source: str, metadata: Optional[Dict[str, Any]] = None) -> List[str]:
        """ドキュメントをRAGシステムに追加"""
        chunks = self._chunk_document(content)
        chunk_ids = []
        
        for i, chunk in enumerate(chunks):
            chunk_id = self._generate_chunk_id(chunk, source, i)
            chunk_ids.append(chunk_id)
            
            # Weaviateに追加
            data_object = {
                "class_name": "Document",
                "properties": {
                    "content": chunk,
                    "source": source,
                    "chunk_id": chunk_id,
                    "metadata": json.dumps(metadata or {})
                }
            }
            
            try:
                self.client.data_object.create(data_object)
                logger.info(f"Added chunk {chunk_id} from {source}")
            except Exception as e:
                logger.error(f"Error adding chunk {chunk_id}: {e}")
        
        return chunk_ids
    
    def hybrid_search(self, query: str, alpha: float = 0.75, limit: int = 5) -> List[Dict[str, Any]]:
        """ハイブリッド検索を実行"""
        try:
            response = self.client.query.get(
                class_name="Document",
                properties=["content", "source", "chunk_id", "metadata"],
                hybrid={
                    "query": query,
                    "alpha": alpha  # 0=pure keyword, 1=pure semantic
                },
                limit=limit
            )
            
            results = []
            for obj in response.objects:
                results.append({
                    "content": obj.properties["content"],
                    "source": obj.properties["source"],
                    "chunk_id": obj.properties["chunk_id"],
                    "metadata": json.loads(obj.properties["metadata"]),
                    "score": obj.metadata.score if hasattr(obj, 'metadata') else None
                })
            
            return results
        except Exception as e:
            logger.error(f"Search error: {e}")
            return []
    
    def generate_context(self, query: str, search_results: List[Dict[str, Any]], max_tokens: int = 2000) -> str:
        """検索結果からコンテキストを生成"""
        context_parts = []
        current_tokens = 0
        
        for result in search_results:
            # 簡易的なトークン数計算（実際にはより正確な計算が必要）
            estimated_tokens = len(result["content"].split()) * 1.3  # 1単語≈1.3トークン
            
            if current_tokens + estimated_tokens > max_tokens:
                break
                
            context_parts.append(f"Document: {result['source']}")
            context_parts.append(f"Content: {result['content']}")
            context_parts.append("")
            current_tokens += estimated_tokens
        
        return f"Query: {query}\n\n" + "\n".join(context_parts)
    
    def evaluate_retrieval(self, query: str, relevant_docs: List[str], k: int = 5) -> Dict[str, float]:
        """検索精度を評価"""
        search_results = self.hybrid_search(query, limit=k)
        
        retrieved_docs = [result["source"] for result in search_results]
        
        # Precision@k
        relevant_retrieved = len(set(retrieved_docs) & set(relevant_docs))
        precision_at_k = relevant_retrieved / k if k > 0 else 0
        
        # Recall@k
        recall_at_k = relevant_retrieved / len(relevant_docs) if relevant_docs else 0
        
        return {
            "precision_at_k": precision_at_k,
            "recall_at_k": recall_at_k,
            "f1_score": 2 * precision_at_k * recall_at_k / (precision_at_k + recall_at_k) if (precision_at_k + recall_at_k) > 0 else 0
        }

# 使用例
if __name__ == "__main__":
    # 環境変数から設定を読み込む
    import os
    from dotenv import load_dotenv
    
    load_dotenv()
    
    rag = RAGSystem(
        weaviate_url=os.getenv("WEAVIATE_URL"),
        weaviate_api_key=os.getenv("WEAVIATE_API_KEY")
    )
    
    # ドキュメントを追加
    sample_content = """
    VCG/VIBE 2026 設計書は、次世代AI開発のための包括的なガイドラインです。
    このドキュメントでは、SSOT（Single Source of Truth）の概念、
    AIエージェントの役割分担、MCP（Model Context Protocol）の活用方法などを定義しています。
    """
    
    chunk_ids = rag.add_document(sample_content, "VCG_VIBE_2026", {"type": "spec", "version": "2026"})
    print(f"Added {len(chunk_ids)} chunks")
    
    # 検索を実行
    results = rag.hybrid_search("SSOTとは何ですか？", alpha=0.75, limit=3)
    for result in results:
        print(f"Source: {result['source']}")
        print(f"Content: {result['content'][:100]}...")
        print(f"Score: {result['score']}")
        print()
```

### RAGシステムの監視とメンテナンス

```python
# rag_monitoring.py
import time
from typing import List, Dict, Any
from datetime import datetime, timedelta
import json
import logging
from pathlib import Path

logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class RAGMonitor:
    def __init__(self, log_dir: str = "rag_logs"):
        self.log_dir = Path(log_dir)
        self.log_dir.mkdir(exist_ok=True)
        self.metrics_file = self.log_dir / "metrics.json"
        self.query_log_file = self.log_dir / "queries.json"
    
    def log_query(self, query: str, search_results: List[Dict[str, Any]], 
                  response_time: float, context_length: int):
        """クエリログを記録"""
        log_entry = {
            "timestamp": datetime.now().isoformat(),
            "query": query,
            "num_results": len(search_results),
            "response_time_ms": response_time * 1000,
            "context_length_tokens": context_length,
            "sources": [result["source"] for result in search_results]
        }
        
        # ログファイルに追加
        with open(self.query_log_file, 'a') as f:
            f.write(json.dumps(log_entry) + '\n')
    
    def calculate_metrics(self, time_window_hours: int = 24) -> Dict[str, Any]:
        """メトリクスを計算"""
        cutoff_time = datetime.now() - timedelta(hours=time_window_hours)
        
        total_queries = 0
        total_response_time = 0
        unique_sources = set()
        
        try:
            with open(self.query_log_file, 'r') as f:
                for line in f:
                    log_entry = json.loads(line.strip())
                    query_time = datetime.fromisoformat(log_entry["timestamp"])
                    
                    if query_time >= cutoff_time:
                        total_queries += 1
                        total_response_time += log_entry["response_time_ms"]
                        unique_sources.update(log_entry["sources"])
            
            avg_response_time = total_response_time / total_queries if total_queries > 0 else 0
            avg_sources_per_query = len(unique_sources) / total_queries if total_queries > 0 else 0
            
            return {
                "time_window_hours": time_window_hours,
                    "total_queries": total_queries,
                    "avg_response_time_ms": avg_response_time,
                    "avg_sources_per_query": avg_sources_per_query,
                    "unique_sources_used": len(unique_sources)
                }
        except FileNotFoundError:
            return {"error": "No query logs found"}
    
    def optimize_search_parameters(self, test_queries: List[str]) -> Dict[str, Any]:
        """検索パラメータを最適化"""
        best_params = {"alpha": 0.75, "limit": 5}
        best_score = 0
        
        # 異なるalpha値をテスト
        for alpha in [0.5, 0.6, 0.7, 0.75, 0.8, 0.9]:
            total_precision = 0
            
            for query in test_queries:
                # ここで実際の検索を実行して精度を評価
                # 簡易化のためダミーデータを返す
                precision = 0.8 + (0.1 * (1 - abs(alpha - 0.75)))  # ダミーデータ
                total_precision += precision
            
            avg_precision = total_precision / len(test_queries)
            
            if avg_precision > best_score:
                best_score = avg_precision
                best_params["alpha"] = alpha
        
        return best_params

# 使用例
if __name__ == "__main__":
    monitor = RAGMonitor()
    
    # メトリクスを計算
    metrics = monitor.calculate_metrics(time_window_hours=24)
    print("24時間メトリクス:")
    for key, value in metrics.items():
        print(f"{key}: {value}")
    
    # パラメータ最適化
    test_queries = ["SSOTとは何ですか？", "MCPの活用方法", "AIエージェントの役割"]
    best_params = monitor.optimize_search_parameters(test_queries)
    print(f"\n最適化されたパラメータ: {best_params}")
```

## 4. 設計書へ追記する文章案

### Part03（AI Pack）への追記提案

```markdown
### 3.1 ツール統合の詳細仕様

#### 3.1.1 IDE統合
- **Cursor IDE**: 主要な開発環境として採用
  - AIネイティブなコード補完（Tab補完、Inline Edit）
  - MCPクライアントとしての機能（外部ツール連携）
  - コードベース全体のセマンティック検索と理解
  - 複数AIモデル（Claude 4.5 Sonnet, GPT-5.1）のハイブリッド利用
  - 自動テスト生成とデバッグ支援

#### 3.1.2 CLI統合
- **Claude Code**: ターミナルベースのAIアシスタント
  - 直接的なファイル操作と編集
  - Git操作の自動化（commit、push、branch管理）
  - CI/CDパイプラインへの統合
  - エージェントモードでの自律的なタスク実行
  - VRループ（Verify-Repair Loop）の自動化

#### 3.1.3 MCPサーバー構成
1. **SSOTサーバー**: docs/内のドキュメント管理
   - 用語定義の検索と取得
   - ドキュメント間の関連性チェック
   - ハイパーリンクの検証

2. **外部情報サーバー**: 公式ドキュメントの取得
   - API仕様書の最新化
   - ベストプラクティスの検索
   - 外部ナレッジの統合

3. **品質チェックサーバー**: コード品質検証
   - 静的解析の自動実行
   - テストカバレッジの確認
   - リントルールの適用

4. **進捗管理サーバー**: VIBEKANBAN連携
   - タスク状態の追跡
   - WIP制限の監視
   - チームコラボレーション支援

5. **監査ログサーバー**: 全操作の記録
   - MCP操作の監査証跡
   - セキュメントアクセスログ
   - セキュリティイベントの記録

#### 3.1.4 RAGシステム
- **ベクトルDB**: Weaviateを採用
  - ハイブリッド検索（BM25 + セマンティック検索）
  - スケーラブルなクラスタリング
  - リアルタイムインデックス更新

- **埋め込みモデル**: OpenAI embeddings
  - 高精度なテキストベクトル化
  - 多言語対応
  - バッチ処理による効率化

- **検索最適化**:
  - alphaパラメータの動的調整（キーワードvsセマンティック）
  - 結果のランク付けアルゴリズムの選択
  - キャッシュ戦略による応答速度向上

### 3.1.5 セキュリティ対策
- **認証と認可**:
  - OAuth 2.0 / OpenID Connect 1.0 対応
  - APIキーのローテーション
  - ロールベースアクセス制御（RBAC）

- **データ保護**:
  - 通信のTLS 1.3暗号化
  - 機密データのマスキング
  - 監査ログの完全記録

- **入力検証**:
  - プロンプトインジェクション対策
  - SQLインジェクション対策
  - パス入力値の検証

### 3.1.6 パフォーマンス最適化
- **コスト管理**:
  - トークン消費量の監視
  - 軽量モデルの適切な使用
  - バッチ処理とキャッシュ戦略

- **応答速度**:
  - 非同期処理の活用
  - インデックスの最適化
  - CDNを活用した静的コンテンツ配信

- **スケーラビリティ**:
  - 水平スケーリングのためのロードバランシング
  - コンテナの自動再起動
  - ヘルスチェックと自動復旧
```

### Part04（作業管理）への追記提案

```markdown
### 4.1 MCP統合による作業効率化

#### 4.1.1 MCPを活用したTICKET管理
- **自動TICKET生成**:
  - JIRA/Linear連携MCPサーバーでIssueから自動生成
  - 仕様変更時の関連TICKET一括作成
  - 依存関係の自動解析

- **進捗自動更新**:
  - Gitコミットに連動したステータス更新
  - CI/CDパイプラインの実行結果反映
  - レビューリクエストの自動化

- **品質チェック自動化**:
  - コード提出時の自動レビュー
  - テストカバレッジの自動確認
  - ドキュメント規約への準拠性チェック

#### 4.1.2 AIとの協調作業
- **タスク割り当て**:
  - AIがスキルセットと経験から最適な担当者を推薦
  - ワークロードの平準化
  - 締切れタスクの検出

- **進捗監視**:
  - リアルタイムダッシュボードでの進捗可視化
  - リスクの早期検出とエスカレーション
  - チーム生産性の分析と改善提案

- **知識共有**:
  - 過去の成功事例からの学習
  - ベストプラクティスの自動適用
  - 新規メンバーへのオンボーディング支援
```

### Part10（Verify Gate）への追記提案

```markdown
### 10.1 MCPを活用した検証プロセス

#### 10.1.1 自動検証の拡充
- **MCPサーバーによる検証**:
  - 品質チェックサーバーでのコード分析
  - RAGサーバーによるドキュメント整合性チェック
  - 外部API連携テストの自動化

- **マルチエージェント検証**:
  - 複数AIによる同一タスクの並列検証
  - 異なる環境での再現性テスト
  - エッジケースの網羅的テスト

#### 10.1.2 検証結果の自動分析
- **失敗パターンの検出**:
  - よく発生する問題の自動分類
  - 根本原因の分析と改善提案
  - 再発防止策の自動実装

- **パフォーマンスメトリクス**:
  - 検証時間の追跡と分析
  - リソース使用量の監視
  - コスト効率の評価と最適化

#### 10.1.3 持続的改善
- **検証プロセスの進化**:
  - 新しい検証項目の自動追加
  - テストカバレッジの動的調整
  - ベストプラクティスの反映

- **フィードバックループ**:
  - 開発者からのフィードバック収集
  - 検証プロセスの改善
  - ツールチェーンの最適化
```

## 5. 導入リスクと回避策

### セキュリティティリスクと対策

#### 5.1 データ漏洩
- **リスク**:
  - 機密情報がAIに含まれる可能性
  - 外部MCPサーバーへの不用意なデータ送信
  - ログファイルからの情報漏洩

- **対策**:
  - データマスキングの徹底（PII検出と自動マスキング）
  - ロールベースアクセス制御の厳格な実装
  - 監査ログの定期的なレビューと削除ポリシーの適用
  - 機密データを扱うMCPサーバーの分離と特別扱い

#### 5.2 誤情報生成
- **リスク**:
  - AIによる事実と異なる情報の生成
  - 古い情報に基づいた回答
  - コンテキスト理解の不足

- **対策**:
  - RAGシステムによる事実に基づいた回答の強制
  - 情報源の明示と引用の徹底
  - 複数AIによるクロスチェック（ChatGPTとClaude Codeの相互検証）
  - ハルシネーション（Human-in-the-loop）の必須化

#### 5.3 権限昇格
- **リスク**:
  - AIが予期せぬ操作を実行
  - システム設定の不用意な変更
  - 外部サービスへの不正アクセス

- **対策**:
  - Permission Tierの厳格な適用（ReadOnly → PatchOnly → ExecLimited → HumanGate）
  - MCPサーバーの権限制限（読み取り専用、書き込み制限）
  - 危険な操作（`rm -rf`, `git push --force`等）の禁止
  - 全操作の監査ログ記録と定期的なレビュー

### パフォーマンスリスクと対策

#### 5.4 コスト超過
- **リスク**:
  - 高価なAIモデルの使いすぎ
  - 効率の悪いプロンプト設計
  - 不必要な再生成

- **対策**:
  - モデル選択の自動化（タスク複雑度に応じた最適化）
  - 軽量モデル（Z.ai GLM-4.5-AirX）の活用
  - キャッシュ戦略とバッチ処理の実装
  - トークン消費量の監視とアラート設定

#### 5.5 応答速度の低下
- **リスク**:
  - 複雑な処理による遅延
  - 外部APIのレイテンシ問題
  - リソース不足

- **対策**:
  - 非同期処理の活用による並列化
  - RAGシステムの最適化（インデックス設計、クエリ最適化）
  - CDNを活用した静的コンテンツ配信
  - 水平スケーリングとロードバランシング

#### 5.6 スケーラビリティの問題
- **リスク**:
  - 単一障害によるシステム停止
  - データ量増加によるパフォーマンス低下
  - 同時アクセスの急増

- **対策**:
  - コンテナオーケストレーション（Kubernetes, Docker Swarm）
  - オートスケーリングとヘルスチェックの自動化
  - 読み込み設計とフェイルオーバーの対策
  - 複数リージョンでの冗長化

### 運用性リスクと対策

#### 5.7 依存関係の複雑化
- **リスク**:
  - 複数のAIモデルやツールの連携
  - 外部APIのバージョン互換性
  - ベンダーロインの問題

- **対策**:
  - MCPのような標準プロトコルの活用
  - 抽象化レイヤの導入（アダプター、ブリッジパターン）
  - コンテナ化による依存関係の管理
  - ベンダーロインを避けたオープンソースの優先採用

#### 5.8 学習コスト
- **リスク**:
  - 新しいツールやフレームワークの習得
  - ベストプラクティスの確立
  - チーム全体のスキルアップ

- **対策**:
  - 段階的な導入（小規模から始めて拡大）
  - ドキュメント化されたガイドラインとトレーニング
  - メンターシッププログラムの実施
  - 成功事例の共有と知識ベースの構築

#### 5.9 変更管理
- **リスク**:
  - 仕様変更の影響範囲の特定困難
  - 複数の変更が同時に発生
  - 以前のバージョンとの互換性喪失

- **対策**:
  - ADR（Architecture Decision Record）プロセスの厳格な適用
  - 変更のインパクト分析の自動化
  - バージョン管理とタグ付けの徹底
  - ロールバック計画の事前準備

### モニタリングと監視

#### 5.10 品質保証
- **監視項目**:
  - AI生成コードの品質メトリクス
  - レスポンスタイムと正確性
  - セキュリティインシデントの発生数

- **監視方法**:
  - 自動テストスイートの実行
  - コードレビューAIの活用
  - セキュリティスキャンの定期的な実施

#### 5.11 パフォーマンス監視
- **監視項目**:
  - 平均応答時間
  - トークン消費量
  - システムリソース使用率

- **監視方法**:
  - APM（Application Performance Monitoring）ツールの活用
  - OpenTelemetryによるメトリクス収集
  - ダッシュボードによる可視化

#### 5.12 コスト管理
- **監視項目**:
  - 月次AI利用コスト
  - 1リクエストあたりのコスト
  - ROI（投資収益率）

- **監視方法**:
  - コスト配分最適化の自動化
  - 予算対実績の追跡
  - コスト削減機会の特定と実施

この深掘り版アーキテクチャにより、2026年時点での最新技術を活用しつつ、精度・コスパ・事故防止・スピードを最大化したツール統合が実現可能です。各コンポーネントを適切に連携させ、継続的な改善を行うことで、AI活用の効果を最大化できます。